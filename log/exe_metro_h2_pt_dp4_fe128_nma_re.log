validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/data/research_data/driver_activity/data/train, modalities:['inside', 'outside']
embed_dir_base: /data/research_data/driver_activity/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.4.0
GPU Availability: cuda:1, no_gpus: 1
total_activities: 5train person_ids: [1 2 4 5 6]

	Start execution training validation it 1 

train_dataloader len: 421
valid_dataloader len: 444
test_dataloader len: 113
train performers ids: [4, 5, 6]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 842, train dataloader len: 421
valid dataset len: 888, valid dataloader len: 444
valid dataset len: 226, test dataloader len: 444
====> Epoch: 1 Train Avg loss: 0.67607, Acc: 0.57720, F1: 0.57720#####> Valid Avg loss: 0.67997, Acc:0.47185, F1: 0.47185
===> Epoch: 1: Training loss decreased (inf --> 0.67607), Acc: (0.00000 --> 0.57720), F1: (0.00000 --> 0.57720).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.67997), Acc: (0.00000 --> 0.47185), F1: (0.00000 --> 0.47185).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.67997), Acc: (0.00000 --> 0.47185), F1: (0.00000 --> 0.47185).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 2 Train Avg loss: 0.62183, Acc: 0.57007, F1: 0.57007#####> Valid Avg loss: 0.86672, Acc:0.47185, F1: 0.47185
===> Epoch: 2: Training loss decreased (0.67607 --> 0.62183), Acc: (0.57720 --> 0.57007), F1: (0.57720 --> 0.57007).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 3 Train Avg loss: 0.62228, Acc: 0.58432, F1: 0.58432#####> Valid Avg loss: 0.73117, Acc:0.47185, F1: 0.47185
====> Epoch: 4 Train Avg loss: 0.60348, Acc: 0.58195, F1: 0.58195#####> Valid Avg loss: 0.66696, Acc:0.47185, F1: 0.47185
===> Epoch: 4: Training loss decreased (0.62183 --> 0.60348), Acc: (0.57007 --> 0.58195), F1: (0.57007 --> 0.58195).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1

####> Epoch: 4: validation loss decreased (0.67997 --> 0.66696), Acc: (0.47185 --> 0.47185), F1: (0.47185 --> 0.47185).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 5 Train Avg loss: 0.59426, Acc: 0.57838, F1: 0.57838#####> Valid Avg loss: 0.69295, Acc:0.47185, F1: 0.47185
===> Epoch: 5: Training loss decreased (0.60348 --> 0.59426), Acc: (0.58195 --> 0.57838), F1: (0.58195 --> 0.57838).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 6 Train Avg loss: 0.58607, Acc: 0.58314, F1: 0.58314#####> Valid Avg loss: 0.71605, Acc:0.47185, F1: 0.47185
===> Epoch: 6: Training loss decreased (0.59426 --> 0.58607), Acc: (0.57838 --> 0.58314), F1: (0.57838 --> 0.58314).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 7 Train Avg loss: 0.58381, Acc: 0.58314, F1: 0.58314#####> Valid Avg loss: 0.70908, Acc:0.47185, F1: 0.47185
===> Epoch: 7: Training loss decreased (0.58607 --> 0.58381), Acc: (0.58314 --> 0.58314), F1: (0.58314 --> 0.58314).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 8 Train Avg loss: 0.57386, Acc: 0.60214, F1: 0.60214#####> Valid Avg loss: 0.65940, Acc:0.47410, F1: 0.47410
===> Epoch: 8: Training loss decreased (0.58381 --> 0.57386), Acc: (0.58314 --> 0.60214), F1: (0.58314 --> 0.60214).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1

####> Epoch: 8: validation loss decreased (0.66696 --> 0.65940), Acc: (0.47185 --> 0.47410), F1: (0.47185 --> 0.47410).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1

####> Epoch: 8: validation acc increase (0.67997 --> 0.65940), Acc: (0.47185 --> 0.47410), F1: (0.47185 --> 0.47410).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 9 Train Avg loss: 0.56787, Acc: 0.59976, F1: 0.59976#####> Valid Avg loss: 0.73183, Acc:0.46847, F1: 0.46847
===> Epoch: 9: Training loss decreased (0.57386 --> 0.56787), Acc: (0.60214 --> 0.59976), F1: (0.60214 --> 0.59976).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 10 Train Avg loss: 0.55899, Acc: 0.60451, F1: 0.60451#####> Valid Avg loss: 0.67223, Acc:0.47297, F1: 0.47297
===> Epoch: 10: Training loss decreased (0.56787 --> 0.55899), Acc: (0.59976 --> 0.60451), F1: (0.59976 --> 0.60451).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 11 Train Avg loss: 0.55297, Acc: 0.60926, F1: 0.60926#####> Valid Avg loss: 0.72871, Acc:0.47072, F1: 0.47072
===> Epoch: 11: Training loss decreased (0.55899 --> 0.55297), Acc: (0.60451 --> 0.60926), F1: (0.60451 --> 0.60926).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 12 Train Avg loss: 0.53435, Acc: 0.61758, F1: 0.61758#####> Valid Avg loss: 0.68742, Acc:0.43694, F1: 0.43694
===> Epoch: 12: Training loss decreased (0.55297 --> 0.53435), Acc: (0.60926 --> 0.61758), F1: (0.60926 --> 0.61758).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 13 Train Avg loss: 0.52693, Acc: 0.61520, F1: 0.61520#####> Valid Avg loss: 0.71724, Acc:0.46847, F1: 0.46847
===> Epoch: 13: Training loss decreased (0.53435 --> 0.52693), Acc: (0.61758 --> 0.61520), F1: (0.61758 --> 0.61520).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 14 Train Avg loss: 0.51832, Acc: 0.62114, F1: 0.62114#####> Valid Avg loss: 0.72218, Acc:0.45045, F1: 0.45045
===> Epoch: 14: Training loss decreased (0.52693 --> 0.51832), Acc: (0.61520 --> 0.62114), F1: (0.61520 --> 0.62114).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 15 Train Avg loss: 0.52196, Acc: 0.62233, F1: 0.62233#####> Valid Avg loss: 0.76825, Acc:0.41216, F1: 0.41216
====> Epoch: 16 Train Avg loss: 0.52065, Acc: 0.62945, F1: 0.62945#####> Valid Avg loss: 0.84326, Acc:0.42230, F1: 0.42230
====> Epoch: 17 Train Avg loss: 0.52102, Acc: 0.62470, F1: 0.62470#####> Valid Avg loss: 0.79427, Acc:0.44144, F1: 0.44144
====> Epoch: 18 Train Avg loss: 0.51736, Acc: 0.61876, F1: 0.61876#####> Valid Avg loss: 0.79845, Acc:0.36036, F1: 0.36036
===> Epoch: 18: Training loss decreased (0.51832 --> 0.51736), Acc: (0.62114 --> 0.61876), F1: (0.62114 --> 0.61876).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 19 Train Avg loss: 0.48912, Acc: 0.63420, F1: 0.63420#####> Valid Avg loss: 0.83394, Acc:0.44820, F1: 0.44820
===> Epoch: 19: Training loss decreased (0.51736 --> 0.48912), Acc: (0.61876 --> 0.63420), F1: (0.61876 --> 0.63420).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 20 Train Avg loss: 0.48064, Acc: 0.64371, F1: 0.64371#####> Valid Avg loss: 0.77527, Acc:0.42680, F1: 0.42680
===> Epoch: 20: Training loss decreased (0.48912 --> 0.48064), Acc: (0.63420 --> 0.64371), F1: (0.63420 --> 0.64371).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 21 Train Avg loss: 0.46929, Acc: 0.66271, F1: 0.66271#####> Valid Avg loss: 0.94162, Acc:0.46509, F1: 0.46509
===> Epoch: 21: Training loss decreased (0.48064 --> 0.46929), Acc: (0.64371 --> 0.66271), F1: (0.64371 --> 0.66271).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 22 Train Avg loss: 0.46313, Acc: 0.63777, F1: 0.63777#####> Valid Avg loss: 0.78077, Acc:0.42342, F1: 0.42342
===> Epoch: 22: Training loss decreased (0.46929 --> 0.46313), Acc: (0.66271 --> 0.63777), F1: (0.66271 --> 0.63777).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 23 Train Avg loss: 0.45103, Acc: 0.66865, F1: 0.66865#####> Valid Avg loss: 0.75216, Acc:0.42905, F1: 0.42905
===> Epoch: 23: Training loss decreased (0.46313 --> 0.45103), Acc: (0.63777 --> 0.66865), F1: (0.63777 --> 0.66865).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 24 Train Avg loss: 0.44123, Acc: 0.67102, F1: 0.67102#####> Valid Avg loss: 0.76682, Acc:0.45383, F1: 0.45383
===> Epoch: 24: Training loss decreased (0.45103 --> 0.44123), Acc: (0.66865 --> 0.67102), F1: (0.66865 --> 0.67102).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 25 Train Avg loss: 0.43069, Acc: 0.66627, F1: 0.66627#####> Valid Avg loss: 0.79802, Acc:0.39189, F1: 0.39189
===> Epoch: 25: Training loss decreased (0.44123 --> 0.43069), Acc: (0.67102 --> 0.66627), F1: (0.67102 --> 0.66627).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 26 Train Avg loss: 0.43002, Acc: 0.69359, F1: 0.69359#####> Valid Avg loss: 0.75741, Acc:0.40991, F1: 0.40991
===> Epoch: 26: Training loss decreased (0.43069 --> 0.43002), Acc: (0.66627 --> 0.69359), F1: (0.66627 --> 0.69359).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 27 Train Avg loss: 0.40959, Acc: 0.67933, F1: 0.67933#####> Valid Avg loss: 0.80147, Acc:0.28716, F1: 0.28716
===> Epoch: 27: Training loss decreased (0.43002 --> 0.40959), Acc: (0.69359 --> 0.67933), F1: (0.69359 --> 0.67933).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 28 Train Avg loss: 0.39732, Acc: 0.69240, F1: 0.69240#####> Valid Avg loss: 1.00135, Acc:0.27703, F1: 0.27703
===> Epoch: 28: Training loss decreased (0.40959 --> 0.39732), Acc: (0.67933 --> 0.69240), F1: (0.67933 --> 0.69240).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 29 Train Avg loss: 0.38469, Acc: 0.70071, F1: 0.70071#####> Valid Avg loss: 0.86085, Acc:0.42117, F1: 0.42117
===> Epoch: 29: Training loss decreased (0.39732 --> 0.38469), Acc: (0.69240 --> 0.70071), F1: (0.69240 --> 0.70071).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 30 Train Avg loss: 0.36769, Acc: 0.72209, F1: 0.72209#####> Valid Avg loss: 0.81556, Acc:0.39865, F1: 0.39865
===> Epoch: 30: Training loss decreased (0.38469 --> 0.36769), Acc: (0.70071 --> 0.72209), F1: (0.70071 --> 0.72209).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 31 Train Avg loss: 0.36799, Acc: 0.71734, F1: 0.71734#####> Valid Avg loss: 0.78915, Acc:0.44820, F1: 0.44820
====> Epoch: 32 Train Avg loss: 0.36413, Acc: 0.72565, F1: 0.72565#####> Valid Avg loss: 0.84015, Acc:0.37950, F1: 0.37950
===> Epoch: 32: Training loss decreased (0.36769 --> 0.36413), Acc: (0.72209 --> 0.72565), F1: (0.72209 --> 0.72565).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 33 Train Avg loss: 0.35891, Acc: 0.71615, F1: 0.71615#####> Valid Avg loss: 0.93392, Acc:0.35135, F1: 0.35135
===> Epoch: 33: Training loss decreased (0.36413 --> 0.35891), Acc: (0.72565 --> 0.71615), F1: (0.72565 --> 0.71615).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 34 Train Avg loss: 0.32925, Acc: 0.74584, F1: 0.74584#####> Valid Avg loss: 0.90625, Acc:0.36712, F1: 0.36712
===> Epoch: 34: Training loss decreased (0.35891 --> 0.32925), Acc: (0.71615 --> 0.74584), F1: (0.71615 --> 0.74584).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 35 Train Avg loss: 0.31288, Acc: 0.74703, F1: 0.74703#####> Valid Avg loss: 1.03996, Acc:0.26577, F1: 0.26577
===> Epoch: 35: Training loss decreased (0.32925 --> 0.31288), Acc: (0.74584 --> 0.74703), F1: (0.74584 --> 0.74703).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 36 Train Avg loss: 0.30982, Acc: 0.76366, F1: 0.76366#####> Valid Avg loss: 0.98836, Acc:0.35923, F1: 0.35923
===> Epoch: 36: Training loss decreased (0.31288 --> 0.30982), Acc: (0.74703 --> 0.76366), F1: (0.74703 --> 0.76366).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 37 Train Avg loss: 0.30902, Acc: 0.74941, F1: 0.74941#####> Valid Avg loss: 0.96928, Acc:0.29617, F1: 0.29617
===> Epoch: 37: Training loss decreased (0.30982 --> 0.30902), Acc: (0.76366 --> 0.74941), F1: (0.76366 --> 0.74941).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 38 Train Avg loss: 0.28345, Acc: 0.77078, F1: 0.77078#####> Valid Avg loss: 1.04343, Acc:0.31532, F1: 0.31532
===> Epoch: 38: Training loss decreased (0.30902 --> 0.28345), Acc: (0.74941 --> 0.77078), F1: (0.74941 --> 0.77078).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 39 Train Avg loss: 0.26397, Acc: 0.79929, F1: 0.79929#####> Valid Avg loss: 0.93830, Acc:0.41104, F1: 0.41104
===> Epoch: 39: Training loss decreased (0.28345 --> 0.26397), Acc: (0.77078 --> 0.79929), F1: (0.77078 --> 0.79929).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 40 Train Avg loss: 0.25392, Acc: 0.80166, F1: 0.80166#####> Valid Avg loss: 1.02426, Acc:0.41779, F1: 0.41779
===> Epoch: 40: Training loss decreased (0.26397 --> 0.25392), Acc: (0.79929 --> 0.80166), F1: (0.79929 --> 0.80166).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 41 Train Avg loss: 0.23829, Acc: 0.81710, F1: 0.81710#####> Valid Avg loss: 1.07623, Acc:0.36486, F1: 0.36486
===> Epoch: 41: Training loss decreased (0.25392 --> 0.23829), Acc: (0.80166 --> 0.81710), F1: (0.80166 --> 0.81710).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 42 Train Avg loss: 0.23224, Acc: 0.81591, F1: 0.81591#####> Valid Avg loss: 1.06076, Acc:0.39865, F1: 0.39865
===> Epoch: 42: Training loss decreased (0.23829 --> 0.23224), Acc: (0.81710 --> 0.81591), F1: (0.81710 --> 0.81591).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 43 Train Avg loss: 0.20058, Acc: 0.83492, F1: 0.83492#####> Valid Avg loss: 1.12250, Acc:0.37500, F1: 0.37500
===> Epoch: 43: Training loss decreased (0.23224 --> 0.20058), Acc: (0.81591 --> 0.83492), F1: (0.81591 --> 0.83492).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 44 Train Avg loss: 0.19177, Acc: 0.84323, F1: 0.84323#####> Valid Avg loss: 1.24550, Acc:0.34347, F1: 0.34347
===> Epoch: 44: Training loss decreased (0.20058 --> 0.19177), Acc: (0.83492 --> 0.84323), F1: (0.83492 --> 0.84323).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 45 Train Avg loss: 0.17795, Acc: 0.86342, F1: 0.86342#####> Valid Avg loss: 1.43325, Acc:0.28266, F1: 0.28266
===> Epoch: 45: Training loss decreased (0.19177 --> 0.17795), Acc: (0.84323 --> 0.86342), F1: (0.84323 --> 0.86342).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 46 Train Avg loss: 0.16205, Acc: 0.87292, F1: 0.87292#####> Valid Avg loss: 1.23316, Acc:0.34685, F1: 0.34685
===> Epoch: 46: Training loss decreased (0.17795 --> 0.16205), Acc: (0.86342 --> 0.87292), F1: (0.86342 --> 0.87292).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 47 Train Avg loss: 0.16376, Acc: 0.86342, F1: 0.86342#####> Valid Avg loss: 1.24652, Acc:0.37050, F1: 0.37050
====> Epoch: 48 Train Avg loss: 0.16781, Acc: 0.85986, F1: 0.85986#####> Valid Avg loss: 1.32117, Acc:0.34009, F1: 0.34009
====> Epoch: 49 Train Avg loss: 0.12475, Acc: 0.90143, F1: 0.90143#####> Valid Avg loss: 1.42688, Acc:0.38964, F1: 0.38964
===> Epoch: 49: Training loss decreased (0.16205 --> 0.12475), Acc: (0.87292 --> 0.90143), F1: (0.87292 --> 0.90143).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 50 Train Avg loss: 0.12610, Acc: 0.90499, F1: 0.90499#####> Valid Avg loss: 1.46441, Acc:0.33446, F1: 0.33446
====> Epoch: 51 Train Avg loss: 0.10280, Acc: 0.92162, F1: 0.92162#####> Valid Avg loss: 1.51992, Acc:0.31419, F1: 0.31419
===> Epoch: 51: Training loss decreased (0.12475 --> 0.10280), Acc: (0.90143 --> 0.92162), F1: (0.90143 --> 0.92162).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 52 Train Avg loss: 0.12384, Acc: 0.89786, F1: 0.89786#####> Valid Avg loss: 1.64213, Acc:0.32658, F1: 0.32658
====> Epoch: 53 Train Avg loss: 0.11496, Acc: 0.90499, F1: 0.90499#####> Valid Avg loss: 1.57382, Acc:0.34009, F1: 0.34009
====> Epoch: 54 Train Avg loss: 0.07797, Acc: 0.93943, F1: 0.93943#####> Valid Avg loss: 1.67903, Acc:0.36261, F1: 0.36261
===> Epoch: 54: Training loss decreased (0.10280 --> 0.07797), Acc: (0.92162 --> 0.93943), F1: (0.92162 --> 0.93943).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 55 Train Avg loss: 0.06281, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 1.78502, Acc:0.37162, F1: 0.37162
===> Epoch: 55: Training loss decreased (0.07797 --> 0.06281), Acc: (0.93943 --> 0.95487), F1: (0.93943 --> 0.95487).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 56 Train Avg loss: 0.07393, Acc: 0.94893, F1: 0.94893#####> Valid Avg loss: 1.95247, Acc:0.31644, F1: 0.31644
====> Epoch: 57 Train Avg loss: 0.05772, Acc: 0.95962, F1: 0.95962#####> Valid Avg loss: 2.39109, Acc:0.34910, F1: 0.34910
===> Epoch: 57: Training loss decreased (0.06281 --> 0.05772), Acc: (0.95487 --> 0.95962), F1: (0.95487 --> 0.95962).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 58 Train Avg loss: 0.06218, Acc: 0.95131, F1: 0.95131#####> Valid Avg loss: 1.87399, Acc:0.36712, F1: 0.36712
====> Epoch: 59 Train Avg loss: 0.04882, Acc: 0.95606, F1: 0.95606#####> Valid Avg loss: 1.88892, Acc:0.31419, F1: 0.31419
===> Epoch: 59: Training loss decreased (0.05772 --> 0.04882), Acc: (0.95962 --> 0.95606), F1: (0.95962 --> 0.95606).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 60 Train Avg loss: 0.04769, Acc: 0.96556, F1: 0.96556#####> Valid Avg loss: 2.10714, Acc:0.35473, F1: 0.35473
===> Epoch: 60: Training loss decreased (0.04882 --> 0.04769), Acc: (0.95606 --> 0.96556), F1: (0.95606 --> 0.96556).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 61 Train Avg loss: 0.06750, Acc: 0.95249, F1: 0.95249#####> Valid Avg loss: 1.95081, Acc:0.33784, F1: 0.33784
====> Epoch: 62 Train Avg loss: 0.05355, Acc: 0.96556, F1: 0.96556#####> Valid Avg loss: 1.97498, Acc:0.34347, F1: 0.34347
====> Epoch: 63 Train Avg loss: 0.03721, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 2.02372, Acc:0.34910, F1: 0.34910
===> Epoch: 63: Training loss decreased (0.04769 --> 0.03721), Acc: (0.96556 --> 0.96793), F1: (0.96556 --> 0.96793).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 64 Train Avg loss: 0.02875, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.11064, Acc:0.33221, F1: 0.33221
===> Epoch: 64: Training loss decreased (0.03721 --> 0.02875), Acc: (0.96793 --> 0.97743), F1: (0.96793 --> 0.97743).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 65 Train Avg loss: 0.03383, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.14114, Acc:0.35248, F1: 0.35248
====> Epoch: 66 Train Avg loss: 0.04162, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 2.25497, Acc:0.31757, F1: 0.31757
====> Epoch: 67 Train Avg loss: 0.03060, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 2.13813, Acc:0.32320, F1: 0.32320
====> Epoch: 68 Train Avg loss: 0.02263, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.25765, Acc:0.34797, F1: 0.34797
===> Epoch: 68: Training loss decreased (0.02875 --> 0.02263), Acc: (0.97743 --> 0.97862), F1: (0.97743 --> 0.97862).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 69 Train Avg loss: 0.03724, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 2.10999, Acc:0.31532, F1: 0.31532
====> Epoch: 70 Train Avg loss: 0.02138, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.18132, Acc:0.35248, F1: 0.35248
===> Epoch: 70: Training loss decreased (0.02263 --> 0.02138), Acc: (0.97862 --> 0.98219), F1: (0.97862 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 71 Train Avg loss: 0.01900, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.18135, Acc:0.34009, F1: 0.34009
===> Epoch: 71: Training loss decreased (0.02138 --> 0.01900), Acc: (0.98219 --> 0.98337), F1: (0.98219 --> 0.98337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 72 Train Avg loss: 0.02070, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.17745, Acc:0.38964, F1: 0.38964
====> Epoch: 73 Train Avg loss: 0.01740, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.27401, Acc:0.35473, F1: 0.35473
===> Epoch: 73: Training loss decreased (0.01900 --> 0.01740), Acc: (0.98337 --> 0.98219), F1: (0.98337 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 74 Train Avg loss: 0.01667, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.20124, Acc:0.34797, F1: 0.34797
===> Epoch: 74: Training loss decreased (0.01740 --> 0.01667), Acc: (0.98219 --> 0.97981), F1: (0.98219 --> 0.97981).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 75 Train Avg loss: 0.01600, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.38841, Acc:0.34572, F1: 0.34572
===> Epoch: 75: Training loss decreased (0.01667 --> 0.01600), Acc: (0.97981 --> 0.98337), F1: (0.97981 --> 0.98337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 76 Train Avg loss: 0.02213, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.44483, Acc:0.35023, F1: 0.35023
====> Epoch: 77 Train Avg loss: 0.01750, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.38331, Acc:0.34009, F1: 0.34009
====> Epoch: 78 Train Avg loss: 0.01529, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.33030, Acc:0.35811, F1: 0.35811
===> Epoch: 78: Training loss decreased (0.01600 --> 0.01529), Acc: (0.98337 --> 0.98337), F1: (0.98337 --> 0.98337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 79 Train Avg loss: 0.01386, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.40830, Acc:0.33333, F1: 0.33333
===> Epoch: 79: Training loss decreased (0.01529 --> 0.01386), Acc: (0.98337 --> 0.98456), F1: (0.98337 --> 0.98456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 80 Train Avg loss: 0.01616, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.51199, Acc:0.31194, F1: 0.31194
====> Epoch: 81 Train Avg loss: 0.01377, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.36835, Acc:0.34347, F1: 0.34347
===> Epoch: 81: Training loss decreased (0.01386 --> 0.01377), Acc: (0.98456 --> 0.98100), F1: (0.98456 --> 0.98100).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 82 Train Avg loss: 0.01195, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.41509, Acc:0.33559, F1: 0.33559
===> Epoch: 82: Training loss decreased (0.01377 --> 0.01195), Acc: (0.98100 --> 0.98219), F1: (0.98100 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 83 Train Avg loss: 0.01373, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.30741, Acc:0.34234, F1: 0.34234
====> Epoch: 84 Train Avg loss: 0.01229, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.43553, Acc:0.34122, F1: 0.34122
====> Epoch: 85 Train Avg loss: 0.01303, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.35737, Acc:0.34797, F1: 0.34797
====> Epoch: 86 Train Avg loss: 0.01218, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.35148, Acc:0.36712, F1: 0.36712
====> Epoch: 87 Train Avg loss: 0.01371, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.44675, Acc:0.34797, F1: 0.34797
====> Epoch: 88 Train Avg loss: 0.01220, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.39508, Acc:0.35248, F1: 0.35248
====> Epoch: 89 Train Avg loss: 0.01149, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.34925, Acc:0.35135, F1: 0.35135
===> Epoch: 89: Training loss decreased (0.01195 --> 0.01149), Acc: (0.98219 --> 0.98456), F1: (0.98219 --> 0.98456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 90 Train Avg loss: 0.01065, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.35443, Acc:0.35360, F1: 0.35360
===> Epoch: 90: Training loss decreased (0.01149 --> 0.01065), Acc: (0.98456 --> 0.98456), F1: (0.98456 --> 0.98456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 91 Train Avg loss: 0.01025, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.34791, Acc:0.35923, F1: 0.35923
===> Epoch: 91: Training loss decreased (0.01065 --> 0.01025), Acc: (0.98456 --> 0.98219), F1: (0.98456 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 92 Train Avg loss: 0.01084, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.43414, Acc:0.35248, F1: 0.35248
====> Epoch: 93 Train Avg loss: 0.01353, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.34475, Acc:0.35023, F1: 0.35023
====> Epoch: 94 Train Avg loss: 0.01052, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.35752, Acc:0.34459, F1: 0.34459
====> Epoch: 95 Train Avg loss: 0.01120, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.31448, Acc:0.34910, F1: 0.34910
====> Epoch: 96 Train Avg loss: 0.00989, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.39349, Acc:0.34685, F1: 0.34685
===> Epoch: 96: Training loss decreased (0.01025 --> 0.00989), Acc: (0.98219 --> 0.98694), F1: (0.98219 --> 0.98694).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 97 Train Avg loss: 0.01023, Acc: 0.99050, F1: 0.99050#####> Valid Avg loss: 2.38611, Acc:0.35135, F1: 0.35135
====> Epoch: 98 Train Avg loss: 0.01009, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.44798, Acc:0.34685, F1: 0.34685
====> Epoch: 99 Train Avg loss: 0.01062, Acc: 0.98812, F1: 0.98812#####> Valid Avg loss: 2.40800, Acc:0.35135, F1: 0.35135
====> Epoch: 100 Train Avg loss: 0.61179, Acc: 0.60333, F1: 0.60333#####> Valid Avg loss: 0.70579, Acc:0.45495, F1: 0.45495
====> Epoch: 101 Train Avg loss: 0.46157, Acc: 0.64371, F1: 0.64371#####> Valid Avg loss: 0.79796, Acc:0.39640, F1: 0.39640
====> Epoch: 102 Train Avg loss: 0.41156, Acc: 0.68884, F1: 0.68884#####> Valid Avg loss: 0.80539, Acc:0.36712, F1: 0.36712
====> Epoch: 103 Train Avg loss: 0.39593, Acc: 0.70665, F1: 0.70665#####> Valid Avg loss: 1.21528, Acc:0.22973, F1: 0.22973
====> Epoch: 104 Train Avg loss: 0.38190, Acc: 0.70546, F1: 0.70546#####> Valid Avg loss: 0.81318, Acc:0.45270, F1: 0.45270
====> Epoch: 105 Train Avg loss: 0.36434, Acc: 0.70546, F1: 0.70546#####> Valid Avg loss: 0.88432, Acc:0.37275, F1: 0.37275
====> Epoch: 106 Train Avg loss: 0.29895, Acc: 0.77078, F1: 0.77078#####> Valid Avg loss: 0.87577, Acc:0.31419, F1: 0.31419
====> Epoch: 107 Train Avg loss: 0.30393, Acc: 0.75891, F1: 0.75891#####> Valid Avg loss: 1.18033, Acc:0.34459, F1: 0.34459
====> Epoch: 108 Train Avg loss: 0.27421, Acc: 0.79454, F1: 0.79454#####> Valid Avg loss: 1.04992, Acc:0.35023, F1: 0.35023
====> Epoch: 109 Train Avg loss: 0.28027, Acc: 0.78504, F1: 0.78504#####> Valid Avg loss: 0.96445, Acc:0.37838, F1: 0.37838
====> Epoch: 110 Train Avg loss: 0.25110, Acc: 0.80998, F1: 0.80998#####> Valid Avg loss: 0.93892, Acc:0.34910, F1: 0.34910
====> Epoch: 111 Train Avg loss: 0.20647, Acc: 0.83610, F1: 0.83610#####> Valid Avg loss: 1.22327, Acc:0.40766, F1: 0.40766
====> Epoch: 112 Train Avg loss: 0.19246, Acc: 0.85629, F1: 0.85629#####> Valid Avg loss: 1.42820, Acc:0.29842, F1: 0.29842
====> Epoch: 113 Train Avg loss: 0.21496, Acc: 0.83610, F1: 0.83610#####> Valid Avg loss: 1.40732, Acc:0.35248, F1: 0.35248
====> Epoch: 114 Train Avg loss: 0.20118, Acc: 0.84323, F1: 0.84323#####> Valid Avg loss: 1.23570, Acc:0.30180, F1: 0.30180
====> Epoch: 115 Train Avg loss: 0.15350, Acc: 0.88124, F1: 0.88124#####> Valid Avg loss: 1.49379, Acc:0.31194, F1: 0.31194
====> Epoch: 116 Train Avg loss: 0.18030, Acc: 0.86580, F1: 0.86580#####> Valid Avg loss: 1.42925, Acc:0.30631, F1: 0.30631
====> Epoch: 117 Train Avg loss: 0.15238, Acc: 0.87648, F1: 0.87648#####> Valid Avg loss: 1.53114, Acc:0.34347, F1: 0.34347
====> Epoch: 118 Train Avg loss: 0.17499, Acc: 0.85154, F1: 0.85154#####> Valid Avg loss: 1.26801, Acc:0.35360, F1: 0.35360
====> Epoch: 119 Train Avg loss: 0.13970, Acc: 0.89074, F1: 0.89074#####> Valid Avg loss: 1.44153, Acc:0.35473, F1: 0.35473
====> Epoch: 120 Train Avg loss: 0.12894, Acc: 0.90024, F1: 0.90024#####> Valid Avg loss: 1.67225, Acc:0.36712, F1: 0.36712
====> Epoch: 121 Train Avg loss: 0.16250, Acc: 0.87411, F1: 0.87411#####> Valid Avg loss: 1.39456, Acc:0.34685, F1: 0.34685
====> Epoch: 122 Train Avg loss: 0.14557, Acc: 0.88242, F1: 0.88242#####> Valid Avg loss: 1.64834, Acc:0.30405, F1: 0.30405
====> Epoch: 123 Train Avg loss: 0.12650, Acc: 0.90855, F1: 0.90855#####> Valid Avg loss: 1.47934, Acc:0.35135, F1: 0.35135
====> Epoch: 124 Train Avg loss: 0.11578, Acc: 0.90380, F1: 0.90380#####> Valid Avg loss: 1.63833, Acc:0.31306, F1: 0.31306
====> Epoch: 125 Train Avg loss: 0.14781, Acc: 0.89667, F1: 0.89667#####> Valid Avg loss: 1.48679, Acc:0.35473, F1: 0.35473
====> Epoch: 126 Train Avg loss: 0.13574, Acc: 0.90143, F1: 0.90143#####> Valid Avg loss: 1.46631, Acc:0.35360, F1: 0.35360
====> Epoch: 127 Train Avg loss: 0.06185, Acc: 0.95606, F1: 0.95606#####> Valid Avg loss: 1.75246, Acc:0.35811, F1: 0.35811
====> Epoch: 128 Train Avg loss: 0.12620, Acc: 0.91211, F1: 0.91211#####> Valid Avg loss: 1.57179, Acc:0.29167, F1: 0.29167
====> Epoch: 129 Train Avg loss: 0.08086, Acc: 0.94774, F1: 0.94774#####> Valid Avg loss: 1.92682, Acc:0.28266, F1: 0.28266
====> Epoch: 130 Train Avg loss: 0.12928, Acc: 0.90024, F1: 0.90024#####> Valid Avg loss: 1.49544, Acc:0.29955, F1: 0.29955
====> Epoch: 131 Train Avg loss: 0.15320, Acc: 0.89905, F1: 0.89905#####> Valid Avg loss: 1.60384, Acc:0.36149, F1: 0.36149
====> Epoch: 132 Train Avg loss: 0.13062, Acc: 0.90380, F1: 0.90380#####> Valid Avg loss: 1.56201, Acc:0.33108, F1: 0.33108
====> Epoch: 133 Train Avg loss: 0.06794, Acc: 0.94774, F1: 0.94774#####> Valid Avg loss: 1.67593, Acc:0.33559, F1: 0.33559
====> Epoch: 134 Train Avg loss: 0.10347, Acc: 0.92637, F1: 0.92637#####> Valid Avg loss: 1.67721, Acc:0.37950, F1: 0.37950
====> Epoch: 135 Train Avg loss: 0.08971, Acc: 0.92518, F1: 0.92518#####> Valid Avg loss: 1.70425, Acc:0.35586, F1: 0.35586
====> Epoch: 136 Train Avg loss: 0.08555, Acc: 0.95249, F1: 0.95249#####> Valid Avg loss: 1.52935, Acc:0.39414, F1: 0.39414
====> Epoch: 137 Train Avg loss: 0.10011, Acc: 0.92518, F1: 0.92518#####> Valid Avg loss: 1.68415, Acc:0.35923, F1: 0.35923
====> Epoch: 138 Train Avg loss: 0.08770, Acc: 0.94418, F1: 0.94418#####> Valid Avg loss: 1.55761, Acc:0.37613, F1: 0.37613
====> Epoch: 139 Train Avg loss: 0.09747, Acc: 0.92993, F1: 0.92993#####> Valid Avg loss: 1.61662, Acc:0.37613, F1: 0.37613
====> Epoch: 140 Train Avg loss: 0.08305, Acc: 0.94062, F1: 0.94062#####> Valid Avg loss: 1.61039, Acc:0.39189, F1: 0.39189
====> Epoch: 141 Train Avg loss: 0.03823, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 1.75732, Acc:0.35811, F1: 0.35811
====> Epoch: 142 Train Avg loss: 0.17418, Acc: 0.88836, F1: 0.88836#####> Valid Avg loss: 1.47255, Acc:0.31757, F1: 0.31757
====> Epoch: 143 Train Avg loss: 0.11876, Acc: 0.91805, F1: 0.91805#####> Valid Avg loss: 1.32194, Acc:0.36486, F1: 0.36486
====> Epoch: 144 Train Avg loss: 0.09320, Acc: 0.93705, F1: 0.93705#####> Valid Avg loss: 1.54065, Acc:0.39865, F1: 0.39865
====> Epoch: 145 Train Avg loss: 0.05732, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 1.83069, Acc:0.28941, F1: 0.28941
====> Epoch: 146 Train Avg loss: 0.07391, Acc: 0.95131, F1: 0.95131#####> Valid Avg loss: 1.97972, Acc:0.33333, F1: 0.33333
====> Epoch: 147 Train Avg loss: 0.06071, Acc: 0.95606, F1: 0.95606#####> Valid Avg loss: 1.73150, Acc:0.32432, F1: 0.32432
====> Epoch: 148 Train Avg loss: 0.03322, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.79023, Acc:0.32995, F1: 0.32995
====> Epoch: 149 Train Avg loss: 0.06255, Acc: 0.95368, F1: 0.95368#####> Valid Avg loss: 2.04798, Acc:0.31757, F1: 0.31757
====> Epoch: 150 Train Avg loss: 0.09595, Acc: 0.93349, F1: 0.93349#####> Valid Avg loss: 2.04338, Acc:0.30631, F1: 0.30631
====> Epoch: 151 Train Avg loss: 0.05043, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 2.09312, Acc:0.30405, F1: 0.30405
====> Epoch: 152 Train Avg loss: 0.09113, Acc: 0.93230, F1: 0.93230#####> Valid Avg loss: 1.72707, Acc:0.32995, F1: 0.32995
====> Epoch: 153 Train Avg loss: 0.04979, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.80435, Acc:0.37950, F1: 0.37950
====> Epoch: 154 Train Avg loss: 0.06532, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 2.24588, Acc:0.31194, F1: 0.31194
====> Epoch: 155 Train Avg loss: 0.06820, Acc: 0.95012, F1: 0.95012#####> Valid Avg loss: 1.79580, Acc:0.33784, F1: 0.33784
====> Epoch: 156 Train Avg loss: 0.03734, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 1.97655, Acc:0.31869, F1: 0.31869
====> Epoch: 157 Train Avg loss: 0.03765, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 1.94114, Acc:0.37838, F1: 0.37838
====> Epoch: 158 Train Avg loss: 0.09906, Acc: 0.93112, F1: 0.93112#####> Valid Avg loss: 1.71635, Acc:0.35248, F1: 0.35248
====> Epoch: 159 Train Avg loss: 0.07473, Acc: 0.95131, F1: 0.95131#####> Valid Avg loss: 1.69981, Acc:0.37725, F1: 0.37725
====> Epoch: 160 Train Avg loss: 0.02993, Acc: 0.97150, F1: 0.97150#####> Valid Avg loss: 1.79724, Acc:0.36149, F1: 0.36149
====> Epoch: 161 Train Avg loss: 0.09180, Acc: 0.93112, F1: 0.93112#####> Valid Avg loss: 1.70166, Acc:0.34234, F1: 0.34234
====> Epoch: 162 Train Avg loss: 0.03995, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 1.89591, Acc:0.33784, F1: 0.33784
====> Epoch: 163 Train Avg loss: 0.04834, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 2.27996, Acc:0.29617, F1: 0.29617
====> Epoch: 164 Train Avg loss: 0.03146, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 1.94973, Acc:0.36374, F1: 0.36374
====> Epoch: 165 Train Avg loss: 0.08655, Acc: 0.94774, F1: 0.94774#####> Valid Avg loss: 2.10515, Acc:0.42230, F1: 0.42230
====> Epoch: 166 Train Avg loss: 0.08847, Acc: 0.93824, F1: 0.93824#####> Valid Avg loss: 1.63311, Acc:0.34797, F1: 0.34797
====> Epoch: 167 Train Avg loss: 0.02384, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.91513, Acc:0.36599, F1: 0.36599
====> Epoch: 168 Train Avg loss: 0.03158, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 2.05246, Acc:0.33333, F1: 0.33333
====> Epoch: 169 Train Avg loss: 0.07396, Acc: 0.94299, F1: 0.94299#####> Valid Avg loss: 1.64082, Acc:0.34234, F1: 0.34234
====> Epoch: 170 Train Avg loss: 0.06494, Acc: 0.95131, F1: 0.95131#####> Valid Avg loss: 1.76708, Acc:0.34797, F1: 0.34797
====> Epoch: 171 Train Avg loss: 0.04103, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 1.73002, Acc:0.38514, F1: 0.38514
====> Epoch: 172 Train Avg loss: 0.04177, Acc: 0.95962, F1: 0.95962#####> Valid Avg loss: 1.74555, Acc:0.34347, F1: 0.34347
====> Epoch: 173 Train Avg loss: 0.03489, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 1.72200, Acc:0.36149, F1: 0.36149
====> Epoch: 174 Train Avg loss: 0.03164, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 1.77395, Acc:0.36824, F1: 0.36824
====> Epoch: 175 Train Avg loss: 0.02410, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.22217, Acc:0.37725, F1: 0.37725
====> Epoch: 176 Train Avg loss: 0.07218, Acc: 0.94537, F1: 0.94537#####> Valid Avg loss: 1.85748, Acc:0.35360, F1: 0.35360
====> Epoch: 177 Train Avg loss: 0.03442, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 1.78844, Acc:0.36261, F1: 0.36261
====> Epoch: 178 Train Avg loss: 0.02783, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.01237, Acc:0.36374, F1: 0.36374
====> Epoch: 179 Train Avg loss: 0.02860, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 1.91978, Acc:0.31306, F1: 0.31306
====> Epoch: 180 Train Avg loss: 0.08319, Acc: 0.93468, F1: 0.93468#####> Valid Avg loss: 1.84794, Acc:0.34009, F1: 0.34009
====> Epoch: 181 Train Avg loss: 0.05130, Acc: 0.96081, F1: 0.96081#####> Valid Avg loss: 1.73518, Acc:0.33671, F1: 0.33671
====> Epoch: 182 Train Avg loss: 0.02048, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.09668, Acc:0.30518, F1: 0.30518
====> Epoch: 183 Train Avg loss: 0.02103, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 1.82813, Acc:0.36261, F1: 0.36261
====> Epoch: 184 Train Avg loss: 0.02784, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 1.92482, Acc:0.35135, F1: 0.35135
====> Epoch: 185 Train Avg loss: 0.01738, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.98109, Acc:0.34459, F1: 0.34459
====> Epoch: 186 Train Avg loss: 0.04001, Acc: 0.96556, F1: 0.96556#####> Valid Avg loss: 1.93320, Acc:0.36599, F1: 0.36599
====> Epoch: 187 Train Avg loss: 0.04596, Acc: 0.96081, F1: 0.96081#####> Valid Avg loss: 1.79140, Acc:0.37050, F1: 0.37050
====> Epoch: 188 Train Avg loss: 0.04503, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 2.10419, Acc:0.32658, F1: 0.32658
====> Epoch: 189 Train Avg loss: 0.01509, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.03176, Acc:0.35811, F1: 0.35811
====> Epoch: 190 Train Avg loss: 0.02295, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.15989, Acc:0.33108, F1: 0.33108
====> Epoch: 191 Train Avg loss: 0.01966, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.15633, Acc:0.35135, F1: 0.35135
====> Epoch: 192 Train Avg loss: 0.01670, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.33493, Acc:0.35923, F1: 0.35923
====> Epoch: 193 Train Avg loss: 0.01836, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.16062, Acc:0.35586, F1: 0.35586
====> Epoch: 194 Train Avg loss: 0.03715, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 2.01288, Acc:0.35473, F1: 0.35473
====> Epoch: 195 Train Avg loss: 0.03392, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.09120, Acc:0.34122, F1: 0.34122
====> Epoch: 196 Train Avg loss: 0.04091, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 1.97431, Acc:0.36937, F1: 0.36937
====> Epoch: 197 Train Avg loss: 0.02301, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.80584, Acc:0.37725, F1: 0.37725
====> Epoch: 198 Train Avg loss: 0.01305, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 1.95699, Acc:0.38401, F1: 0.38401
====> Epoch: 199 Train Avg loss: 0.01360, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.87491, Acc:0.37500, F1: 0.37500
====> Epoch: 200 Train Avg loss: 0.01363, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.93436, Acc:0.35586, F1: 0.35586
====> Epoch: 201 Train Avg loss: 0.04035, Acc: 0.96318, F1: 0.96318#####> Valid Avg loss: 2.11942, Acc:0.32658, F1: 0.32658
====> Epoch: 202 Train Avg loss: 0.02702, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.11151, Acc:0.35360, F1: 0.35360
====> Epoch: 203 Train Avg loss: 0.01499, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.16658, Acc:0.34459, F1: 0.34459
====> Epoch: 204 Train Avg loss: 0.01637, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.01901, Acc:0.37838, F1: 0.37838
====> Epoch: 205 Train Avg loss: 0.03958, Acc: 0.96556, F1: 0.96556#####> Valid Avg loss: 1.92206, Acc:0.36036, F1: 0.36036
====> Epoch: 206 Train Avg loss: 0.02955, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 1.80535, Acc:0.36261, F1: 0.36261
====> Epoch: 207 Train Avg loss: 0.01744, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.00715, Acc:0.36374, F1: 0.36374
====> Epoch: 208 Train Avg loss: 0.01312, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.16228, Acc:0.35698, F1: 0.35698
====> Epoch: 209 Train Avg loss: 0.01250, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.07882, Acc:0.36486, F1: 0.36486
====> Epoch: 210 Train Avg loss: 0.01990, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.05046, Acc:0.38964, F1: 0.38964
====> Epoch: 211 Train Avg loss: 0.01516, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.08140, Acc:0.35586, F1: 0.35586
====> Epoch: 212 Train Avg loss: 0.01490, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.07394, Acc:0.35248, F1: 0.35248
====> Epoch: 213 Train Avg loss: 0.04143, Acc: 0.96437, F1: 0.96437#####> Valid Avg loss: 2.17975, Acc:0.34797, F1: 0.34797
====> Epoch: 214 Train Avg loss: 0.02847, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.04896, Acc:0.36824, F1: 0.36824
====> Epoch: 215 Train Avg loss: 0.01330, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.01001, Acc:0.35473, F1: 0.35473
====> Epoch: 216 Train Avg loss: 0.01247, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.11340, Acc:0.37613, F1: 0.37613
====> Epoch: 217 Train Avg loss: 0.01173, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.13184, Acc:0.37050, F1: 0.37050
====> Epoch: 218 Train Avg loss: 0.01209, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.06771, Acc:0.37500, F1: 0.37500
====> Epoch: 219 Train Avg loss: 0.01198, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.00785, Acc:0.37162, F1: 0.37162
====> Epoch: 220 Train Avg loss: 0.01240, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.10473, Acc:0.37725, F1: 0.37725
====> Epoch: 221 Train Avg loss: 0.02053, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.02821, Acc:0.33108, F1: 0.33108
====> Epoch: 222 Train Avg loss: 0.03618, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 2.18041, Acc:0.36374, F1: 0.36374
====> Epoch: 223 Train Avg loss: 0.01243, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.11492, Acc:0.35473, F1: 0.35473
====> Epoch: 224 Train Avg loss: 0.01405, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.03824, Acc:0.34572, F1: 0.34572
====> Epoch: 225 Train Avg loss: 0.01586, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.08999, Acc:0.36937, F1: 0.36937
====> Epoch: 226 Train Avg loss: 0.01405, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.12740, Acc:0.37275, F1: 0.37275
====> Epoch: 227 Train Avg loss: 0.01286, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.07221, Acc:0.35698, F1: 0.35698
====> Epoch: 228 Train Avg loss: 0.01251, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.11844, Acc:0.36486, F1: 0.36486
====> Epoch: 229 Train Avg loss: 0.01156, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.06715, Acc:0.39414, F1: 0.39414
====> Epoch: 230 Train Avg loss: 0.01199, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.16612, Acc:0.37725, F1: 0.37725
====> Epoch: 231 Train Avg loss: 0.01231, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.15228, Acc:0.34122, F1: 0.34122
====> Epoch: 232 Train Avg loss: 0.01267, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.25884, Acc:0.35248, F1: 0.35248
====> Epoch: 233 Train Avg loss: 0.01805, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.21428, Acc:0.35586, F1: 0.35586
====> Epoch: 234 Train Avg loss: 0.01104, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.18732, Acc:0.34572, F1: 0.34572
====> Epoch: 235 Train Avg loss: 0.01171, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.16439, Acc:0.36486, F1: 0.36486
====> Epoch: 236 Train Avg loss: 0.01008, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.03144, Acc:0.37500, F1: 0.37500
====> Epoch: 237 Train Avg loss: 0.01132, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.18314, Acc:0.35698, F1: 0.35698
====> Epoch: 238 Train Avg loss: 0.01138, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.28450, Acc:0.33784, F1: 0.33784
====> Epoch: 239 Train Avg loss: 0.01054, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.20662, Acc:0.36149, F1: 0.36149
====> Epoch: 240 Train Avg loss: 0.01075, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.10384, Acc:0.36599, F1: 0.36599
====> Epoch: 241 Train Avg loss: 0.01189, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.18616, Acc:0.38851, F1: 0.38851
====> Epoch: 242 Train Avg loss: 0.01116, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.20073, Acc:0.34797, F1: 0.34797
====> Epoch: 243 Train Avg loss: 0.01225, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.35669, Acc:0.38626, F1: 0.38626
====> Epoch: 244 Train Avg loss: 0.01019, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.17432, Acc:0.35698, F1: 0.35698
====> Epoch: 245 Train Avg loss: 0.01001, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.23427, Acc:0.37500, F1: 0.37500
====> Epoch: 246 Train Avg loss: 0.00984, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.20078, Acc:0.39189, F1: 0.39189
===> Epoch: 246: Training loss decreased (0.00989 --> 0.00984), Acc: (0.98694 --> 0.98694), F1: (0.98694 --> 0.98694).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 247 Train Avg loss: 0.01004, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.20339, Acc:0.36712, F1: 0.36712
====> Epoch: 248 Train Avg loss: 0.01077, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.28895, Acc:0.35023, F1: 0.35023
====> Epoch: 249 Train Avg loss: 0.01021, Acc: 0.98812, F1: 0.98812#####> Valid Avg loss: 2.25879, Acc:0.38514, F1: 0.38514
====> Epoch: 250 Train Avg loss: 0.01004, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.23894, Acc:0.35811, F1: 0.35811
====> Epoch: 251 Train Avg loss: 0.00896, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.09616, Acc:0.37275, F1: 0.37275
===> Epoch: 251: Training loss decreased (0.00984 --> 0.00896), Acc: (0.98694 --> 0.98456), F1: (0.98694 --> 0.98456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 252 Train Avg loss: 0.00992, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.22903, Acc:0.35360, F1: 0.35360
====> Epoch: 253 Train Avg loss: 0.01022, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.22664, Acc:0.35698, F1: 0.35698
====> Epoch: 254 Train Avg loss: 0.01178, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.25682, Acc:0.34459, F1: 0.34459
====> Epoch: 255 Train Avg loss: 0.01052, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.24180, Acc:0.35360, F1: 0.35360
====> Epoch: 256 Train Avg loss: 0.00919, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.19648, Acc:0.36824, F1: 0.36824
====> Epoch: 257 Train Avg loss: 0.00936, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.13319, Acc:0.37162, F1: 0.37162
====> Epoch: 258 Train Avg loss: 0.01027, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.24527, Acc:0.37275, F1: 0.37275
====> Epoch: 259 Train Avg loss: 0.00965, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.23562, Acc:0.35135, F1: 0.35135
====> Epoch: 260 Train Avg loss: 0.00952, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.23848, Acc:0.37500, F1: 0.37500
====> Epoch: 261 Train Avg loss: 0.00956, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.23885, Acc:0.38401, F1: 0.38401
====> Epoch: 262 Train Avg loss: 0.00933, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.26541, Acc:0.36261, F1: 0.36261
====> Epoch: 263 Train Avg loss: 0.00928, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.26196, Acc:0.36261, F1: 0.36261
====> Epoch: 264 Train Avg loss: 0.00941, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.24303, Acc:0.35586, F1: 0.35586
====> Epoch: 265 Train Avg loss: 0.00870, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.26179, Acc:0.37162, F1: 0.37162
===> Epoch: 265: Training loss decreased (0.00896 --> 0.00870), Acc: (0.98456 --> 0.98219), F1: (0.98456 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 266 Train Avg loss: 0.00993, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.24031, Acc:0.37950, F1: 0.37950
====> Epoch: 267 Train Avg loss: 0.00941, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.25619, Acc:0.36261, F1: 0.36261
====> Epoch: 268 Train Avg loss: 0.00919, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.27433, Acc:0.35473, F1: 0.35473
====> Epoch: 269 Train Avg loss: 0.00831, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.27316, Acc:0.37725, F1: 0.37725
===> Epoch: 269: Training loss decreased (0.00870 --> 0.00831), Acc: (0.98219 --> 0.98575), F1: (0.98219 --> 0.98575).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 270 Train Avg loss: 0.00843, Acc: 0.98812, F1: 0.98812#####> Valid Avg loss: 2.24613, Acc:0.37275, F1: 0.37275
====> Epoch: 271 Train Avg loss: 0.00915, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.28647, Acc:0.35923, F1: 0.35923
====> Epoch: 272 Train Avg loss: 0.01133, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.32358, Acc:0.36824, F1: 0.36824
====> Epoch: 273 Train Avg loss: 0.00908, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.38536, Acc:0.37275, F1: 0.37275
====> Epoch: 274 Train Avg loss: 0.00858, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.27809, Acc:0.36712, F1: 0.36712
====> Epoch: 275 Train Avg loss: 0.00865, Acc: 0.98812, F1: 0.98812#####> Valid Avg loss: 2.27367, Acc:0.36712, F1: 0.36712
====> Epoch: 276 Train Avg loss: 0.00869, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.30159, Acc:0.37725, F1: 0.37725
====> Epoch: 277 Train Avg loss: 0.00866, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.27469, Acc:0.36374, F1: 0.36374
====> Epoch: 278 Train Avg loss: 0.00893, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.30140, Acc:0.36937, F1: 0.36937
====> Epoch: 279 Train Avg loss: 0.00909, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.28922, Acc:0.36261, F1: 0.36261
====> Epoch: 280 Train Avg loss: 0.00946, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.31149, Acc:0.35923, F1: 0.35923
====> Epoch: 281 Train Avg loss: 0.01029, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.23240, Acc:0.37050, F1: 0.37050
====> Epoch: 282 Train Avg loss: 0.00945, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.26115, Acc:0.37162, F1: 0.37162
====> Epoch: 283 Train Avg loss: 0.00847, Acc: 0.99050, F1: 0.99050#####> Valid Avg loss: 2.24540, Acc:0.37500, F1: 0.37500
====> Epoch: 284 Train Avg loss: 0.00858, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.34940, Acc:0.37162, F1: 0.37162
====> Epoch: 285 Train Avg loss: 0.00842, Acc: 0.98812, F1: 0.98812#####> Valid Avg loss: 2.25967, Acc:0.37500, F1: 0.37500
====> Epoch: 286 Train Avg loss: 0.00924, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.30134, Acc:0.36824, F1: 0.36824
====> Epoch: 287 Train Avg loss: 0.00885, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.28406, Acc:0.37162, F1: 0.37162
====> Epoch: 288 Train Avg loss: 0.00837, Acc: 0.98931, F1: 0.98931#####> Valid Avg loss: 2.27904, Acc:0.37387, F1: 0.37387
====> Epoch: 289 Train Avg loss: 0.00864, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.28344, Acc:0.37275, F1: 0.37275
====> Epoch: 290 Train Avg loss: 0.00885, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.23636, Acc:0.37613, F1: 0.37613
====> Epoch: 291 Train Avg loss: 0.00858, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.30023, Acc:0.37275, F1: 0.37275
====> Epoch: 292 Train Avg loss: 0.00827, Acc: 0.99050, F1: 0.99050#####> Valid Avg loss: 2.28343, Acc:0.37500, F1: 0.37500
===> Epoch: 292: Training loss decreased (0.00831 --> 0.00827), Acc: (0.98575 --> 0.99050), F1: (0.98575 --> 0.99050).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_1
====> Epoch: 293 Train Avg loss: 0.00852, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.32144, Acc:0.37275, F1: 0.37275
====> Epoch: 294 Train Avg loss: 0.00829, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.25919, Acc:0.37387, F1: 0.37387
====> Epoch: 295 Train Avg loss: 0.00834, Acc: 0.99169, F1: 0.99169#####> Valid Avg loss: 2.30748, Acc:0.37500, F1: 0.37500
====> Epoch: 296 Train Avg loss: 0.00963, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.28962, Acc:0.37613, F1: 0.37613
====> Epoch: 297 Train Avg loss: 0.00853, Acc: 0.98812, F1: 0.98812#####> Valid Avg loss: 2.27613, Acc:0.37387, F1: 0.37387
====> Epoch: 298 Train Avg loss: 0.00845, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.23548, Acc:0.37500, F1: 0.37500
====> Epoch: 299 Train Avg loss: 0.00912, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.22963, Acc:0.37500, F1: 0.37500
====> Epoch: 300 Train Avg loss: 0.57165, Acc: 0.63064, F1: 0.63064#####> Valid Avg loss: 0.86275, Acc:0.31644, F1: 0.31644
====> Epoch: 301 Train Avg loss: 0.44063, Acc: 0.67458, F1: 0.67458#####> Valid Avg loss: 0.93967, Acc:0.38514, F1: 0.38514
====> Epoch: 302 Train Avg loss: 0.38534, Acc: 0.70190, F1: 0.70190#####> Valid Avg loss: 1.01946, Acc:0.46396, F1: 0.46396
====> Epoch: 303 Train Avg loss: 0.34045, Acc: 0.75297, F1: 0.75297#####> Valid Avg loss: 0.98360, Acc:0.28491, F1: 0.28491
====> Epoch: 304 Train Avg loss: 0.31287, Acc: 0.76485, F1: 0.76485#####> Valid Avg loss: 1.10041, Acc:0.35698, F1: 0.35698
====> Epoch: 305 Train Avg loss: 0.29215, Acc: 0.78741, F1: 0.78741#####> Valid Avg loss: 1.02246, Acc:0.32545, F1: 0.32545
====> Epoch: 306 Train Avg loss: 0.24418, Acc: 0.81948, F1: 0.81948#####> Valid Avg loss: 1.15126, Acc:0.29617, F1: 0.29617
====> Epoch: 307 Train Avg loss: 0.23520, Acc: 0.82185, F1: 0.82185#####> Valid Avg loss: 1.08476, Acc:0.39077, F1: 0.39077
====> Epoch: 308 Train Avg loss: 0.18289, Acc: 0.86105, F1: 0.86105#####> Valid Avg loss: 1.66777, Acc:0.26802, F1: 0.26802
====> Epoch: 309 Train Avg loss: 0.21028, Acc: 0.83729, F1: 0.83729#####> Valid Avg loss: 1.45002, Acc:0.28041, F1: 0.28041
====> Epoch: 310 Train Avg loss: 0.12778, Acc: 0.91449, F1: 0.91449#####> Valid Avg loss: 1.37687, Acc:0.34459, F1: 0.34459
====> Epoch: 311 Train Avg loss: 0.13920, Acc: 0.89786, F1: 0.89786#####> Valid Avg loss: 1.44732, Acc:0.37950, F1: 0.37950
====> Epoch: 312 Train Avg loss: 0.07218, Acc: 0.95012, F1: 0.95012#####> Valid Avg loss: 1.63258, Acc:0.35811, F1: 0.35811
====> Epoch: 313 Train Avg loss: 0.09019, Acc: 0.93230, F1: 0.93230#####> Valid Avg loss: 1.68961, Acc:0.30518, F1: 0.30518
====> Epoch: 314 Train Avg loss: 0.09668, Acc: 0.92637, F1: 0.92637#####> Valid Avg loss: 1.60061, Acc:0.30631, F1: 0.30631
====> Epoch: 315 Train Avg loss: 0.04590, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 1.78097, Acc:0.32770, F1: 0.32770
====> Epoch: 316 Train Avg loss: 0.03955, Acc: 0.96437, F1: 0.96437#####> Valid Avg loss: 1.85835, Acc:0.34009, F1: 0.34009
====> Epoch: 317 Train Avg loss: 0.10426, Acc: 0.92162, F1: 0.92162#####> Valid Avg loss: 1.62850, Acc:0.30968, F1: 0.30968
====> Epoch: 318 Train Avg loss: 0.06951, Acc: 0.95249, F1: 0.95249#####> Valid Avg loss: 1.73159, Acc:0.32207, F1: 0.32207
====> Epoch: 319 Train Avg loss: 0.11228, Acc: 0.90974, F1: 0.90974#####> Valid Avg loss: 1.41647, Acc:0.41329, F1: 0.41329
====> Epoch: 320 Train Avg loss: 0.05462, Acc: 0.95962, F1: 0.95962#####> Valid Avg loss: 1.71778, Acc:0.31982, F1: 0.31982
====> Epoch: 321 Train Avg loss: 0.03630, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 1.66436, Acc:0.34459, F1: 0.34459
====> Epoch: 322 Train Avg loss: 0.05518, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.70540, Acc:0.37387, F1: 0.37387
====> Epoch: 323 Train Avg loss: 0.08767, Acc: 0.93349, F1: 0.93349#####> Valid Avg loss: 1.52180, Acc:0.31757, F1: 0.31757
====> Epoch: 324 Train Avg loss: 0.05244, Acc: 0.96556, F1: 0.96556#####> Valid Avg loss: 1.61828, Acc:0.34459, F1: 0.34459
====> Epoch: 325 Train Avg loss: 0.06490, Acc: 0.94893, F1: 0.94893#####> Valid Avg loss: 1.64761, Acc:0.32432, F1: 0.32432
====> Epoch: 326 Train Avg loss: 0.07228, Acc: 0.94893, F1: 0.94893#####> Valid Avg loss: 1.49673, Acc:0.32432, F1: 0.32432
====> Epoch: 327 Train Avg loss: 0.06576, Acc: 0.95249, F1: 0.95249#####> Valid Avg loss: 1.59992, Acc:0.34685, F1: 0.34685
====> Epoch: 328 Train Avg loss: 0.04607, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.80518, Acc:0.32883, F1: 0.32883
====> Epoch: 329 Train Avg loss: 0.05139, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 1.50071, Acc:0.39077, F1: 0.39077
====> Epoch: 330 Train Avg loss: 0.14090, Acc: 0.89311, F1: 0.89311#####> Valid Avg loss: 1.51155, Acc:0.34797, F1: 0.34797
====> Epoch: 331 Train Avg loss: 0.03202, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 1.56180, Acc:0.32320, F1: 0.32320
====> Epoch: 332 Train Avg loss: 0.01751, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.70287, Acc:0.39189, F1: 0.39189
====> Epoch: 333 Train Avg loss: 0.02096, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.85747, Acc:0.31644, F1: 0.31644
====> Epoch: 334 Train Avg loss: 0.05845, Acc: 0.96318, F1: 0.96318#####> Valid Avg loss: 1.74348, Acc:0.29730, F1: 0.29730
====> Epoch: 335 Train Avg loss: 0.09903, Acc: 0.92874, F1: 0.92874#####> Valid Avg loss: 1.51065, Acc:0.34685, F1: 0.34685
====> Epoch: 336 Train Avg loss: 0.07424, Acc: 0.94299, F1: 0.94299#####> Valid Avg loss: 1.38842, Acc:0.35586, F1: 0.35586
====> Epoch: 337 Train Avg loss: 0.03932, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 1.58096, Acc:0.29505, F1: 0.29505
====> Epoch: 338 Train Avg loss: 0.02064, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.77570, Acc:0.34572, F1: 0.34572
====> Epoch: 339 Train Avg loss: 0.08281, Acc: 0.94299, F1: 0.94299#####> Valid Avg loss: 1.44112, Acc:0.39865, F1: 0.39865
====> Epoch: 340 Train Avg loss: 0.03586, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 1.67096, Acc:0.34347, F1: 0.34347
====> Epoch: 341 Train Avg loss: 0.02829, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.52224, Acc:0.35923, F1: 0.35923
====> Epoch: 342 Train Avg loss: 0.05674, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 1.74340, Acc:0.32320, F1: 0.32320
====> Epoch: 343 Train Avg loss: 0.09871, Acc: 0.92637, F1: 0.92637#####> Valid Avg loss: 1.50880, Acc:0.32883, F1: 0.32883
====> Epoch: 344 Train Avg loss: 0.05117, Acc: 0.96556, F1: 0.96556#####> Valid Avg loss: 1.59221, Acc:0.38063, F1: 0.38063
====> Epoch: 345 Train Avg loss: 0.03593, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 1.63690, Acc:0.34234, F1: 0.34234
====> Epoch: 346 Train Avg loss: 0.01975, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.65770, Acc:0.40766, F1: 0.40766
====> Epoch: 347 Train Avg loss: 0.01446, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.76105, Acc:0.36149, F1: 0.36149
====> Epoch: 348 Train Avg loss: 0.15678, Acc: 0.89074, F1: 0.89074#####> Valid Avg loss: 1.30173, Acc:0.32432, F1: 0.32432
====> Epoch: 349 Train Avg loss: 0.04996, Acc: 0.95843, F1: 0.95843#####> Valid Avg loss: 1.61176, Acc:0.35135, F1: 0.35135
====> Epoch: 350 Train Avg loss: 0.06158, Acc: 0.96081, F1: 0.96081#####> Valid Avg loss: 1.50351, Acc:0.33333, F1: 0.33333
====> Epoch: 351 Train Avg loss: 0.08270, Acc: 0.94181, F1: 0.94181#####> Valid Avg loss: 1.52551, Acc:0.29054, F1: 0.29054
====> Epoch: 352 Train Avg loss: 0.04434, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 1.67711, Acc:0.35473, F1: 0.35473
====> Epoch: 353 Train Avg loss: 0.06671, Acc: 0.95843, F1: 0.95843#####> Valid Avg loss: 1.77931, Acc:0.34459, F1: 0.34459
====> Epoch: 354 Train Avg loss: 0.04032, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 1.56959, Acc:0.34347, F1: 0.34347
====> Epoch: 355 Train Avg loss: 0.01450, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.74337, Acc:0.35023, F1: 0.35023
====> Epoch: 356 Train Avg loss: 0.01609, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.72391, Acc:0.35586, F1: 0.35586
====> Epoch: 357 Train Avg loss: 0.05601, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 1.65707, Acc:0.34122, F1: 0.34122
====> Epoch: 358 Train Avg loss: 0.03417, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 2.04927, Acc:0.31644, F1: 0.31644
====> Epoch: 359 Train Avg loss: 0.08379, Acc: 0.94299, F1: 0.94299#####> Valid Avg loss: 1.46097, Acc:0.34122, F1: 0.34122
====> Epoch: 360 Train Avg loss: 0.03966, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 1.83439, Acc:0.27477, F1: 0.27477
====> Epoch: 361 Train Avg loss: 0.05582, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 1.65483, Acc:0.32883, F1: 0.32883
====> Epoch: 362 Train Avg loss: 0.06026, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.65591, Acc:0.36599, F1: 0.36599
====> Epoch: 363 Train Avg loss: 0.08280, Acc: 0.93705, F1: 0.93705#####> Valid Avg loss: 1.60670, Acc:0.36374, F1: 0.36374
====> Epoch: 364 Train Avg loss: 0.05345, Acc: 0.95843, F1: 0.95843#####> Valid Avg loss: 1.70525, Acc:0.33108, F1: 0.33108
====> Epoch: 365 Train Avg loss: 0.01919, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.92559, Acc:0.29054, F1: 0.29054
====> Epoch: 366 Train Avg loss: 0.03184, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 1.64475, Acc:0.37950, F1: 0.37950
====> Epoch: 367 Train Avg loss: 0.08353, Acc: 0.94181, F1: 0.94181#####> Valid Avg loss: 1.45573, Acc:0.35811, F1: 0.35811
====> Epoch: 368 Train Avg loss: 0.04416, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 1.75508, Acc:0.33671, F1: 0.33671
====> Epoch: 369 Train Avg loss: 0.01550, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.69632, Acc:0.36149, F1: 0.36149
====> Epoch: 370 Train Avg loss: 0.01744, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.79796, Acc:0.34685, F1: 0.34685
====> Epoch: 371 Train Avg loss: 0.09763, Acc: 0.93587, F1: 0.93587#####> Valid Avg loss: 1.54932, Acc:0.28716, F1: 0.28716
====> Epoch: 372 Train Avg loss: 0.02374, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 1.68130, Acc:0.34797, F1: 0.34797
====> Epoch: 373 Train Avg loss: 0.04369, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 1.69478, Acc:0.35586, F1: 0.35586
====> Epoch: 374 Train Avg loss: 0.05193, Acc: 0.96437, F1: 0.96437#####> Valid Avg loss: 1.67793, Acc:0.35923, F1: 0.35923
====> Epoch: 375 Train Avg loss: 0.05847, Acc: 0.95012, F1: 0.95012#####> Valid Avg loss: 1.76918, Acc:0.34685, F1: 0.34685
====> Epoch: 376 Train Avg loss: 0.04366, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 1.62856, Acc:0.34797, F1: 0.34797
====> Epoch: 377 Train Avg loss: 0.05277, Acc: 0.96081, F1: 0.96081#####> Valid Avg loss: 1.88946, Acc:0.24662, F1: 0.24662
====> Epoch: 378 Train Avg loss: 0.04955, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.53167, Acc:0.32658, F1: 0.32658
====> Epoch: 379 Train Avg loss: 0.02656, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 1.72925, Acc:0.35135, F1: 0.35135
====> Epoch: 380 Train Avg loss: 0.01471, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.80318, Acc:0.30631, F1: 0.30631
====> Epoch: 381 Train Avg loss: 0.01972, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.93813, Acc:0.29279, F1: 0.29279
====> Epoch: 382 Train Avg loss: 0.01641, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.00839, Acc:0.33221, F1: 0.33221
====> Epoch: 383 Train Avg loss: 0.13179, Acc: 0.90380, F1: 0.90380#####> Valid Avg loss: 1.60114, Acc:0.27140, F1: 0.27140
====> Epoch: 384 Train Avg loss: 0.03790, Acc: 0.95962, F1: 0.95962#####> Valid Avg loss: 1.53626, Acc:0.34572, F1: 0.34572
====> Epoch: 385 Train Avg loss: 0.02003, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.57018, Acc:0.33896, F1: 0.33896
====> Epoch: 386 Train Avg loss: 0.01464, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.73719, Acc:0.34459, F1: 0.34459
====> Epoch: 387 Train Avg loss: 0.13056, Acc: 0.90380, F1: 0.90380#####> Valid Avg loss: 1.31904, Acc:0.31869, F1: 0.31869
====> Epoch: 388 Train Avg loss: 0.02221, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.42605, Acc:0.32658, F1: 0.32658
====> Epoch: 389 Train Avg loss: 0.01583, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.44732, Acc:0.35248, F1: 0.35248
====> Epoch: 390 Train Avg loss: 0.03120, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 1.47390, Acc:0.34234, F1: 0.34234
====> Epoch: 391 Train Avg loss: 0.07087, Acc: 0.94774, F1: 0.94774#####> Valid Avg loss: 1.57000, Acc:0.37950, F1: 0.37950
====> Epoch: 392 Train Avg loss: 0.01447, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.57043, Acc:0.33446, F1: 0.33446
====> Epoch: 393 Train Avg loss: 0.02070, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.69943, Acc:0.39527, F1: 0.39527
====> Epoch: 394 Train Avg loss: 0.11545, Acc: 0.92874, F1: 0.92874#####> Valid Avg loss: 1.70236, Acc:0.38288, F1: 0.38288
====> Epoch: 395 Train Avg loss: 0.02451, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 1.63716, Acc:0.39865, F1: 0.39865
====> Epoch: 396 Train Avg loss: 0.01769, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.69267, Acc:0.35023, F1: 0.35023
====> Epoch: 397 Train Avg loss: 0.01555, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.74535, Acc:0.35023, F1: 0.35023
====> Epoch: 398 Train Avg loss: 0.01258, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.86802, Acc:0.33559, F1: 0.33559
====> Epoch: 399 Train Avg loss: 0.03951, Acc: 0.96556, F1: 0.96556#####> Valid Avg loss: 1.49315, Acc:0.40203, F1: 0.40203
====> Epoch: 400 Train Avg loss: 0.05850, Acc: 0.95131, F1: 0.95131#####> Valid Avg loss: 1.60274, Acc:0.29955, F1: 0.29955
====> Epoch: 401 Train Avg loss: 0.05245, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.63370, Acc:0.40991, F1: 0.40991
====> Epoch: 402 Train Avg loss: 0.01580, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.73627, Acc:0.36937, F1: 0.36937
====> Epoch: 403 Train Avg loss: 0.01246, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 1.66678, Acc:0.37275, F1: 0.37275
====> Epoch: 404 Train Avg loss: 0.01216, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.69756, Acc:0.36599, F1: 0.36599
====> Epoch: 405 Train Avg loss: 0.16518, Acc: 0.90261, F1: 0.90261#####> Valid Avg loss: 1.28709, Acc:0.38626, F1: 0.38626
====> Epoch: 406 Train Avg loss: 0.02875, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 1.48157, Acc:0.35473, F1: 0.35473
====> Epoch: 407 Train Avg loss: 0.01645, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.57468, Acc:0.39302, F1: 0.39302
====> Epoch: 408 Train Avg loss: 0.02328, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 1.90736, Acc:0.35698, F1: 0.35698
====> Epoch: 409 Train Avg loss: 0.09608, Acc: 0.93468, F1: 0.93468#####> Valid Avg loss: 1.38497, Acc:0.38063, F1: 0.38063
====> Epoch: 410 Train Avg loss: 0.02335, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.63997, Acc:0.36036, F1: 0.36036
====> Epoch: 411 Train Avg loss: 0.01402, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.72549, Acc:0.37838, F1: 0.37838
====> Epoch: 412 Train Avg loss: 0.01217, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 1.77205, Acc:0.36599, F1: 0.36599
====> Epoch: 413 Train Avg loss: 0.01384, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.74251, Acc:0.34797, F1: 0.34797
====> Epoch: 414 Train Avg loss: 0.07300, Acc: 0.94418, F1: 0.94418#####> Valid Avg loss: 1.49407, Acc:0.37050, F1: 0.37050
====> Epoch: 415 Train Avg loss: 0.04243, Acc: 0.96081, F1: 0.96081#####> Valid Avg loss: 1.76790, Acc:0.34122, F1: 0.34122
====> Epoch: 416 Train Avg loss: 0.06956, Acc: 0.94656, F1: 0.94656#####> Valid Avg loss: 1.74519, Acc:0.35023, F1: 0.35023
====> Epoch: 417 Train Avg loss: 0.02630, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 1.64658, Acc:0.38288, F1: 0.38288
====> Epoch: 418 Train Avg loss: 0.01438, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 1.71054, Acc:0.38401, F1: 0.38401
====> Epoch: 419 Train Avg loss: 0.01465, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.74137, Acc:0.36261, F1: 0.36261
====> Epoch: 420 Train Avg loss: 0.02473, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.11295, Acc:0.28266, F1: 0.28266
====> Epoch: 421 Train Avg loss: 0.06747, Acc: 0.94774, F1: 0.94774#####> Valid Avg loss: 1.61052, Acc:0.36036, F1: 0.36036
====> Epoch: 422 Train Avg loss: 0.02148, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.70788, Acc:0.39640, F1: 0.39640
====> Epoch: 423 Train Avg loss: 0.03673, Acc: 0.96437, F1: 0.96437#####> Valid Avg loss: 1.75538, Acc:0.35135, F1: 0.35135
====> Epoch: 424 Train Avg loss: 0.02266, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 1.74427, Acc:0.37387, F1: 0.37387
====> Epoch: 425 Train Avg loss: 0.02714, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 1.84281, Acc:0.29054, F1: 0.29054
====> Epoch: 426 Train Avg loss: 0.03034, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 1.81757, Acc:0.35023, F1: 0.35023
====> Epoch: 427 Train Avg loss: 0.05921, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.69186, Acc:0.35023, F1: 0.35023
====> Epoch: 428 Train Avg loss: 0.02072, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.75064, Acc:0.35586, F1: 0.35586
====> Epoch: 429 Train Avg loss: 0.01354, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.90163, Acc:0.35248, F1: 0.35248
====> Epoch: 430 Train Avg loss: 0.01290, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.90494, Acc:0.35586, F1: 0.35586
====> Epoch: 431 Train Avg loss: 0.01339, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.91305, Acc:0.34910, F1: 0.34910
====> Epoch: 432 Train Avg loss: 0.01090, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.95602, Acc:0.36036, F1: 0.36036
====> Epoch: 433 Train Avg loss: 0.02874, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 1.54540, Acc:0.28829, F1: 0.28829
====> Epoch: 434 Train Avg loss: 0.08521, Acc: 0.94418, F1: 0.94418#####> Valid Avg loss: 1.73267, Acc:0.36486, F1: 0.36486
====> Epoch: 435 Train Avg loss: 0.01677, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.71750, Acc:0.36261, F1: 0.36261
====> Epoch: 436 Train Avg loss: 0.01375, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.82184, Acc:0.36712, F1: 0.36712
====> Epoch: 437 Train Avg loss: 0.01247, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.83496, Acc:0.37275, F1: 0.37275
====> Epoch: 438 Train Avg loss: 0.04190, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 1.82260, Acc:0.36036, F1: 0.36036
====> Epoch: 439 Train Avg loss: 0.05461, Acc: 0.96437, F1: 0.96437#####> Valid Avg loss: 1.76084, Acc:0.36036, F1: 0.36036
====> Epoch: 440 Train Avg loss: 0.02780, Acc: 0.97150, F1: 0.97150#####> Valid Avg loss: 1.67601, Acc:0.39977, F1: 0.39977
====> Epoch: 441 Train Avg loss: 0.01246, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.80236, Acc:0.36374, F1: 0.36374
====> Epoch: 442 Train Avg loss: 0.01265, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.80269, Acc:0.37387, F1: 0.37387
====> Epoch: 443 Train Avg loss: 0.01339, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.95126, Acc:0.37275, F1: 0.37275
====> Epoch: 444 Train Avg loss: 0.01398, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.80119, Acc:0.32770, F1: 0.32770
====> Epoch: 445 Train Avg loss: 0.06998, Acc: 0.94537, F1: 0.94537#####> Valid Avg loss: 1.40251, Acc:0.37950, F1: 0.37950
====> Epoch: 446 Train Avg loss: 0.03228, Acc: 0.97150, F1: 0.97150#####> Valid Avg loss: 1.55017, Acc:0.35586, F1: 0.35586
====> Epoch: 447 Train Avg loss: 0.01866, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.69798, Acc:0.35023, F1: 0.35023
====> Epoch: 448 Train Avg loss: 0.01542, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.81508, Acc:0.36036, F1: 0.36036
====> Epoch: 449 Train Avg loss: 0.01215, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.85132, Acc:0.34572, F1: 0.34572
====> Epoch: 450 Train Avg loss: 0.01004, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.92588, Acc:0.36036, F1: 0.36036
====> Epoch: 451 Train Avg loss: 0.01428, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.85577, Acc:0.36486, F1: 0.36486
====> Epoch: 452 Train Avg loss: 0.06968, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.53085, Acc:0.32095, F1: 0.32095
====> Epoch: 453 Train Avg loss: 0.03023, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 1.73761, Acc:0.33221, F1: 0.33221
====> Epoch: 454 Train Avg loss: 0.01349, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 1.72231, Acc:0.32883, F1: 0.32883
====> Epoch: 455 Train Avg loss: 0.01253, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 1.61525, Acc:0.35473, F1: 0.35473
====> Epoch: 456 Train Avg loss: 0.01132, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.75575, Acc:0.35135, F1: 0.35135
====> Epoch: 457 Train Avg loss: 0.01101, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.98326, Acc:0.35586, F1: 0.35586
====> Epoch: 458 Train Avg loss: 0.01042, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.86384, Acc:0.35135, F1: 0.35135
====> Epoch: 459 Train Avg loss: 0.06876, Acc: 0.94774, F1: 0.94774#####> Valid Avg loss: 1.82953, Acc:0.30405, F1: 0.30405
====> Epoch: 460 Train Avg loss: 0.03913, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 1.78753, Acc:0.32995, F1: 0.32995
====> Epoch: 461 Train Avg loss: 0.02615, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 1.98348, Acc:0.28941, F1: 0.28941
====> Epoch: 462 Train Avg loss: 0.01380, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.93843, Acc:0.34797, F1: 0.34797
====> Epoch: 463 Train Avg loss: 0.03175, Acc: 0.97150, F1: 0.97150#####> Valid Avg loss: 1.80756, Acc:0.33559, F1: 0.33559
====> Epoch: 464 Train Avg loss: 0.02034, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 1.85701, Acc:0.30968, F1: 0.30968
====> Epoch: 465 Train Avg loss: 0.01956, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.95983, Acc:0.35586, F1: 0.35586
====> Epoch: 466 Train Avg loss: 0.01855, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.24708, Acc:0.41216, F1: 0.41216
====> Epoch: 467 Train Avg loss: 0.02387, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 1.93981, Acc:0.34910, F1: 0.34910
====> Epoch: 468 Train Avg loss: 0.01232, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.94807, Acc:0.33896, F1: 0.33896
====> Epoch: 469 Train Avg loss: 0.01654, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.03372, Acc:0.34347, F1: 0.34347
====> Epoch: 470 Train Avg loss: 0.01292, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.97783, Acc:0.33896, F1: 0.33896
====> Epoch: 471 Train Avg loss: 0.01113, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.05084, Acc:0.33559, F1: 0.33559
====> Epoch: 472 Train Avg loss: 0.03801, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 1.87917, Acc:0.35248, F1: 0.35248
====> Epoch: 473 Train Avg loss: 0.05223, Acc: 0.95606, F1: 0.95606#####> Valid Avg loss: 1.86216, Acc:0.39977, F1: 0.39977
====> Epoch: 474 Train Avg loss: 0.01831, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.73424, Acc:0.35811, F1: 0.35811
====> Epoch: 475 Train Avg loss: 0.01399, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.77601, Acc:0.34572, F1: 0.34572
====> Epoch: 476 Train Avg loss: 0.01120, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.84123, Acc:0.34234, F1: 0.34234
====> Epoch: 477 Train Avg loss: 0.01929, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 1.97603, Acc:0.25450, F1: 0.25450
====> Epoch: 478 Train Avg loss: 0.01577, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.77039, Acc:0.36599, F1: 0.36599
====> Epoch: 479 Train Avg loss: 0.01251, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.80030, Acc:0.33108, F1: 0.33108
====> Epoch: 480 Train Avg loss: 0.01374, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.81236, Acc:0.34685, F1: 0.34685
====> Epoch: 481 Train Avg loss: 0.06436, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.49653, Acc:0.39640, F1: 0.39640
====> Epoch: 482 Train Avg loss: 0.01785, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.71555, Acc:0.36261, F1: 0.36261
====> Epoch: 483 Train Avg loss: 0.01107, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.73831, Acc:0.35811, F1: 0.35811
====> Epoch: 484 Train Avg loss: 0.00993, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.78564, Acc:0.36036, F1: 0.36036
====> Epoch: 485 Train Avg loss: 0.01016, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.74892, Acc:0.34347, F1: 0.34347
====> Epoch: 486 Train Avg loss: 0.01052, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.81841, Acc:0.35586, F1: 0.35586
====> Epoch: 487 Train Avg loss: 0.01739, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 1.96523, Acc:0.28716, F1: 0.28716
====> Epoch: 488 Train Avg loss: 0.03852, Acc: 0.96437, F1: 0.96437#####> Valid Avg loss: 1.87430, Acc:0.34347, F1: 0.34347
====> Epoch: 489 Train Avg loss: 0.01343, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 1.85251, Acc:0.32995, F1: 0.32995
====> Epoch: 490 Train Avg loss: 0.01035, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.84159, Acc:0.35586, F1: 0.35586
====> Epoch: 491 Train Avg loss: 0.01014, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 1.92247, Acc:0.34797, F1: 0.34797
====> Epoch: 492 Train Avg loss: 0.00965, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.02480, Acc:0.35360, F1: 0.35360
====> Epoch: 493 Train Avg loss: 0.01150, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.98390, Acc:0.33784, F1: 0.33784
====> Epoch: 494 Train Avg loss: 0.01176, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.18696, Acc:0.35698, F1: 0.35698
====> Epoch: 495 Train Avg loss: 0.01073, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.22432, Acc:0.34347, F1: 0.34347
====> Epoch: 496 Train Avg loss: 0.06104, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 1.77482, Acc:0.31644, F1: 0.31644
====> Epoch: 497 Train Avg loss: 0.01248, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.83396, Acc:0.32883, F1: 0.32883
====> Epoch: 498 Train Avg loss: 0.01081, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.85149, Acc:0.31532, F1: 0.31532
====> Epoch: 499 Train Avg loss: 0.01160, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.82859, Acc:0.33784, F1: 0.33784
====> Epoch: 500 Train Avg loss: 0.01069, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 1.99263, Acc:0.32095, F1: 0.32095
#####> Valid Avg loss: 2.81685, Acc:0.40708, F1: 0.40708


$$$$$$> Test it 1: (from train best model) Final Test Avg loss:2.81685, Acc:0.40708, F1:0.40708\n
#####> Valid Avg loss: 0.68464, Acc:0.46903, F1: 0.46903


$$$$$$> Test it 1: (from max acc valid model) Final Test Avg loss:0.68464, Acc:0.46903, F1:0.46903\n
#####> Valid Avg loss: 0.68464, Acc:0.46903, F1: 0.46903


$$$$$$> Test it 1: (from min loss valid model) Final Test Avg loss:0.68464, Acc:0.46903, F1:0.46903\n


	Start execution training validation it 2 

train_dataloader len: 421
valid_dataloader len: 113
test_dataloader len: 444
train performers ids: [4, 5, 6]
valid performers ids: [1]
test performers ids: [2]
train dataset len: 842, train dataloader len: 421
valid dataset len: 226, valid dataloader len: 113
valid dataset len: 888, test dataloader len: 113
====> Epoch: 1 Train Avg loss: 0.68617, Acc: 0.55819, F1: 0.55819#####> Valid Avg loss: 0.87137, Acc:0.47345, F1: 0.47345
===> Epoch: 1: Training loss decreased (inf --> 0.68617), Acc: (0.00000 --> 0.55819), F1: (0.00000 --> 0.55819).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2

####> Epoch: 1: validation loss decreased (inf --> 0.87137), Acc: (0.00000 --> 0.47345), F1: (0.00000 --> 0.47345).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2

####> Epoch: 1: validation acc increase (inf --> 0.87137), Acc: (0.00000 --> 0.47345), F1: (0.00000 --> 0.47345).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 2 Train Avg loss: 0.62761, Acc: 0.58195, F1: 0.58195#####> Valid Avg loss: 0.71608, Acc:0.47345, F1: 0.47345
===> Epoch: 2: Training loss decreased (0.68617 --> 0.62761), Acc: (0.55819 --> 0.58195), F1: (0.55819 --> 0.58195).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2

####> Epoch: 2: validation loss decreased (0.87137 --> 0.71608), Acc: (0.47345 --> 0.47345), F1: (0.47345 --> 0.47345).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 3 Train Avg loss: 0.62087, Acc: 0.57363, F1: 0.57363#####> Valid Avg loss: 0.70718, Acc:0.47345, F1: 0.47345
===> Epoch: 3: Training loss decreased (0.62761 --> 0.62087), Acc: (0.58195 --> 0.57363), F1: (0.58195 --> 0.57363).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2

####> Epoch: 3: validation loss decreased (0.71608 --> 0.70718), Acc: (0.47345 --> 0.47345), F1: (0.47345 --> 0.47345).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 4 Train Avg loss: 0.60284, Acc: 0.57720, F1: 0.57720#####> Valid Avg loss: 0.73785, Acc:0.47345, F1: 0.47345
===> Epoch: 4: Training loss decreased (0.62087 --> 0.60284), Acc: (0.57363 --> 0.57720), F1: (0.57363 --> 0.57720).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 5 Train Avg loss: 0.59643, Acc: 0.57126, F1: 0.57126#####> Valid Avg loss: 0.73817, Acc:0.47345, F1: 0.47345
===> Epoch: 5: Training loss decreased (0.60284 --> 0.59643), Acc: (0.57720 --> 0.57126), F1: (0.57720 --> 0.57126).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 6 Train Avg loss: 0.58302, Acc: 0.59026, F1: 0.59026#####> Valid Avg loss: 0.77437, Acc:0.47345, F1: 0.47345
===> Epoch: 6: Training loss decreased (0.59643 --> 0.58302), Acc: (0.57126 --> 0.59026), F1: (0.57126 --> 0.59026).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 7 Train Avg loss: 0.57651, Acc: 0.57482, F1: 0.57482#####> Valid Avg loss: 0.75983, Acc:0.47345, F1: 0.47345
===> Epoch: 7: Training loss decreased (0.58302 --> 0.57651), Acc: (0.59026 --> 0.57482), F1: (0.59026 --> 0.57482).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 8 Train Avg loss: 0.56702, Acc: 0.58432, F1: 0.58432#####> Valid Avg loss: 0.79920, Acc:0.47345, F1: 0.47345
===> Epoch: 8: Training loss decreased (0.57651 --> 0.56702), Acc: (0.57482 --> 0.58432), F1: (0.57482 --> 0.58432).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 9 Train Avg loss: 0.56893, Acc: 0.58670, F1: 0.58670#####> Valid Avg loss: 0.72576, Acc:0.47345, F1: 0.47345
====> Epoch: 10 Train Avg loss: 0.54807, Acc: 0.60214, F1: 0.60214#####> Valid Avg loss: 0.74313, Acc:0.45133, F1: 0.45133
===> Epoch: 10: Training loss decreased (0.56702 --> 0.54807), Acc: (0.58432 --> 0.60214), F1: (0.58432 --> 0.60214).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 11 Train Avg loss: 0.55201, Acc: 0.59976, F1: 0.59976#####> Valid Avg loss: 0.90237, Acc:0.47345, F1: 0.47345
====> Epoch: 12 Train Avg loss: 0.54244, Acc: 0.60214, F1: 0.60214#####> Valid Avg loss: 0.83298, Acc:0.47345, F1: 0.47345
===> Epoch: 12: Training loss decreased (0.54807 --> 0.54244), Acc: (0.60214 --> 0.60214), F1: (0.60214 --> 0.60214).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 13 Train Avg loss: 0.52715, Acc: 0.60095, F1: 0.60095#####> Valid Avg loss: 0.71611, Acc:0.45575, F1: 0.45575
===> Epoch: 13: Training loss decreased (0.54244 --> 0.52715), Acc: (0.60214 --> 0.60095), F1: (0.60214 --> 0.60095).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 14 Train Avg loss: 0.52427, Acc: 0.61401, F1: 0.61401#####> Valid Avg loss: 0.72089, Acc:0.45575, F1: 0.45575
===> Epoch: 14: Training loss decreased (0.52715 --> 0.52427), Acc: (0.60095 --> 0.61401), F1: (0.60095 --> 0.61401).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 15 Train Avg loss: 0.53344, Acc: 0.60926, F1: 0.60926#####> Valid Avg loss: 0.78184, Acc:0.47345, F1: 0.47345
====> Epoch: 16 Train Avg loss: 0.50966, Acc: 0.60808, F1: 0.60808#####> Valid Avg loss: 0.76574, Acc:0.40708, F1: 0.40708
===> Epoch: 16: Training loss decreased (0.52427 --> 0.50966), Acc: (0.61401 --> 0.60808), F1: (0.61401 --> 0.60808).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 17 Train Avg loss: 0.49679, Acc: 0.62352, F1: 0.62352#####> Valid Avg loss: 0.86727, Acc:0.45575, F1: 0.45575
===> Epoch: 17: Training loss decreased (0.50966 --> 0.49679), Acc: (0.60808 --> 0.62352), F1: (0.60808 --> 0.62352).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 18 Train Avg loss: 0.49567, Acc: 0.61164, F1: 0.61164#####> Valid Avg loss: 0.78484, Acc:0.44690, F1: 0.44690
===> Epoch: 18: Training loss decreased (0.49679 --> 0.49567), Acc: (0.62352 --> 0.61164), F1: (0.62352 --> 0.61164).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 19 Train Avg loss: 0.48577, Acc: 0.61995, F1: 0.61995#####> Valid Avg loss: 0.80426, Acc:0.45575, F1: 0.45575
===> Epoch: 19: Training loss decreased (0.49567 --> 0.48577), Acc: (0.61164 --> 0.61995), F1: (0.61164 --> 0.61995).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 20 Train Avg loss: 0.47015, Acc: 0.64489, F1: 0.64489#####> Valid Avg loss: 0.94033, Acc:0.46018, F1: 0.46018
===> Epoch: 20: Training loss decreased (0.48577 --> 0.47015), Acc: (0.61995 --> 0.64489), F1: (0.61995 --> 0.64489).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 21 Train Avg loss: 0.46795, Acc: 0.64489, F1: 0.64489#####> Valid Avg loss: 0.84592, Acc:0.41150, F1: 0.41150
===> Epoch: 21: Training loss decreased (0.47015 --> 0.46795), Acc: (0.64489 --> 0.64489), F1: (0.64489 --> 0.64489).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 22 Train Avg loss: 0.45383, Acc: 0.65439, F1: 0.65439#####> Valid Avg loss: 0.79127, Acc:0.45133, F1: 0.45133
===> Epoch: 22: Training loss decreased (0.46795 --> 0.45383), Acc: (0.64489 --> 0.65439), F1: (0.64489 --> 0.65439).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 23 Train Avg loss: 0.44383, Acc: 0.66152, F1: 0.66152#####> Valid Avg loss: 0.83013, Acc:0.46018, F1: 0.46018
===> Epoch: 23: Training loss decreased (0.45383 --> 0.44383), Acc: (0.65439 --> 0.66152), F1: (0.65439 --> 0.66152).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 24 Train Avg loss: 0.43533, Acc: 0.66033, F1: 0.66033#####> Valid Avg loss: 0.84238, Acc:0.46018, F1: 0.46018
===> Epoch: 24: Training loss decreased (0.44383 --> 0.43533), Acc: (0.66152 --> 0.66033), F1: (0.66152 --> 0.66033).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 25 Train Avg loss: 0.41508, Acc: 0.68052, F1: 0.68052#####> Valid Avg loss: 1.03518, Acc:0.47345, F1: 0.47345
===> Epoch: 25: Training loss decreased (0.43533 --> 0.41508), Acc: (0.66033 --> 0.68052), F1: (0.66033 --> 0.68052).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 26 Train Avg loss: 0.40336, Acc: 0.68646, F1: 0.68646#####> Valid Avg loss: 0.92178, Acc:0.45575, F1: 0.45575
===> Epoch: 26: Training loss decreased (0.41508 --> 0.40336), Acc: (0.68052 --> 0.68646), F1: (0.68052 --> 0.68646).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 27 Train Avg loss: 0.38214, Acc: 0.69359, F1: 0.69359#####> Valid Avg loss: 0.87772, Acc:0.38496, F1: 0.38496
===> Epoch: 27: Training loss decreased (0.40336 --> 0.38214), Acc: (0.68646 --> 0.69359), F1: (0.68646 --> 0.69359).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 28 Train Avg loss: 0.38198, Acc: 0.70665, F1: 0.70665#####> Valid Avg loss: 0.91360, Acc:0.44248, F1: 0.44248
===> Epoch: 28: Training loss decreased (0.38214 --> 0.38198), Acc: (0.69359 --> 0.70665), F1: (0.69359 --> 0.70665).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 29 Train Avg loss: 0.37170, Acc: 0.69834, F1: 0.69834#####> Valid Avg loss: 1.14281, Acc:0.45575, F1: 0.45575
===> Epoch: 29: Training loss decreased (0.38198 --> 0.37170), Acc: (0.70665 --> 0.69834), F1: (0.70665 --> 0.69834).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 30 Train Avg loss: 0.35733, Acc: 0.72447, F1: 0.72447#####> Valid Avg loss: 0.95380, Acc:0.42920, F1: 0.42920
===> Epoch: 30: Training loss decreased (0.37170 --> 0.35733), Acc: (0.69834 --> 0.72447), F1: (0.69834 --> 0.72447).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 31 Train Avg loss: 0.35187, Acc: 0.72447, F1: 0.72447#####> Valid Avg loss: 1.02941, Acc:0.44248, F1: 0.44248
===> Epoch: 31: Training loss decreased (0.35733 --> 0.35187), Acc: (0.72447 --> 0.72447), F1: (0.72447 --> 0.72447).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 32 Train Avg loss: 0.35228, Acc: 0.71971, F1: 0.71971#####> Valid Avg loss: 0.99417, Acc:0.45133, F1: 0.45133
====> Epoch: 33 Train Avg loss: 0.33535, Acc: 0.73753, F1: 0.73753#####> Valid Avg loss: 1.00825, Acc:0.38053, F1: 0.38053
===> Epoch: 33: Training loss decreased (0.35187 --> 0.33535), Acc: (0.72447 --> 0.73753), F1: (0.72447 --> 0.73753).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 34 Train Avg loss: 0.31125, Acc: 0.76010, F1: 0.76010#####> Valid Avg loss: 1.06089, Acc:0.41593, F1: 0.41593
===> Epoch: 34: Training loss decreased (0.33535 --> 0.31125), Acc: (0.73753 --> 0.76010), F1: (0.73753 --> 0.76010).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 35 Train Avg loss: 0.30802, Acc: 0.76722, F1: 0.76722#####> Valid Avg loss: 1.08124, Acc:0.41150, F1: 0.41150
===> Epoch: 35: Training loss decreased (0.31125 --> 0.30802), Acc: (0.76010 --> 0.76722), F1: (0.76010 --> 0.76722).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 36 Train Avg loss: 0.27831, Acc: 0.77672, F1: 0.77672#####> Valid Avg loss: 1.13527, Acc:0.44248, F1: 0.44248
===> Epoch: 36: Training loss decreased (0.30802 --> 0.27831), Acc: (0.76722 --> 0.77672), F1: (0.76722 --> 0.77672).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 37 Train Avg loss: 0.26722, Acc: 0.79691, F1: 0.79691#####> Valid Avg loss: 1.08590, Acc:0.39823, F1: 0.39823
===> Epoch: 37: Training loss decreased (0.27831 --> 0.26722), Acc: (0.77672 --> 0.79691), F1: (0.77672 --> 0.79691).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 38 Train Avg loss: 0.25791, Acc: 0.79691, F1: 0.79691#####> Valid Avg loss: 1.10807, Acc:0.41593, F1: 0.41593
===> Epoch: 38: Training loss decreased (0.26722 --> 0.25791), Acc: (0.79691 --> 0.79691), F1: (0.79691 --> 0.79691).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 39 Train Avg loss: 0.22975, Acc: 0.80879, F1: 0.80879#####> Valid Avg loss: 1.35914, Acc:0.40708, F1: 0.40708
===> Epoch: 39: Training loss decreased (0.25791 --> 0.22975), Acc: (0.79691 --> 0.80879), F1: (0.79691 --> 0.80879).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 40 Train Avg loss: 0.21842, Acc: 0.82779, F1: 0.82779#####> Valid Avg loss: 1.52484, Acc:0.34071, F1: 0.34071
===> Epoch: 40: Training loss decreased (0.22975 --> 0.21842), Acc: (0.80879 --> 0.82779), F1: (0.80879 --> 0.82779).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 41 Train Avg loss: 0.24957, Acc: 0.78029, F1: 0.78029#####> Valid Avg loss: 1.19834, Acc:0.37611, F1: 0.37611
====> Epoch: 42 Train Avg loss: 0.21211, Acc: 0.82779, F1: 0.82779#####> Valid Avg loss: 1.43005, Acc:0.39823, F1: 0.39823
===> Epoch: 42: Training loss decreased (0.21842 --> 0.21211), Acc: (0.82779 --> 0.82779), F1: (0.82779 --> 0.82779).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 43 Train Avg loss: 0.18150, Acc: 0.84679, F1: 0.84679#####> Valid Avg loss: 1.57683, Acc:0.34513, F1: 0.34513
===> Epoch: 43: Training loss decreased (0.21211 --> 0.18150), Acc: (0.82779 --> 0.84679), F1: (0.82779 --> 0.84679).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 44 Train Avg loss: 0.20336, Acc: 0.83135, F1: 0.83135#####> Valid Avg loss: 1.45400, Acc:0.35841, F1: 0.35841
====> Epoch: 45 Train Avg loss: 0.16249, Acc: 0.87055, F1: 0.87055#####> Valid Avg loss: 1.54045, Acc:0.43363, F1: 0.43363
===> Epoch: 45: Training loss decreased (0.18150 --> 0.16249), Acc: (0.84679 --> 0.87055), F1: (0.84679 --> 0.87055).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 46 Train Avg loss: 0.14354, Acc: 0.88717, F1: 0.88717#####> Valid Avg loss: 1.74224, Acc:0.38053, F1: 0.38053
===> Epoch: 46: Training loss decreased (0.16249 --> 0.14354), Acc: (0.87055 --> 0.88717), F1: (0.87055 --> 0.88717).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 47 Train Avg loss: 0.13516, Acc: 0.89667, F1: 0.89667#####> Valid Avg loss: 1.69306, Acc:0.39381, F1: 0.39381
===> Epoch: 47: Training loss decreased (0.14354 --> 0.13516), Acc: (0.88717 --> 0.89667), F1: (0.88717 --> 0.89667).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 48 Train Avg loss: 0.18072, Acc: 0.87055, F1: 0.87055#####> Valid Avg loss: 1.50897, Acc:0.35398, F1: 0.35398
====> Epoch: 49 Train Avg loss: 0.13096, Acc: 0.88599, F1: 0.88599#####> Valid Avg loss: 1.70230, Acc:0.32301, F1: 0.32301
===> Epoch: 49: Training loss decreased (0.13516 --> 0.13096), Acc: (0.89667 --> 0.88599), F1: (0.89667 --> 0.88599).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 50 Train Avg loss: 0.12802, Acc: 0.89549, F1: 0.89549#####> Valid Avg loss: 1.84469, Acc:0.36283, F1: 0.36283
===> Epoch: 50: Training loss decreased (0.13096 --> 0.12802), Acc: (0.88599 --> 0.89549), F1: (0.88599 --> 0.89549).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 51 Train Avg loss: 0.10249, Acc: 0.92043, F1: 0.92043#####> Valid Avg loss: 2.05298, Acc:0.40708, F1: 0.40708
===> Epoch: 51: Training loss decreased (0.12802 --> 0.10249), Acc: (0.89549 --> 0.92043), F1: (0.89549 --> 0.92043).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 52 Train Avg loss: 0.08537, Acc: 0.93230, F1: 0.93230#####> Valid Avg loss: 2.02782, Acc:0.36283, F1: 0.36283
===> Epoch: 52: Training loss decreased (0.10249 --> 0.08537), Acc: (0.92043 --> 0.93230), F1: (0.92043 --> 0.93230).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 53 Train Avg loss: 0.08750, Acc: 0.93587, F1: 0.93587#####> Valid Avg loss: 2.05970, Acc:0.39823, F1: 0.39823
====> Epoch: 54 Train Avg loss: 0.08453, Acc: 0.93943, F1: 0.93943#####> Valid Avg loss: 1.93981, Acc:0.37168, F1: 0.37168
===> Epoch: 54: Training loss decreased (0.08537 --> 0.08453), Acc: (0.93230 --> 0.93943), F1: (0.93230 --> 0.93943).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 55 Train Avg loss: 0.10377, Acc: 0.92280, F1: 0.92280#####> Valid Avg loss: 2.08573, Acc:0.39381, F1: 0.39381
====> Epoch: 56 Train Avg loss: 0.06157, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 2.19520, Acc:0.38938, F1: 0.38938
===> Epoch: 56: Training loss decreased (0.08453 --> 0.06157), Acc: (0.93943 --> 0.95487), F1: (0.93943 --> 0.95487).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 57 Train Avg loss: 0.06074, Acc: 0.94418, F1: 0.94418#####> Valid Avg loss: 2.22610, Acc:0.35398, F1: 0.35398
===> Epoch: 57: Training loss decreased (0.06157 --> 0.06074), Acc: (0.95487 --> 0.94418), F1: (0.95487 --> 0.94418).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 58 Train Avg loss: 0.05723, Acc: 0.94893, F1: 0.94893#####> Valid Avg loss: 2.41882, Acc:0.37168, F1: 0.37168
===> Epoch: 58: Training loss decreased (0.06074 --> 0.05723), Acc: (0.94418 --> 0.94893), F1: (0.94418 --> 0.94893).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 59 Train Avg loss: 0.07183, Acc: 0.94774, F1: 0.94774#####> Valid Avg loss: 2.31906, Acc:0.35841, F1: 0.35841
====> Epoch: 60 Train Avg loss: 0.05276, Acc: 0.96318, F1: 0.96318#####> Valid Avg loss: 2.57514, Acc:0.38496, F1: 0.38496
===> Epoch: 60: Training loss decreased (0.05723 --> 0.05276), Acc: (0.94893 --> 0.96318), F1: (0.94893 --> 0.96318).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 61 Train Avg loss: 0.04777, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 2.44071, Acc:0.34071, F1: 0.34071
===> Epoch: 61: Training loss decreased (0.05276 --> 0.04777), Acc: (0.96318 --> 0.96675), F1: (0.96318 --> 0.96675).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 62 Train Avg loss: 0.03915, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.57269, Acc:0.38496, F1: 0.38496
===> Epoch: 62: Training loss decreased (0.04777 --> 0.03915), Acc: (0.96675 --> 0.97031), F1: (0.96675 --> 0.97031).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 63 Train Avg loss: 0.05685, Acc: 0.95368, F1: 0.95368#####> Valid Avg loss: 2.55203, Acc:0.35841, F1: 0.35841
====> Epoch: 64 Train Avg loss: 0.03394, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.51559, Acc:0.36726, F1: 0.36726
===> Epoch: 64: Training loss decreased (0.03915 --> 0.03394), Acc: (0.97031 --> 0.97031), F1: (0.97031 --> 0.97031).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 65 Train Avg loss: 0.03699, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 2.55798, Acc:0.35841, F1: 0.35841
====> Epoch: 66 Train Avg loss: 0.02905, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.85927, Acc:0.34956, F1: 0.34956
===> Epoch: 66: Training loss decreased (0.03394 --> 0.02905), Acc: (0.97031 --> 0.97031), F1: (0.97031 --> 0.97031).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 67 Train Avg loss: 0.02930, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.87528, Acc:0.38938, F1: 0.38938
====> Epoch: 68 Train Avg loss: 0.05437, Acc: 0.96318, F1: 0.96318#####> Valid Avg loss: 2.58584, Acc:0.37168, F1: 0.37168
====> Epoch: 69 Train Avg loss: 0.02372, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.69977, Acc:0.34956, F1: 0.34956
===> Epoch: 69: Training loss decreased (0.02905 --> 0.02372), Acc: (0.97031 --> 0.97625), F1: (0.97031 --> 0.97625).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 70 Train Avg loss: 0.02915, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.63612, Acc:0.35841, F1: 0.35841
====> Epoch: 71 Train Avg loss: 0.02194, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.53882, Acc:0.34071, F1: 0.34071
===> Epoch: 71: Training loss decreased (0.02372 --> 0.02194), Acc: (0.97625 --> 0.97981), F1: (0.97625 --> 0.97981).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 72 Train Avg loss: 0.02185, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.71369, Acc:0.36283, F1: 0.36283
===> Epoch: 72: Training loss decreased (0.02194 --> 0.02185), Acc: (0.97981 --> 0.98100), F1: (0.97981 --> 0.98100).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 73 Train Avg loss: 0.02028, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.65643, Acc:0.34956, F1: 0.34956
===> Epoch: 73: Training loss decreased (0.02185 --> 0.02028), Acc: (0.98100 --> 0.97625), F1: (0.98100 --> 0.97625).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 74 Train Avg loss: 0.01657, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.64159, Acc:0.33186, F1: 0.33186
===> Epoch: 74: Training loss decreased (0.02028 --> 0.01657), Acc: (0.97625 --> 0.98575), F1: (0.97625 --> 0.98575).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 75 Train Avg loss: 0.01777, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.66761, Acc:0.37168, F1: 0.37168
====> Epoch: 76 Train Avg loss: 0.01907, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.65143, Acc:0.35398, F1: 0.35398
====> Epoch: 77 Train Avg loss: 0.01990, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.66144, Acc:0.35398, F1: 0.35398
====> Epoch: 78 Train Avg loss: 0.01421, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.76961, Acc:0.35841, F1: 0.35841
===> Epoch: 78: Training loss decreased (0.01657 --> 0.01421), Acc: (0.98575 --> 0.98337), F1: (0.98575 --> 0.98337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 79 Train Avg loss: 0.01437, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.75567, Acc:0.37168, F1: 0.37168
====> Epoch: 80 Train Avg loss: 0.01481, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.82782, Acc:0.34071, F1: 0.34071
====> Epoch: 81 Train Avg loss: 0.01698, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 3.03881, Acc:0.36283, F1: 0.36283
====> Epoch: 82 Train Avg loss: 0.01280, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.96348, Acc:0.35841, F1: 0.35841
===> Epoch: 82: Training loss decreased (0.01421 --> 0.01280), Acc: (0.98337 --> 0.98337), F1: (0.98337 --> 0.98337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 83 Train Avg loss: 0.01578, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.95124, Acc:0.37168, F1: 0.37168
====> Epoch: 84 Train Avg loss: 0.01427, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.87467, Acc:0.34513, F1: 0.34513
====> Epoch: 85 Train Avg loss: 0.01466, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 3.01161, Acc:0.35841, F1: 0.35841
====> Epoch: 86 Train Avg loss: 0.01199, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.88707, Acc:0.34513, F1: 0.34513
===> Epoch: 86: Training loss decreased (0.01280 --> 0.01199), Acc: (0.98337 --> 0.97981), F1: (0.98337 --> 0.97981).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 87 Train Avg loss: 0.01161, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 3.05563, Acc:0.35841, F1: 0.35841
===> Epoch: 87: Training loss decreased (0.01199 --> 0.01161), Acc: (0.97981 --> 0.98337), F1: (0.97981 --> 0.98337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 88 Train Avg loss: 0.01088, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.91191, Acc:0.34956, F1: 0.34956
===> Epoch: 88: Training loss decreased (0.01161 --> 0.01088), Acc: (0.98337 --> 0.98219), F1: (0.98337 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 89 Train Avg loss: 0.01103, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.84457, Acc:0.35841, F1: 0.35841
====> Epoch: 90 Train Avg loss: 0.01065, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.88232, Acc:0.35841, F1: 0.35841
===> Epoch: 90: Training loss decreased (0.01088 --> 0.01065), Acc: (0.98219 --> 0.98456), F1: (0.98219 --> 0.98456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 91 Train Avg loss: 0.01041, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.97795, Acc:0.34956, F1: 0.34956
===> Epoch: 91: Training loss decreased (0.01065 --> 0.01041), Acc: (0.98456 --> 0.98456), F1: (0.98456 --> 0.98456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 92 Train Avg loss: 0.01238, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.98571, Acc:0.35841, F1: 0.35841
====> Epoch: 93 Train Avg loss: 0.01085, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.81373, Acc:0.34513, F1: 0.34513
====> Epoch: 94 Train Avg loss: 0.01111, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 3.02089, Acc:0.36283, F1: 0.36283
====> Epoch: 95 Train Avg loss: 0.00932, Acc: 0.99406, F1: 0.99406#####> Valid Avg loss: 2.85226, Acc:0.36283, F1: 0.36283
===> Epoch: 95: Training loss decreased (0.01041 --> 0.00932), Acc: (0.98456 --> 0.99406), F1: (0.98456 --> 0.99406).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 96 Train Avg loss: 0.01281, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.98283, Acc:0.35841, F1: 0.35841
====> Epoch: 97 Train Avg loss: 0.01031, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 3.05535, Acc:0.35841, F1: 0.35841
====> Epoch: 98 Train Avg loss: 0.01212, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.96718, Acc:0.36283, F1: 0.36283
====> Epoch: 99 Train Avg loss: 0.00934, Acc: 0.98812, F1: 0.98812#####> Valid Avg loss: 2.91177, Acc:0.35841, F1: 0.35841
====> Epoch: 100 Train Avg loss: 0.64301, Acc: 0.61401, F1: 0.61401#####> Valid Avg loss: 0.77018, Acc:0.42920, F1: 0.42920
====> Epoch: 101 Train Avg loss: 0.50173, Acc: 0.61995, F1: 0.61995#####> Valid Avg loss: 0.92331, Acc:0.45575, F1: 0.45575
====> Epoch: 102 Train Avg loss: 0.44295, Acc: 0.67102, F1: 0.67102#####> Valid Avg loss: 0.89533, Acc:0.45575, F1: 0.45575
====> Epoch: 103 Train Avg loss: 0.43193, Acc: 0.67458, F1: 0.67458#####> Valid Avg loss: 0.93013, Acc:0.39823, F1: 0.39823
====> Epoch: 104 Train Avg loss: 0.42583, Acc: 0.66390, F1: 0.66390#####> Valid Avg loss: 0.91277, Acc:0.46018, F1: 0.46018
====> Epoch: 105 Train Avg loss: 0.39478, Acc: 0.69240, F1: 0.69240#####> Valid Avg loss: 0.87578, Acc:0.44248, F1: 0.44248
====> Epoch: 106 Train Avg loss: 0.36931, Acc: 0.70784, F1: 0.70784#####> Valid Avg loss: 1.24924, Acc:0.28319, F1: 0.28319
====> Epoch: 107 Train Avg loss: 0.37127, Acc: 0.70903, F1: 0.70903#####> Valid Avg loss: 1.06565, Acc:0.45575, F1: 0.45575
====> Epoch: 108 Train Avg loss: 0.34153, Acc: 0.73040, F1: 0.73040#####> Valid Avg loss: 0.96952, Acc:0.40265, F1: 0.40265
====> Epoch: 109 Train Avg loss: 0.32033, Acc: 0.75178, F1: 0.75178#####> Valid Avg loss: 1.12876, Acc:0.39823, F1: 0.39823
====> Epoch: 110 Train Avg loss: 0.31394, Acc: 0.76128, F1: 0.76128#####> Valid Avg loss: 1.15752, Acc:0.40708, F1: 0.40708
====> Epoch: 111 Train Avg loss: 0.24483, Acc: 0.80760, F1: 0.80760#####> Valid Avg loss: 1.27051, Acc:0.46460, F1: 0.46460
====> Epoch: 112 Train Avg loss: 0.24280, Acc: 0.83017, F1: 0.83017#####> Valid Avg loss: 1.34843, Acc:0.43363, F1: 0.43363
====> Epoch: 113 Train Avg loss: 0.19121, Acc: 0.84323, F1: 0.84323#####> Valid Avg loss: 1.39653, Acc:0.42478, F1: 0.42478
====> Epoch: 114 Train Avg loss: 0.19380, Acc: 0.84442, F1: 0.84442#####> Valid Avg loss: 1.15680, Acc:0.40265, F1: 0.40265
====> Epoch: 115 Train Avg loss: 0.18477, Acc: 0.84917, F1: 0.84917#####> Valid Avg loss: 1.48935, Acc:0.31858, F1: 0.31858
====> Epoch: 116 Train Avg loss: 0.19884, Acc: 0.84204, F1: 0.84204#####> Valid Avg loss: 1.37314, Acc:0.31416, F1: 0.31416
====> Epoch: 117 Train Avg loss: 0.15726, Acc: 0.86698, F1: 0.86698#####> Valid Avg loss: 1.50234, Acc:0.36283, F1: 0.36283
====> Epoch: 118 Train Avg loss: 0.18497, Acc: 0.85867, F1: 0.85867#####> Valid Avg loss: 1.50815, Acc:0.35398, F1: 0.35398
====> Epoch: 119 Train Avg loss: 0.16935, Acc: 0.88124, F1: 0.88124#####> Valid Avg loss: 1.36031, Acc:0.37611, F1: 0.37611
====> Epoch: 120 Train Avg loss: 0.13803, Acc: 0.90024, F1: 0.90024#####> Valid Avg loss: 1.49673, Acc:0.34956, F1: 0.34956
====> Epoch: 121 Train Avg loss: 0.11626, Acc: 0.91924, F1: 0.91924#####> Valid Avg loss: 1.72111, Acc:0.38496, F1: 0.38496
====> Epoch: 122 Train Avg loss: 0.13251, Acc: 0.89667, F1: 0.89667#####> Valid Avg loss: 1.58452, Acc:0.40708, F1: 0.40708
====> Epoch: 123 Train Avg loss: 0.09602, Acc: 0.93824, F1: 0.93824#####> Valid Avg loss: 1.73462, Acc:0.38053, F1: 0.38053
====> Epoch: 124 Train Avg loss: 0.20393, Acc: 0.84798, F1: 0.84798#####> Valid Avg loss: 1.59865, Acc:0.37168, F1: 0.37168
====> Epoch: 125 Train Avg loss: 0.12391, Acc: 0.90736, F1: 0.90736#####> Valid Avg loss: 1.51846, Acc:0.35398, F1: 0.35398
====> Epoch: 126 Train Avg loss: 0.11141, Acc: 0.91686, F1: 0.91686#####> Valid Avg loss: 1.67313, Acc:0.46018, F1: 0.46018
====> Epoch: 127 Train Avg loss: 0.14746, Acc: 0.88955, F1: 0.88955#####> Valid Avg loss: 2.02748, Acc:0.36283, F1: 0.36283
====> Epoch: 128 Train Avg loss: 0.13756, Acc: 0.90618, F1: 0.90618#####> Valid Avg loss: 1.56941, Acc:0.34513, F1: 0.34513
====> Epoch: 129 Train Avg loss: 0.13032, Acc: 0.88955, F1: 0.88955#####> Valid Avg loss: 1.71119, Acc:0.42478, F1: 0.42478
====> Epoch: 130 Train Avg loss: 0.09710, Acc: 0.92280, F1: 0.92280#####> Valid Avg loss: 1.69324, Acc:0.35398, F1: 0.35398
====> Epoch: 131 Train Avg loss: 0.09655, Acc: 0.93112, F1: 0.93112#####> Valid Avg loss: 1.85873, Acc:0.39381, F1: 0.39381
====> Epoch: 132 Train Avg loss: 0.11546, Acc: 0.91330, F1: 0.91330#####> Valid Avg loss: 1.82603, Acc:0.38938, F1: 0.38938
====> Epoch: 133 Train Avg loss: 0.09583, Acc: 0.93112, F1: 0.93112#####> Valid Avg loss: 2.07070, Acc:0.44248, F1: 0.44248
====> Epoch: 134 Train Avg loss: 0.09586, Acc: 0.92755, F1: 0.92755#####> Valid Avg loss: 2.08490, Acc:0.38938, F1: 0.38938
====> Epoch: 135 Train Avg loss: 0.08558, Acc: 0.93112, F1: 0.93112#####> Valid Avg loss: 1.98919, Acc:0.40708, F1: 0.40708
====> Epoch: 136 Train Avg loss: 0.06332, Acc: 0.95606, F1: 0.95606#####> Valid Avg loss: 2.17752, Acc:0.33186, F1: 0.33186
====> Epoch: 137 Train Avg loss: 0.12132, Acc: 0.91805, F1: 0.91805#####> Valid Avg loss: 2.02805, Acc:0.35398, F1: 0.35398
====> Epoch: 138 Train Avg loss: 0.07503, Acc: 0.94299, F1: 0.94299#####> Valid Avg loss: 1.99696, Acc:0.33186, F1: 0.33186
====> Epoch: 139 Train Avg loss: 0.07876, Acc: 0.94062, F1: 0.94062#####> Valid Avg loss: 2.18492, Acc:0.38496, F1: 0.38496
====> Epoch: 140 Train Avg loss: 0.10566, Acc: 0.92043, F1: 0.92043#####> Valid Avg loss: 1.82298, Acc:0.37168, F1: 0.37168
====> Epoch: 141 Train Avg loss: 0.07922, Acc: 0.94299, F1: 0.94299#####> Valid Avg loss: 1.98708, Acc:0.34513, F1: 0.34513
====> Epoch: 142 Train Avg loss: 0.08532, Acc: 0.93349, F1: 0.93349#####> Valid Avg loss: 1.83061, Acc:0.37168, F1: 0.37168
====> Epoch: 143 Train Avg loss: 0.13738, Acc: 0.90261, F1: 0.90261#####> Valid Avg loss: 1.76300, Acc:0.37611, F1: 0.37611
====> Epoch: 144 Train Avg loss: 0.04422, Acc: 0.97150, F1: 0.97150#####> Valid Avg loss: 2.00933, Acc:0.36283, F1: 0.36283
====> Epoch: 145 Train Avg loss: 0.08916, Acc: 0.93112, F1: 0.93112#####> Valid Avg loss: 2.05059, Acc:0.38496, F1: 0.38496
====> Epoch: 146 Train Avg loss: 0.08254, Acc: 0.93705, F1: 0.93705#####> Valid Avg loss: 1.90641, Acc:0.24779, F1: 0.24779
====> Epoch: 147 Train Avg loss: 0.06744, Acc: 0.94893, F1: 0.94893#####> Valid Avg loss: 1.90580, Acc:0.34956, F1: 0.34956
====> Epoch: 148 Train Avg loss: 0.04108, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 2.12393, Acc:0.41150, F1: 0.41150
====> Epoch: 149 Train Avg loss: 0.06467, Acc: 0.95012, F1: 0.95012#####> Valid Avg loss: 2.13141, Acc:0.35841, F1: 0.35841
====> Epoch: 150 Train Avg loss: 0.07135, Acc: 0.94418, F1: 0.94418#####> Valid Avg loss: 2.18617, Acc:0.37611, F1: 0.37611
====> Epoch: 151 Train Avg loss: 0.07997, Acc: 0.93349, F1: 0.93349#####> Valid Avg loss: 1.98473, Acc:0.34071, F1: 0.34071
====> Epoch: 152 Train Avg loss: 0.03156, Acc: 0.97150, F1: 0.97150#####> Valid Avg loss: 2.35543, Acc:0.34513, F1: 0.34513
====> Epoch: 153 Train Avg loss: 0.04377, Acc: 0.96556, F1: 0.96556#####> Valid Avg loss: 2.29580, Acc:0.41150, F1: 0.41150
====> Epoch: 154 Train Avg loss: 0.11547, Acc: 0.92043, F1: 0.92043#####> Valid Avg loss: 1.77072, Acc:0.38496, F1: 0.38496
====> Epoch: 155 Train Avg loss: 0.05507, Acc: 0.96081, F1: 0.96081#####> Valid Avg loss: 2.00844, Acc:0.35398, F1: 0.35398
====> Epoch: 156 Train Avg loss: 0.04731, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 2.04033, Acc:0.28319, F1: 0.28319
====> Epoch: 157 Train Avg loss: 0.04441, Acc: 0.96318, F1: 0.96318#####> Valid Avg loss: 2.06104, Acc:0.33186, F1: 0.33186
====> Epoch: 158 Train Avg loss: 0.01631, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.17918, Acc:0.35398, F1: 0.35398
====> Epoch: 159 Train Avg loss: 0.01604, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.23340, Acc:0.30973, F1: 0.30973
====> Epoch: 160 Train Avg loss: 0.11233, Acc: 0.91924, F1: 0.91924#####> Valid Avg loss: 2.01425, Acc:0.36283, F1: 0.36283
====> Epoch: 161 Train Avg loss: 0.02548, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.34742, Acc:0.34513, F1: 0.34513
====> Epoch: 162 Train Avg loss: 0.10658, Acc: 0.92874, F1: 0.92874#####> Valid Avg loss: 1.92093, Acc:0.33186, F1: 0.33186
====> Epoch: 163 Train Avg loss: 0.03502, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 1.97252, Acc:0.35398, F1: 0.35398
====> Epoch: 164 Train Avg loss: 0.02040, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.16338, Acc:0.37168, F1: 0.37168
====> Epoch: 165 Train Avg loss: 0.01786, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.26013, Acc:0.36726, F1: 0.36726
====> Epoch: 166 Train Avg loss: 0.01500, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.47638, Acc:0.33628, F1: 0.33628
====> Epoch: 167 Train Avg loss: 0.08803, Acc: 0.94537, F1: 0.94537#####> Valid Avg loss: 1.89410, Acc:0.36283, F1: 0.36283
====> Epoch: 168 Train Avg loss: 0.14395, Acc: 0.89905, F1: 0.89905#####> Valid Avg loss: 1.89818, Acc:0.35398, F1: 0.35398
====> Epoch: 169 Train Avg loss: 0.02852, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.02922, Acc:0.38053, F1: 0.38053
====> Epoch: 170 Train Avg loss: 0.05164, Acc: 0.95368, F1: 0.95368#####> Valid Avg loss: 1.99119, Acc:0.26991, F1: 0.26991
====> Epoch: 171 Train Avg loss: 0.05105, Acc: 0.95843, F1: 0.95843#####> Valid Avg loss: 2.21433, Acc:0.35398, F1: 0.35398
====> Epoch: 172 Train Avg loss: 0.01999, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.27706, Acc:0.38053, F1: 0.38053
====> Epoch: 173 Train Avg loss: 0.01645, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 1.95766, Acc:0.39381, F1: 0.39381
====> Epoch: 174 Train Avg loss: 0.12488, Acc: 0.90143, F1: 0.90143#####> Valid Avg loss: 2.26580, Acc:0.35398, F1: 0.35398
====> Epoch: 175 Train Avg loss: 0.03565, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.18821, Acc:0.32743, F1: 0.32743
====> Epoch: 176 Train Avg loss: 0.06330, Acc: 0.94893, F1: 0.94893#####> Valid Avg loss: 2.18720, Acc:0.36283, F1: 0.36283
====> Epoch: 177 Train Avg loss: 0.02171, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.23893, Acc:0.39823, F1: 0.39823
====> Epoch: 178 Train Avg loss: 0.01656, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.20257, Acc:0.33628, F1: 0.33628
====> Epoch: 179 Train Avg loss: 0.01790, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.12216, Acc:0.37611, F1: 0.37611
====> Epoch: 180 Train Avg loss: 0.09411, Acc: 0.93943, F1: 0.93943#####> Valid Avg loss: 2.01337, Acc:0.30973, F1: 0.30973
====> Epoch: 181 Train Avg loss: 0.02256, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.10333, Acc:0.38496, F1: 0.38496
====> Epoch: 182 Train Avg loss: 0.03152, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.31827, Acc:0.35398, F1: 0.35398
====> Epoch: 183 Train Avg loss: 0.03169, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.23960, Acc:0.34513, F1: 0.34513
====> Epoch: 184 Train Avg loss: 0.05769, Acc: 0.96081, F1: 0.96081#####> Valid Avg loss: 2.23995, Acc:0.35398, F1: 0.35398
====> Epoch: 185 Train Avg loss: 0.02347, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 2.25576, Acc:0.33186, F1: 0.33186
====> Epoch: 186 Train Avg loss: 0.01877, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.28225, Acc:0.32301, F1: 0.32301
====> Epoch: 187 Train Avg loss: 0.01584, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.42838, Acc:0.32301, F1: 0.32301
====> Epoch: 188 Train Avg loss: 0.01465, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.50234, Acc:0.36283, F1: 0.36283
====> Epoch: 189 Train Avg loss: 0.08017, Acc: 0.94537, F1: 0.94537#####> Valid Avg loss: 2.20872, Acc:0.35841, F1: 0.35841
====> Epoch: 190 Train Avg loss: 0.02362, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.21482, Acc:0.37611, F1: 0.37611
====> Epoch: 191 Train Avg loss: 0.02905, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.36442, Acc:0.36726, F1: 0.36726
====> Epoch: 192 Train Avg loss: 0.02588, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.39983, Acc:0.35398, F1: 0.35398
====> Epoch: 193 Train Avg loss: 0.05828, Acc: 0.95606, F1: 0.95606#####> Valid Avg loss: 2.49375, Acc:0.38053, F1: 0.38053
====> Epoch: 194 Train Avg loss: 0.02331, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.21801, Acc:0.36283, F1: 0.36283
====> Epoch: 195 Train Avg loss: 0.01163, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.36027, Acc:0.38938, F1: 0.38938
====> Epoch: 196 Train Avg loss: 0.01206, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.19461, Acc:0.35841, F1: 0.35841
====> Epoch: 197 Train Avg loss: 0.01540, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 2.29746, Acc:0.38053, F1: 0.38053
====> Epoch: 198 Train Avg loss: 0.05741, Acc: 0.96081, F1: 0.96081#####> Valid Avg loss: 2.19311, Acc:0.36283, F1: 0.36283
====> Epoch: 199 Train Avg loss: 0.01764, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.49678, Acc:0.35841, F1: 0.35841
====> Epoch: 200 Train Avg loss: 0.02557, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.31035, Acc:0.32743, F1: 0.32743
====> Epoch: 201 Train Avg loss: 0.01652, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.34403, Acc:0.37168, F1: 0.37168
====> Epoch: 202 Train Avg loss: 0.01329, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.28903, Acc:0.36283, F1: 0.36283
====> Epoch: 203 Train Avg loss: 0.01160, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.36865, Acc:0.38053, F1: 0.38053
====> Epoch: 204 Train Avg loss: 0.03720, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.34616, Acc:0.32301, F1: 0.32301
====> Epoch: 205 Train Avg loss: 0.04981, Acc: 0.96081, F1: 0.96081#####> Valid Avg loss: 2.05679, Acc:0.35841, F1: 0.35841
====> Epoch: 206 Train Avg loss: 0.01266, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.05878, Acc:0.32301, F1: 0.32301
====> Epoch: 207 Train Avg loss: 0.01520, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.32882, Acc:0.38938, F1: 0.38938
====> Epoch: 208 Train Avg loss: 0.01235, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.27393, Acc:0.37611, F1: 0.37611
====> Epoch: 209 Train Avg loss: 0.01224, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.21477, Acc:0.37611, F1: 0.37611
====> Epoch: 210 Train Avg loss: 0.01032, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.26544, Acc:0.34956, F1: 0.34956
====> Epoch: 211 Train Avg loss: 0.01233, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.51121, Acc:0.38053, F1: 0.38053
====> Epoch: 212 Train Avg loss: 0.01146, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.50338, Acc:0.35841, F1: 0.35841
====> Epoch: 213 Train Avg loss: 0.01206, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.38300, Acc:0.37611, F1: 0.37611
====> Epoch: 214 Train Avg loss: 0.03216, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 2.60782, Acc:0.39381, F1: 0.39381
====> Epoch: 215 Train Avg loss: 0.02000, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.39666, Acc:0.36283, F1: 0.36283
====> Epoch: 216 Train Avg loss: 0.01200, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.42209, Acc:0.36726, F1: 0.36726
====> Epoch: 217 Train Avg loss: 0.01057, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.38600, Acc:0.37168, F1: 0.37168
====> Epoch: 218 Train Avg loss: 0.01130, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.41666, Acc:0.34071, F1: 0.34071
====> Epoch: 219 Train Avg loss: 0.02942, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.63332, Acc:0.34956, F1: 0.34956
====> Epoch: 220 Train Avg loss: 0.02122, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.35652, Acc:0.36283, F1: 0.36283
====> Epoch: 221 Train Avg loss: 0.01231, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.37941, Acc:0.36283, F1: 0.36283
====> Epoch: 222 Train Avg loss: 0.01282, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.54838, Acc:0.33628, F1: 0.33628
====> Epoch: 223 Train Avg loss: 0.01020, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.53047, Acc:0.33186, F1: 0.33186
====> Epoch: 224 Train Avg loss: 0.01015, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.60432, Acc:0.35398, F1: 0.35398
====> Epoch: 225 Train Avg loss: 0.01337, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.76536, Acc:0.32301, F1: 0.32301
====> Epoch: 226 Train Avg loss: 0.02622, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 2.73905, Acc:0.34956, F1: 0.34956
====> Epoch: 227 Train Avg loss: 0.01165, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.42867, Acc:0.37168, F1: 0.37168
====> Epoch: 228 Train Avg loss: 0.01150, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.54137, Acc:0.36283, F1: 0.36283
====> Epoch: 229 Train Avg loss: 0.01034, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.57761, Acc:0.34513, F1: 0.34513
====> Epoch: 230 Train Avg loss: 0.00916, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.40526, Acc:0.35841, F1: 0.35841
===> Epoch: 230: Training loss decreased (0.00932 --> 0.00916), Acc: (0.99406 --> 0.98337), F1: (0.99406 --> 0.98337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 231 Train Avg loss: 0.00996, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.65590, Acc:0.37168, F1: 0.37168
====> Epoch: 232 Train Avg loss: 0.01442, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.72655, Acc:0.37168, F1: 0.37168
====> Epoch: 233 Train Avg loss: 0.01602, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.68631, Acc:0.33186, F1: 0.33186
====> Epoch: 234 Train Avg loss: 0.00986, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.67352, Acc:0.38053, F1: 0.38053
====> Epoch: 235 Train Avg loss: 0.00968, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.63144, Acc:0.34071, F1: 0.34071
====> Epoch: 236 Train Avg loss: 0.02258, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.48223, Acc:0.31416, F1: 0.31416
====> Epoch: 237 Train Avg loss: 0.01036, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.68422, Acc:0.34071, F1: 0.34071
====> Epoch: 238 Train Avg loss: 0.00946, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.68633, Acc:0.35841, F1: 0.35841
====> Epoch: 239 Train Avg loss: 0.01410, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.62056, Acc:0.33628, F1: 0.33628
====> Epoch: 240 Train Avg loss: 0.00928, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.54833, Acc:0.36283, F1: 0.36283
====> Epoch: 241 Train Avg loss: 0.00942, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.53342, Acc:0.34513, F1: 0.34513
====> Epoch: 242 Train Avg loss: 0.01251, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.61545, Acc:0.36726, F1: 0.36726
====> Epoch: 243 Train Avg loss: 0.01081, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.95397, Acc:0.38496, F1: 0.38496
====> Epoch: 244 Train Avg loss: 0.01489, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.65817, Acc:0.32743, F1: 0.32743
====> Epoch: 245 Train Avg loss: 0.01043, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.59193, Acc:0.35398, F1: 0.35398
====> Epoch: 246 Train Avg loss: 0.00985, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.61921, Acc:0.34956, F1: 0.34956
====> Epoch: 247 Train Avg loss: 0.01404, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.70105, Acc:0.37168, F1: 0.37168
====> Epoch: 248 Train Avg loss: 0.00939, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.65658, Acc:0.38053, F1: 0.38053
====> Epoch: 249 Train Avg loss: 0.00936, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.62757, Acc:0.38053, F1: 0.38053
====> Epoch: 250 Train Avg loss: 0.00914, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.67625, Acc:0.35841, F1: 0.35841
===> Epoch: 250: Training loss decreased (0.00916 --> 0.00914), Acc: (0.98337 --> 0.98100), F1: (0.98337 --> 0.98100).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 251 Train Avg loss: 0.00958, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.73946, Acc:0.37168, F1: 0.37168
====> Epoch: 252 Train Avg loss: 0.00906, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.72984, Acc:0.38938, F1: 0.38938
===> Epoch: 252: Training loss decreased (0.00914 --> 0.00906), Acc: (0.98100 --> 0.98100), F1: (0.98100 --> 0.98100).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 253 Train Avg loss: 0.01060, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.62069, Acc:0.32743, F1: 0.32743
====> Epoch: 254 Train Avg loss: 0.00957, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.65749, Acc:0.33628, F1: 0.33628
====> Epoch: 255 Train Avg loss: 0.00951, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.75120, Acc:0.34071, F1: 0.34071
====> Epoch: 256 Train Avg loss: 0.00893, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.71482, Acc:0.36726, F1: 0.36726
===> Epoch: 256: Training loss decreased (0.00906 --> 0.00893), Acc: (0.98100 --> 0.98456), F1: (0.98100 --> 0.98456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 257 Train Avg loss: 0.00905, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.77333, Acc:0.36726, F1: 0.36726
====> Epoch: 258 Train Avg loss: 0.00924, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.67152, Acc:0.35841, F1: 0.35841
====> Epoch: 259 Train Avg loss: 0.00922, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.69894, Acc:0.33186, F1: 0.33186
====> Epoch: 260 Train Avg loss: 0.01194, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.66227, Acc:0.37611, F1: 0.37611
====> Epoch: 261 Train Avg loss: 0.00893, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.73504, Acc:0.33628, F1: 0.33628
====> Epoch: 262 Train Avg loss: 0.00880, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.72535, Acc:0.32743, F1: 0.32743
===> Epoch: 262: Training loss decreased (0.00893 --> 0.00880), Acc: (0.98456 --> 0.98219), F1: (0.98456 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 263 Train Avg loss: 0.00886, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.75956, Acc:0.32743, F1: 0.32743
====> Epoch: 264 Train Avg loss: 0.00889, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.76608, Acc:0.34956, F1: 0.34956
====> Epoch: 265 Train Avg loss: 0.00878, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.67842, Acc:0.35398, F1: 0.35398
===> Epoch: 265: Training loss decreased (0.00880 --> 0.00878), Acc: (0.98219 --> 0.98694), F1: (0.98219 --> 0.98694).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 266 Train Avg loss: 0.00873, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.72201, Acc:0.33186, F1: 0.33186
===> Epoch: 266: Training loss decreased (0.00878 --> 0.00873), Acc: (0.98694 --> 0.98219), F1: (0.98694 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 267 Train Avg loss: 0.00978, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.90317, Acc:0.34513, F1: 0.34513
====> Epoch: 268 Train Avg loss: 0.00842, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.76184, Acc:0.34513, F1: 0.34513
===> Epoch: 268: Training loss decreased (0.00873 --> 0.00842), Acc: (0.98219 --> 0.98575), F1: (0.98219 --> 0.98575).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 269 Train Avg loss: 0.00905, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.77944, Acc:0.34956, F1: 0.34956
====> Epoch: 270 Train Avg loss: 0.00936, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.74317, Acc:0.35398, F1: 0.35398
====> Epoch: 271 Train Avg loss: 0.00859, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.76203, Acc:0.36726, F1: 0.36726
====> Epoch: 272 Train Avg loss: 0.00854, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.80641, Acc:0.36726, F1: 0.36726
====> Epoch: 273 Train Avg loss: 0.00863, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.77078, Acc:0.36283, F1: 0.36283
====> Epoch: 274 Train Avg loss: 0.00869, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.82086, Acc:0.37168, F1: 0.37168
====> Epoch: 275 Train Avg loss: 0.00871, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.77441, Acc:0.34513, F1: 0.34513
====> Epoch: 276 Train Avg loss: 0.00857, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.92583, Acc:0.35841, F1: 0.35841
====> Epoch: 277 Train Avg loss: 0.00866, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.81524, Acc:0.35398, F1: 0.35398
====> Epoch: 278 Train Avg loss: 0.00861, Acc: 0.98931, F1: 0.98931#####> Valid Avg loss: 2.78441, Acc:0.34513, F1: 0.34513
====> Epoch: 279 Train Avg loss: 0.00850, Acc: 0.98931, F1: 0.98931#####> Valid Avg loss: 2.75265, Acc:0.35841, F1: 0.35841
====> Epoch: 280 Train Avg loss: 0.00831, Acc: 0.99050, F1: 0.99050#####> Valid Avg loss: 2.80640, Acc:0.34956, F1: 0.34956
===> Epoch: 280: Training loss decreased (0.00842 --> 0.00831), Acc: (0.98575 --> 0.99050), F1: (0.98575 --> 0.99050).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 281 Train Avg loss: 0.00918, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.80335, Acc:0.35841, F1: 0.35841
====> Epoch: 282 Train Avg loss: 0.00851, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.78462, Acc:0.34956, F1: 0.34956
====> Epoch: 283 Train Avg loss: 0.00911, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.77898, Acc:0.35841, F1: 0.35841
====> Epoch: 284 Train Avg loss: 0.00815, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.75907, Acc:0.35398, F1: 0.35398
===> Epoch: 284: Training loss decreased (0.00831 --> 0.00815), Acc: (0.99050 --> 0.98575), F1: (0.99050 --> 0.98575).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 285 Train Avg loss: 0.00843, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.76129, Acc:0.35398, F1: 0.35398
====> Epoch: 286 Train Avg loss: 0.00846, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.79165, Acc:0.35398, F1: 0.35398
====> Epoch: 287 Train Avg loss: 0.00840, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.72813, Acc:0.34956, F1: 0.34956
====> Epoch: 288 Train Avg loss: 0.00829, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.74899, Acc:0.35398, F1: 0.35398
====> Epoch: 289 Train Avg loss: 0.00909, Acc: 0.99050, F1: 0.99050#####> Valid Avg loss: 2.78880, Acc:0.34956, F1: 0.34956
====> Epoch: 290 Train Avg loss: 0.00866, Acc: 0.98812, F1: 0.98812#####> Valid Avg loss: 2.75013, Acc:0.35398, F1: 0.35398
====> Epoch: 291 Train Avg loss: 0.00848, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.86770, Acc:0.34956, F1: 0.34956
====> Epoch: 292 Train Avg loss: 0.00832, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.86417, Acc:0.35841, F1: 0.35841
====> Epoch: 293 Train Avg loss: 0.00817, Acc: 0.99169, F1: 0.99169#####> Valid Avg loss: 2.63299, Acc:0.34513, F1: 0.34513
====> Epoch: 294 Train Avg loss: 0.00844, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.75573, Acc:0.35841, F1: 0.35841
====> Epoch: 295 Train Avg loss: 0.00839, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.90974, Acc:0.35841, F1: 0.35841
====> Epoch: 296 Train Avg loss: 0.00813, Acc: 0.99169, F1: 0.99169#####> Valid Avg loss: 2.77073, Acc:0.34956, F1: 0.34956
===> Epoch: 296: Training loss decreased (0.00815 --> 0.00813), Acc: (0.98575 --> 0.99169), F1: (0.98575 --> 0.99169).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 297 Train Avg loss: 0.00847, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.81638, Acc:0.35398, F1: 0.35398
====> Epoch: 298 Train Avg loss: 0.00837, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.71154, Acc:0.34956, F1: 0.34956
====> Epoch: 299 Train Avg loss: 0.00810, Acc: 0.99050, F1: 0.99050#####> Valid Avg loss: 2.83349, Acc:0.35841, F1: 0.35841
===> Epoch: 299: Training loss decreased (0.00813 --> 0.00810), Acc: (0.99169 --> 0.99050), F1: (0.99169 --> 0.99050).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_2
====> Epoch: 300 Train Avg loss: 0.47549, Acc: 0.68646, F1: 0.68646#####> Valid Avg loss: 0.89247, Acc:0.43363, F1: 0.43363
====> Epoch: 301 Train Avg loss: 0.44060, Acc: 0.65796, F1: 0.65796#####> Valid Avg loss: 0.85806, Acc:0.41593, F1: 0.41593
====> Epoch: 302 Train Avg loss: 0.41069, Acc: 0.68409, F1: 0.68409#####> Valid Avg loss: 1.19251, Acc:0.46460, F1: 0.46460
====> Epoch: 303 Train Avg loss: 0.39539, Acc: 0.71734, F1: 0.71734#####> Valid Avg loss: 0.98867, Acc:0.44690, F1: 0.44690
====> Epoch: 304 Train Avg loss: 0.35933, Acc: 0.72565, F1: 0.72565#####> Valid Avg loss: 0.96234, Acc:0.35841, F1: 0.35841
====> Epoch: 305 Train Avg loss: 0.31272, Acc: 0.76485, F1: 0.76485#####> Valid Avg loss: 0.99797, Acc:0.34513, F1: 0.34513
====> Epoch: 306 Train Avg loss: 0.30801, Acc: 0.77672, F1: 0.77672#####> Valid Avg loss: 0.99044, Acc:0.39381, F1: 0.39381
====> Epoch: 307 Train Avg loss: 0.26536, Acc: 0.81235, F1: 0.81235#####> Valid Avg loss: 1.10329, Acc:0.29204, F1: 0.29204
====> Epoch: 308 Train Avg loss: 0.22337, Acc: 0.82542, F1: 0.82542#####> Valid Avg loss: 1.38184, Acc:0.34513, F1: 0.34513
====> Epoch: 309 Train Avg loss: 0.20772, Acc: 0.85273, F1: 0.85273#####> Valid Avg loss: 1.38799, Acc:0.35398, F1: 0.35398
====> Epoch: 310 Train Avg loss: 0.19837, Acc: 0.85986, F1: 0.85986#####> Valid Avg loss: 1.28585, Acc:0.34513, F1: 0.34513
====> Epoch: 311 Train Avg loss: 0.16514, Acc: 0.87411, F1: 0.87411#####> Valid Avg loss: 1.56754, Acc:0.30531, F1: 0.30531
====> Epoch: 312 Train Avg loss: 0.17874, Acc: 0.87055, F1: 0.87055#####> Valid Avg loss: 1.52585, Acc:0.30973, F1: 0.30973
====> Epoch: 313 Train Avg loss: 0.16327, Acc: 0.89430, F1: 0.89430#####> Valid Avg loss: 1.34399, Acc:0.35841, F1: 0.35841
====> Epoch: 314 Train Avg loss: 0.11723, Acc: 0.90380, F1: 0.90380#####> Valid Avg loss: 1.89486, Acc:0.31858, F1: 0.31858
====> Epoch: 315 Train Avg loss: 0.12636, Acc: 0.90024, F1: 0.90024#####> Valid Avg loss: 1.55341, Acc:0.34071, F1: 0.34071
====> Epoch: 316 Train Avg loss: 0.15432, Acc: 0.88717, F1: 0.88717#####> Valid Avg loss: 1.60293, Acc:0.36726, F1: 0.36726
====> Epoch: 317 Train Avg loss: 0.08966, Acc: 0.93230, F1: 0.93230#####> Valid Avg loss: 1.78270, Acc:0.37168, F1: 0.37168
====> Epoch: 318 Train Avg loss: 0.08827, Acc: 0.93230, F1: 0.93230#####> Valid Avg loss: 2.04266, Acc:0.34513, F1: 0.34513
====> Epoch: 319 Train Avg loss: 0.11837, Acc: 0.91330, F1: 0.91330#####> Valid Avg loss: 2.30867, Acc:0.44248, F1: 0.44248
====> Epoch: 320 Train Avg loss: 0.09246, Acc: 0.93943, F1: 0.93943#####> Valid Avg loss: 1.70211, Acc:0.31858, F1: 0.31858
====> Epoch: 321 Train Avg loss: 0.08056, Acc: 0.94537, F1: 0.94537#####> Valid Avg loss: 1.87192, Acc:0.38053, F1: 0.38053
====> Epoch: 322 Train Avg loss: 0.10188, Acc: 0.92280, F1: 0.92280#####> Valid Avg loss: 1.87074, Acc:0.36283, F1: 0.36283
====> Epoch: 323 Train Avg loss: 0.07680, Acc: 0.94062, F1: 0.94062#####> Valid Avg loss: 2.34306, Acc:0.32743, F1: 0.32743
====> Epoch: 324 Train Avg loss: 0.06725, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 2.08106, Acc:0.33628, F1: 0.33628
====> Epoch: 325 Train Avg loss: 0.11996, Acc: 0.91330, F1: 0.91330#####> Valid Avg loss: 1.79900, Acc:0.34513, F1: 0.34513
====> Epoch: 326 Train Avg loss: 0.07278, Acc: 0.94537, F1: 0.94537#####> Valid Avg loss: 2.11680, Acc:0.27876, F1: 0.27876
====> Epoch: 327 Train Avg loss: 0.13378, Acc: 0.91924, F1: 0.91924#####> Valid Avg loss: 1.76917, Acc:0.31416, F1: 0.31416
====> Epoch: 328 Train Avg loss: 0.03922, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 2.03631, Acc:0.38938, F1: 0.38938
====> Epoch: 329 Train Avg loss: 0.02945, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.12932, Acc:0.33628, F1: 0.33628
====> Epoch: 330 Train Avg loss: 0.06372, Acc: 0.94893, F1: 0.94893#####> Valid Avg loss: 2.13200, Acc:0.30088, F1: 0.30088
====> Epoch: 331 Train Avg loss: 0.14107, Acc: 0.89074, F1: 0.89074#####> Valid Avg loss: 1.62486, Acc:0.39823, F1: 0.39823
====> Epoch: 332 Train Avg loss: 0.05498, Acc: 0.96318, F1: 0.96318#####> Valid Avg loss: 1.90834, Acc:0.36726, F1: 0.36726
====> Epoch: 333 Train Avg loss: 0.02879, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.12944, Acc:0.34513, F1: 0.34513
====> Epoch: 334 Train Avg loss: 0.16338, Acc: 0.89905, F1: 0.89905#####> Valid Avg loss: 1.32911, Acc:0.39823, F1: 0.39823
====> Epoch: 335 Train Avg loss: 0.06958, Acc: 0.95368, F1: 0.95368#####> Valid Avg loss: 1.83071, Acc:0.40265, F1: 0.40265
====> Epoch: 336 Train Avg loss: 0.03115, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.16439, Acc:0.36283, F1: 0.36283
====> Epoch: 337 Train Avg loss: 0.05557, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 2.04822, Acc:0.38938, F1: 0.38938
====> Epoch: 338 Train Avg loss: 0.09022, Acc: 0.93705, F1: 0.93705#####> Valid Avg loss: 1.58543, Acc:0.34513, F1: 0.34513
====> Epoch: 339 Train Avg loss: 0.07160, Acc: 0.95012, F1: 0.95012#####> Valid Avg loss: 2.03409, Acc:0.34071, F1: 0.34071
====> Epoch: 340 Train Avg loss: 0.08064, Acc: 0.93112, F1: 0.93112#####> Valid Avg loss: 2.06833, Acc:0.34956, F1: 0.34956
====> Epoch: 341 Train Avg loss: 0.09655, Acc: 0.92755, F1: 0.92755#####> Valid Avg loss: 1.97788, Acc:0.42478, F1: 0.42478
====> Epoch: 342 Train Avg loss: 0.07589, Acc: 0.94537, F1: 0.94537#####> Valid Avg loss: 1.77881, Acc:0.38938, F1: 0.38938
====> Epoch: 343 Train Avg loss: 0.02941, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.32017, Acc:0.38053, F1: 0.38053
====> Epoch: 344 Train Avg loss: 0.02438, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.14759, Acc:0.37611, F1: 0.37611
====> Epoch: 345 Train Avg loss: 0.03574, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.15316, Acc:0.32743, F1: 0.32743
====> Epoch: 346 Train Avg loss: 0.15390, Acc: 0.89905, F1: 0.89905#####> Valid Avg loss: 1.75938, Acc:0.37168, F1: 0.37168
====> Epoch: 347 Train Avg loss: 0.05931, Acc: 0.94537, F1: 0.94537#####> Valid Avg loss: 2.09082, Acc:0.40708, F1: 0.40708
====> Epoch: 348 Train Avg loss: 0.06412, Acc: 0.95012, F1: 0.95012#####> Valid Avg loss: 1.89217, Acc:0.35841, F1: 0.35841
====> Epoch: 349 Train Avg loss: 0.04698, Acc: 0.95962, F1: 0.95962#####> Valid Avg loss: 2.17558, Acc:0.32301, F1: 0.32301
====> Epoch: 350 Train Avg loss: 0.06114, Acc: 0.95131, F1: 0.95131#####> Valid Avg loss: 2.11555, Acc:0.33628, F1: 0.33628
====> Epoch: 351 Train Avg loss: 0.04389, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 2.21008, Acc:0.37611, F1: 0.37611
====> Epoch: 352 Train Avg loss: 0.06876, Acc: 0.94062, F1: 0.94062#####> Valid Avg loss: 2.28457, Acc:0.31858, F1: 0.31858
====> Epoch: 353 Train Avg loss: 0.04720, Acc: 0.95843, F1: 0.95843#####> Valid Avg loss: 2.10110, Acc:0.34513, F1: 0.34513
====> Epoch: 354 Train Avg loss: 0.06003, Acc: 0.94656, F1: 0.94656#####> Valid Avg loss: 1.77054, Acc:0.36726, F1: 0.36726
====> Epoch: 355 Train Avg loss: 0.04819, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 2.45020, Acc:0.38053, F1: 0.38053
====> Epoch: 356 Train Avg loss: 0.13409, Acc: 0.90618, F1: 0.90618#####> Valid Avg loss: 1.77812, Acc:0.36726, F1: 0.36726
====> Epoch: 357 Train Avg loss: 0.02019, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.01185, Acc:0.36726, F1: 0.36726
====> Epoch: 358 Train Avg loss: 0.01540, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.11881, Acc:0.35398, F1: 0.35398
====> Epoch: 359 Train Avg loss: 0.01761, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.31626, Acc:0.34513, F1: 0.34513
====> Epoch: 360 Train Avg loss: 0.04458, Acc: 0.95962, F1: 0.95962#####> Valid Avg loss: 2.35849, Acc:0.45575, F1: 0.45575
====> Epoch: 361 Train Avg loss: 0.15519, Acc: 0.89549, F1: 0.89549#####> Valid Avg loss: 1.98608, Acc:0.30531, F1: 0.30531
====> Epoch: 362 Train Avg loss: 0.03495, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 2.11299, Acc:0.32301, F1: 0.32301
====> Epoch: 363 Train Avg loss: 0.03869, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 1.95176, Acc:0.38053, F1: 0.38053
====> Epoch: 364 Train Avg loss: 0.05311, Acc: 0.95962, F1: 0.95962#####> Valid Avg loss: 2.15252, Acc:0.39823, F1: 0.39823
====> Epoch: 365 Train Avg loss: 0.07387, Acc: 0.93824, F1: 0.93824#####> Valid Avg loss: 2.07829, Acc:0.38938, F1: 0.38938
====> Epoch: 366 Train Avg loss: 0.02454, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.17826, Acc:0.40265, F1: 0.40265
====> Epoch: 367 Train Avg loss: 0.01873, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.09702, Acc:0.33186, F1: 0.33186
====> Epoch: 368 Train Avg loss: 0.10827, Acc: 0.93230, F1: 0.93230#####> Valid Avg loss: 2.12391, Acc:0.34071, F1: 0.34071
====> Epoch: 369 Train Avg loss: 0.02809, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.22415, Acc:0.33628, F1: 0.33628
====> Epoch: 370 Train Avg loss: 0.02972, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.05586, Acc:0.34513, F1: 0.34513
====> Epoch: 371 Train Avg loss: 0.07440, Acc: 0.94181, F1: 0.94181#####> Valid Avg loss: 1.97331, Acc:0.41150, F1: 0.41150
====> Epoch: 372 Train Avg loss: 0.03702, Acc: 0.97150, F1: 0.97150#####> Valid Avg loss: 2.36117, Acc:0.37611, F1: 0.37611
====> Epoch: 373 Train Avg loss: 0.08273, Acc: 0.93824, F1: 0.93824#####> Valid Avg loss: 1.99508, Acc:0.36283, F1: 0.36283
====> Epoch: 374 Train Avg loss: 0.03503, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 1.92023, Acc:0.29646, F1: 0.29646
====> Epoch: 375 Train Avg loss: 0.02374, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.21341, Acc:0.36283, F1: 0.36283
====> Epoch: 376 Train Avg loss: 0.10449, Acc: 0.92162, F1: 0.92162#####> Valid Avg loss: 2.01372, Acc:0.34956, F1: 0.34956
====> Epoch: 377 Train Avg loss: 0.02685, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.12212, Acc:0.38938, F1: 0.38938
====> Epoch: 378 Train Avg loss: 0.02621, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.47514, Acc:0.36283, F1: 0.36283
====> Epoch: 379 Train Avg loss: 0.02267, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.50547, Acc:0.35841, F1: 0.35841
====> Epoch: 380 Train Avg loss: 0.01643, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.38575, Acc:0.33186, F1: 0.33186
====> Epoch: 381 Train Avg loss: 0.12238, Acc: 0.92518, F1: 0.92518#####> Valid Avg loss: 1.94379, Acc:0.34956, F1: 0.34956
====> Epoch: 382 Train Avg loss: 0.02938, Acc: 0.97268, F1: 0.97268#####> Valid Avg loss: 2.24516, Acc:0.33628, F1: 0.33628
====> Epoch: 383 Train Avg loss: 0.02290, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.27688, Acc:0.35398, F1: 0.35398
====> Epoch: 384 Train Avg loss: 0.02439, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.54975, Acc:0.38938, F1: 0.38938
====> Epoch: 385 Train Avg loss: 0.09824, Acc: 0.92637, F1: 0.92637#####> Valid Avg loss: 1.96860, Acc:0.41593, F1: 0.41593
====> Epoch: 386 Train Avg loss: 0.15136, Acc: 0.89192, F1: 0.89192#####> Valid Avg loss: 1.83268, Acc:0.39381, F1: 0.39381
====> Epoch: 387 Train Avg loss: 0.01851, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.11553, Acc:0.37611, F1: 0.37611
====> Epoch: 388 Train Avg loss: 0.01646, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.35094, Acc:0.38496, F1: 0.38496
====> Epoch: 389 Train Avg loss: 0.01488, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.36737, Acc:0.40265, F1: 0.40265
====> Epoch: 390 Train Avg loss: 0.01158, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.27490, Acc:0.38496, F1: 0.38496
====> Epoch: 391 Train Avg loss: 0.01232, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.40608, Acc:0.31858, F1: 0.31858
====> Epoch: 392 Train Avg loss: 0.01202, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.50467, Acc:0.34071, F1: 0.34071
====> Epoch: 393 Train Avg loss: 0.18760, Acc: 0.88005, F1: 0.88005#####> Valid Avg loss: 1.29374, Acc:0.28319, F1: 0.28319
====> Epoch: 394 Train Avg loss: 0.11690, Acc: 0.91568, F1: 0.91568#####> Valid Avg loss: 1.74560, Acc:0.38053, F1: 0.38053
====> Epoch: 395 Train Avg loss: 0.04451, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 1.94733, Acc:0.36726, F1: 0.36726
====> Epoch: 396 Train Avg loss: 0.03669, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.05067, Acc:0.33186, F1: 0.33186
====> Epoch: 397 Train Avg loss: 0.01548, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.42449, Acc:0.37168, F1: 0.37168
====> Epoch: 398 Train Avg loss: 0.04467, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 2.45715, Acc:0.34513, F1: 0.34513
====> Epoch: 399 Train Avg loss: 0.08098, Acc: 0.94418, F1: 0.94418#####> Valid Avg loss: 1.84935, Acc:0.36726, F1: 0.36726
====> Epoch: 400 Train Avg loss: 0.01845, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.20641, Acc:0.33628, F1: 0.33628
====> Epoch: 401 Train Avg loss: 0.01234, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.47702, Acc:0.36283, F1: 0.36283
====> Epoch: 402 Train Avg loss: 0.01231, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.32523, Acc:0.35841, F1: 0.35841
====> Epoch: 403 Train Avg loss: 0.01159, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.47564, Acc:0.37168, F1: 0.37168
====> Epoch: 404 Train Avg loss: 0.15506, Acc: 0.90380, F1: 0.90380#####> Valid Avg loss: 1.75252, Acc:0.32743, F1: 0.32743
====> Epoch: 405 Train Avg loss: 0.03487, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 2.15040, Acc:0.33628, F1: 0.33628
====> Epoch: 406 Train Avg loss: 0.04491, Acc: 0.96318, F1: 0.96318#####> Valid Avg loss: 1.99196, Acc:0.34956, F1: 0.34956
====> Epoch: 407 Train Avg loss: 0.04652, Acc: 0.96200, F1: 0.96200#####> Valid Avg loss: 2.13692, Acc:0.33628, F1: 0.33628
====> Epoch: 408 Train Avg loss: 0.01751, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.07288, Acc:0.37168, F1: 0.37168
====> Epoch: 409 Train Avg loss: 0.01428, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.27705, Acc:0.33628, F1: 0.33628
====> Epoch: 410 Train Avg loss: 0.01232, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.27041, Acc:0.33628, F1: 0.33628
====> Epoch: 411 Train Avg loss: 0.01151, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.33233, Acc:0.37611, F1: 0.37611
====> Epoch: 412 Train Avg loss: 0.01068, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.28577, Acc:0.35398, F1: 0.35398
====> Epoch: 413 Train Avg loss: 0.01220, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.59575, Acc:0.35841, F1: 0.35841
====> Epoch: 414 Train Avg loss: 0.01405, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.54281, Acc:0.38496, F1: 0.38496
====> Epoch: 415 Train Avg loss: 0.12702, Acc: 0.92162, F1: 0.92162#####> Valid Avg loss: 1.73509, Acc:0.34956, F1: 0.34956
====> Epoch: 416 Train Avg loss: 0.01726, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.85722, Acc:0.39381, F1: 0.39381
====> Epoch: 417 Train Avg loss: 0.01366, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.08929, Acc:0.36726, F1: 0.36726
====> Epoch: 418 Train Avg loss: 0.05560, Acc: 0.95606, F1: 0.95606#####> Valid Avg loss: 1.98697, Acc:0.35398, F1: 0.35398
====> Epoch: 419 Train Avg loss: 0.05006, Acc: 0.95012, F1: 0.95012#####> Valid Avg loss: 2.20417, Acc:0.33186, F1: 0.33186
====> Epoch: 420 Train Avg loss: 0.02900, Acc: 0.97387, F1: 0.97387#####> Valid Avg loss: 2.20960, Acc:0.38053, F1: 0.38053
====> Epoch: 421 Train Avg loss: 0.01124, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.27125, Acc:0.37168, F1: 0.37168
====> Epoch: 422 Train Avg loss: 0.01260, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.42356, Acc:0.38053, F1: 0.38053
====> Epoch: 423 Train Avg loss: 0.01212, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.32537, Acc:0.35398, F1: 0.35398
====> Epoch: 424 Train Avg loss: 0.01114, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.45529, Acc:0.38938, F1: 0.38938
====> Epoch: 425 Train Avg loss: 0.16262, Acc: 0.88836, F1: 0.88836#####> Valid Avg loss: 1.83674, Acc:0.42035, F1: 0.42035
====> Epoch: 426 Train Avg loss: 0.04686, Acc: 0.95962, F1: 0.95962#####> Valid Avg loss: 1.93066, Acc:0.34956, F1: 0.34956
====> Epoch: 427 Train Avg loss: 0.01843, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.02535, Acc:0.37168, F1: 0.37168
====> Epoch: 428 Train Avg loss: 0.01331, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.97575, Acc:0.37611, F1: 0.37611
====> Epoch: 429 Train Avg loss: 0.01206, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.29156, Acc:0.39823, F1: 0.39823
====> Epoch: 430 Train Avg loss: 0.01176, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.29524, Acc:0.38496, F1: 0.38496
====> Epoch: 431 Train Avg loss: 0.01187, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.39709, Acc:0.40265, F1: 0.40265
====> Epoch: 432 Train Avg loss: 0.01130, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.29828, Acc:0.35398, F1: 0.35398
====> Epoch: 433 Train Avg loss: 0.01409, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 2.53625, Acc:0.32743, F1: 0.32743
====> Epoch: 434 Train Avg loss: 0.36638, Acc: 0.74822, F1: 0.74822#####> Valid Avg loss: 1.15489, Acc:0.34071, F1: 0.34071
====> Epoch: 435 Train Avg loss: 0.12257, Acc: 0.91211, F1: 0.91211#####> Valid Avg loss: 1.65119, Acc:0.38938, F1: 0.38938
====> Epoch: 436 Train Avg loss: 0.06014, Acc: 0.95487, F1: 0.95487#####> Valid Avg loss: 2.18648, Acc:0.38053, F1: 0.38053
====> Epoch: 437 Train Avg loss: 0.03243, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 2.07352, Acc:0.28319, F1: 0.28319
====> Epoch: 438 Train Avg loss: 0.06096, Acc: 0.95249, F1: 0.95249#####> Valid Avg loss: 1.89052, Acc:0.30088, F1: 0.30088
====> Epoch: 439 Train Avg loss: 0.01821, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.23816, Acc:0.37168, F1: 0.37168
====> Epoch: 440 Train Avg loss: 0.05787, Acc: 0.95962, F1: 0.95962#####> Valid Avg loss: 2.11395, Acc:0.38938, F1: 0.38938
====> Epoch: 441 Train Avg loss: 0.01615, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.26777, Acc:0.35841, F1: 0.35841
====> Epoch: 442 Train Avg loss: 0.01092, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.20528, Acc:0.37611, F1: 0.37611
====> Epoch: 443 Train Avg loss: 0.01110, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.37729, Acc:0.39823, F1: 0.39823
====> Epoch: 444 Train Avg loss: 0.01150, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.41410, Acc:0.38938, F1: 0.38938
====> Epoch: 445 Train Avg loss: 0.01098, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.68876, Acc:0.42035, F1: 0.42035
====> Epoch: 446 Train Avg loss: 0.01171, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.42919, Acc:0.38938, F1: 0.38938
====> Epoch: 447 Train Avg loss: 0.01084, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.51185, Acc:0.37611, F1: 0.37611
====> Epoch: 448 Train Avg loss: 0.07766, Acc: 0.95843, F1: 0.95843#####> Valid Avg loss: 2.10734, Acc:0.39381, F1: 0.39381
====> Epoch: 449 Train Avg loss: 0.08060, Acc: 0.94893, F1: 0.94893#####> Valid Avg loss: 1.84049, Acc:0.32301, F1: 0.32301
====> Epoch: 450 Train Avg loss: 0.01452, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.17213, Acc:0.35398, F1: 0.35398
====> Epoch: 451 Train Avg loss: 0.01269, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.18285, Acc:0.35841, F1: 0.35841
====> Epoch: 452 Train Avg loss: 0.01168, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.23040, Acc:0.34956, F1: 0.34956
====> Epoch: 453 Train Avg loss: 0.01074, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.26354, Acc:0.35398, F1: 0.35398
====> Epoch: 454 Train Avg loss: 0.01207, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.38584, Acc:0.36726, F1: 0.36726
====> Epoch: 455 Train Avg loss: 0.01077, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.45733, Acc:0.35398, F1: 0.35398
====> Epoch: 456 Train Avg loss: 0.05285, Acc: 0.96318, F1: 0.96318#####> Valid Avg loss: 2.33648, Acc:0.37611, F1: 0.37611
====> Epoch: 457 Train Avg loss: 0.03600, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 2.14586, Acc:0.31416, F1: 0.31416
====> Epoch: 458 Train Avg loss: 0.02967, Acc: 0.97150, F1: 0.97150#####> Valid Avg loss: 2.30455, Acc:0.40265, F1: 0.40265
====> Epoch: 459 Train Avg loss: 0.01261, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.25081, Acc:0.38053, F1: 0.38053
====> Epoch: 460 Train Avg loss: 0.01175, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.31227, Acc:0.36726, F1: 0.36726
====> Epoch: 461 Train Avg loss: 0.01113, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.24059, Acc:0.36283, F1: 0.36283
====> Epoch: 462 Train Avg loss: 0.01006, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.47942, Acc:0.38496, F1: 0.38496
====> Epoch: 463 Train Avg loss: 0.01004, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.54055, Acc:0.36726, F1: 0.36726
====> Epoch: 464 Train Avg loss: 0.01019, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.68309, Acc:0.38053, F1: 0.38053
====> Epoch: 465 Train Avg loss: 0.02872, Acc: 0.96556, F1: 0.96556#####> Valid Avg loss: 2.70926, Acc:0.36726, F1: 0.36726
====> Epoch: 466 Train Avg loss: 0.07470, Acc: 0.94774, F1: 0.94774#####> Valid Avg loss: 2.24192, Acc:0.32743, F1: 0.32743
====> Epoch: 467 Train Avg loss: 0.01311, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.41016, Acc:0.33628, F1: 0.33628
====> Epoch: 468 Train Avg loss: 0.01056, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.37356, Acc:0.32743, F1: 0.32743
====> Epoch: 469 Train Avg loss: 0.01070, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 2.41095, Acc:0.33186, F1: 0.33186
====> Epoch: 470 Train Avg loss: 0.01258, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.32526, Acc:0.31416, F1: 0.31416
====> Epoch: 471 Train Avg loss: 0.01081, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.47460, Acc:0.35398, F1: 0.35398
====> Epoch: 472 Train Avg loss: 0.01006, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.50387, Acc:0.32301, F1: 0.32301
====> Epoch: 473 Train Avg loss: 0.09807, Acc: 0.93349, F1: 0.93349#####> Valid Avg loss: 1.88736, Acc:0.34071, F1: 0.34071
====> Epoch: 474 Train Avg loss: 0.03785, Acc: 0.96675, F1: 0.96675#####> Valid Avg loss: 2.06789, Acc:0.34513, F1: 0.34513
====> Epoch: 475 Train Avg loss: 0.01527, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.07318, Acc:0.33628, F1: 0.33628
====> Epoch: 476 Train Avg loss: 0.01038, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.20822, Acc:0.35841, F1: 0.35841
====> Epoch: 477 Train Avg loss: 0.00995, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.23739, Acc:0.35398, F1: 0.35398
====> Epoch: 478 Train Avg loss: 0.00969, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.30767, Acc:0.34513, F1: 0.34513
====> Epoch: 479 Train Avg loss: 0.00965, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.58972, Acc:0.36726, F1: 0.36726
====> Epoch: 480 Train Avg loss: 0.01071, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.50428, Acc:0.35398, F1: 0.35398
====> Epoch: 481 Train Avg loss: 0.01039, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.66228, Acc:0.28761, F1: 0.28761
====> Epoch: 482 Train Avg loss: 0.06512, Acc: 0.94537, F1: 0.94537#####> Valid Avg loss: 2.34406, Acc:0.40265, F1: 0.40265
====> Epoch: 483 Train Avg loss: 0.02249, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.42638, Acc:0.32301, F1: 0.32301
====> Epoch: 484 Train Avg loss: 0.01646, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.18962, Acc:0.28319, F1: 0.28319
====> Epoch: 485 Train Avg loss: 0.01125, Acc: 0.98694, F1: 0.98694#####> Valid Avg loss: 2.38190, Acc:0.36726, F1: 0.36726
====> Epoch: 486 Train Avg loss: 0.01371, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.34515, Acc:0.32743, F1: 0.32743
====> Epoch: 487 Train Avg loss: 0.01163, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.53783, Acc:0.33186, F1: 0.33186
====> Epoch: 488 Train Avg loss: 0.01006, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.68005, Acc:0.35398, F1: 0.35398
====> Epoch: 489 Train Avg loss: 0.03576, Acc: 0.97031, F1: 0.97031#####> Valid Avg loss: 2.91277, Acc:0.45133, F1: 0.45133
====> Epoch: 490 Train Avg loss: 0.06445, Acc: 0.95012, F1: 0.95012#####> Valid Avg loss: 2.21287, Acc:0.30088, F1: 0.30088
====> Epoch: 491 Train Avg loss: 0.01816, Acc: 0.97625, F1: 0.97625#####> Valid Avg loss: 2.36499, Acc:0.36283, F1: 0.36283
====> Epoch: 492 Train Avg loss: 0.01146, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.30715, Acc:0.29204, F1: 0.29204
====> Epoch: 493 Train Avg loss: 0.01082, Acc: 0.98575, F1: 0.98575#####> Valid Avg loss: 2.39938, Acc:0.33186, F1: 0.33186
====> Epoch: 494 Train Avg loss: 0.01103, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 2.51393, Acc:0.29646, F1: 0.29646
====> Epoch: 495 Train Avg loss: 0.01001, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.37077, Acc:0.30973, F1: 0.30973
====> Epoch: 496 Train Avg loss: 0.02774, Acc: 0.97506, F1: 0.97506#####> Valid Avg loss: 2.59471, Acc:0.36283, F1: 0.36283
====> Epoch: 497 Train Avg loss: 0.01455, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.70904, Acc:0.37611, F1: 0.37611
====> Epoch: 498 Train Avg loss: 0.01186, Acc: 0.98100, F1: 0.98100#####> Valid Avg loss: 2.66892, Acc:0.37611, F1: 0.37611
====> Epoch: 499 Train Avg loss: 0.05699, Acc: 0.96793, F1: 0.96793#####> Valid Avg loss: 2.55305, Acc:0.30973, F1: 0.30973
====> Epoch: 500 Train Avg loss: 0.01010, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 2.35401, Acc:0.33628, F1: 0.33628
#####> Valid Avg loss: 2.61697, Acc:0.31081, F1: 0.31081


$$$$$$> Test it 2: (from train best model) Final Test Avg loss:2.61697, Acc:0.31081, F1:0.31081\n
#####> Valid Avg loss: 0.87472, Acc:0.47185, F1: 0.47185


$$$$$$> Test it 2: (from max acc valid model) Final Test Avg loss:0.87472, Acc:0.47185, F1:0.47185\n
#####> Valid Avg loss: 0.69345, Acc:0.47185, F1: 0.47185


$$$$$$> Test it 2: (from min loss valid model) Final Test Avg loss:0.69345, Acc:0.47185, F1:0.47185\n


	Start execution training validation it 3 

train_dataloader len: 663
valid_dataloader len: 113
test_dataloader len: 202
train performers ids: [2, 5, 6]
valid performers ids: [1]
test performers ids: [4]
train dataset len: 1326, train dataloader len: 663
valid dataset len: 226, valid dataloader len: 113
valid dataset len: 404, test dataloader len: 113
====> Epoch: 1 Train Avg loss: 0.65720, Acc: 0.51735, F1: 0.51735#####> Valid Avg loss: 0.69823, Acc:0.47345, F1: 0.47345
===> Epoch: 1: Training loss decreased (inf --> 0.65720), Acc: (0.00000 --> 0.51735), F1: (0.00000 --> 0.51735).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3

####> Epoch: 1: validation loss decreased (inf --> 0.69823), Acc: (0.00000 --> 0.47345), F1: (0.00000 --> 0.47345).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3

####> Epoch: 1: validation acc increase (inf --> 0.69823), Acc: (0.00000 --> 0.47345), F1: (0.00000 --> 0.47345).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 2 Train Avg loss: 0.61640, Acc: 0.52640, F1: 0.52640#####> Valid Avg loss: 0.81219, Acc:0.47345, F1: 0.47345
===> Epoch: 2: Training loss decreased (0.65720 --> 0.61640), Acc: (0.51735 --> 0.52640), F1: (0.51735 --> 0.52640).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 3 Train Avg loss: 0.60042, Acc: 0.53620, F1: 0.53620#####> Valid Avg loss: 0.79535, Acc:0.47345, F1: 0.47345
===> Epoch: 3: Training loss decreased (0.61640 --> 0.60042), Acc: (0.52640 --> 0.53620), F1: (0.52640 --> 0.53620).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 4 Train Avg loss: 0.59172, Acc: 0.53243, F1: 0.53243#####> Valid Avg loss: 0.71771, Acc:0.47345, F1: 0.47345
===> Epoch: 4: Training loss decreased (0.60042 --> 0.59172), Acc: (0.53620 --> 0.53243), F1: (0.53620 --> 0.53243).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 5 Train Avg loss: 0.59043, Acc: 0.55958, F1: 0.55958#####> Valid Avg loss: 0.70251, Acc:0.47345, F1: 0.47345
===> Epoch: 5: Training loss decreased (0.59172 --> 0.59043), Acc: (0.53243 --> 0.55958), F1: (0.53243 --> 0.55958).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 6 Train Avg loss: 0.58374, Acc: 0.55732, F1: 0.55732#####> Valid Avg loss: 0.71724, Acc:0.47345, F1: 0.47345
===> Epoch: 6: Training loss decreased (0.59043 --> 0.58374), Acc: (0.55958 --> 0.55732), F1: (0.55958 --> 0.55732).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 7 Train Avg loss: 0.57752, Acc: 0.54751, F1: 0.54751#####> Valid Avg loss: 0.71112, Acc:0.47345, F1: 0.47345
===> Epoch: 7: Training loss decreased (0.58374 --> 0.57752), Acc: (0.55732 --> 0.54751), F1: (0.55732 --> 0.54751).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 8 Train Avg loss: 0.57325, Acc: 0.54299, F1: 0.54299#####> Valid Avg loss: 0.76902, Acc:0.47345, F1: 0.47345
===> Epoch: 8: Training loss decreased (0.57752 --> 0.57325), Acc: (0.54751 --> 0.54299), F1: (0.54751 --> 0.54299).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 9 Train Avg loss: 0.56582, Acc: 0.55732, F1: 0.55732#####> Valid Avg loss: 0.75227, Acc:0.47345, F1: 0.47345
===> Epoch: 9: Training loss decreased (0.57325 --> 0.56582), Acc: (0.54299 --> 0.55732), F1: (0.54299 --> 0.55732).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 10 Train Avg loss: 0.56575, Acc: 0.56184, F1: 0.56184#####> Valid Avg loss: 0.73692, Acc:0.47345, F1: 0.47345
===> Epoch: 10: Training loss decreased (0.56582 --> 0.56575), Acc: (0.55732 --> 0.56184), F1: (0.55732 --> 0.56184).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 11 Train Avg loss: 0.55170, Acc: 0.57164, F1: 0.57164#####> Valid Avg loss: 0.82202, Acc:0.47345, F1: 0.47345
===> Epoch: 11: Training loss decreased (0.56575 --> 0.55170), Acc: (0.56184 --> 0.57164), F1: (0.56184 --> 0.57164).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 12 Train Avg loss: 0.54686, Acc: 0.56637, F1: 0.56637#####> Valid Avg loss: 0.84387, Acc:0.46460, F1: 0.46460
===> Epoch: 12: Training loss decreased (0.55170 --> 0.54686), Acc: (0.57164 --> 0.56637), F1: (0.57164 --> 0.56637).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 13 Train Avg loss: 0.54188, Acc: 0.56335, F1: 0.56335#####> Valid Avg loss: 0.79741, Acc:0.37611, F1: 0.37611
===> Epoch: 13: Training loss decreased (0.54686 --> 0.54188), Acc: (0.56637 --> 0.56335), F1: (0.56637 --> 0.56335).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 14 Train Avg loss: 0.53511, Acc: 0.57089, F1: 0.57089#####> Valid Avg loss: 0.74085, Acc:0.45133, F1: 0.45133
===> Epoch: 14: Training loss decreased (0.54188 --> 0.53511), Acc: (0.56335 --> 0.57089), F1: (0.56335 --> 0.57089).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 15 Train Avg loss: 0.52520, Acc: 0.58446, F1: 0.58446#####> Valid Avg loss: 0.78284, Acc:0.45575, F1: 0.45575
===> Epoch: 15: Training loss decreased (0.53511 --> 0.52520), Acc: (0.57089 --> 0.58446), F1: (0.57089 --> 0.58446).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 16 Train Avg loss: 0.52947, Acc: 0.57919, F1: 0.57919#####> Valid Avg loss: 0.85296, Acc:0.46460, F1: 0.46460
====> Epoch: 17 Train Avg loss: 0.52234, Acc: 0.56259, F1: 0.56259#####> Valid Avg loss: 0.82178, Acc:0.46018, F1: 0.46018
===> Epoch: 17: Training loss decreased (0.52520 --> 0.52234), Acc: (0.58446 --> 0.56259), F1: (0.58446 --> 0.56259).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 18 Train Avg loss: 0.50861, Acc: 0.58673, F1: 0.58673#####> Valid Avg loss: 0.88942, Acc:0.46018, F1: 0.46018
===> Epoch: 18: Training loss decreased (0.52234 --> 0.50861), Acc: (0.56259 --> 0.58673), F1: (0.56259 --> 0.58673).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 19 Train Avg loss: 0.50601, Acc: 0.59125, F1: 0.59125#####> Valid Avg loss: 0.86219, Acc:0.45575, F1: 0.45575
===> Epoch: 19: Training loss decreased (0.50861 --> 0.50601), Acc: (0.58673 --> 0.59125), F1: (0.58673 --> 0.59125).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 20 Train Avg loss: 0.49850, Acc: 0.58974, F1: 0.58974#####> Valid Avg loss: 0.87934, Acc:0.48230, F1: 0.48230
===> Epoch: 20: Training loss decreased (0.50601 --> 0.49850), Acc: (0.59125 --> 0.58974), F1: (0.59125 --> 0.58974).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3

####> Epoch: 20: validation acc increase (0.69823 --> 0.87934), Acc: (0.47345 --> 0.48230), F1: (0.47345 --> 0.48230).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 21 Train Avg loss: 0.49365, Acc: 0.58371, F1: 0.58371#####> Valid Avg loss: 1.06195, Acc:0.46903, F1: 0.46903
===> Epoch: 21: Training loss decreased (0.49850 --> 0.49365), Acc: (0.58974 --> 0.58371), F1: (0.58974 --> 0.58371).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 22 Train Avg loss: 0.48421, Acc: 0.58446, F1: 0.58446#####> Valid Avg loss: 1.00242, Acc:0.46903, F1: 0.46903
===> Epoch: 22: Training loss decreased (0.49365 --> 0.48421), Acc: (0.58371 --> 0.58446), F1: (0.58371 --> 0.58446).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 23 Train Avg loss: 0.48517, Acc: 0.59050, F1: 0.59050#####> Valid Avg loss: 1.13061, Acc:0.47345, F1: 0.47345
====> Epoch: 24 Train Avg loss: 0.47895, Acc: 0.60558, F1: 0.60558#####> Valid Avg loss: 1.12599, Acc:0.46460, F1: 0.46460
===> Epoch: 24: Training loss decreased (0.48421 --> 0.47895), Acc: (0.58446 --> 0.60558), F1: (0.58446 --> 0.60558).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 25 Train Avg loss: 0.46571, Acc: 0.60860, F1: 0.60860#####> Valid Avg loss: 1.04883, Acc:0.41150, F1: 0.41150
===> Epoch: 25: Training loss decreased (0.47895 --> 0.46571), Acc: (0.60558 --> 0.60860), F1: (0.60558 --> 0.60860).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 26 Train Avg loss: 0.45592, Acc: 0.62368, F1: 0.62368#####> Valid Avg loss: 0.92899, Acc:0.40265, F1: 0.40265
===> Epoch: 26: Training loss decreased (0.46571 --> 0.45592), Acc: (0.60860 --> 0.62368), F1: (0.60860 --> 0.62368).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 27 Train Avg loss: 0.44943, Acc: 0.61388, F1: 0.61388#####> Valid Avg loss: 1.13130, Acc:0.47345, F1: 0.47345
===> Epoch: 27: Training loss decreased (0.45592 --> 0.44943), Acc: (0.62368 --> 0.61388), F1: (0.62368 --> 0.61388).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 28 Train Avg loss: 0.44993, Acc: 0.61916, F1: 0.61916#####> Valid Avg loss: 1.22409, Acc:0.46460, F1: 0.46460
====> Epoch: 29 Train Avg loss: 0.43712, Acc: 0.62293, F1: 0.62293#####> Valid Avg loss: 1.13920, Acc:0.46018, F1: 0.46018
===> Epoch: 29: Training loss decreased (0.44943 --> 0.43712), Acc: (0.61388 --> 0.62293), F1: (0.61388 --> 0.62293).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 30 Train Avg loss: 0.42764, Acc: 0.62821, F1: 0.62821#####> Valid Avg loss: 1.18295, Acc:0.45133, F1: 0.45133
===> Epoch: 30: Training loss decreased (0.43712 --> 0.42764), Acc: (0.62293 --> 0.62821), F1: (0.62293 --> 0.62821).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 31 Train Avg loss: 0.41061, Acc: 0.65309, F1: 0.65309#####> Valid Avg loss: 1.15656, Acc:0.36726, F1: 0.36726
===> Epoch: 31: Training loss decreased (0.42764 --> 0.41061), Acc: (0.62821 --> 0.65309), F1: (0.62821 --> 0.65309).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 32 Train Avg loss: 0.40733, Acc: 0.65535, F1: 0.65535#####> Valid Avg loss: 1.18873, Acc:0.40265, F1: 0.40265
===> Epoch: 32: Training loss decreased (0.41061 --> 0.40733), Acc: (0.65309 --> 0.65535), F1: (0.65309 --> 0.65535).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 33 Train Avg loss: 0.38956, Acc: 0.66667, F1: 0.66667#####> Valid Avg loss: 1.14536, Acc:0.43805, F1: 0.43805
===> Epoch: 33: Training loss decreased (0.40733 --> 0.38956), Acc: (0.65535 --> 0.66667), F1: (0.65535 --> 0.66667).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 34 Train Avg loss: 0.38310, Acc: 0.65460, F1: 0.65460#####> Valid Avg loss: 1.33843, Acc:0.43805, F1: 0.43805
===> Epoch: 34: Training loss decreased (0.38956 --> 0.38310), Acc: (0.66667 --> 0.65460), F1: (0.66667 --> 0.65460).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 35 Train Avg loss: 0.37160, Acc: 0.67798, F1: 0.67798#####> Valid Avg loss: 1.41474, Acc:0.42920, F1: 0.42920
===> Epoch: 35: Training loss decreased (0.38310 --> 0.37160), Acc: (0.65460 --> 0.67798), F1: (0.65460 --> 0.67798).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 36 Train Avg loss: 0.35397, Acc: 0.68627, F1: 0.68627#####> Valid Avg loss: 1.55102, Acc:0.46018, F1: 0.46018
===> Epoch: 36: Training loss decreased (0.37160 --> 0.35397), Acc: (0.67798 --> 0.68627), F1: (0.67798 --> 0.68627).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 37 Train Avg loss: 0.34759, Acc: 0.68703, F1: 0.68703#####> Valid Avg loss: 1.60471, Acc:0.45133, F1: 0.45133
===> Epoch: 37: Training loss decreased (0.35397 --> 0.34759), Acc: (0.68627 --> 0.68703), F1: (0.68627 --> 0.68703).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 38 Train Avg loss: 0.33724, Acc: 0.70739, F1: 0.70739#####> Valid Avg loss: 1.36873, Acc:0.42035, F1: 0.42035
===> Epoch: 38: Training loss decreased (0.34759 --> 0.33724), Acc: (0.68703 --> 0.70739), F1: (0.68703 --> 0.70739).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 39 Train Avg loss: 0.32205, Acc: 0.72926, F1: 0.72926#####> Valid Avg loss: 1.65803, Acc:0.39823, F1: 0.39823
===> Epoch: 39: Training loss decreased (0.33724 --> 0.32205), Acc: (0.70739 --> 0.72926), F1: (0.70739 --> 0.72926).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 40 Train Avg loss: 0.31195, Acc: 0.73529, F1: 0.73529#####> Valid Avg loss: 1.87720, Acc:0.39823, F1: 0.39823
===> Epoch: 40: Training loss decreased (0.32205 --> 0.31195), Acc: (0.72926 --> 0.73529), F1: (0.72926 --> 0.73529).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 41 Train Avg loss: 0.30608, Acc: 0.73680, F1: 0.73680#####> Valid Avg loss: 1.78771, Acc:0.40708, F1: 0.40708
===> Epoch: 41: Training loss decreased (0.31195 --> 0.30608), Acc: (0.73529 --> 0.73680), F1: (0.73529 --> 0.73680).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 42 Train Avg loss: 0.28607, Acc: 0.76094, F1: 0.76094#####> Valid Avg loss: 1.87148, Acc:0.39381, F1: 0.39381
===> Epoch: 42: Training loss decreased (0.30608 --> 0.28607), Acc: (0.73680 --> 0.76094), F1: (0.73680 --> 0.76094).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 43 Train Avg loss: 0.26686, Acc: 0.75490, F1: 0.75490#####> Valid Avg loss: 1.97102, Acc:0.41150, F1: 0.41150
===> Epoch: 43: Training loss decreased (0.28607 --> 0.26686), Acc: (0.76094 --> 0.75490), F1: (0.76094 --> 0.75490).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 44 Train Avg loss: 0.24867, Acc: 0.78281, F1: 0.78281#####> Valid Avg loss: 2.14783, Acc:0.40708, F1: 0.40708
===> Epoch: 44: Training loss decreased (0.26686 --> 0.24867), Acc: (0.75490 --> 0.78281), F1: (0.75490 --> 0.78281).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 45 Train Avg loss: 0.23745, Acc: 0.79789, F1: 0.79789#####> Valid Avg loss: 2.40583, Acc:0.42478, F1: 0.42478
===> Epoch: 45: Training loss decreased (0.24867 --> 0.23745), Acc: (0.78281 --> 0.79789), F1: (0.78281 --> 0.79789).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 46 Train Avg loss: 0.22305, Acc: 0.81900, F1: 0.81900#####> Valid Avg loss: 2.98980, Acc:0.44690, F1: 0.44690
===> Epoch: 46: Training loss decreased (0.23745 --> 0.22305), Acc: (0.79789 --> 0.81900), F1: (0.79789 --> 0.81900).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 47 Train Avg loss: 0.21060, Acc: 0.82202, F1: 0.82202#####> Valid Avg loss: 2.89534, Acc:0.42035, F1: 0.42035
===> Epoch: 47: Training loss decreased (0.22305 --> 0.21060), Acc: (0.81900 --> 0.82202), F1: (0.81900 --> 0.82202).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 48 Train Avg loss: 0.20323, Acc: 0.82051, F1: 0.82051#####> Valid Avg loss: 2.66830, Acc:0.37168, F1: 0.37168
===> Epoch: 48: Training loss decreased (0.21060 --> 0.20323), Acc: (0.82202 --> 0.82051), F1: (0.82202 --> 0.82051).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 49 Train Avg loss: 0.18361, Acc: 0.84842, F1: 0.84842#####> Valid Avg loss: 2.94573, Acc:0.37168, F1: 0.37168
===> Epoch: 49: Training loss decreased (0.20323 --> 0.18361), Acc: (0.82051 --> 0.84842), F1: (0.82051 --> 0.84842).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 50 Train Avg loss: 0.18518, Acc: 0.84917, F1: 0.84917#####> Valid Avg loss: 2.96883, Acc:0.44690, F1: 0.44690
====> Epoch: 51 Train Avg loss: 0.16133, Acc: 0.86350, F1: 0.86350#####> Valid Avg loss: 2.86946, Acc:0.34513, F1: 0.34513
===> Epoch: 51: Training loss decreased (0.18361 --> 0.16133), Acc: (0.84842 --> 0.86350), F1: (0.84842 --> 0.86350).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 52 Train Avg loss: 0.15181, Acc: 0.87481, F1: 0.87481#####> Valid Avg loss: 3.09571, Acc:0.41593, F1: 0.41593
===> Epoch: 52: Training loss decreased (0.16133 --> 0.15181), Acc: (0.86350 --> 0.87481), F1: (0.86350 --> 0.87481).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 53 Train Avg loss: 0.13548, Acc: 0.88914, F1: 0.88914#####> Valid Avg loss: 3.13304, Acc:0.42920, F1: 0.42920
===> Epoch: 53: Training loss decreased (0.15181 --> 0.13548), Acc: (0.87481 --> 0.88914), F1: (0.87481 --> 0.88914).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 54 Train Avg loss: 0.13673, Acc: 0.89216, F1: 0.89216#####> Valid Avg loss: 3.43344, Acc:0.42478, F1: 0.42478
====> Epoch: 55 Train Avg loss: 0.12791, Acc: 0.89367, F1: 0.89367#####> Valid Avg loss: 3.26011, Acc:0.42920, F1: 0.42920
===> Epoch: 55: Training loss decreased (0.13548 --> 0.12791), Acc: (0.88914 --> 0.89367), F1: (0.88914 --> 0.89367).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 56 Train Avg loss: 0.10768, Acc: 0.90573, F1: 0.90573#####> Valid Avg loss: 3.47478, Acc:0.41150, F1: 0.41150
===> Epoch: 56: Training loss decreased (0.12791 --> 0.10768), Acc: (0.89367 --> 0.90573), F1: (0.89367 --> 0.90573).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 57 Train Avg loss: 0.10554, Acc: 0.91629, F1: 0.91629#####> Valid Avg loss: 3.86142, Acc:0.44248, F1: 0.44248
===> Epoch: 57: Training loss decreased (0.10768 --> 0.10554), Acc: (0.90573 --> 0.91629), F1: (0.90573 --> 0.91629).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 58 Train Avg loss: 0.10910, Acc: 0.91327, F1: 0.91327#####> Valid Avg loss: 3.32116, Acc:0.40708, F1: 0.40708
====> Epoch: 59 Train Avg loss: 0.09307, Acc: 0.93288, F1: 0.93288#####> Valid Avg loss: 3.64051, Acc:0.43363, F1: 0.43363
===> Epoch: 59: Training loss decreased (0.10554 --> 0.09307), Acc: (0.91629 --> 0.93288), F1: (0.91629 --> 0.93288).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 60 Train Avg loss: 0.07599, Acc: 0.93514, F1: 0.93514#####> Valid Avg loss: 3.74500, Acc:0.42035, F1: 0.42035
===> Epoch: 60: Training loss decreased (0.09307 --> 0.07599), Acc: (0.93288 --> 0.93514), F1: (0.93288 --> 0.93514).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 61 Train Avg loss: 0.06757, Acc: 0.94721, F1: 0.94721#####> Valid Avg loss: 4.14722, Acc:0.40265, F1: 0.40265
===> Epoch: 61: Training loss decreased (0.07599 --> 0.06757), Acc: (0.93514 --> 0.94721), F1: (0.93514 --> 0.94721).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 62 Train Avg loss: 0.06214, Acc: 0.95928, F1: 0.95928#####> Valid Avg loss: 3.95286, Acc:0.42035, F1: 0.42035
===> Epoch: 62: Training loss decreased (0.06757 --> 0.06214), Acc: (0.94721 --> 0.95928), F1: (0.94721 --> 0.95928).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 63 Train Avg loss: 0.05744, Acc: 0.95701, F1: 0.95701#####> Valid Avg loss: 4.01446, Acc:0.41593, F1: 0.41593
===> Epoch: 63: Training loss decreased (0.06214 --> 0.05744), Acc: (0.95928 --> 0.95701), F1: (0.95928 --> 0.95701).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 64 Train Avg loss: 0.07149, Acc: 0.94419, F1: 0.94419#####> Valid Avg loss: 4.10993, Acc:0.40708, F1: 0.40708
====> Epoch: 65 Train Avg loss: 0.04702, Acc: 0.96606, F1: 0.96606#####> Valid Avg loss: 4.68558, Acc:0.42920, F1: 0.42920
===> Epoch: 65: Training loss decreased (0.05744 --> 0.04702), Acc: (0.95701 --> 0.96606), F1: (0.95701 --> 0.96606).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 66 Train Avg loss: 0.04559, Acc: 0.96456, F1: 0.96456#####> Valid Avg loss: 4.49128, Acc:0.42478, F1: 0.42478
===> Epoch: 66: Training loss decreased (0.04702 --> 0.04559), Acc: (0.96606 --> 0.96456), F1: (0.96606 --> 0.96456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 67 Train Avg loss: 0.04271, Acc: 0.96380, F1: 0.96380#####> Valid Avg loss: 4.68581, Acc:0.42478, F1: 0.42478
===> Epoch: 67: Training loss decreased (0.04559 --> 0.04271), Acc: (0.96456 --> 0.96380), F1: (0.96456 --> 0.96380).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 68 Train Avg loss: 0.04337, Acc: 0.96606, F1: 0.96606#####> Valid Avg loss: 4.25604, Acc:0.38938, F1: 0.38938
====> Epoch: 69 Train Avg loss: 0.03922, Acc: 0.96833, F1: 0.96833#####> Valid Avg loss: 4.94226, Acc:0.47345, F1: 0.47345
===> Epoch: 69: Training loss decreased (0.04271 --> 0.03922), Acc: (0.96380 --> 0.96833), F1: (0.96380 --> 0.96833).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 70 Train Avg loss: 0.03471, Acc: 0.97134, F1: 0.97134#####> Valid Avg loss: 5.20152, Acc:0.42920, F1: 0.42920
===> Epoch: 70: Training loss decreased (0.03922 --> 0.03471), Acc: (0.96833 --> 0.97134), F1: (0.96833 --> 0.97134).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 71 Train Avg loss: 0.03126, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 4.78148, Acc:0.42478, F1: 0.42478
===> Epoch: 71: Training loss decreased (0.03471 --> 0.03126), Acc: (0.97134 --> 0.97511), F1: (0.97134 --> 0.97511).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 72 Train Avg loss: 0.02625, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 4.81661, Acc:0.41150, F1: 0.41150
===> Epoch: 72: Training loss decreased (0.03126 --> 0.02625), Acc: (0.97511 --> 0.97964), F1: (0.97511 --> 0.97964).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 73 Train Avg loss: 0.02653, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 4.82461, Acc:0.44248, F1: 0.44248
====> Epoch: 74 Train Avg loss: 0.02663, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 4.99088, Acc:0.42035, F1: 0.42035
====> Epoch: 75 Train Avg loss: 0.02640, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 4.91709, Acc:0.42920, F1: 0.42920
====> Epoch: 76 Train Avg loss: 0.02187, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 4.88758, Acc:0.40265, F1: 0.40265
===> Epoch: 76: Training loss decreased (0.02625 --> 0.02187), Acc: (0.97964 --> 0.98115), F1: (0.97964 --> 0.98115).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 77 Train Avg loss: 0.02447, Acc: 0.97813, F1: 0.97813#####> Valid Avg loss: 4.54786, Acc:0.41150, F1: 0.41150
====> Epoch: 78 Train Avg loss: 0.02016, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 4.72498, Acc:0.41593, F1: 0.41593
===> Epoch: 78: Training loss decreased (0.02187 --> 0.02016), Acc: (0.98115 --> 0.97738), F1: (0.98115 --> 0.97738).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 79 Train Avg loss: 0.02189, Acc: 0.97587, F1: 0.97587#####> Valid Avg loss: 5.07634, Acc:0.42920, F1: 0.42920
====> Epoch: 80 Train Avg loss: 0.01862, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 4.68623, Acc:0.42478, F1: 0.42478
===> Epoch: 80: Training loss decreased (0.02016 --> 0.01862), Acc: (0.97738 --> 0.97738), F1: (0.97738 --> 0.97738).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 81 Train Avg loss: 0.02253, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 4.76653, Acc:0.42920, F1: 0.42920
====> Epoch: 82 Train Avg loss: 0.01771, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 4.74264, Acc:0.42478, F1: 0.42478
===> Epoch: 82: Training loss decreased (0.01862 --> 0.01771), Acc: (0.97738 --> 0.98265), F1: (0.97738 --> 0.98265).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 83 Train Avg loss: 0.01806, Acc: 0.97813, F1: 0.97813#####> Valid Avg loss: 4.96568, Acc:0.44248, F1: 0.44248
====> Epoch: 84 Train Avg loss: 0.01593, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 4.97148, Acc:0.42920, F1: 0.42920
===> Epoch: 84: Training loss decreased (0.01771 --> 0.01593), Acc: (0.98265 --> 0.97888), F1: (0.98265 --> 0.97888).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 85 Train Avg loss: 0.01505, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 4.96669, Acc:0.43363, F1: 0.43363
===> Epoch: 85: Training loss decreased (0.01593 --> 0.01505), Acc: (0.97888 --> 0.98039), F1: (0.97888 --> 0.98039).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 86 Train Avg loss: 0.01471, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 4.98982, Acc:0.42035, F1: 0.42035
===> Epoch: 86: Training loss decreased (0.01505 --> 0.01471), Acc: (0.98039 --> 0.98115), F1: (0.98039 --> 0.98115).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 87 Train Avg loss: 0.01605, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 5.01778, Acc:0.43363, F1: 0.43363
====> Epoch: 88 Train Avg loss: 0.01455, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 4.77893, Acc:0.41150, F1: 0.41150
===> Epoch: 88: Training loss decreased (0.01471 --> 0.01455), Acc: (0.98115 --> 0.98115), F1: (0.98115 --> 0.98115).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 89 Train Avg loss: 0.01761, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 4.68956, Acc:0.41150, F1: 0.41150
====> Epoch: 90 Train Avg loss: 0.01412, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 4.91623, Acc:0.43363, F1: 0.43363
===> Epoch: 90: Training loss decreased (0.01455 --> 0.01412), Acc: (0.98115 --> 0.98190), F1: (0.98115 --> 0.98190).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 91 Train Avg loss: 0.01316, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 4.99308, Acc:0.43805, F1: 0.43805
===> Epoch: 91: Training loss decreased (0.01412 --> 0.01316), Acc: (0.98190 --> 0.97964), F1: (0.98190 --> 0.97964).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 92 Train Avg loss: 0.01308, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 5.12823, Acc:0.42920, F1: 0.42920
===> Epoch: 92: Training loss decreased (0.01316 --> 0.01308), Acc: (0.97964 --> 0.98190), F1: (0.97964 --> 0.98190).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 93 Train Avg loss: 0.01215, Acc: 0.98492, F1: 0.98492#####> Valid Avg loss: 5.06563, Acc:0.43363, F1: 0.43363
===> Epoch: 93: Training loss decreased (0.01308 --> 0.01215), Acc: (0.98190 --> 0.98492), F1: (0.98190 --> 0.98492).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 94 Train Avg loss: 0.01176, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 5.16501, Acc:0.43805, F1: 0.43805
===> Epoch: 94: Training loss decreased (0.01215 --> 0.01176), Acc: (0.98492 --> 0.98341), F1: (0.98492 --> 0.98341).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 95 Train Avg loss: 0.01272, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 5.01560, Acc:0.43805, F1: 0.43805
====> Epoch: 96 Train Avg loss: 0.01217, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 5.07357, Acc:0.43805, F1: 0.43805
====> Epoch: 97 Train Avg loss: 0.01290, Acc: 0.98567, F1: 0.98567#####> Valid Avg loss: 5.02150, Acc:0.43805, F1: 0.43805
====> Epoch: 98 Train Avg loss: 0.01163, Acc: 0.98567, F1: 0.98567#####> Valid Avg loss: 5.01455, Acc:0.43805, F1: 0.43805
===> Epoch: 98: Training loss decreased (0.01176 --> 0.01163), Acc: (0.98341 --> 0.98567), F1: (0.98341 --> 0.98567).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 99 Train Avg loss: 0.01517, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 5.04104, Acc:0.43805, F1: 0.43805
====> Epoch: 100 Train Avg loss: 0.62328, Acc: 0.57466, F1: 0.57466#####> Valid Avg loss: 0.80915, Acc:0.39823, F1: 0.39823
====> Epoch: 101 Train Avg loss: 0.51357, Acc: 0.58597, F1: 0.58597#####> Valid Avg loss: 0.90535, Acc:0.41593, F1: 0.41593
====> Epoch: 102 Train Avg loss: 0.48128, Acc: 0.61614, F1: 0.61614#####> Valid Avg loss: 0.94960, Acc:0.43805, F1: 0.43805
====> Epoch: 103 Train Avg loss: 0.46758, Acc: 0.60784, F1: 0.60784#####> Valid Avg loss: 1.07999, Acc:0.47345, F1: 0.47345
====> Epoch: 104 Train Avg loss: 0.45035, Acc: 0.63198, F1: 0.63198#####> Valid Avg loss: 0.95468, Acc:0.41593, F1: 0.41593
====> Epoch: 105 Train Avg loss: 0.42942, Acc: 0.63424, F1: 0.63424#####> Valid Avg loss: 0.92886, Acc:0.40708, F1: 0.40708
====> Epoch: 106 Train Avg loss: 0.42760, Acc: 0.64329, F1: 0.64329#####> Valid Avg loss: 1.31792, Acc:0.45133, F1: 0.45133
====> Epoch: 107 Train Avg loss: 0.40738, Acc: 0.67496, F1: 0.67496#####> Valid Avg loss: 1.13801, Acc:0.39823, F1: 0.39823
====> Epoch: 108 Train Avg loss: 0.38524, Acc: 0.69080, F1: 0.69080#####> Valid Avg loss: 1.32781, Acc:0.45575, F1: 0.45575
====> Epoch: 109 Train Avg loss: 0.38296, Acc: 0.67647, F1: 0.67647#####> Valid Avg loss: 1.40769, Acc:0.46460, F1: 0.46460
====> Epoch: 110 Train Avg loss: 0.37463, Acc: 0.68250, F1: 0.68250#####> Valid Avg loss: 1.68950, Acc:0.45575, F1: 0.45575
====> Epoch: 111 Train Avg loss: 0.35178, Acc: 0.70060, F1: 0.70060#####> Valid Avg loss: 1.38207, Acc:0.40265, F1: 0.40265
====> Epoch: 112 Train Avg loss: 0.34053, Acc: 0.71267, F1: 0.71267#####> Valid Avg loss: 1.43937, Acc:0.43363, F1: 0.43363
====> Epoch: 113 Train Avg loss: 0.31857, Acc: 0.71569, F1: 0.71569#####> Valid Avg loss: 1.71007, Acc:0.44248, F1: 0.44248
====> Epoch: 114 Train Avg loss: 0.29853, Acc: 0.73982, F1: 0.73982#####> Valid Avg loss: 1.92185, Acc:0.43805, F1: 0.43805
====> Epoch: 115 Train Avg loss: 0.29372, Acc: 0.74811, F1: 0.74811#####> Valid Avg loss: 1.65922, Acc:0.41150, F1: 0.41150
====> Epoch: 116 Train Avg loss: 0.27118, Acc: 0.76998, F1: 0.76998#####> Valid Avg loss: 1.90433, Acc:0.43805, F1: 0.43805
====> Epoch: 117 Train Avg loss: 0.26702, Acc: 0.78281, F1: 0.78281#####> Valid Avg loss: 2.13414, Acc:0.42478, F1: 0.42478
====> Epoch: 118 Train Avg loss: 0.28038, Acc: 0.76320, F1: 0.76320#####> Valid Avg loss: 2.08466, Acc:0.41150, F1: 0.41150
====> Epoch: 119 Train Avg loss: 0.25837, Acc: 0.78808, F1: 0.78808#####> Valid Avg loss: 1.98318, Acc:0.38496, F1: 0.38496
====> Epoch: 120 Train Avg loss: 0.24259, Acc: 0.80845, F1: 0.80845#####> Valid Avg loss: 2.20326, Acc:0.45133, F1: 0.45133
====> Epoch: 121 Train Avg loss: 0.24022, Acc: 0.80468, F1: 0.80468#####> Valid Avg loss: 1.95789, Acc:0.42920, F1: 0.42920
====> Epoch: 122 Train Avg loss: 0.21907, Acc: 0.82127, F1: 0.82127#####> Valid Avg loss: 1.87058, Acc:0.43363, F1: 0.43363
====> Epoch: 123 Train Avg loss: 0.25442, Acc: 0.77451, F1: 0.77451#####> Valid Avg loss: 2.02764, Acc:0.41150, F1: 0.41150
====> Epoch: 124 Train Avg loss: 0.20658, Acc: 0.84992, F1: 0.84992#####> Valid Avg loss: 2.30674, Acc:0.43363, F1: 0.43363
====> Epoch: 125 Train Avg loss: 0.20356, Acc: 0.83258, F1: 0.83258#####> Valid Avg loss: 2.27412, Acc:0.41593, F1: 0.41593
====> Epoch: 126 Train Avg loss: 0.18970, Acc: 0.85294, F1: 0.85294#####> Valid Avg loss: 2.63953, Acc:0.39381, F1: 0.39381
====> Epoch: 127 Train Avg loss: 0.17498, Acc: 0.85596, F1: 0.85596#####> Valid Avg loss: 2.49888, Acc:0.43805, F1: 0.43805
====> Epoch: 128 Train Avg loss: 0.19897, Acc: 0.83861, F1: 0.83861#####> Valid Avg loss: 2.94418, Acc:0.44690, F1: 0.44690
====> Epoch: 129 Train Avg loss: 0.18621, Acc: 0.85370, F1: 0.85370#####> Valid Avg loss: 2.30438, Acc:0.39823, F1: 0.39823
====> Epoch: 130 Train Avg loss: 0.15446, Acc: 0.87934, F1: 0.87934#####> Valid Avg loss: 2.52407, Acc:0.42920, F1: 0.42920
====> Epoch: 131 Train Avg loss: 0.15916, Acc: 0.87858, F1: 0.87858#####> Valid Avg loss: 2.54192, Acc:0.44248, F1: 0.44248
====> Epoch: 132 Train Avg loss: 0.17543, Acc: 0.85897, F1: 0.85897#####> Valid Avg loss: 2.61415, Acc:0.40708, F1: 0.40708
====> Epoch: 133 Train Avg loss: 0.16137, Acc: 0.88009, F1: 0.88009#####> Valid Avg loss: 2.14270, Acc:0.38053, F1: 0.38053
====> Epoch: 134 Train Avg loss: 0.14620, Acc: 0.88462, F1: 0.88462#####> Valid Avg loss: 2.53277, Acc:0.46018, F1: 0.46018
====> Epoch: 135 Train Avg loss: 0.13667, Acc: 0.89744, F1: 0.89744#####> Valid Avg loss: 3.21411, Acc:0.41150, F1: 0.41150
====> Epoch: 136 Train Avg loss: 0.15396, Acc: 0.88914, F1: 0.88914#####> Valid Avg loss: 2.44375, Acc:0.41593, F1: 0.41593
====> Epoch: 137 Train Avg loss: 0.11430, Acc: 0.90724, F1: 0.90724#####> Valid Avg loss: 2.64721, Acc:0.42035, F1: 0.42035
====> Epoch: 138 Train Avg loss: 0.11817, Acc: 0.90875, F1: 0.90875#####> Valid Avg loss: 2.63304, Acc:0.40265, F1: 0.40265
====> Epoch: 139 Train Avg loss: 0.09993, Acc: 0.92534, F1: 0.92534#####> Valid Avg loss: 2.47076, Acc:0.40265, F1: 0.40265
====> Epoch: 140 Train Avg loss: 0.13248, Acc: 0.89517, F1: 0.89517#####> Valid Avg loss: 2.46257, Acc:0.37611, F1: 0.37611
====> Epoch: 141 Train Avg loss: 0.11511, Acc: 0.91176, F1: 0.91176#####> Valid Avg loss: 2.47270, Acc:0.39823, F1: 0.39823
====> Epoch: 142 Train Avg loss: 0.10563, Acc: 0.92459, F1: 0.92459#####> Valid Avg loss: 3.00216, Acc:0.42478, F1: 0.42478
====> Epoch: 143 Train Avg loss: 0.11652, Acc: 0.91403, F1: 0.91403#####> Valid Avg loss: 2.76693, Acc:0.43805, F1: 0.43805
====> Epoch: 144 Train Avg loss: 0.09972, Acc: 0.92609, F1: 0.92609#####> Valid Avg loss: 3.00153, Acc:0.43805, F1: 0.43805
====> Epoch: 145 Train Avg loss: 0.10731, Acc: 0.92006, F1: 0.92006#####> Valid Avg loss: 3.22100, Acc:0.40708, F1: 0.40708
====> Epoch: 146 Train Avg loss: 0.11085, Acc: 0.91554, F1: 0.91554#####> Valid Avg loss: 2.77508, Acc:0.43805, F1: 0.43805
====> Epoch: 147 Train Avg loss: 0.08257, Acc: 0.93891, F1: 0.93891#####> Valid Avg loss: 2.70051, Acc:0.44248, F1: 0.44248
====> Epoch: 148 Train Avg loss: 0.10015, Acc: 0.91780, F1: 0.91780#####> Valid Avg loss: 2.69840, Acc:0.43363, F1: 0.43363
====> Epoch: 149 Train Avg loss: 0.12394, Acc: 0.91554, F1: 0.91554#####> Valid Avg loss: 2.86494, Acc:0.41593, F1: 0.41593
====> Epoch: 150 Train Avg loss: 0.08357, Acc: 0.94118, F1: 0.94118#####> Valid Avg loss: 2.59252, Acc:0.39823, F1: 0.39823
====> Epoch: 151 Train Avg loss: 0.05947, Acc: 0.95475, F1: 0.95475#####> Valid Avg loss: 3.09535, Acc:0.42478, F1: 0.42478
====> Epoch: 152 Train Avg loss: 0.10135, Acc: 0.92609, F1: 0.92609#####> Valid Avg loss: 2.77963, Acc:0.38053, F1: 0.38053
====> Epoch: 153 Train Avg loss: 0.07394, Acc: 0.94419, F1: 0.94419#####> Valid Avg loss: 2.43865, Acc:0.38496, F1: 0.38496
====> Epoch: 154 Train Avg loss: 0.07763, Acc: 0.94118, F1: 0.94118#####> Valid Avg loss: 2.46354, Acc:0.39381, F1: 0.39381
====> Epoch: 155 Train Avg loss: 0.08056, Acc: 0.93665, F1: 0.93665#####> Valid Avg loss: 2.62704, Acc:0.37611, F1: 0.37611
====> Epoch: 156 Train Avg loss: 0.09779, Acc: 0.92911, F1: 0.92911#####> Valid Avg loss: 2.72666, Acc:0.42478, F1: 0.42478
====> Epoch: 157 Train Avg loss: 0.07688, Acc: 0.94646, F1: 0.94646#####> Valid Avg loss: 2.69637, Acc:0.43805, F1: 0.43805
====> Epoch: 158 Train Avg loss: 0.08371, Acc: 0.93514, F1: 0.93514#####> Valid Avg loss: 2.88881, Acc:0.44248, F1: 0.44248
====> Epoch: 159 Train Avg loss: 0.06858, Acc: 0.94495, F1: 0.94495#####> Valid Avg loss: 2.86470, Acc:0.42920, F1: 0.42920
====> Epoch: 160 Train Avg loss: 0.07379, Acc: 0.94646, F1: 0.94646#####> Valid Avg loss: 2.70170, Acc:0.42920, F1: 0.42920
====> Epoch: 161 Train Avg loss: 0.06093, Acc: 0.95701, F1: 0.95701#####> Valid Avg loss: 2.69623, Acc:0.39381, F1: 0.39381
====> Epoch: 162 Train Avg loss: 0.10133, Acc: 0.92685, F1: 0.92685#####> Valid Avg loss: 2.83090, Acc:0.42920, F1: 0.42920
====> Epoch: 163 Train Avg loss: 0.05955, Acc: 0.95626, F1: 0.95626#####> Valid Avg loss: 2.89275, Acc:0.40708, F1: 0.40708
====> Epoch: 164 Train Avg loss: 0.03017, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 2.95892, Acc:0.40708, F1: 0.40708
====> Epoch: 165 Train Avg loss: 0.06477, Acc: 0.94721, F1: 0.94721#####> Valid Avg loss: 3.17902, Acc:0.40708, F1: 0.40708
====> Epoch: 166 Train Avg loss: 0.10008, Acc: 0.92760, F1: 0.92760#####> Valid Avg loss: 2.96991, Acc:0.42920, F1: 0.42920
====> Epoch: 167 Train Avg loss: 0.06108, Acc: 0.95249, F1: 0.95249#####> Valid Avg loss: 3.15632, Acc:0.42920, F1: 0.42920
====> Epoch: 168 Train Avg loss: 0.06348, Acc: 0.95173, F1: 0.95173#####> Valid Avg loss: 2.87719, Acc:0.42035, F1: 0.42035
====> Epoch: 169 Train Avg loss: 0.05266, Acc: 0.95701, F1: 0.95701#####> Valid Avg loss: 2.93086, Acc:0.43805, F1: 0.43805
====> Epoch: 170 Train Avg loss: 0.06138, Acc: 0.95173, F1: 0.95173#####> Valid Avg loss: 3.12163, Acc:0.39823, F1: 0.39823
====> Epoch: 171 Train Avg loss: 0.05071, Acc: 0.95777, F1: 0.95777#####> Valid Avg loss: 3.35232, Acc:0.42920, F1: 0.42920
====> Epoch: 172 Train Avg loss: 0.03154, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 3.25432, Acc:0.41593, F1: 0.41593
====> Epoch: 173 Train Avg loss: 0.07501, Acc: 0.94042, F1: 0.94042#####> Valid Avg loss: 3.11264, Acc:0.45133, F1: 0.45133
====> Epoch: 174 Train Avg loss: 0.05832, Acc: 0.95023, F1: 0.95023#####> Valid Avg loss: 2.83585, Acc:0.40265, F1: 0.40265
====> Epoch: 175 Train Avg loss: 0.03350, Acc: 0.96606, F1: 0.96606#####> Valid Avg loss: 3.00428, Acc:0.42478, F1: 0.42478
====> Epoch: 176 Train Avg loss: 0.07233, Acc: 0.94721, F1: 0.94721#####> Valid Avg loss: 3.14210, Acc:0.43363, F1: 0.43363
====> Epoch: 177 Train Avg loss: 0.04026, Acc: 0.96229, F1: 0.96229#####> Valid Avg loss: 3.03560, Acc:0.40265, F1: 0.40265
====> Epoch: 178 Train Avg loss: 0.02194, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.29183, Acc:0.40708, F1: 0.40708
====> Epoch: 179 Train Avg loss: 0.02605, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 3.37294, Acc:0.44248, F1: 0.44248
====> Epoch: 180 Train Avg loss: 0.11825, Acc: 0.91780, F1: 0.91780#####> Valid Avg loss: 3.26079, Acc:0.44690, F1: 0.44690
====> Epoch: 181 Train Avg loss: 0.02338, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.82393, Acc:0.44248, F1: 0.44248
====> Epoch: 182 Train Avg loss: 0.03149, Acc: 0.97285, F1: 0.97285#####> Valid Avg loss: 3.24276, Acc:0.43805, F1: 0.43805
====> Epoch: 183 Train Avg loss: 0.05558, Acc: 0.95098, F1: 0.95098#####> Valid Avg loss: 2.96336, Acc:0.46018, F1: 0.46018
====> Epoch: 184 Train Avg loss: 0.04505, Acc: 0.96078, F1: 0.96078#####> Valid Avg loss: 3.01599, Acc:0.42478, F1: 0.42478
====> Epoch: 185 Train Avg loss: 0.04039, Acc: 0.96908, F1: 0.96908#####> Valid Avg loss: 3.20824, Acc:0.41593, F1: 0.41593
====> Epoch: 186 Train Avg loss: 0.02814, Acc: 0.97662, F1: 0.97662#####> Valid Avg loss: 3.22393, Acc:0.41150, F1: 0.41150
====> Epoch: 187 Train Avg loss: 0.05716, Acc: 0.95626, F1: 0.95626#####> Valid Avg loss: 2.30282, Acc:0.42478, F1: 0.42478
====> Epoch: 188 Train Avg loss: 0.04288, Acc: 0.96456, F1: 0.96456#####> Valid Avg loss: 3.13650, Acc:0.44690, F1: 0.44690
====> Epoch: 189 Train Avg loss: 0.03922, Acc: 0.96983, F1: 0.96983#####> Valid Avg loss: 3.25041, Acc:0.44248, F1: 0.44248
====> Epoch: 190 Train Avg loss: 0.02453, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 3.28912, Acc:0.43363, F1: 0.43363
====> Epoch: 191 Train Avg loss: 0.03445, Acc: 0.96380, F1: 0.96380#####> Valid Avg loss: 3.49842, Acc:0.46018, F1: 0.46018
====> Epoch: 192 Train Avg loss: 0.05455, Acc: 0.95551, F1: 0.95551#####> Valid Avg loss: 3.57698, Acc:0.43805, F1: 0.43805
====> Epoch: 193 Train Avg loss: 0.02580, Acc: 0.97360, F1: 0.97360#####> Valid Avg loss: 3.47595, Acc:0.41593, F1: 0.41593
====> Epoch: 194 Train Avg loss: 0.03535, Acc: 0.96456, F1: 0.96456#####> Valid Avg loss: 3.51835, Acc:0.44690, F1: 0.44690
====> Epoch: 195 Train Avg loss: 0.02350, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 3.16892, Acc:0.42920, F1: 0.42920
====> Epoch: 196 Train Avg loss: 0.02298, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 3.19409, Acc:0.40708, F1: 0.40708
====> Epoch: 197 Train Avg loss: 0.06470, Acc: 0.95173, F1: 0.95173#####> Valid Avg loss: 3.18397, Acc:0.42920, F1: 0.42920
====> Epoch: 198 Train Avg loss: 0.02832, Acc: 0.97210, F1: 0.97210#####> Valid Avg loss: 3.42226, Acc:0.42920, F1: 0.42920
====> Epoch: 199 Train Avg loss: 0.01600, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.30216, Acc:0.42920, F1: 0.42920
====> Epoch: 200 Train Avg loss: 0.01875, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.27209, Acc:0.43805, F1: 0.43805
====> Epoch: 201 Train Avg loss: 0.03377, Acc: 0.97134, F1: 0.97134#####> Valid Avg loss: 3.32328, Acc:0.45133, F1: 0.45133
====> Epoch: 202 Train Avg loss: 0.03435, Acc: 0.96983, F1: 0.96983#####> Valid Avg loss: 3.58177, Acc:0.42478, F1: 0.42478
====> Epoch: 203 Train Avg loss: 0.01865, Acc: 0.97587, F1: 0.97587#####> Valid Avg loss: 3.24437, Acc:0.42920, F1: 0.42920
====> Epoch: 204 Train Avg loss: 0.01675, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.10452, Acc:0.40708, F1: 0.40708
====> Epoch: 205 Train Avg loss: 0.01594, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.31317, Acc:0.41150, F1: 0.41150
====> Epoch: 206 Train Avg loss: 0.04140, Acc: 0.96456, F1: 0.96456#####> Valid Avg loss: 3.16550, Acc:0.43805, F1: 0.43805
====> Epoch: 207 Train Avg loss: 0.01629, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.25785, Acc:0.43363, F1: 0.43363
====> Epoch: 208 Train Avg loss: 0.01732, Acc: 0.97587, F1: 0.97587#####> Valid Avg loss: 3.32989, Acc:0.42920, F1: 0.42920
====> Epoch: 209 Train Avg loss: 0.04353, Acc: 0.96606, F1: 0.96606#####> Valid Avg loss: 3.10837, Acc:0.42478, F1: 0.42478
====> Epoch: 210 Train Avg loss: 0.01606, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.46880, Acc:0.43805, F1: 0.43805
====> Epoch: 211 Train Avg loss: 0.01505, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.19386, Acc:0.44248, F1: 0.44248
====> Epoch: 212 Train Avg loss: 0.01635, Acc: 0.97813, F1: 0.97813#####> Valid Avg loss: 3.41714, Acc:0.44690, F1: 0.44690
====> Epoch: 213 Train Avg loss: 0.05006, Acc: 0.96003, F1: 0.96003#####> Valid Avg loss: 3.14302, Acc:0.42920, F1: 0.42920
====> Epoch: 214 Train Avg loss: 0.01706, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 3.09275, Acc:0.41593, F1: 0.41593
====> Epoch: 215 Train Avg loss: 0.01515, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.10410, Acc:0.42035, F1: 0.42035
====> Epoch: 216 Train Avg loss: 0.01427, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.24759, Acc:0.42478, F1: 0.42478
====> Epoch: 217 Train Avg loss: 0.01443, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.14779, Acc:0.41150, F1: 0.41150
====> Epoch: 218 Train Avg loss: 0.04485, Acc: 0.96531, F1: 0.96531#####> Valid Avg loss: 3.17239, Acc:0.43805, F1: 0.43805
====> Epoch: 219 Train Avg loss: 0.01622, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.35096, Acc:0.43805, F1: 0.43805
====> Epoch: 220 Train Avg loss: 0.01324, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 2.91304, Acc:0.41593, F1: 0.41593
====> Epoch: 221 Train Avg loss: 0.01463, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.07226, Acc:0.42920, F1: 0.42920
====> Epoch: 222 Train Avg loss: 0.01294, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.08739, Acc:0.42478, F1: 0.42478
====> Epoch: 223 Train Avg loss: 0.01531, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.01454, Acc:0.40265, F1: 0.40265
====> Epoch: 224 Train Avg loss: 0.02452, Acc: 0.97360, F1: 0.97360#####> Valid Avg loss: 3.72481, Acc:0.42478, F1: 0.42478
====> Epoch: 225 Train Avg loss: 0.02304, Acc: 0.97436, F1: 0.97436#####> Valid Avg loss: 3.22272, Acc:0.41593, F1: 0.41593
====> Epoch: 226 Train Avg loss: 0.01291, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 3.38063, Acc:0.42920, F1: 0.42920
====> Epoch: 227 Train Avg loss: 0.01345, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.36747, Acc:0.43363, F1: 0.43363
====> Epoch: 228 Train Avg loss: 0.01270, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.50988, Acc:0.43363, F1: 0.43363
====> Epoch: 229 Train Avg loss: 0.02432, Acc: 0.97210, F1: 0.97210#####> Valid Avg loss: 3.19975, Acc:0.44690, F1: 0.44690
====> Epoch: 230 Train Avg loss: 0.01171, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.44845, Acc:0.44248, F1: 0.44248
====> Epoch: 231 Train Avg loss: 0.01119, Acc: 0.98492, F1: 0.98492#####> Valid Avg loss: 3.01804, Acc:0.43363, F1: 0.43363
===> Epoch: 231: Training loss decreased (0.01163 --> 0.01119), Acc: (0.98567 --> 0.98492), F1: (0.98567 --> 0.98492).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 232 Train Avg loss: 0.01264, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.43446, Acc:0.44248, F1: 0.44248
====> Epoch: 233 Train Avg loss: 0.01284, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 3.18835, Acc:0.42035, F1: 0.42035
====> Epoch: 234 Train Avg loss: 0.01437, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 3.31155, Acc:0.42478, F1: 0.42478
====> Epoch: 235 Train Avg loss: 0.01428, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.52814, Acc:0.44248, F1: 0.44248
====> Epoch: 236 Train Avg loss: 0.01234, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.46253, Acc:0.43363, F1: 0.43363
====> Epoch: 237 Train Avg loss: 0.01232, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.24094, Acc:0.42920, F1: 0.42920
====> Epoch: 238 Train Avg loss: 0.01206, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.19521, Acc:0.38053, F1: 0.38053
====> Epoch: 239 Train Avg loss: 0.01375, Acc: 0.97813, F1: 0.97813#####> Valid Avg loss: 3.08371, Acc:0.40708, F1: 0.40708
====> Epoch: 240 Train Avg loss: 0.01183, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.37400, Acc:0.42478, F1: 0.42478
====> Epoch: 241 Train Avg loss: 0.01552, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.06346, Acc:0.40265, F1: 0.40265
====> Epoch: 242 Train Avg loss: 0.01161, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.36268, Acc:0.42478, F1: 0.42478
====> Epoch: 243 Train Avg loss: 0.01075, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.50094, Acc:0.42478, F1: 0.42478
===> Epoch: 243: Training loss decreased (0.01119 --> 0.01075), Acc: (0.98492 --> 0.98190), F1: (0.98492 --> 0.98190).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 244 Train Avg loss: 0.01159, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.56875, Acc:0.42035, F1: 0.42035
====> Epoch: 245 Train Avg loss: 0.01421, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.49345, Acc:0.40708, F1: 0.40708
====> Epoch: 246 Train Avg loss: 0.01304, Acc: 0.97813, F1: 0.97813#####> Valid Avg loss: 3.70613, Acc:0.42920, F1: 0.42920
====> Epoch: 247 Train Avg loss: 0.01154, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.80961, Acc:0.42478, F1: 0.42478
====> Epoch: 248 Train Avg loss: 0.01109, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.65751, Acc:0.43805, F1: 0.43805
====> Epoch: 249 Train Avg loss: 0.01150, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.38447, Acc:0.43363, F1: 0.43363
====> Epoch: 250 Train Avg loss: 0.01092, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.22817, Acc:0.40265, F1: 0.40265
====> Epoch: 251 Train Avg loss: 0.01096, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.54069, Acc:0.42478, F1: 0.42478
====> Epoch: 252 Train Avg loss: 0.01116, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.66475, Acc:0.42920, F1: 0.42920
====> Epoch: 253 Train Avg loss: 0.01101, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.42571, Acc:0.40265, F1: 0.40265
====> Epoch: 254 Train Avg loss: 0.01054, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.59770, Acc:0.42478, F1: 0.42478
===> Epoch: 254: Training loss decreased (0.01075 --> 0.01054), Acc: (0.98190 --> 0.98039), F1: (0.98190 --> 0.98039).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 255 Train Avg loss: 0.01084, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 3.24399, Acc:0.42478, F1: 0.42478
====> Epoch: 256 Train Avg loss: 0.01119, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.58713, Acc:0.41593, F1: 0.41593
====> Epoch: 257 Train Avg loss: 0.01108, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 3.67540, Acc:0.42478, F1: 0.42478
====> Epoch: 258 Train Avg loss: 0.01035, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.51837, Acc:0.42478, F1: 0.42478
===> Epoch: 258: Training loss decreased (0.01054 --> 0.01035), Acc: (0.98039 --> 0.97964), F1: (0.98039 --> 0.97964).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 259 Train Avg loss: 0.01120, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.71332, Acc:0.43363, F1: 0.43363
====> Epoch: 260 Train Avg loss: 0.01116, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.42900, Acc:0.40708, F1: 0.40708
====> Epoch: 261 Train Avg loss: 0.01036, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.53416, Acc:0.43363, F1: 0.43363
====> Epoch: 262 Train Avg loss: 0.01023, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.49731, Acc:0.41593, F1: 0.41593
===> Epoch: 262: Training loss decreased (0.01035 --> 0.01023), Acc: (0.97964 --> 0.97888), F1: (0.97964 --> 0.97888).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 263 Train Avg loss: 0.01012, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.54253, Acc:0.42478, F1: 0.42478
===> Epoch: 263: Training loss decreased (0.01023 --> 0.01012), Acc: (0.97888 --> 0.98039), F1: (0.97888 --> 0.98039).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 264 Train Avg loss: 0.01023, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.57284, Acc:0.43805, F1: 0.43805
====> Epoch: 265 Train Avg loss: 0.01020, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 3.48667, Acc:0.42920, F1: 0.42920
====> Epoch: 266 Train Avg loss: 0.01017, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.66584, Acc:0.41593, F1: 0.41593
====> Epoch: 267 Train Avg loss: 0.01021, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.67806, Acc:0.42478, F1: 0.42478
====> Epoch: 268 Train Avg loss: 0.01042, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.71070, Acc:0.41593, F1: 0.41593
====> Epoch: 269 Train Avg loss: 0.00998, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.67334, Acc:0.43805, F1: 0.43805
===> Epoch: 269: Training loss decreased (0.01012 --> 0.00998), Acc: (0.98039 --> 0.98115), F1: (0.98039 --> 0.98115).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 270 Train Avg loss: 0.01016, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 3.78413, Acc:0.42035, F1: 0.42035
====> Epoch: 271 Train Avg loss: 0.00989, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.87276, Acc:0.42920, F1: 0.42920
===> Epoch: 271: Training loss decreased (0.00998 --> 0.00989), Acc: (0.98115 --> 0.98115), F1: (0.98115 --> 0.98115).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 272 Train Avg loss: 0.01017, Acc: 0.98416, F1: 0.98416#####> Valid Avg loss: 3.81511, Acc:0.42035, F1: 0.42035
====> Epoch: 273 Train Avg loss: 0.01010, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 3.90016, Acc:0.41593, F1: 0.41593
====> Epoch: 274 Train Avg loss: 0.01008, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 3.73122, Acc:0.43805, F1: 0.43805
====> Epoch: 275 Train Avg loss: 0.00989, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.70157, Acc:0.43363, F1: 0.43363
====> Epoch: 276 Train Avg loss: 0.00990, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 3.66472, Acc:0.42920, F1: 0.42920
====> Epoch: 277 Train Avg loss: 0.00990, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 3.77743, Acc:0.43363, F1: 0.43363
====> Epoch: 278 Train Avg loss: 0.01001, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.61765, Acc:0.42478, F1: 0.42478
====> Epoch: 279 Train Avg loss: 0.00978, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.74226, Acc:0.42920, F1: 0.42920
===> Epoch: 279: Training loss decreased (0.00989 --> 0.00978), Acc: (0.98115 --> 0.98265), F1: (0.98115 --> 0.98265).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 280 Train Avg loss: 0.00989, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.72520, Acc:0.42920, F1: 0.42920
====> Epoch: 281 Train Avg loss: 0.01104, Acc: 0.98416, F1: 0.98416#####> Valid Avg loss: 3.83062, Acc:0.42478, F1: 0.42478
====> Epoch: 282 Train Avg loss: 0.00971, Acc: 0.98567, F1: 0.98567#####> Valid Avg loss: 3.87653, Acc:0.42920, F1: 0.42920
===> Epoch: 282: Training loss decreased (0.00978 --> 0.00971), Acc: (0.98265 --> 0.98567), F1: (0.98265 --> 0.98567).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 283 Train Avg loss: 0.00971, Acc: 0.98492, F1: 0.98492#####> Valid Avg loss: 3.82233, Acc:0.42035, F1: 0.42035
====> Epoch: 284 Train Avg loss: 0.00968, Acc: 0.98416, F1: 0.98416#####> Valid Avg loss: 3.73743, Acc:0.42035, F1: 0.42035
===> Epoch: 284: Training loss decreased (0.00971 --> 0.00968), Acc: (0.98567 --> 0.98416), F1: (0.98567 --> 0.98416).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 285 Train Avg loss: 0.00946, Acc: 0.98643, F1: 0.98643#####> Valid Avg loss: 3.73813, Acc:0.42035, F1: 0.42035
===> Epoch: 285: Training loss decreased (0.00968 --> 0.00946), Acc: (0.98416 --> 0.98643), F1: (0.98416 --> 0.98643).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 286 Train Avg loss: 0.01056, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 3.72331, Acc:0.42035, F1: 0.42035
====> Epoch: 287 Train Avg loss: 0.00966, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.67433, Acc:0.42035, F1: 0.42035
====> Epoch: 288 Train Avg loss: 0.01004, Acc: 0.98416, F1: 0.98416#####> Valid Avg loss: 3.67491, Acc:0.41150, F1: 0.41150
====> Epoch: 289 Train Avg loss: 0.00986, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.90407, Acc:0.42035, F1: 0.42035
====> Epoch: 290 Train Avg loss: 0.00958, Acc: 0.98416, F1: 0.98416#####> Valid Avg loss: 3.85016, Acc:0.42035, F1: 0.42035
====> Epoch: 291 Train Avg loss: 0.00958, Acc: 0.98492, F1: 0.98492#####> Valid Avg loss: 3.77105, Acc:0.42035, F1: 0.42035
====> Epoch: 292 Train Avg loss: 0.00956, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.72432, Acc:0.41593, F1: 0.41593
====> Epoch: 293 Train Avg loss: 0.00949, Acc: 0.98567, F1: 0.98567#####> Valid Avg loss: 3.75886, Acc:0.42035, F1: 0.42035
====> Epoch: 294 Train Avg loss: 0.00948, Acc: 0.98567, F1: 0.98567#####> Valid Avg loss: 3.77803, Acc:0.42035, F1: 0.42035
====> Epoch: 295 Train Avg loss: 0.01006, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.83309, Acc:0.42035, F1: 0.42035
====> Epoch: 296 Train Avg loss: 0.00938, Acc: 0.98718, F1: 0.98718#####> Valid Avg loss: 3.68763, Acc:0.42035, F1: 0.42035
===> Epoch: 296: Training loss decreased (0.00946 --> 0.00938), Acc: (0.98643 --> 0.98718), F1: (0.98643 --> 0.98718).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 297 Train Avg loss: 0.00960, Acc: 0.98793, F1: 0.98793#####> Valid Avg loss: 3.88239, Acc:0.42035, F1: 0.42035
====> Epoch: 298 Train Avg loss: 0.00916, Acc: 0.98492, F1: 0.98492#####> Valid Avg loss: 3.75785, Acc:0.42035, F1: 0.42035
===> Epoch: 298: Training loss decreased (0.00938 --> 0.00916), Acc: (0.98718 --> 0.98492), F1: (0.98718 --> 0.98492).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_3
====> Epoch: 299 Train Avg loss: 0.00954, Acc: 0.98643, F1: 0.98643#####> Valid Avg loss: 3.81294, Acc:0.42035, F1: 0.42035
====> Epoch: 300 Train Avg loss: 0.47870, Acc: 0.67421, F1: 0.67421#####> Valid Avg loss: 0.85288, Acc:0.42478, F1: 0.42478
====> Epoch: 301 Train Avg loss: 0.46057, Acc: 0.63047, F1: 0.63047#####> Valid Avg loss: 1.15741, Acc:0.46460, F1: 0.46460
====> Epoch: 302 Train Avg loss: 0.42964, Acc: 0.64253, F1: 0.64253#####> Valid Avg loss: 0.95397, Acc:0.42920, F1: 0.42920
====> Epoch: 303 Train Avg loss: 0.41154, Acc: 0.67270, F1: 0.67270#####> Valid Avg loss: 1.22119, Acc:0.42035, F1: 0.42035
====> Epoch: 304 Train Avg loss: 0.38010, Acc: 0.68175, F1: 0.68175#####> Valid Avg loss: 1.20398, Acc:0.43363, F1: 0.43363
====> Epoch: 305 Train Avg loss: 0.35758, Acc: 0.71342, F1: 0.71342#####> Valid Avg loss: 1.18238, Acc:0.46018, F1: 0.46018
====> Epoch: 306 Train Avg loss: 0.34129, Acc: 0.70814, F1: 0.70814#####> Valid Avg loss: 1.30671, Acc:0.42920, F1: 0.42920
====> Epoch: 307 Train Avg loss: 0.33753, Acc: 0.72624, F1: 0.72624#####> Valid Avg loss: 1.23555, Acc:0.38496, F1: 0.38496
====> Epoch: 308 Train Avg loss: 0.30073, Acc: 0.75339, F1: 0.75339#####> Valid Avg loss: 1.57023, Acc:0.41593, F1: 0.41593
====> Epoch: 309 Train Avg loss: 0.29679, Acc: 0.76320, F1: 0.76320#####> Valid Avg loss: 1.49406, Acc:0.41150, F1: 0.41150
====> Epoch: 310 Train Avg loss: 0.28676, Acc: 0.77225, F1: 0.77225#####> Valid Avg loss: 1.81616, Acc:0.39823, F1: 0.39823
====> Epoch: 311 Train Avg loss: 0.25420, Acc: 0.78884, F1: 0.78884#####> Valid Avg loss: 1.64283, Acc:0.44690, F1: 0.44690
====> Epoch: 312 Train Avg loss: 0.24814, Acc: 0.80317, F1: 0.80317#####> Valid Avg loss: 1.83176, Acc:0.43363, F1: 0.43363
====> Epoch: 313 Train Avg loss: 0.22622, Acc: 0.81976, F1: 0.81976#####> Valid Avg loss: 1.82174, Acc:0.41593, F1: 0.41593
====> Epoch: 314 Train Avg loss: 0.26589, Acc: 0.78733, F1: 0.78733#####> Valid Avg loss: 1.65159, Acc:0.40265, F1: 0.40265
====> Epoch: 315 Train Avg loss: 0.18784, Acc: 0.84842, F1: 0.84842#####> Valid Avg loss: 2.08148, Acc:0.37168, F1: 0.37168
====> Epoch: 316 Train Avg loss: 0.17050, Acc: 0.86953, F1: 0.86953#####> Valid Avg loss: 2.37642, Acc:0.46018, F1: 0.46018
====> Epoch: 317 Train Avg loss: 0.20523, Acc: 0.84615, F1: 0.84615#####> Valid Avg loss: 2.25508, Acc:0.44690, F1: 0.44690
====> Epoch: 318 Train Avg loss: 0.18635, Acc: 0.86124, F1: 0.86124#####> Valid Avg loss: 2.17748, Acc:0.42920, F1: 0.42920
====> Epoch: 319 Train Avg loss: 0.19300, Acc: 0.84238, F1: 0.84238#####> Valid Avg loss: 2.13784, Acc:0.45133, F1: 0.45133
====> Epoch: 320 Train Avg loss: 0.14899, Acc: 0.88311, F1: 0.88311#####> Valid Avg loss: 1.76364, Acc:0.40265, F1: 0.40265
====> Epoch: 321 Train Avg loss: 0.14361, Acc: 0.89593, F1: 0.89593#####> Valid Avg loss: 2.27035, Acc:0.39381, F1: 0.39381
====> Epoch: 322 Train Avg loss: 0.13879, Acc: 0.88989, F1: 0.88989#####> Valid Avg loss: 2.75987, Acc:0.41593, F1: 0.41593
====> Epoch: 323 Train Avg loss: 0.15713, Acc: 0.88160, F1: 0.88160#####> Valid Avg loss: 2.38303, Acc:0.44690, F1: 0.44690
====> Epoch: 324 Train Avg loss: 0.13236, Acc: 0.89517, F1: 0.89517#####> Valid Avg loss: 1.99348, Acc:0.38496, F1: 0.38496
====> Epoch: 325 Train Avg loss: 0.18190, Acc: 0.85822, F1: 0.85822#####> Valid Avg loss: 2.18078, Acc:0.43805, F1: 0.43805
====> Epoch: 326 Train Avg loss: 0.10939, Acc: 0.92760, F1: 0.92760#####> Valid Avg loss: 2.35551, Acc:0.38053, F1: 0.38053
====> Epoch: 327 Train Avg loss: 0.11748, Acc: 0.91780, F1: 0.91780#####> Valid Avg loss: 2.54426, Acc:0.41593, F1: 0.41593
====> Epoch: 328 Train Avg loss: 0.14406, Acc: 0.89442, F1: 0.89442#####> Valid Avg loss: 2.77625, Acc:0.42478, F1: 0.42478
====> Epoch: 329 Train Avg loss: 0.10672, Acc: 0.91252, F1: 0.91252#####> Valid Avg loss: 2.98703, Acc:0.43805, F1: 0.43805
====> Epoch: 330 Train Avg loss: 0.10657, Acc: 0.91704, F1: 0.91704#####> Valid Avg loss: 2.19205, Acc:0.34956, F1: 0.34956
====> Epoch: 331 Train Avg loss: 0.12817, Acc: 0.90347, F1: 0.90347#####> Valid Avg loss: 2.69590, Acc:0.40708, F1: 0.40708
====> Epoch: 332 Train Avg loss: 0.10150, Acc: 0.92308, F1: 0.92308#####> Valid Avg loss: 2.82968, Acc:0.43363, F1: 0.43363
====> Epoch: 333 Train Avg loss: 0.10931, Acc: 0.91780, F1: 0.91780#####> Valid Avg loss: 2.34571, Acc:0.36726, F1: 0.36726
====> Epoch: 334 Train Avg loss: 0.12023, Acc: 0.90799, F1: 0.90799#####> Valid Avg loss: 2.72814, Acc:0.42920, F1: 0.42920
====> Epoch: 335 Train Avg loss: 0.07501, Acc: 0.94570, F1: 0.94570#####> Valid Avg loss: 2.84575, Acc:0.46018, F1: 0.46018
====> Epoch: 336 Train Avg loss: 0.13456, Acc: 0.90649, F1: 0.90649#####> Valid Avg loss: 2.66380, Acc:0.42920, F1: 0.42920
====> Epoch: 337 Train Avg loss: 0.09570, Acc: 0.93213, F1: 0.93213#####> Valid Avg loss: 2.32877, Acc:0.41150, F1: 0.41150
====> Epoch: 338 Train Avg loss: 0.11291, Acc: 0.91101, F1: 0.91101#####> Valid Avg loss: 2.60608, Acc:0.42920, F1: 0.42920
====> Epoch: 339 Train Avg loss: 0.13855, Acc: 0.89744, F1: 0.89744#####> Valid Avg loss: 1.93903, Acc:0.38938, F1: 0.38938
====> Epoch: 340 Train Avg loss: 0.06885, Acc: 0.95023, F1: 0.95023#####> Valid Avg loss: 2.30369, Acc:0.39381, F1: 0.39381
====> Epoch: 341 Train Avg loss: 0.08403, Acc: 0.93816, F1: 0.93816#####> Valid Avg loss: 2.82108, Acc:0.42035, F1: 0.42035
====> Epoch: 342 Train Avg loss: 0.08803, Acc: 0.93967, F1: 0.93967#####> Valid Avg loss: 3.06730, Acc:0.43805, F1: 0.43805
====> Epoch: 343 Train Avg loss: 0.07623, Acc: 0.93665, F1: 0.93665#####> Valid Avg loss: 2.95139, Acc:0.40265, F1: 0.40265
====> Epoch: 344 Train Avg loss: 0.12589, Acc: 0.90422, F1: 0.90422#####> Valid Avg loss: 2.66403, Acc:0.40708, F1: 0.40708
====> Epoch: 345 Train Avg loss: 0.06161, Acc: 0.95701, F1: 0.95701#####> Valid Avg loss: 2.68500, Acc:0.42478, F1: 0.42478
====> Epoch: 346 Train Avg loss: 0.06503, Acc: 0.94796, F1: 0.94796#####> Valid Avg loss: 3.26052, Acc:0.41593, F1: 0.41593
====> Epoch: 347 Train Avg loss: 0.14528, Acc: 0.89668, F1: 0.89668#####> Valid Avg loss: 2.41712, Acc:0.38053, F1: 0.38053
====> Epoch: 348 Train Avg loss: 0.09221, Acc: 0.92685, F1: 0.92685#####> Valid Avg loss: 2.64310, Acc:0.41150, F1: 0.41150
====> Epoch: 349 Train Avg loss: 0.09592, Acc: 0.93439, F1: 0.93439#####> Valid Avg loss: 2.34904, Acc:0.42035, F1: 0.42035
====> Epoch: 350 Train Avg loss: 0.05367, Acc: 0.95701, F1: 0.95701#####> Valid Avg loss: 2.73316, Acc:0.43805, F1: 0.43805
====> Epoch: 351 Train Avg loss: 0.07890, Acc: 0.94268, F1: 0.94268#####> Valid Avg loss: 3.06070, Acc:0.42035, F1: 0.42035
====> Epoch: 352 Train Avg loss: 0.08839, Acc: 0.92986, F1: 0.92986#####> Valid Avg loss: 2.34666, Acc:0.43363, F1: 0.43363
====> Epoch: 353 Train Avg loss: 0.09729, Acc: 0.92836, F1: 0.92836#####> Valid Avg loss: 2.32622, Acc:0.36726, F1: 0.36726
====> Epoch: 354 Train Avg loss: 0.04788, Acc: 0.96078, F1: 0.96078#####> Valid Avg loss: 3.24483, Acc:0.43805, F1: 0.43805
====> Epoch: 355 Train Avg loss: 0.11859, Acc: 0.91554, F1: 0.91554#####> Valid Avg loss: 2.00967, Acc:0.39823, F1: 0.39823
====> Epoch: 356 Train Avg loss: 0.11055, Acc: 0.91629, F1: 0.91629#####> Valid Avg loss: 2.31248, Acc:0.42035, F1: 0.42035
====> Epoch: 357 Train Avg loss: 0.06639, Acc: 0.94721, F1: 0.94721#####> Valid Avg loss: 2.48069, Acc:0.41593, F1: 0.41593
====> Epoch: 358 Train Avg loss: 0.10748, Acc: 0.91931, F1: 0.91931#####> Valid Avg loss: 2.61155, Acc:0.44690, F1: 0.44690
====> Epoch: 359 Train Avg loss: 0.07211, Acc: 0.94947, F1: 0.94947#####> Valid Avg loss: 2.65842, Acc:0.42920, F1: 0.42920
====> Epoch: 360 Train Avg loss: 0.04356, Acc: 0.96305, F1: 0.96305#####> Valid Avg loss: 2.45715, Acc:0.38053, F1: 0.38053
====> Epoch: 361 Train Avg loss: 0.08072, Acc: 0.94118, F1: 0.94118#####> Valid Avg loss: 2.96240, Acc:0.44248, F1: 0.44248
====> Epoch: 362 Train Avg loss: 0.09346, Acc: 0.92986, F1: 0.92986#####> Valid Avg loss: 2.67881, Acc:0.35841, F1: 0.35841
====> Epoch: 363 Train Avg loss: 0.08949, Acc: 0.92986, F1: 0.92986#####> Valid Avg loss: 2.61462, Acc:0.41150, F1: 0.41150
====> Epoch: 364 Train Avg loss: 0.06662, Acc: 0.94646, F1: 0.94646#####> Valid Avg loss: 2.53342, Acc:0.42035, F1: 0.42035
====> Epoch: 365 Train Avg loss: 0.05071, Acc: 0.96380, F1: 0.96380#####> Valid Avg loss: 2.86766, Acc:0.39823, F1: 0.39823
====> Epoch: 366 Train Avg loss: 0.07734, Acc: 0.94570, F1: 0.94570#####> Valid Avg loss: 2.62688, Acc:0.40708, F1: 0.40708
====> Epoch: 367 Train Avg loss: 0.06788, Acc: 0.94495, F1: 0.94495#####> Valid Avg loss: 2.85661, Acc:0.43363, F1: 0.43363
====> Epoch: 368 Train Avg loss: 0.06889, Acc: 0.94646, F1: 0.94646#####> Valid Avg loss: 2.65322, Acc:0.43363, F1: 0.43363
====> Epoch: 369 Train Avg loss: 0.05552, Acc: 0.95852, F1: 0.95852#####> Valid Avg loss: 2.79059, Acc:0.42478, F1: 0.42478
====> Epoch: 370 Train Avg loss: 0.07122, Acc: 0.94570, F1: 0.94570#####> Valid Avg loss: 2.45396, Acc:0.39823, F1: 0.39823
====> Epoch: 371 Train Avg loss: 0.02630, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 2.80936, Acc:0.40708, F1: 0.40708
====> Epoch: 372 Train Avg loss: 0.14283, Acc: 0.89442, F1: 0.89442#####> Valid Avg loss: 2.19373, Acc:0.46460, F1: 0.46460
====> Epoch: 373 Train Avg loss: 0.08303, Acc: 0.93665, F1: 0.93665#####> Valid Avg loss: 2.52017, Acc:0.42478, F1: 0.42478
====> Epoch: 374 Train Avg loss: 0.03548, Acc: 0.96983, F1: 0.96983#####> Valid Avg loss: 2.86799, Acc:0.42035, F1: 0.42035
====> Epoch: 375 Train Avg loss: 0.06681, Acc: 0.94947, F1: 0.94947#####> Valid Avg loss: 2.62739, Acc:0.39823, F1: 0.39823
====> Epoch: 376 Train Avg loss: 0.05298, Acc: 0.95777, F1: 0.95777#####> Valid Avg loss: 2.76667, Acc:0.42478, F1: 0.42478
====> Epoch: 377 Train Avg loss: 0.06577, Acc: 0.94796, F1: 0.94796#####> Valid Avg loss: 2.71408, Acc:0.38496, F1: 0.38496
====> Epoch: 378 Train Avg loss: 0.06122, Acc: 0.94570, F1: 0.94570#####> Valid Avg loss: 2.98803, Acc:0.42920, F1: 0.42920
====> Epoch: 379 Train Avg loss: 0.04726, Acc: 0.96229, F1: 0.96229#####> Valid Avg loss: 3.02231, Acc:0.42035, F1: 0.42035
====> Epoch: 380 Train Avg loss: 0.07950, Acc: 0.93816, F1: 0.93816#####> Valid Avg loss: 2.75330, Acc:0.41150, F1: 0.41150
====> Epoch: 381 Train Avg loss: 0.02754, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 3.03475, Acc:0.43805, F1: 0.43805
====> Epoch: 382 Train Avg loss: 0.06641, Acc: 0.95098, F1: 0.95098#####> Valid Avg loss: 2.67266, Acc:0.33186, F1: 0.33186
====> Epoch: 383 Train Avg loss: 0.05619, Acc: 0.96078, F1: 0.96078#####> Valid Avg loss: 3.02112, Acc:0.44690, F1: 0.44690
====> Epoch: 384 Train Avg loss: 0.08975, Acc: 0.92760, F1: 0.92760#####> Valid Avg loss: 2.59991, Acc:0.43363, F1: 0.43363
====> Epoch: 385 Train Avg loss: 0.03652, Acc: 0.96757, F1: 0.96757#####> Valid Avg loss: 2.88088, Acc:0.43363, F1: 0.43363
====> Epoch: 386 Train Avg loss: 0.05215, Acc: 0.95475, F1: 0.95475#####> Valid Avg loss: 2.31227, Acc:0.39381, F1: 0.39381
====> Epoch: 387 Train Avg loss: 0.06358, Acc: 0.94419, F1: 0.94419#####> Valid Avg loss: 2.70331, Acc:0.44690, F1: 0.44690
====> Epoch: 388 Train Avg loss: 0.05167, Acc: 0.95852, F1: 0.95852#####> Valid Avg loss: 2.52532, Acc:0.38053, F1: 0.38053
====> Epoch: 389 Train Avg loss: 0.03012, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 3.13187, Acc:0.43805, F1: 0.43805
====> Epoch: 390 Train Avg loss: 0.02840, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 2.75958, Acc:0.42920, F1: 0.42920
====> Epoch: 391 Train Avg loss: 0.07591, Acc: 0.93665, F1: 0.93665#####> Valid Avg loss: 2.67093, Acc:0.41593, F1: 0.41593
====> Epoch: 392 Train Avg loss: 0.05495, Acc: 0.95249, F1: 0.95249#####> Valid Avg loss: 2.61286, Acc:0.45575, F1: 0.45575
====> Epoch: 393 Train Avg loss: 0.07072, Acc: 0.94721, F1: 0.94721#####> Valid Avg loss: 2.62023, Acc:0.41593, F1: 0.41593
====> Epoch: 394 Train Avg loss: 0.02630, Acc: 0.97587, F1: 0.97587#####> Valid Avg loss: 2.80281, Acc:0.44690, F1: 0.44690
====> Epoch: 395 Train Avg loss: 0.01732, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.98747, Acc:0.46460, F1: 0.46460
====> Epoch: 396 Train Avg loss: 0.07563, Acc: 0.94947, F1: 0.94947#####> Valid Avg loss: 2.54275, Acc:0.41593, F1: 0.41593
====> Epoch: 397 Train Avg loss: 0.06928, Acc: 0.94570, F1: 0.94570#####> Valid Avg loss: 2.72903, Acc:0.43805, F1: 0.43805
====> Epoch: 398 Train Avg loss: 0.03119, Acc: 0.96757, F1: 0.96757#####> Valid Avg loss: 2.62428, Acc:0.41150, F1: 0.41150
====> Epoch: 399 Train Avg loss: 0.06629, Acc: 0.95400, F1: 0.95400#####> Valid Avg loss: 2.54189, Acc:0.42478, F1: 0.42478
====> Epoch: 400 Train Avg loss: 0.05168, Acc: 0.95852, F1: 0.95852#####> Valid Avg loss: 2.84166, Acc:0.41593, F1: 0.41593
====> Epoch: 401 Train Avg loss: 0.04784, Acc: 0.95852, F1: 0.95852#####> Valid Avg loss: 2.46789, Acc:0.39823, F1: 0.39823
====> Epoch: 402 Train Avg loss: 0.03964, Acc: 0.96757, F1: 0.96757#####> Valid Avg loss: 2.90419, Acc:0.42478, F1: 0.42478
====> Epoch: 403 Train Avg loss: 0.04978, Acc: 0.96003, F1: 0.96003#####> Valid Avg loss: 2.76403, Acc:0.38496, F1: 0.38496
====> Epoch: 404 Train Avg loss: 0.03590, Acc: 0.96757, F1: 0.96757#####> Valid Avg loss: 2.91519, Acc:0.43363, F1: 0.43363
====> Epoch: 405 Train Avg loss: 0.08719, Acc: 0.94268, F1: 0.94268#####> Valid Avg loss: 2.44759, Acc:0.41593, F1: 0.41593
====> Epoch: 406 Train Avg loss: 0.02697, Acc: 0.97285, F1: 0.97285#####> Valid Avg loss: 2.81032, Acc:0.42035, F1: 0.42035
====> Epoch: 407 Train Avg loss: 0.02843, Acc: 0.97662, F1: 0.97662#####> Valid Avg loss: 3.02608, Acc:0.40708, F1: 0.40708
====> Epoch: 408 Train Avg loss: 0.04724, Acc: 0.96305, F1: 0.96305#####> Valid Avg loss: 3.18659, Acc:0.42035, F1: 0.42035
====> Epoch: 409 Train Avg loss: 0.03407, Acc: 0.96757, F1: 0.96757#####> Valid Avg loss: 2.97039, Acc:0.40708, F1: 0.40708
====> Epoch: 410 Train Avg loss: 0.08618, Acc: 0.94419, F1: 0.94419#####> Valid Avg loss: 2.35527, Acc:0.41593, F1: 0.41593
====> Epoch: 411 Train Avg loss: 0.02472, Acc: 0.97436, F1: 0.97436#####> Valid Avg loss: 2.63667, Acc:0.43805, F1: 0.43805
====> Epoch: 412 Train Avg loss: 0.02001, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 2.61289, Acc:0.42478, F1: 0.42478
====> Epoch: 413 Train Avg loss: 0.01666, Acc: 0.98416, F1: 0.98416#####> Valid Avg loss: 2.61612, Acc:0.41150, F1: 0.41150
====> Epoch: 414 Train Avg loss: 0.09121, Acc: 0.93213, F1: 0.93213#####> Valid Avg loss: 2.88761, Acc:0.42478, F1: 0.42478
====> Epoch: 415 Train Avg loss: 0.05526, Acc: 0.96154, F1: 0.96154#####> Valid Avg loss: 2.52867, Acc:0.37168, F1: 0.37168
====> Epoch: 416 Train Avg loss: 0.03541, Acc: 0.96380, F1: 0.96380#####> Valid Avg loss: 2.95792, Acc:0.40265, F1: 0.40265
====> Epoch: 417 Train Avg loss: 0.01580, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.04058, Acc:0.44248, F1: 0.44248
====> Epoch: 418 Train Avg loss: 0.04217, Acc: 0.96456, F1: 0.96456#####> Valid Avg loss: 2.84370, Acc:0.43363, F1: 0.43363
====> Epoch: 419 Train Avg loss: 0.07744, Acc: 0.93590, F1: 0.93590#####> Valid Avg loss: 2.39164, Acc:0.42035, F1: 0.42035
====> Epoch: 420 Train Avg loss: 0.02728, Acc: 0.97285, F1: 0.97285#####> Valid Avg loss: 2.55047, Acc:0.42920, F1: 0.42920
====> Epoch: 421 Train Avg loss: 0.02327, Acc: 0.97587, F1: 0.97587#####> Valid Avg loss: 2.94956, Acc:0.42035, F1: 0.42035
====> Epoch: 422 Train Avg loss: 0.07952, Acc: 0.94570, F1: 0.94570#####> Valid Avg loss: 1.97192, Acc:0.42478, F1: 0.42478
====> Epoch: 423 Train Avg loss: 0.04650, Acc: 0.96380, F1: 0.96380#####> Valid Avg loss: 2.38934, Acc:0.43805, F1: 0.43805
====> Epoch: 424 Train Avg loss: 0.01538, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 2.56610, Acc:0.42920, F1: 0.42920
====> Epoch: 425 Train Avg loss: 0.01411, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 2.90254, Acc:0.42920, F1: 0.42920
====> Epoch: 426 Train Avg loss: 0.01504, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 2.90016, Acc:0.45133, F1: 0.45133
====> Epoch: 427 Train Avg loss: 0.14742, Acc: 0.89367, F1: 0.89367#####> Valid Avg loss: 1.84903, Acc:0.35841, F1: 0.35841
====> Epoch: 428 Train Avg loss: 0.07059, Acc: 0.94495, F1: 0.94495#####> Valid Avg loss: 2.10397, Acc:0.38938, F1: 0.38938
====> Epoch: 429 Train Avg loss: 0.02785, Acc: 0.97285, F1: 0.97285#####> Valid Avg loss: 2.50198, Acc:0.41150, F1: 0.41150
====> Epoch: 430 Train Avg loss: 0.03911, Acc: 0.96531, F1: 0.96531#####> Valid Avg loss: 2.75489, Acc:0.41150, F1: 0.41150
====> Epoch: 431 Train Avg loss: 0.01426, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 2.77237, Acc:0.39823, F1: 0.39823
====> Epoch: 432 Train Avg loss: 0.03414, Acc: 0.96456, F1: 0.96456#####> Valid Avg loss: 2.86166, Acc:0.42035, F1: 0.42035
====> Epoch: 433 Train Avg loss: 0.11748, Acc: 0.91780, F1: 0.91780#####> Valid Avg loss: 2.63623, Acc:0.43363, F1: 0.43363
====> Epoch: 434 Train Avg loss: 0.01818, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.55103, Acc:0.43363, F1: 0.43363
====> Epoch: 435 Train Avg loss: 0.01574, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 2.73610, Acc:0.42478, F1: 0.42478
====> Epoch: 436 Train Avg loss: 0.01466, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 2.66479, Acc:0.42920, F1: 0.42920
====> Epoch: 437 Train Avg loss: 0.07982, Acc: 0.94344, F1: 0.94344#####> Valid Avg loss: 2.34114, Acc:0.42035, F1: 0.42035
====> Epoch: 438 Train Avg loss: 0.02217, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 2.31106, Acc:0.38496, F1: 0.38496
====> Epoch: 439 Train Avg loss: 0.04625, Acc: 0.95928, F1: 0.95928#####> Valid Avg loss: 3.04005, Acc:0.44248, F1: 0.44248
====> Epoch: 440 Train Avg loss: 0.04173, Acc: 0.96229, F1: 0.96229#####> Valid Avg loss: 2.47035, Acc:0.40708, F1: 0.40708
====> Epoch: 441 Train Avg loss: 0.04183, Acc: 0.96456, F1: 0.96456#####> Valid Avg loss: 2.90355, Acc:0.42035, F1: 0.42035
====> Epoch: 442 Train Avg loss: 0.01603, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 3.06477, Acc:0.44248, F1: 0.44248
====> Epoch: 443 Train Avg loss: 0.01336, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 2.99392, Acc:0.43805, F1: 0.43805
====> Epoch: 444 Train Avg loss: 0.01331, Acc: 0.98492, F1: 0.98492#####> Valid Avg loss: 3.19974, Acc:0.44690, F1: 0.44690
====> Epoch: 445 Train Avg loss: 0.07029, Acc: 0.94268, F1: 0.94268#####> Valid Avg loss: 2.30812, Acc:0.40708, F1: 0.40708
====> Epoch: 446 Train Avg loss: 0.02140, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 2.77694, Acc:0.42920, F1: 0.42920
====> Epoch: 447 Train Avg loss: 0.01370, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 2.93260, Acc:0.45575, F1: 0.45575
====> Epoch: 448 Train Avg loss: 0.08508, Acc: 0.92986, F1: 0.92986#####> Valid Avg loss: 2.39677, Acc:0.44690, F1: 0.44690
====> Epoch: 449 Train Avg loss: 0.01756, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 2.65757, Acc:0.42920, F1: 0.42920
====> Epoch: 450 Train Avg loss: 0.01576, Acc: 0.98416, F1: 0.98416#####> Valid Avg loss: 2.67756, Acc:0.42035, F1: 0.42035
====> Epoch: 451 Train Avg loss: 0.01262, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 2.95464, Acc:0.42035, F1: 0.42035
====> Epoch: 452 Train Avg loss: 0.01338, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 2.76843, Acc:0.42478, F1: 0.42478
====> Epoch: 453 Train Avg loss: 0.01245, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 2.98699, Acc:0.42478, F1: 0.42478
====> Epoch: 454 Train Avg loss: 0.13302, Acc: 0.91101, F1: 0.91101#####> Valid Avg loss: 2.28495, Acc:0.42920, F1: 0.42920
====> Epoch: 455 Train Avg loss: 0.01853, Acc: 0.98115, F1: 0.98115#####> Valid Avg loss: 2.50911, Acc:0.41593, F1: 0.41593
====> Epoch: 456 Train Avg loss: 0.01400, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 2.67255, Acc:0.44248, F1: 0.44248
====> Epoch: 457 Train Avg loss: 0.01304, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 2.97789, Acc:0.43805, F1: 0.43805
====> Epoch: 458 Train Avg loss: 0.07148, Acc: 0.94646, F1: 0.94646#####> Valid Avg loss: 2.50341, Acc:0.42920, F1: 0.42920
====> Epoch: 459 Train Avg loss: 0.02643, Acc: 0.97662, F1: 0.97662#####> Valid Avg loss: 2.45653, Acc:0.42478, F1: 0.42478
====> Epoch: 460 Train Avg loss: 0.01847, Acc: 0.97662, F1: 0.97662#####> Valid Avg loss: 2.58150, Acc:0.41593, F1: 0.41593
====> Epoch: 461 Train Avg loss: 0.02382, Acc: 0.97210, F1: 0.97210#####> Valid Avg loss: 2.13134, Acc:0.38938, F1: 0.38938
====> Epoch: 462 Train Avg loss: 0.06746, Acc: 0.94570, F1: 0.94570#####> Valid Avg loss: 2.57185, Acc:0.42478, F1: 0.42478
====> Epoch: 463 Train Avg loss: 0.02155, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 2.92453, Acc:0.44248, F1: 0.44248
====> Epoch: 464 Train Avg loss: 0.01490, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 2.93677, Acc:0.44690, F1: 0.44690
====> Epoch: 465 Train Avg loss: 0.01238, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 3.19033, Acc:0.44248, F1: 0.44248
====> Epoch: 466 Train Avg loss: 0.01498, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.31686, Acc:0.44690, F1: 0.44690
====> Epoch: 467 Train Avg loss: 0.10483, Acc: 0.93137, F1: 0.93137#####> Valid Avg loss: 2.80751, Acc:0.43363, F1: 0.43363
====> Epoch: 468 Train Avg loss: 0.01837, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 2.67148, Acc:0.43363, F1: 0.43363
====> Epoch: 469 Train Avg loss: 0.01399, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 2.80166, Acc:0.44248, F1: 0.44248
====> Epoch: 470 Train Avg loss: 0.01194, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.79130, Acc:0.43805, F1: 0.43805
====> Epoch: 471 Train Avg loss: 0.01181, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 2.85260, Acc:0.44690, F1: 0.44690
====> Epoch: 472 Train Avg loss: 0.11057, Acc: 0.93137, F1: 0.93137#####> Valid Avg loss: 2.11603, Acc:0.41593, F1: 0.41593
====> Epoch: 473 Train Avg loss: 0.02824, Acc: 0.97662, F1: 0.97662#####> Valid Avg loss: 2.38499, Acc:0.42035, F1: 0.42035
====> Epoch: 474 Train Avg loss: 0.01459, Acc: 0.98416, F1: 0.98416#####> Valid Avg loss: 2.57508, Acc:0.43805, F1: 0.43805
====> Epoch: 475 Train Avg loss: 0.01362, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 2.73890, Acc:0.44248, F1: 0.44248
====> Epoch: 476 Train Avg loss: 0.05556, Acc: 0.95400, F1: 0.95400#####> Valid Avg loss: 2.32492, Acc:0.45133, F1: 0.45133
====> Epoch: 477 Train Avg loss: 0.03668, Acc: 0.97059, F1: 0.97059#####> Valid Avg loss: 2.47046, Acc:0.41593, F1: 0.41593
====> Epoch: 478 Train Avg loss: 0.01276, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 2.81865, Acc:0.42035, F1: 0.42035
====> Epoch: 479 Train Avg loss: 0.01809, Acc: 0.97888, F1: 0.97888#####> Valid Avg loss: 2.78954, Acc:0.39381, F1: 0.39381
====> Epoch: 480 Train Avg loss: 0.01198, Acc: 0.98492, F1: 0.98492#####> Valid Avg loss: 2.72814, Acc:0.41593, F1: 0.41593
====> Epoch: 481 Train Avg loss: 0.01212, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 2.82305, Acc:0.40708, F1: 0.40708
====> Epoch: 482 Train Avg loss: 0.06730, Acc: 0.94947, F1: 0.94947#####> Valid Avg loss: 2.56396, Acc:0.44690, F1: 0.44690
====> Epoch: 483 Train Avg loss: 0.04228, Acc: 0.95928, F1: 0.95928#####> Valid Avg loss: 2.41124, Acc:0.40708, F1: 0.40708
====> Epoch: 484 Train Avg loss: 0.02741, Acc: 0.97360, F1: 0.97360#####> Valid Avg loss: 2.64262, Acc:0.43805, F1: 0.43805
====> Epoch: 485 Train Avg loss: 0.01333, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 2.81392, Acc:0.43805, F1: 0.43805
====> Epoch: 486 Train Avg loss: 0.01172, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 2.85653, Acc:0.43363, F1: 0.43363
====> Epoch: 487 Train Avg loss: 0.01184, Acc: 0.97813, F1: 0.97813#####> Valid Avg loss: 2.99112, Acc:0.43363, F1: 0.43363
====> Epoch: 488 Train Avg loss: 0.01140, Acc: 0.98190, F1: 0.98190#####> Valid Avg loss: 2.84990, Acc:0.43363, F1: 0.43363
====> Epoch: 489 Train Avg loss: 0.01121, Acc: 0.98492, F1: 0.98492#####> Valid Avg loss: 3.03991, Acc:0.42478, F1: 0.42478
====> Epoch: 490 Train Avg loss: 0.05816, Acc: 0.95324, F1: 0.95324#####> Valid Avg loss: 2.62014, Acc:0.43363, F1: 0.43363
====> Epoch: 491 Train Avg loss: 0.03927, Acc: 0.96380, F1: 0.96380#####> Valid Avg loss: 2.49523, Acc:0.42478, F1: 0.42478
====> Epoch: 492 Train Avg loss: 0.01369, Acc: 0.98341, F1: 0.98341#####> Valid Avg loss: 2.68492, Acc:0.42920, F1: 0.42920
====> Epoch: 493 Train Avg loss: 0.01192, Acc: 0.98039, F1: 0.98039#####> Valid Avg loss: 2.96967, Acc:0.43363, F1: 0.43363
====> Epoch: 494 Train Avg loss: 0.01382, Acc: 0.97813, F1: 0.97813#####> Valid Avg loss: 3.12432, Acc:0.44248, F1: 0.44248
====> Epoch: 495 Train Avg loss: 0.01188, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.90696, Acc:0.41593, F1: 0.41593
====> Epoch: 496 Train Avg loss: 0.01248, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.02274, Acc:0.42035, F1: 0.42035
====> Epoch: 497 Train Avg loss: 0.01182, Acc: 0.98265, F1: 0.98265#####> Valid Avg loss: 3.21231, Acc:0.43363, F1: 0.43363
====> Epoch: 498 Train Avg loss: 0.04336, Acc: 0.95701, F1: 0.95701#####> Valid Avg loss: 3.06844, Acc:0.43363, F1: 0.43363
====> Epoch: 499 Train Avg loss: 0.01258, Acc: 0.98492, F1: 0.98492#####> Valid Avg loss: 3.14925, Acc:0.43805, F1: 0.43805
====> Epoch: 500 Train Avg loss: 0.01178, Acc: 0.97738, F1: 0.97738#####> Valid Avg loss: 3.46810, Acc:0.44248, F1: 0.44248
#####> Valid Avg loss: 3.24635, Acc:0.37871, F1: 0.37871


$$$$$$> Test it 3: (from train best model) Final Test Avg loss:3.24635, Acc:0.37871, F1:0.37871\n
#####> Valid Avg loss: 0.87941, Acc:0.44802, F1: 0.44802


$$$$$$> Test it 3: (from max acc valid model) Final Test Avg loss:0.87941, Acc:0.44802, F1:0.44802\n
#####> Valid Avg loss: 0.78026, Acc:0.44307, F1: 0.44307


$$$$$$> Test it 3: (from min loss valid model) Final Test Avg loss:0.78026, Acc:0.44307, F1:0.44307\n


	Start execution training validation it 4 

train_dataloader len: 725
valid_dataloader len: 113
test_dataloader len: 140
train performers ids: [2, 4, 6]
valid performers ids: [1]
test performers ids: [5]
train dataset len: 1450, train dataloader len: 725
valid dataset len: 226, valid dataloader len: 113
valid dataset len: 280, test dataloader len: 113
====> Epoch: 1 Train Avg loss: 0.71089, Acc: 0.45310, F1: 0.45310#####> Valid Avg loss: 0.70337, Acc:0.47345, F1: 0.47345
===> Epoch: 1: Training loss decreased (inf --> 0.71089), Acc: (0.00000 --> 0.45310), F1: (0.00000 --> 0.45310).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4

####> Epoch: 1: validation loss decreased (inf --> 0.70337), Acc: (0.00000 --> 0.47345), F1: (0.00000 --> 0.47345).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4

####> Epoch: 1: validation acc increase (inf --> 0.70337), Acc: (0.00000 --> 0.47345), F1: (0.00000 --> 0.47345).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 2 Train Avg loss: 0.67931, Acc: 0.46690, F1: 0.46690#####> Valid Avg loss: 0.69852, Acc:0.47345, F1: 0.47345
===> Epoch: 2: Training loss decreased (0.71089 --> 0.67931), Acc: (0.45310 --> 0.46690), F1: (0.45310 --> 0.46690).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4

####> Epoch: 2: validation loss decreased (0.70337 --> 0.69852), Acc: (0.47345 --> 0.47345), F1: (0.47345 --> 0.47345).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 3 Train Avg loss: 0.66526, Acc: 0.48000, F1: 0.48000#####> Valid Avg loss: 0.68283, Acc:0.47345, F1: 0.47345
===> Epoch: 3: Training loss decreased (0.67931 --> 0.66526), Acc: (0.46690 --> 0.48000), F1: (0.46690 --> 0.48000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4

####> Epoch: 3: validation loss decreased (0.69852 --> 0.68283), Acc: (0.47345 --> 0.47345), F1: (0.47345 --> 0.47345).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 4 Train Avg loss: 0.65541, Acc: 0.48000, F1: 0.48000#####> Valid Avg loss: 0.69941, Acc:0.47345, F1: 0.47345
===> Epoch: 4: Training loss decreased (0.66526 --> 0.65541), Acc: (0.48000 --> 0.48000), F1: (0.48000 --> 0.48000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 5 Train Avg loss: 0.65095, Acc: 0.47862, F1: 0.47862#####> Valid Avg loss: 0.70174, Acc:0.47345, F1: 0.47345
===> Epoch: 5: Training loss decreased (0.65541 --> 0.65095), Acc: (0.48000 --> 0.47862), F1: (0.48000 --> 0.47862).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 6 Train Avg loss: 0.64406, Acc: 0.46759, F1: 0.46759#####> Valid Avg loss: 0.72673, Acc:0.47345, F1: 0.47345
===> Epoch: 6: Training loss decreased (0.65095 --> 0.64406), Acc: (0.47862 --> 0.46759), F1: (0.47862 --> 0.46759).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 7 Train Avg loss: 0.63676, Acc: 0.49517, F1: 0.49517#####> Valid Avg loss: 0.76802, Acc:0.47345, F1: 0.47345
===> Epoch: 7: Training loss decreased (0.64406 --> 0.63676), Acc: (0.46759 --> 0.49517), F1: (0.46759 --> 0.49517).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 8 Train Avg loss: 0.63471, Acc: 0.48069, F1: 0.48069#####> Valid Avg loss: 0.71169, Acc:0.47345, F1: 0.47345
===> Epoch: 8: Training loss decreased (0.63676 --> 0.63471), Acc: (0.49517 --> 0.48069), F1: (0.49517 --> 0.48069).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 9 Train Avg loss: 0.62459, Acc: 0.50000, F1: 0.50000#####> Valid Avg loss: 0.81657, Acc:0.47788, F1: 0.47788
===> Epoch: 9: Training loss decreased (0.63471 --> 0.62459), Acc: (0.48069 --> 0.50000), F1: (0.48069 --> 0.50000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4

####> Epoch: 9: validation acc increase (0.70337 --> 0.81657), Acc: (0.47345 --> 0.47788), F1: (0.47345 --> 0.47788).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 10 Train Avg loss: 0.62193, Acc: 0.51241, F1: 0.51241#####> Valid Avg loss: 0.76119, Acc:0.47345, F1: 0.47345
===> Epoch: 10: Training loss decreased (0.62459 --> 0.62193), Acc: (0.50000 --> 0.51241), F1: (0.50000 --> 0.51241).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 11 Train Avg loss: 0.61624, Acc: 0.51241, F1: 0.51241#####> Valid Avg loss: 0.71222, Acc:0.44248, F1: 0.44248
===> Epoch: 11: Training loss decreased (0.62193 --> 0.61624), Acc: (0.51241 --> 0.51241), F1: (0.51241 --> 0.51241).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 12 Train Avg loss: 0.61382, Acc: 0.51172, F1: 0.51172#####> Valid Avg loss: 0.75207, Acc:0.47345, F1: 0.47345
===> Epoch: 12: Training loss decreased (0.61624 --> 0.61382), Acc: (0.51241 --> 0.51172), F1: (0.51241 --> 0.51172).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 13 Train Avg loss: 0.60916, Acc: 0.49172, F1: 0.49172#####> Valid Avg loss: 0.76339, Acc:0.40265, F1: 0.40265
===> Epoch: 13: Training loss decreased (0.61382 --> 0.60916), Acc: (0.51172 --> 0.49172), F1: (0.51172 --> 0.49172).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 14 Train Avg loss: 0.60246, Acc: 0.50966, F1: 0.50966#####> Valid Avg loss: 0.72156, Acc:0.39823, F1: 0.39823
===> Epoch: 14: Training loss decreased (0.60916 --> 0.60246), Acc: (0.49172 --> 0.50966), F1: (0.49172 --> 0.50966).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 15 Train Avg loss: 0.59941, Acc: 0.52345, F1: 0.52345#####> Valid Avg loss: 0.73854, Acc:0.47345, F1: 0.47345
===> Epoch: 15: Training loss decreased (0.60246 --> 0.59941), Acc: (0.50966 --> 0.52345), F1: (0.50966 --> 0.52345).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 16 Train Avg loss: 0.59356, Acc: 0.52207, F1: 0.52207#####> Valid Avg loss: 0.80992, Acc:0.46460, F1: 0.46460
===> Epoch: 16: Training loss decreased (0.59941 --> 0.59356), Acc: (0.52345 --> 0.52207), F1: (0.52345 --> 0.52207).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 17 Train Avg loss: 0.58574, Acc: 0.52897, F1: 0.52897#####> Valid Avg loss: 0.77215, Acc:0.42478, F1: 0.42478
===> Epoch: 17: Training loss decreased (0.59356 --> 0.58574), Acc: (0.52207 --> 0.52897), F1: (0.52207 --> 0.52897).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 18 Train Avg loss: 0.57981, Acc: 0.53448, F1: 0.53448#####> Valid Avg loss: 0.79884, Acc:0.44690, F1: 0.44690
===> Epoch: 18: Training loss decreased (0.58574 --> 0.57981), Acc: (0.52897 --> 0.53448), F1: (0.52897 --> 0.53448).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 19 Train Avg loss: 0.57505, Acc: 0.52966, F1: 0.52966#####> Valid Avg loss: 0.87915, Acc:0.43805, F1: 0.43805
===> Epoch: 19: Training loss decreased (0.57981 --> 0.57505), Acc: (0.53448 --> 0.52966), F1: (0.53448 --> 0.52966).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 20 Train Avg loss: 0.56987, Acc: 0.53586, F1: 0.53586#####> Valid Avg loss: 0.87242, Acc:0.45575, F1: 0.45575
===> Epoch: 20: Training loss decreased (0.57505 --> 0.56987), Acc: (0.52966 --> 0.53586), F1: (0.52966 --> 0.53586).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 21 Train Avg loss: 0.57003, Acc: 0.53448, F1: 0.53448#####> Valid Avg loss: 0.91850, Acc:0.41150, F1: 0.41150
====> Epoch: 22 Train Avg loss: 0.55460, Acc: 0.55862, F1: 0.55862#####> Valid Avg loss: 0.89084, Acc:0.42035, F1: 0.42035
===> Epoch: 22: Training loss decreased (0.56987 --> 0.55460), Acc: (0.53586 --> 0.55862), F1: (0.53586 --> 0.55862).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 23 Train Avg loss: 0.55418, Acc: 0.54621, F1: 0.54621#####> Valid Avg loss: 0.87164, Acc:0.48230, F1: 0.48230
===> Epoch: 23: Training loss decreased (0.55460 --> 0.55418), Acc: (0.55862 --> 0.54621), F1: (0.55862 --> 0.54621).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4

####> Epoch: 23: validation acc increase (0.81657 --> 0.87164), Acc: (0.47788 --> 0.48230), F1: (0.47788 --> 0.48230).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 24 Train Avg loss: 0.55103, Acc: 0.54069, F1: 0.54069#####> Valid Avg loss: 0.78884, Acc:0.41150, F1: 0.41150
===> Epoch: 24: Training loss decreased (0.55418 --> 0.55103), Acc: (0.54621 --> 0.54069), F1: (0.54621 --> 0.54069).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 25 Train Avg loss: 0.53436, Acc: 0.56483, F1: 0.56483#####> Valid Avg loss: 0.85510, Acc:0.45133, F1: 0.45133
===> Epoch: 25: Training loss decreased (0.55103 --> 0.53436), Acc: (0.54069 --> 0.56483), F1: (0.54069 --> 0.56483).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 26 Train Avg loss: 0.52926, Acc: 0.57379, F1: 0.57379#####> Valid Avg loss: 0.87021, Acc:0.42920, F1: 0.42920
===> Epoch: 26: Training loss decreased (0.53436 --> 0.52926), Acc: (0.56483 --> 0.57379), F1: (0.56483 --> 0.57379).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 27 Train Avg loss: 0.52566, Acc: 0.56966, F1: 0.56966#####> Valid Avg loss: 0.91541, Acc:0.40708, F1: 0.40708
===> Epoch: 27: Training loss decreased (0.52926 --> 0.52566), Acc: (0.57379 --> 0.56966), F1: (0.57379 --> 0.56966).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 28 Train Avg loss: 0.51136, Acc: 0.58552, F1: 0.58552#####> Valid Avg loss: 0.92649, Acc:0.42920, F1: 0.42920
===> Epoch: 28: Training loss decreased (0.52566 --> 0.51136), Acc: (0.56966 --> 0.58552), F1: (0.56966 --> 0.58552).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 29 Train Avg loss: 0.49976, Acc: 0.59241, F1: 0.59241#####> Valid Avg loss: 0.99688, Acc:0.45575, F1: 0.45575
===> Epoch: 29: Training loss decreased (0.51136 --> 0.49976), Acc: (0.58552 --> 0.59241), F1: (0.58552 --> 0.59241).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 30 Train Avg loss: 0.49524, Acc: 0.59379, F1: 0.59379#####> Valid Avg loss: 0.88436, Acc:0.42035, F1: 0.42035
===> Epoch: 30: Training loss decreased (0.49976 --> 0.49524), Acc: (0.59241 --> 0.59379), F1: (0.59241 --> 0.59379).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 31 Train Avg loss: 0.48101, Acc: 0.60759, F1: 0.60759#####> Valid Avg loss: 1.17578, Acc:0.44690, F1: 0.44690
===> Epoch: 31: Training loss decreased (0.49524 --> 0.48101), Acc: (0.59379 --> 0.60759), F1: (0.59379 --> 0.60759).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 32 Train Avg loss: 0.47057, Acc: 0.62345, F1: 0.62345#####> Valid Avg loss: 1.01231, Acc:0.40708, F1: 0.40708
===> Epoch: 32: Training loss decreased (0.48101 --> 0.47057), Acc: (0.60759 --> 0.62345), F1: (0.60759 --> 0.62345).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 33 Train Avg loss: 0.45602, Acc: 0.63448, F1: 0.63448#####> Valid Avg loss: 1.39972, Acc:0.44248, F1: 0.44248
===> Epoch: 33: Training loss decreased (0.47057 --> 0.45602), Acc: (0.62345 --> 0.63448), F1: (0.62345 --> 0.63448).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 34 Train Avg loss: 0.44088, Acc: 0.65586, F1: 0.65586#####> Valid Avg loss: 1.12435, Acc:0.42478, F1: 0.42478
===> Epoch: 34: Training loss decreased (0.45602 --> 0.44088), Acc: (0.63448 --> 0.65586), F1: (0.63448 --> 0.65586).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 35 Train Avg loss: 0.43435, Acc: 0.63724, F1: 0.63724#####> Valid Avg loss: 1.21383, Acc:0.39381, F1: 0.39381
===> Epoch: 35: Training loss decreased (0.44088 --> 0.43435), Acc: (0.65586 --> 0.63724), F1: (0.65586 --> 0.63724).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 36 Train Avg loss: 0.42853, Acc: 0.64966, F1: 0.64966#####> Valid Avg loss: 1.14197, Acc:0.45575, F1: 0.45575
===> Epoch: 36: Training loss decreased (0.43435 --> 0.42853), Acc: (0.63724 --> 0.64966), F1: (0.63724 --> 0.64966).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 37 Train Avg loss: 0.40893, Acc: 0.66138, F1: 0.66138#####> Valid Avg loss: 1.21403, Acc:0.42920, F1: 0.42920
===> Epoch: 37: Training loss decreased (0.42853 --> 0.40893), Acc: (0.64966 --> 0.66138), F1: (0.64966 --> 0.66138).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 38 Train Avg loss: 0.39953, Acc: 0.67931, F1: 0.67931#####> Valid Avg loss: 1.26593, Acc:0.38053, F1: 0.38053
===> Epoch: 38: Training loss decreased (0.40893 --> 0.39953), Acc: (0.66138 --> 0.67931), F1: (0.66138 --> 0.67931).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 39 Train Avg loss: 0.37815, Acc: 0.67724, F1: 0.67724#####> Valid Avg loss: 1.46645, Acc:0.45575, F1: 0.45575
===> Epoch: 39: Training loss decreased (0.39953 --> 0.37815), Acc: (0.67931 --> 0.67724), F1: (0.67931 --> 0.67724).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 40 Train Avg loss: 0.36975, Acc: 0.69310, F1: 0.69310#####> Valid Avg loss: 1.65256, Acc:0.44690, F1: 0.44690
===> Epoch: 40: Training loss decreased (0.37815 --> 0.36975), Acc: (0.67724 --> 0.69310), F1: (0.67724 --> 0.69310).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 41 Train Avg loss: 0.34662, Acc: 0.70552, F1: 0.70552#####> Valid Avg loss: 1.55116, Acc:0.39823, F1: 0.39823
===> Epoch: 41: Training loss decreased (0.36975 --> 0.34662), Acc: (0.69310 --> 0.70552), F1: (0.69310 --> 0.70552).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 42 Train Avg loss: 0.33692, Acc: 0.73517, F1: 0.73517#####> Valid Avg loss: 1.61751, Acc:0.40708, F1: 0.40708
===> Epoch: 42: Training loss decreased (0.34662 --> 0.33692), Acc: (0.70552 --> 0.73517), F1: (0.70552 --> 0.73517).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 43 Train Avg loss: 0.31669, Acc: 0.74069, F1: 0.74069#####> Valid Avg loss: 1.91353, Acc:0.45133, F1: 0.45133
===> Epoch: 43: Training loss decreased (0.33692 --> 0.31669), Acc: (0.73517 --> 0.74069), F1: (0.73517 --> 0.74069).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 44 Train Avg loss: 0.29247, Acc: 0.76345, F1: 0.76345#####> Valid Avg loss: 1.97211, Acc:0.42478, F1: 0.42478
===> Epoch: 44: Training loss decreased (0.31669 --> 0.29247), Acc: (0.74069 --> 0.76345), F1: (0.74069 --> 0.76345).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 45 Train Avg loss: 0.29256, Acc: 0.75655, F1: 0.75655#####> Valid Avg loss: 1.75204, Acc:0.34071, F1: 0.34071
====> Epoch: 46 Train Avg loss: 0.25885, Acc: 0.78414, F1: 0.78414#####> Valid Avg loss: 2.09988, Acc:0.43363, F1: 0.43363
===> Epoch: 46: Training loss decreased (0.29247 --> 0.25885), Acc: (0.76345 --> 0.78414), F1: (0.76345 --> 0.78414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 47 Train Avg loss: 0.23673, Acc: 0.79793, F1: 0.79793#####> Valid Avg loss: 2.09523, Acc:0.44690, F1: 0.44690
===> Epoch: 47: Training loss decreased (0.25885 --> 0.23673), Acc: (0.78414 --> 0.79793), F1: (0.78414 --> 0.79793).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 48 Train Avg loss: 0.22453, Acc: 0.81655, F1: 0.81655#####> Valid Avg loss: 2.54079, Acc:0.41593, F1: 0.41593
===> Epoch: 48: Training loss decreased (0.23673 --> 0.22453), Acc: (0.79793 --> 0.81655), F1: (0.79793 --> 0.81655).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 49 Train Avg loss: 0.19959, Acc: 0.83310, F1: 0.83310#####> Valid Avg loss: 2.48417, Acc:0.40265, F1: 0.40265
===> Epoch: 49: Training loss decreased (0.22453 --> 0.19959), Acc: (0.81655 --> 0.83310), F1: (0.81655 --> 0.83310).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 50 Train Avg loss: 0.20131, Acc: 0.83517, F1: 0.83517#####> Valid Avg loss: 2.50417, Acc:0.40708, F1: 0.40708
====> Epoch: 51 Train Avg loss: 0.17361, Acc: 0.85862, F1: 0.85862#####> Valid Avg loss: 2.53248, Acc:0.37611, F1: 0.37611
===> Epoch: 51: Training loss decreased (0.19959 --> 0.17361), Acc: (0.83310 --> 0.85862), F1: (0.83310 --> 0.85862).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 52 Train Avg loss: 0.17288, Acc: 0.86552, F1: 0.86552#####> Valid Avg loss: 2.81757, Acc:0.42035, F1: 0.42035
===> Epoch: 52: Training loss decreased (0.17361 --> 0.17288), Acc: (0.85862 --> 0.86552), F1: (0.85862 --> 0.86552).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 53 Train Avg loss: 0.15217, Acc: 0.88621, F1: 0.88621#####> Valid Avg loss: 2.58471, Acc:0.36726, F1: 0.36726
===> Epoch: 53: Training loss decreased (0.17288 --> 0.15217), Acc: (0.86552 --> 0.88621), F1: (0.86552 --> 0.88621).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 54 Train Avg loss: 0.12465, Acc: 0.90138, F1: 0.90138#####> Valid Avg loss: 2.57658, Acc:0.40708, F1: 0.40708
===> Epoch: 54: Training loss decreased (0.15217 --> 0.12465), Acc: (0.88621 --> 0.90138), F1: (0.88621 --> 0.90138).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 55 Train Avg loss: 0.12291, Acc: 0.90828, F1: 0.90828#####> Valid Avg loss: 2.95850, Acc:0.37611, F1: 0.37611
===> Epoch: 55: Training loss decreased (0.12465 --> 0.12291), Acc: (0.90138 --> 0.90828), F1: (0.90138 --> 0.90828).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 56 Train Avg loss: 0.12106, Acc: 0.91241, F1: 0.91241#####> Valid Avg loss: 3.11640, Acc:0.40708, F1: 0.40708
===> Epoch: 56: Training loss decreased (0.12291 --> 0.12106), Acc: (0.90828 --> 0.91241), F1: (0.90828 --> 0.91241).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 57 Train Avg loss: 0.09930, Acc: 0.92690, F1: 0.92690#####> Valid Avg loss: 3.01456, Acc:0.34513, F1: 0.34513
===> Epoch: 57: Training loss decreased (0.12106 --> 0.09930), Acc: (0.91241 --> 0.92690), F1: (0.91241 --> 0.92690).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 58 Train Avg loss: 0.10610, Acc: 0.91724, F1: 0.91724#####> Valid Avg loss: 3.24876, Acc:0.39823, F1: 0.39823
====> Epoch: 59 Train Avg loss: 0.08214, Acc: 0.94552, F1: 0.94552#####> Valid Avg loss: 3.39467, Acc:0.39381, F1: 0.39381
===> Epoch: 59: Training loss decreased (0.09930 --> 0.08214), Acc: (0.92690 --> 0.94552), F1: (0.92690 --> 0.94552).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 60 Train Avg loss: 0.07441, Acc: 0.94966, F1: 0.94966#####> Valid Avg loss: 3.32468, Acc:0.41150, F1: 0.41150
===> Epoch: 60: Training loss decreased (0.08214 --> 0.07441), Acc: (0.94552 --> 0.94966), F1: (0.94552 --> 0.94966).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 61 Train Avg loss: 0.07284, Acc: 0.95034, F1: 0.95034#####> Valid Avg loss: 3.40510, Acc:0.37168, F1: 0.37168
===> Epoch: 61: Training loss decreased (0.07441 --> 0.07284), Acc: (0.94966 --> 0.95034), F1: (0.94966 --> 0.95034).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 62 Train Avg loss: 0.06859, Acc: 0.94759, F1: 0.94759#####> Valid Avg loss: 3.74186, Acc:0.40708, F1: 0.40708
===> Epoch: 62: Training loss decreased (0.07284 --> 0.06859), Acc: (0.95034 --> 0.94759), F1: (0.95034 --> 0.94759).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 63 Train Avg loss: 0.06846, Acc: 0.95310, F1: 0.95310#####> Valid Avg loss: 3.49920, Acc:0.41150, F1: 0.41150
===> Epoch: 63: Training loss decreased (0.06859 --> 0.06846), Acc: (0.94759 --> 0.95310), F1: (0.94759 --> 0.95310).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 64 Train Avg loss: 0.05330, Acc: 0.96276, F1: 0.96276#####> Valid Avg loss: 3.67548, Acc:0.42920, F1: 0.42920
===> Epoch: 64: Training loss decreased (0.06846 --> 0.05330), Acc: (0.95310 --> 0.96276), F1: (0.95310 --> 0.96276).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 65 Train Avg loss: 0.05512, Acc: 0.96345, F1: 0.96345#####> Valid Avg loss: 3.84059, Acc:0.38938, F1: 0.38938
====> Epoch: 66 Train Avg loss: 0.03942, Acc: 0.97517, F1: 0.97517#####> Valid Avg loss: 3.93496, Acc:0.40708, F1: 0.40708
===> Epoch: 66: Training loss decreased (0.05330 --> 0.03942), Acc: (0.96276 --> 0.97517), F1: (0.96276 --> 0.97517).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 67 Train Avg loss: 0.04529, Acc: 0.96276, F1: 0.96276#####> Valid Avg loss: 3.87380, Acc:0.39823, F1: 0.39823
====> Epoch: 68 Train Avg loss: 0.03937, Acc: 0.97103, F1: 0.97103#####> Valid Avg loss: 3.97092, Acc:0.38053, F1: 0.38053
===> Epoch: 68: Training loss decreased (0.03942 --> 0.03937), Acc: (0.97517 --> 0.97103), F1: (0.97517 --> 0.97103).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 69 Train Avg loss: 0.03551, Acc: 0.97241, F1: 0.97241#####> Valid Avg loss: 3.73056, Acc:0.35841, F1: 0.35841
===> Epoch: 69: Training loss decreased (0.03937 --> 0.03551), Acc: (0.97103 --> 0.97241), F1: (0.97103 --> 0.97241).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 70 Train Avg loss: 0.03345, Acc: 0.97586, F1: 0.97586#####> Valid Avg loss: 3.94882, Acc:0.36283, F1: 0.36283
===> Epoch: 70: Training loss decreased (0.03551 --> 0.03345), Acc: (0.97241 --> 0.97586), F1: (0.97241 --> 0.97586).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 71 Train Avg loss: 0.03142, Acc: 0.97448, F1: 0.97448#####> Valid Avg loss: 4.08410, Acc:0.38053, F1: 0.38053
===> Epoch: 71: Training loss decreased (0.03345 --> 0.03142), Acc: (0.97586 --> 0.97448), F1: (0.97586 --> 0.97448).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 72 Train Avg loss: 0.02702, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 3.86302, Acc:0.35841, F1: 0.35841
===> Epoch: 72: Training loss decreased (0.03142 --> 0.02702), Acc: (0.97448 --> 0.98000), F1: (0.97448 --> 0.98000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 73 Train Avg loss: 0.02292, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 4.30795, Acc:0.42478, F1: 0.42478
===> Epoch: 73: Training loss decreased (0.02702 --> 0.02292), Acc: (0.98000 --> 0.98207), F1: (0.98000 --> 0.98207).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 74 Train Avg loss: 0.02407, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 3.88564, Acc:0.37168, F1: 0.37168
====> Epoch: 75 Train Avg loss: 0.02498, Acc: 0.97724, F1: 0.97724#####> Valid Avg loss: 4.23193, Acc:0.42035, F1: 0.42035
====> Epoch: 76 Train Avg loss: 0.02306, Acc: 0.97724, F1: 0.97724#####> Valid Avg loss: 4.10874, Acc:0.39381, F1: 0.39381
====> Epoch: 77 Train Avg loss: 0.02215, Acc: 0.97931, F1: 0.97931#####> Valid Avg loss: 4.13433, Acc:0.39823, F1: 0.39823
===> Epoch: 77: Training loss decreased (0.02292 --> 0.02215), Acc: (0.98207 --> 0.97931), F1: (0.98207 --> 0.97931).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 78 Train Avg loss: 0.02128, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 4.45134, Acc:0.40265, F1: 0.40265
===> Epoch: 78: Training loss decreased (0.02215 --> 0.02128), Acc: (0.97931 --> 0.98000), F1: (0.97931 --> 0.98000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 79 Train Avg loss: 0.01983, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 4.32433, Acc:0.39823, F1: 0.39823
===> Epoch: 79: Training loss decreased (0.02128 --> 0.01983), Acc: (0.98000 --> 0.98276), F1: (0.98000 --> 0.98276).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 80 Train Avg loss: 0.01795, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 4.54775, Acc:0.38938, F1: 0.38938
===> Epoch: 80: Training loss decreased (0.01983 --> 0.01795), Acc: (0.98276 --> 0.98276), F1: (0.98276 --> 0.98276).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 81 Train Avg loss: 0.02010, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 4.16634, Acc:0.41593, F1: 0.41593
====> Epoch: 82 Train Avg loss: 0.01770, Acc: 0.97931, F1: 0.97931#####> Valid Avg loss: 4.32638, Acc:0.37611, F1: 0.37611
===> Epoch: 82: Training loss decreased (0.01795 --> 0.01770), Acc: (0.98276 --> 0.97931), F1: (0.98276 --> 0.97931).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 83 Train Avg loss: 0.01717, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 4.41473, Acc:0.39823, F1: 0.39823
===> Epoch: 83: Training loss decreased (0.01770 --> 0.01717), Acc: (0.97931 --> 0.98000), F1: (0.97931 --> 0.98000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 84 Train Avg loss: 0.02033, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 4.31321, Acc:0.38496, F1: 0.38496
====> Epoch: 85 Train Avg loss: 0.01634, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 4.50575, Acc:0.39823, F1: 0.39823
===> Epoch: 85: Training loss decreased (0.01717 --> 0.01634), Acc: (0.98000 --> 0.98138), F1: (0.98000 --> 0.98138).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 86 Train Avg loss: 0.01623, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 4.44420, Acc:0.39823, F1: 0.39823
===> Epoch: 86: Training loss decreased (0.01634 --> 0.01623), Acc: (0.98138 --> 0.98000), F1: (0.98138 --> 0.98000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 87 Train Avg loss: 0.01705, Acc: 0.97931, F1: 0.97931#####> Valid Avg loss: 4.28341, Acc:0.38938, F1: 0.38938
====> Epoch: 88 Train Avg loss: 0.01420, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 4.18381, Acc:0.38938, F1: 0.38938
===> Epoch: 88: Training loss decreased (0.01623 --> 0.01420), Acc: (0.98000 --> 0.98207), F1: (0.98000 --> 0.98207).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 89 Train Avg loss: 0.01377, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 4.35590, Acc:0.40708, F1: 0.40708
===> Epoch: 89: Training loss decreased (0.01420 --> 0.01377), Acc: (0.98207 --> 0.98276), F1: (0.98207 --> 0.98276).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 90 Train Avg loss: 0.01278, Acc: 0.98483, F1: 0.98483#####> Valid Avg loss: 4.43914, Acc:0.40708, F1: 0.40708
===> Epoch: 90: Training loss decreased (0.01377 --> 0.01278), Acc: (0.98276 --> 0.98483), F1: (0.98276 --> 0.98483).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 91 Train Avg loss: 0.01374, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 4.47555, Acc:0.40265, F1: 0.40265
====> Epoch: 92 Train Avg loss: 0.01261, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 4.34325, Acc:0.38938, F1: 0.38938
===> Epoch: 92: Training loss decreased (0.01278 --> 0.01261), Acc: (0.98483 --> 0.98345), F1: (0.98483 --> 0.98345).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 93 Train Avg loss: 0.01091, Acc: 0.98483, F1: 0.98483#####> Valid Avg loss: 4.37860, Acc:0.38938, F1: 0.38938
===> Epoch: 93: Training loss decreased (0.01261 --> 0.01091), Acc: (0.98345 --> 0.98483), F1: (0.98345 --> 0.98483).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 94 Train Avg loss: 0.01063, Acc: 0.98483, F1: 0.98483#####> Valid Avg loss: 4.23878, Acc:0.38938, F1: 0.38938
===> Epoch: 94: Training loss decreased (0.01091 --> 0.01063), Acc: (0.98483 --> 0.98483), F1: (0.98483 --> 0.98483).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 95 Train Avg loss: 0.01085, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 4.31493, Acc:0.39381, F1: 0.39381
====> Epoch: 96 Train Avg loss: 0.01136, Acc: 0.98690, F1: 0.98690#####> Valid Avg loss: 4.31879, Acc:0.38496, F1: 0.38496
====> Epoch: 97 Train Avg loss: 0.01263, Acc: 0.98552, F1: 0.98552#####> Valid Avg loss: 4.59513, Acc:0.39381, F1: 0.39381
====> Epoch: 98 Train Avg loss: 0.01195, Acc: 0.98621, F1: 0.98621#####> Valid Avg loss: 4.44531, Acc:0.39381, F1: 0.39381
====> Epoch: 99 Train Avg loss: 0.01129, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 4.24551, Acc:0.38496, F1: 0.38496
====> Epoch: 100 Train Avg loss: 0.65866, Acc: 0.53034, F1: 0.53034#####> Valid Avg loss: 0.83921, Acc:0.45575, F1: 0.45575
====> Epoch: 101 Train Avg loss: 0.54110, Acc: 0.57586, F1: 0.57586#####> Valid Avg loss: 0.96733, Acc:0.47345, F1: 0.47345
====> Epoch: 102 Train Avg loss: 0.53537, Acc: 0.56828, F1: 0.56828#####> Valid Avg loss: 0.88992, Acc:0.44248, F1: 0.44248
====> Epoch: 103 Train Avg loss: 0.52108, Acc: 0.57310, F1: 0.57310#####> Valid Avg loss: 0.98142, Acc:0.43363, F1: 0.43363
====> Epoch: 104 Train Avg loss: 0.50873, Acc: 0.59103, F1: 0.59103#####> Valid Avg loss: 0.82675, Acc:0.39381, F1: 0.39381
====> Epoch: 105 Train Avg loss: 0.49631, Acc: 0.60414, F1: 0.60414#####> Valid Avg loss: 0.98734, Acc:0.44690, F1: 0.44690
====> Epoch: 106 Train Avg loss: 0.47665, Acc: 0.62000, F1: 0.62000#####> Valid Avg loss: 0.88657, Acc:0.44248, F1: 0.44248
====> Epoch: 107 Train Avg loss: 0.46309, Acc: 0.61724, F1: 0.61724#####> Valid Avg loss: 1.10074, Acc:0.43363, F1: 0.43363
====> Epoch: 108 Train Avg loss: 0.43937, Acc: 0.63586, F1: 0.63586#####> Valid Avg loss: 1.08056, Acc:0.42478, F1: 0.42478
====> Epoch: 109 Train Avg loss: 0.43301, Acc: 0.64552, F1: 0.64552#####> Valid Avg loss: 1.15577, Acc:0.40708, F1: 0.40708
====> Epoch: 110 Train Avg loss: 0.40882, Acc: 0.66345, F1: 0.66345#####> Valid Avg loss: 1.17131, Acc:0.31858, F1: 0.31858
====> Epoch: 111 Train Avg loss: 0.39307, Acc: 0.68138, F1: 0.68138#####> Valid Avg loss: 1.08193, Acc:0.29646, F1: 0.29646
====> Epoch: 112 Train Avg loss: 0.36307, Acc: 0.70345, F1: 0.70345#####> Valid Avg loss: 1.51557, Acc:0.40708, F1: 0.40708
====> Epoch: 113 Train Avg loss: 0.36405, Acc: 0.69862, F1: 0.69862#####> Valid Avg loss: 1.20383, Acc:0.42920, F1: 0.42920
====> Epoch: 114 Train Avg loss: 0.33523, Acc: 0.72690, F1: 0.72690#####> Valid Avg loss: 1.41944, Acc:0.37168, F1: 0.37168
====> Epoch: 115 Train Avg loss: 0.32059, Acc: 0.73586, F1: 0.73586#####> Valid Avg loss: 1.31428, Acc:0.32301, F1: 0.32301
====> Epoch: 116 Train Avg loss: 0.29594, Acc: 0.77241, F1: 0.77241#####> Valid Avg loss: 1.91868, Acc:0.45133, F1: 0.45133
====> Epoch: 117 Train Avg loss: 0.29805, Acc: 0.75793, F1: 0.75793#####> Valid Avg loss: 1.44113, Acc:0.41593, F1: 0.41593
====> Epoch: 118 Train Avg loss: 0.28629, Acc: 0.76690, F1: 0.76690#####> Valid Avg loss: 1.68406, Acc:0.35398, F1: 0.35398
====> Epoch: 119 Train Avg loss: 0.25393, Acc: 0.79586, F1: 0.79586#####> Valid Avg loss: 1.94132, Acc:0.36726, F1: 0.36726
====> Epoch: 120 Train Avg loss: 0.25532, Acc: 0.78345, F1: 0.78345#####> Valid Avg loss: 1.74070, Acc:0.36726, F1: 0.36726
====> Epoch: 121 Train Avg loss: 0.23090, Acc: 0.80276, F1: 0.80276#####> Valid Avg loss: 1.68897, Acc:0.34071, F1: 0.34071
====> Epoch: 122 Train Avg loss: 0.22452, Acc: 0.81862, F1: 0.81862#####> Valid Avg loss: 1.83695, Acc:0.34956, F1: 0.34956
====> Epoch: 123 Train Avg loss: 0.22900, Acc: 0.81793, F1: 0.81793#####> Valid Avg loss: 1.90129, Acc:0.38053, F1: 0.38053
====> Epoch: 124 Train Avg loss: 0.21404, Acc: 0.82759, F1: 0.82759#####> Valid Avg loss: 1.85390, Acc:0.36726, F1: 0.36726
====> Epoch: 125 Train Avg loss: 0.21656, Acc: 0.83172, F1: 0.83172#####> Valid Avg loss: 2.09682, Acc:0.41150, F1: 0.41150
====> Epoch: 126 Train Avg loss: 0.17262, Acc: 0.86207, F1: 0.86207#####> Valid Avg loss: 2.04252, Acc:0.40265, F1: 0.40265
====> Epoch: 127 Train Avg loss: 0.20136, Acc: 0.84966, F1: 0.84966#####> Valid Avg loss: 2.11730, Acc:0.37611, F1: 0.37611
====> Epoch: 128 Train Avg loss: 0.18065, Acc: 0.85724, F1: 0.85724#####> Valid Avg loss: 2.05284, Acc:0.38938, F1: 0.38938
====> Epoch: 129 Train Avg loss: 0.18901, Acc: 0.85448, F1: 0.85448#####> Valid Avg loss: 1.69499, Acc:0.42920, F1: 0.42920
====> Epoch: 130 Train Avg loss: 0.18568, Acc: 0.84759, F1: 0.84759#####> Valid Avg loss: 1.96412, Acc:0.33186, F1: 0.33186
====> Epoch: 131 Train Avg loss: 0.15179, Acc: 0.88345, F1: 0.88345#####> Valid Avg loss: 2.49952, Acc:0.36283, F1: 0.36283
====> Epoch: 132 Train Avg loss: 0.16516, Acc: 0.88069, F1: 0.88069#####> Valid Avg loss: 2.43239, Acc:0.37168, F1: 0.37168
====> Epoch: 133 Train Avg loss: 0.15627, Acc: 0.87310, F1: 0.87310#####> Valid Avg loss: 1.99651, Acc:0.34956, F1: 0.34956
====> Epoch: 134 Train Avg loss: 0.14368, Acc: 0.88690, F1: 0.88690#####> Valid Avg loss: 2.47211, Acc:0.39381, F1: 0.39381
====> Epoch: 135 Train Avg loss: 0.14839, Acc: 0.88759, F1: 0.88759#####> Valid Avg loss: 2.15287, Acc:0.38496, F1: 0.38496
====> Epoch: 136 Train Avg loss: 0.14041, Acc: 0.88897, F1: 0.88897#####> Valid Avg loss: 2.01244, Acc:0.41150, F1: 0.41150
====> Epoch: 137 Train Avg loss: 0.12282, Acc: 0.90621, F1: 0.90621#####> Valid Avg loss: 2.16321, Acc:0.36283, F1: 0.36283
====> Epoch: 138 Train Avg loss: 0.12739, Acc: 0.90483, F1: 0.90483#####> Valid Avg loss: 2.43549, Acc:0.36283, F1: 0.36283
====> Epoch: 139 Train Avg loss: 0.10791, Acc: 0.92345, F1: 0.92345#####> Valid Avg loss: 2.25034, Acc:0.37611, F1: 0.37611
====> Epoch: 140 Train Avg loss: 0.14191, Acc: 0.90000, F1: 0.90000#####> Valid Avg loss: 2.15180, Acc:0.37611, F1: 0.37611
====> Epoch: 141 Train Avg loss: 0.11045, Acc: 0.91586, F1: 0.91586#####> Valid Avg loss: 2.09422, Acc:0.34956, F1: 0.34956
====> Epoch: 142 Train Avg loss: 0.12161, Acc: 0.91241, F1: 0.91241#####> Valid Avg loss: 2.11513, Acc:0.38938, F1: 0.38938
====> Epoch: 143 Train Avg loss: 0.10330, Acc: 0.92690, F1: 0.92690#####> Valid Avg loss: 2.19399, Acc:0.32301, F1: 0.32301
====> Epoch: 144 Train Avg loss: 0.09768, Acc: 0.91862, F1: 0.91862#####> Valid Avg loss: 2.28644, Acc:0.34071, F1: 0.34071
====> Epoch: 145 Train Avg loss: 0.11696, Acc: 0.92069, F1: 0.92069#####> Valid Avg loss: 2.62653, Acc:0.40265, F1: 0.40265
====> Epoch: 146 Train Avg loss: 0.12783, Acc: 0.91379, F1: 0.91379#####> Valid Avg loss: 2.25902, Acc:0.38496, F1: 0.38496
====> Epoch: 147 Train Avg loss: 0.08281, Acc: 0.94690, F1: 0.94690#####> Valid Avg loss: 2.28805, Acc:0.31416, F1: 0.31416
====> Epoch: 148 Train Avg loss: 0.14003, Acc: 0.89724, F1: 0.89724#####> Valid Avg loss: 2.47351, Acc:0.37168, F1: 0.37168
====> Epoch: 149 Train Avg loss: 0.04910, Acc: 0.96138, F1: 0.96138#####> Valid Avg loss: 2.63160, Acc:0.37611, F1: 0.37611
====> Epoch: 150 Train Avg loss: 0.10591, Acc: 0.91586, F1: 0.91586#####> Valid Avg loss: 2.82364, Acc:0.38496, F1: 0.38496
====> Epoch: 151 Train Avg loss: 0.11029, Acc: 0.92138, F1: 0.92138#####> Valid Avg loss: 2.26039, Acc:0.37168, F1: 0.37168
====> Epoch: 152 Train Avg loss: 0.09664, Acc: 0.93586, F1: 0.93586#####> Valid Avg loss: 2.50891, Acc:0.38053, F1: 0.38053
====> Epoch: 153 Train Avg loss: 0.04143, Acc: 0.97103, F1: 0.97103#####> Valid Avg loss: 2.63598, Acc:0.37611, F1: 0.37611
====> Epoch: 154 Train Avg loss: 0.11388, Acc: 0.92207, F1: 0.92207#####> Valid Avg loss: 2.37908, Acc:0.39381, F1: 0.39381
====> Epoch: 155 Train Avg loss: 0.08211, Acc: 0.93448, F1: 0.93448#####> Valid Avg loss: 2.66436, Acc:0.39381, F1: 0.39381
====> Epoch: 156 Train Avg loss: 0.05401, Acc: 0.96069, F1: 0.96069#####> Valid Avg loss: 2.84627, Acc:0.39381, F1: 0.39381
====> Epoch: 157 Train Avg loss: 0.08718, Acc: 0.92828, F1: 0.92828#####> Valid Avg loss: 2.64617, Acc:0.36726, F1: 0.36726
====> Epoch: 158 Train Avg loss: 0.06093, Acc: 0.95586, F1: 0.95586#####> Valid Avg loss: 2.81947, Acc:0.36283, F1: 0.36283
====> Epoch: 159 Train Avg loss: 0.10278, Acc: 0.92069, F1: 0.92069#####> Valid Avg loss: 2.35337, Acc:0.38053, F1: 0.38053
====> Epoch: 160 Train Avg loss: 0.07301, Acc: 0.94552, F1: 0.94552#####> Valid Avg loss: 2.70883, Acc:0.41593, F1: 0.41593
====> Epoch: 161 Train Avg loss: 0.06484, Acc: 0.94966, F1: 0.94966#####> Valid Avg loss: 2.66530, Acc:0.37168, F1: 0.37168
====> Epoch: 162 Train Avg loss: 0.04727, Acc: 0.96621, F1: 0.96621#####> Valid Avg loss: 2.57691, Acc:0.27876, F1: 0.27876
====> Epoch: 163 Train Avg loss: 0.10031, Acc: 0.92207, F1: 0.92207#####> Valid Avg loss: 2.45322, Acc:0.34513, F1: 0.34513
====> Epoch: 164 Train Avg loss: 0.05665, Acc: 0.95586, F1: 0.95586#####> Valid Avg loss: 2.77773, Acc:0.34956, F1: 0.34956
====> Epoch: 165 Train Avg loss: 0.13190, Acc: 0.91241, F1: 0.91241#####> Valid Avg loss: 2.28305, Acc:0.36283, F1: 0.36283
====> Epoch: 166 Train Avg loss: 0.05679, Acc: 0.95862, F1: 0.95862#####> Valid Avg loss: 2.74519, Acc:0.35841, F1: 0.35841
====> Epoch: 167 Train Avg loss: 0.02709, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 2.89510, Acc:0.38938, F1: 0.38938
====> Epoch: 168 Train Avg loss: 0.08860, Acc: 0.94966, F1: 0.94966#####> Valid Avg loss: 2.02685, Acc:0.33186, F1: 0.33186
====> Epoch: 169 Train Avg loss: 0.05350, Acc: 0.96138, F1: 0.96138#####> Valid Avg loss: 2.76866, Acc:0.40708, F1: 0.40708
====> Epoch: 170 Train Avg loss: 0.04778, Acc: 0.96000, F1: 0.96000#####> Valid Avg loss: 2.97138, Acc:0.36283, F1: 0.36283
====> Epoch: 171 Train Avg loss: 0.06175, Acc: 0.95379, F1: 0.95379#####> Valid Avg loss: 2.64316, Acc:0.36726, F1: 0.36726
====> Epoch: 172 Train Avg loss: 0.07924, Acc: 0.93655, F1: 0.93655#####> Valid Avg loss: 2.50216, Acc:0.38496, F1: 0.38496
====> Epoch: 173 Train Avg loss: 0.03223, Acc: 0.97655, F1: 0.97655#####> Valid Avg loss: 2.56483, Acc:0.37611, F1: 0.37611
====> Epoch: 174 Train Avg loss: 0.03466, Acc: 0.97448, F1: 0.97448#####> Valid Avg loss: 2.85550, Acc:0.38053, F1: 0.38053
====> Epoch: 175 Train Avg loss: 0.10700, Acc: 0.92207, F1: 0.92207#####> Valid Avg loss: 2.63495, Acc:0.39381, F1: 0.39381
====> Epoch: 176 Train Avg loss: 0.03306, Acc: 0.97379, F1: 0.97379#####> Valid Avg loss: 2.74652, Acc:0.40708, F1: 0.40708
====> Epoch: 177 Train Avg loss: 0.03307, Acc: 0.97241, F1: 0.97241#####> Valid Avg loss: 3.08106, Acc:0.38938, F1: 0.38938
====> Epoch: 178 Train Avg loss: 0.07847, Acc: 0.94690, F1: 0.94690#####> Valid Avg loss: 2.88300, Acc:0.38496, F1: 0.38496
====> Epoch: 179 Train Avg loss: 0.05150, Acc: 0.96276, F1: 0.96276#####> Valid Avg loss: 2.45506, Acc:0.35841, F1: 0.35841
====> Epoch: 180 Train Avg loss: 0.05167, Acc: 0.95931, F1: 0.95931#####> Valid Avg loss: 2.91737, Acc:0.42478, F1: 0.42478
====> Epoch: 181 Train Avg loss: 0.02368, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 2.88711, Acc:0.38053, F1: 0.38053
====> Epoch: 182 Train Avg loss: 0.02289, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 2.89113, Acc:0.34071, F1: 0.34071
====> Epoch: 183 Train Avg loss: 0.06257, Acc: 0.95103, F1: 0.95103#####> Valid Avg loss: 2.88633, Acc:0.37168, F1: 0.37168
====> Epoch: 184 Train Avg loss: 0.03353, Acc: 0.97379, F1: 0.97379#####> Valid Avg loss: 2.85768, Acc:0.34513, F1: 0.34513
====> Epoch: 185 Train Avg loss: 0.06049, Acc: 0.95310, F1: 0.95310#####> Valid Avg loss: 2.93148, Acc:0.37611, F1: 0.37611
====> Epoch: 186 Train Avg loss: 0.02326, Acc: 0.98552, F1: 0.98552#####> Valid Avg loss: 3.24797, Acc:0.36283, F1: 0.36283
====> Epoch: 187 Train Avg loss: 0.05326, Acc: 0.95655, F1: 0.95655#####> Valid Avg loss: 3.41223, Acc:0.40265, F1: 0.40265
====> Epoch: 188 Train Avg loss: 0.04603, Acc: 0.96207, F1: 0.96207#####> Valid Avg loss: 2.80417, Acc:0.32301, F1: 0.32301
====> Epoch: 189 Train Avg loss: 0.04853, Acc: 0.95655, F1: 0.95655#####> Valid Avg loss: 2.60339, Acc:0.34956, F1: 0.34956
====> Epoch: 190 Train Avg loss: 0.02341, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 3.24906, Acc:0.39823, F1: 0.39823
====> Epoch: 191 Train Avg loss: 0.02652, Acc: 0.97448, F1: 0.97448#####> Valid Avg loss: 2.80684, Acc:0.32301, F1: 0.32301
====> Epoch: 192 Train Avg loss: 0.02467, Acc: 0.97655, F1: 0.97655#####> Valid Avg loss: 3.17663, Acc:0.38053, F1: 0.38053
====> Epoch: 193 Train Avg loss: 0.05004, Acc: 0.96552, F1: 0.96552#####> Valid Avg loss: 2.87276, Acc:0.39381, F1: 0.39381
====> Epoch: 194 Train Avg loss: 0.02408, Acc: 0.97517, F1: 0.97517#####> Valid Avg loss: 3.09562, Acc:0.38053, F1: 0.38053
====> Epoch: 195 Train Avg loss: 0.04839, Acc: 0.96138, F1: 0.96138#####> Valid Avg loss: 2.66594, Acc:0.34513, F1: 0.34513
====> Epoch: 196 Train Avg loss: 0.04075, Acc: 0.96966, F1: 0.96966#####> Valid Avg loss: 2.77961, Acc:0.37168, F1: 0.37168
====> Epoch: 197 Train Avg loss: 0.02560, Acc: 0.97655, F1: 0.97655#####> Valid Avg loss: 2.90067, Acc:0.38496, F1: 0.38496
====> Epoch: 198 Train Avg loss: 0.03030, Acc: 0.97586, F1: 0.97586#####> Valid Avg loss: 3.07562, Acc:0.38053, F1: 0.38053
====> Epoch: 199 Train Avg loss: 0.02699, Acc: 0.97655, F1: 0.97655#####> Valid Avg loss: 3.12537, Acc:0.38938, F1: 0.38938
====> Epoch: 200 Train Avg loss: 0.02124, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 3.08804, Acc:0.38053, F1: 0.38053
====> Epoch: 201 Train Avg loss: 0.02053, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 3.06242, Acc:0.38053, F1: 0.38053
====> Epoch: 202 Train Avg loss: 0.02663, Acc: 0.97172, F1: 0.97172#####> Valid Avg loss: 3.14454, Acc:0.38496, F1: 0.38496
====> Epoch: 203 Train Avg loss: 0.04571, Acc: 0.96414, F1: 0.96414#####> Valid Avg loss: 2.95110, Acc:0.37168, F1: 0.37168
====> Epoch: 204 Train Avg loss: 0.01450, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 2.87762, Acc:0.34071, F1: 0.34071
====> Epoch: 205 Train Avg loss: 0.01488, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.07667, Acc:0.33628, F1: 0.33628
====> Epoch: 206 Train Avg loss: 0.04199, Acc: 0.96621, F1: 0.96621#####> Valid Avg loss: 3.36270, Acc:0.36726, F1: 0.36726
====> Epoch: 207 Train Avg loss: 0.02650, Acc: 0.97310, F1: 0.97310#####> Valid Avg loss: 3.60097, Acc:0.38938, F1: 0.38938
====> Epoch: 208 Train Avg loss: 0.02035, Acc: 0.97724, F1: 0.97724#####> Valid Avg loss: 3.29251, Acc:0.36726, F1: 0.36726
====> Epoch: 209 Train Avg loss: 0.01563, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 3.26805, Acc:0.36283, F1: 0.36283
====> Epoch: 210 Train Avg loss: 0.03213, Acc: 0.96759, F1: 0.96759#####> Valid Avg loss: 3.23999, Acc:0.38496, F1: 0.38496
====> Epoch: 211 Train Avg loss: 0.01916, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 3.30563, Acc:0.40708, F1: 0.40708
====> Epoch: 212 Train Avg loss: 0.02622, Acc: 0.97448, F1: 0.97448#####> Valid Avg loss: 3.21239, Acc:0.36726, F1: 0.36726
====> Epoch: 213 Train Avg loss: 0.01626, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.46851, Acc:0.38053, F1: 0.38053
====> Epoch: 214 Train Avg loss: 0.01404, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.32697, Acc:0.37168, F1: 0.37168
====> Epoch: 215 Train Avg loss: 0.01991, Acc: 0.97724, F1: 0.97724#####> Valid Avg loss: 3.64140, Acc:0.38496, F1: 0.38496
====> Epoch: 216 Train Avg loss: 0.02608, Acc: 0.97517, F1: 0.97517#####> Valid Avg loss: 3.54903, Acc:0.40708, F1: 0.40708
====> Epoch: 217 Train Avg loss: 0.01693, Acc: 0.97586, F1: 0.97586#####> Valid Avg loss: 3.26869, Acc:0.35398, F1: 0.35398
====> Epoch: 218 Train Avg loss: 0.01496, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 3.34251, Acc:0.39823, F1: 0.39823
====> Epoch: 219 Train Avg loss: 0.02593, Acc: 0.97310, F1: 0.97310#####> Valid Avg loss: 3.51153, Acc:0.41150, F1: 0.41150
====> Epoch: 220 Train Avg loss: 0.01404, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 3.40443, Acc:0.39823, F1: 0.39823
====> Epoch: 221 Train Avg loss: 0.01817, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 3.09725, Acc:0.35841, F1: 0.35841
====> Epoch: 222 Train Avg loss: 0.01704, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 3.43679, Acc:0.36283, F1: 0.36283
====> Epoch: 223 Train Avg loss: 0.01329, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 3.37337, Acc:0.34956, F1: 0.34956
====> Epoch: 224 Train Avg loss: 0.01488, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 3.34981, Acc:0.37611, F1: 0.37611
====> Epoch: 225 Train Avg loss: 0.01211, Acc: 0.98621, F1: 0.98621#####> Valid Avg loss: 3.45322, Acc:0.36283, F1: 0.36283
====> Epoch: 226 Train Avg loss: 0.02488, Acc: 0.97586, F1: 0.97586#####> Valid Avg loss: 3.61625, Acc:0.36283, F1: 0.36283
====> Epoch: 227 Train Avg loss: 0.01396, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 3.53556, Acc:0.32743, F1: 0.32743
====> Epoch: 228 Train Avg loss: 0.01252, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 3.45377, Acc:0.36283, F1: 0.36283
====> Epoch: 229 Train Avg loss: 0.01466, Acc: 0.97931, F1: 0.97931#####> Valid Avg loss: 3.46953, Acc:0.38938, F1: 0.38938
====> Epoch: 230 Train Avg loss: 0.01447, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 3.46187, Acc:0.35398, F1: 0.35398
====> Epoch: 231 Train Avg loss: 0.01294, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.33243, Acc:0.34956, F1: 0.34956
====> Epoch: 232 Train Avg loss: 0.01246, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.30089, Acc:0.34513, F1: 0.34513
====> Epoch: 233 Train Avg loss: 0.01318, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 3.47458, Acc:0.36283, F1: 0.36283
====> Epoch: 234 Train Avg loss: 0.01161, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 3.61552, Acc:0.35398, F1: 0.35398
====> Epoch: 235 Train Avg loss: 0.01689, Acc: 0.97586, F1: 0.97586#####> Valid Avg loss: 3.36934, Acc:0.35398, F1: 0.35398
====> Epoch: 236 Train Avg loss: 0.01191, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 3.35169, Acc:0.34071, F1: 0.34071
====> Epoch: 237 Train Avg loss: 0.01123, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 3.29034, Acc:0.30973, F1: 0.30973
====> Epoch: 238 Train Avg loss: 0.01199, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 3.34004, Acc:0.34071, F1: 0.34071
====> Epoch: 239 Train Avg loss: 0.01050, Acc: 0.98483, F1: 0.98483#####> Valid Avg loss: 3.45431, Acc:0.37168, F1: 0.37168
===> Epoch: 239: Training loss decreased (0.01063 --> 0.01050), Acc: (0.98483 --> 0.98483), F1: (0.98483 --> 0.98483).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 240 Train Avg loss: 0.01150, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 3.83754, Acc:0.37611, F1: 0.37611
====> Epoch: 241 Train Avg loss: 0.01338, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.37898, Acc:0.34956, F1: 0.34956
====> Epoch: 242 Train Avg loss: 0.01082, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 3.43720, Acc:0.35841, F1: 0.35841
====> Epoch: 243 Train Avg loss: 0.01173, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 3.40671, Acc:0.33628, F1: 0.33628
====> Epoch: 244 Train Avg loss: 0.01172, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 3.40971, Acc:0.36283, F1: 0.36283
====> Epoch: 245 Train Avg loss: 0.01091, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 3.36741, Acc:0.32743, F1: 0.32743
====> Epoch: 246 Train Avg loss: 0.01342, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 3.22596, Acc:0.35398, F1: 0.35398
====> Epoch: 247 Train Avg loss: 0.01046, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 3.20201, Acc:0.32743, F1: 0.32743
===> Epoch: 247: Training loss decreased (0.01050 --> 0.01046), Acc: (0.98483 --> 0.98207), F1: (0.98483 --> 0.98207).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 248 Train Avg loss: 0.01041, Acc: 0.98483, F1: 0.98483#####> Valid Avg loss: 3.47655, Acc:0.34513, F1: 0.34513
===> Epoch: 248: Training loss decreased (0.01046 --> 0.01041), Acc: (0.98207 --> 0.98483), F1: (0.98207 --> 0.98483).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 249 Train Avg loss: 0.01362, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.27919, Acc:0.33186, F1: 0.33186
====> Epoch: 250 Train Avg loss: 0.01013, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 3.42230, Acc:0.33628, F1: 0.33628
===> Epoch: 250: Training loss decreased (0.01041 --> 0.01013), Acc: (0.98483 --> 0.98276), F1: (0.98483 --> 0.98276).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 251 Train Avg loss: 0.01060, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 3.33742, Acc:0.34071, F1: 0.34071
====> Epoch: 252 Train Avg loss: 0.01031, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 3.42393, Acc:0.35398, F1: 0.35398
====> Epoch: 253 Train Avg loss: 0.00948, Acc: 0.98552, F1: 0.98552#####> Valid Avg loss: 3.51337, Acc:0.35841, F1: 0.35841
===> Epoch: 253: Training loss decreased (0.01013 --> 0.00948), Acc: (0.98276 --> 0.98552), F1: (0.98276 --> 0.98552).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 254 Train Avg loss: 0.01032, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 3.50592, Acc:0.34956, F1: 0.34956
====> Epoch: 255 Train Avg loss: 0.01034, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 3.52959, Acc:0.34956, F1: 0.34956
====> Epoch: 256 Train Avg loss: 0.01011, Acc: 0.98552, F1: 0.98552#####> Valid Avg loss: 3.59651, Acc:0.32301, F1: 0.32301
====> Epoch: 257 Train Avg loss: 0.00971, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.62804, Acc:0.34956, F1: 0.34956
====> Epoch: 258 Train Avg loss: 0.00941, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 3.65631, Acc:0.34513, F1: 0.34513
===> Epoch: 258: Training loss decreased (0.00948 --> 0.00941), Acc: (0.98552 --> 0.98207), F1: (0.98552 --> 0.98207).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 259 Train Avg loss: 0.00938, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.54440, Acc:0.34071, F1: 0.34071
===> Epoch: 259: Training loss decreased (0.00941 --> 0.00938), Acc: (0.98207 --> 0.98414), F1: (0.98207 --> 0.98414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 260 Train Avg loss: 0.00903, Acc: 0.98552, F1: 0.98552#####> Valid Avg loss: 3.66447, Acc:0.34513, F1: 0.34513
===> Epoch: 260: Training loss decreased (0.00938 --> 0.00903), Acc: (0.98414 --> 0.98552), F1: (0.98414 --> 0.98552).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 261 Train Avg loss: 0.00967, Acc: 0.98621, F1: 0.98621#####> Valid Avg loss: 3.50903, Acc:0.35841, F1: 0.35841
====> Epoch: 262 Train Avg loss: 0.00996, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.54437, Acc:0.33186, F1: 0.33186
====> Epoch: 263 Train Avg loss: 0.00889, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.78192, Acc:0.34956, F1: 0.34956
===> Epoch: 263: Training loss decreased (0.00903 --> 0.00889), Acc: (0.98552 --> 0.98414), F1: (0.98552 --> 0.98414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 264 Train Avg loss: 0.00906, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.64134, Acc:0.35398, F1: 0.35398
====> Epoch: 265 Train Avg loss: 0.00992, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.63157, Acc:0.35398, F1: 0.35398
====> Epoch: 266 Train Avg loss: 0.00900, Acc: 0.98552, F1: 0.98552#####> Valid Avg loss: 3.69955, Acc:0.34956, F1: 0.34956
====> Epoch: 267 Train Avg loss: 0.00921, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 3.74270, Acc:0.37168, F1: 0.37168
====> Epoch: 268 Train Avg loss: 0.00919, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 3.70007, Acc:0.34071, F1: 0.34071
====> Epoch: 269 Train Avg loss: 0.00963, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 3.64965, Acc:0.34071, F1: 0.34071
====> Epoch: 270 Train Avg loss: 0.00881, Acc: 0.98483, F1: 0.98483#####> Valid Avg loss: 3.89733, Acc:0.33628, F1: 0.33628
===> Epoch: 270: Training loss decreased (0.00889 --> 0.00881), Acc: (0.98414 --> 0.98483), F1: (0.98414 --> 0.98483).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 271 Train Avg loss: 0.00879, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 3.72256, Acc:0.34513, F1: 0.34513
===> Epoch: 271: Training loss decreased (0.00881 --> 0.00879), Acc: (0.98483 --> 0.98207), F1: (0.98483 --> 0.98207).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 272 Train Avg loss: 0.00877, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.61920, Acc:0.34956, F1: 0.34956
===> Epoch: 272: Training loss decreased (0.00879 --> 0.00877), Acc: (0.98207 --> 0.98414), F1: (0.98207 --> 0.98414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 273 Train Avg loss: 0.00877, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 3.79537, Acc:0.34513, F1: 0.34513
===> Epoch: 273: Training loss decreased (0.00877 --> 0.00877), Acc: (0.98414 --> 0.98207), F1: (0.98414 --> 0.98207).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 274 Train Avg loss: 0.00866, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 3.79250, Acc:0.34071, F1: 0.34071
===> Epoch: 274: Training loss decreased (0.00877 --> 0.00866), Acc: (0.98207 --> 0.98345), F1: (0.98207 --> 0.98345).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 275 Train Avg loss: 0.00870, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.65023, Acc:0.36726, F1: 0.36726
====> Epoch: 276 Train Avg loss: 0.00860, Acc: 0.98552, F1: 0.98552#####> Valid Avg loss: 3.69266, Acc:0.35841, F1: 0.35841
===> Epoch: 276: Training loss decreased (0.00866 --> 0.00860), Acc: (0.98345 --> 0.98552), F1: (0.98345 --> 0.98552).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 277 Train Avg loss: 0.00851, Acc: 0.98690, F1: 0.98690#####> Valid Avg loss: 3.76002, Acc:0.35398, F1: 0.35398
===> Epoch: 277: Training loss decreased (0.00860 --> 0.00851), Acc: (0.98552 --> 0.98690), F1: (0.98552 --> 0.98690).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 278 Train Avg loss: 0.00897, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 3.70192, Acc:0.36283, F1: 0.36283
====> Epoch: 279 Train Avg loss: 0.00819, Acc: 0.98621, F1: 0.98621#####> Valid Avg loss: 3.75908, Acc:0.36283, F1: 0.36283
===> Epoch: 279: Training loss decreased (0.00851 --> 0.00819), Acc: (0.98690 --> 0.98621), F1: (0.98690 --> 0.98621).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 280 Train Avg loss: 0.00841, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.62804, Acc:0.35398, F1: 0.35398
====> Epoch: 281 Train Avg loss: 0.00848, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 3.67740, Acc:0.35398, F1: 0.35398
====> Epoch: 282 Train Avg loss: 0.00845, Acc: 0.98759, F1: 0.98759#####> Valid Avg loss: 3.70722, Acc:0.34956, F1: 0.34956
====> Epoch: 283 Train Avg loss: 0.00949, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 3.69827, Acc:0.34071, F1: 0.34071
====> Epoch: 284 Train Avg loss: 0.00811, Acc: 0.98897, F1: 0.98897#####> Valid Avg loss: 3.85114, Acc:0.34513, F1: 0.34513
===> Epoch: 284: Training loss decreased (0.00819 --> 0.00811), Acc: (0.98621 --> 0.98897), F1: (0.98621 --> 0.98897).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 285 Train Avg loss: 0.00842, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.84885, Acc:0.34513, F1: 0.34513
====> Epoch: 286 Train Avg loss: 0.00843, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.68292, Acc:0.34513, F1: 0.34513
====> Epoch: 287 Train Avg loss: 0.00861, Acc: 0.98759, F1: 0.98759#####> Valid Avg loss: 3.74105, Acc:0.35841, F1: 0.35841
====> Epoch: 288 Train Avg loss: 0.00875, Acc: 0.98621, F1: 0.98621#####> Valid Avg loss: 3.77066, Acc:0.34956, F1: 0.34956
====> Epoch: 289 Train Avg loss: 0.00843, Acc: 0.98759, F1: 0.98759#####> Valid Avg loss: 3.61534, Acc:0.34956, F1: 0.34956
====> Epoch: 290 Train Avg loss: 0.00834, Acc: 0.98828, F1: 0.98828#####> Valid Avg loss: 3.74752, Acc:0.34956, F1: 0.34956
====> Epoch: 291 Train Avg loss: 0.00822, Acc: 0.98897, F1: 0.98897#####> Valid Avg loss: 3.78887, Acc:0.34956, F1: 0.34956
====> Epoch: 292 Train Avg loss: 0.00823, Acc: 0.98966, F1: 0.98966#####> Valid Avg loss: 3.68129, Acc:0.34513, F1: 0.34513
====> Epoch: 293 Train Avg loss: 0.00835, Acc: 0.98690, F1: 0.98690#####> Valid Avg loss: 3.72632, Acc:0.34513, F1: 0.34513
====> Epoch: 294 Train Avg loss: 0.00834, Acc: 0.98759, F1: 0.98759#####> Valid Avg loss: 3.87235, Acc:0.34513, F1: 0.34513
====> Epoch: 295 Train Avg loss: 0.00835, Acc: 0.98621, F1: 0.98621#####> Valid Avg loss: 3.70730, Acc:0.34513, F1: 0.34513
====> Epoch: 296 Train Avg loss: 0.00805, Acc: 0.98759, F1: 0.98759#####> Valid Avg loss: 3.84659, Acc:0.34513, F1: 0.34513
===> Epoch: 296: Training loss decreased (0.00811 --> 0.00805), Acc: (0.98897 --> 0.98759), F1: (0.98897 --> 0.98759).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_4
====> Epoch: 297 Train Avg loss: 0.00819, Acc: 0.98828, F1: 0.98828#####> Valid Avg loss: 3.77925, Acc:0.34513, F1: 0.34513
====> Epoch: 298 Train Avg loss: 0.00812, Acc: 0.98897, F1: 0.98897#####> Valid Avg loss: 3.67526, Acc:0.34513, F1: 0.34513
====> Epoch: 299 Train Avg loss: 0.00820, Acc: 0.98759, F1: 0.98759#####> Valid Avg loss: 3.76325, Acc:0.34513, F1: 0.34513
====> Epoch: 300 Train Avg loss: 0.58497, Acc: 0.57103, F1: 0.57103#####> Valid Avg loss: 0.92312, Acc:0.40708, F1: 0.40708
====> Epoch: 301 Train Avg loss: 0.48012, Acc: 0.60690, F1: 0.60690#####> Valid Avg loss: 1.03657, Acc:0.40265, F1: 0.40265
====> Epoch: 302 Train Avg loss: 0.28881, Acc: 0.78138, F1: 0.78138#####> Valid Avg loss: 1.80652, Acc:0.37611, F1: 0.37611
====> Epoch: 303 Train Avg loss: 0.15387, Acc: 0.89103, F1: 0.89103#####> Valid Avg loss: 1.99003, Acc:0.38053, F1: 0.38053
====> Epoch: 304 Train Avg loss: 0.09058, Acc: 0.93517, F1: 0.93517#####> Valid Avg loss: 2.20530, Acc:0.38053, F1: 0.38053
====> Epoch: 305 Train Avg loss: 0.10814, Acc: 0.91586, F1: 0.91586#####> Valid Avg loss: 2.71127, Acc:0.40265, F1: 0.40265
====> Epoch: 306 Train Avg loss: 0.10781, Acc: 0.92621, F1: 0.92621#####> Valid Avg loss: 2.46106, Acc:0.33628, F1: 0.33628
====> Epoch: 307 Train Avg loss: 0.11003, Acc: 0.92069, F1: 0.92069#####> Valid Avg loss: 2.30922, Acc:0.35398, F1: 0.35398
====> Epoch: 308 Train Avg loss: 0.07264, Acc: 0.94690, F1: 0.94690#####> Valid Avg loss: 2.51667, Acc:0.35841, F1: 0.35841
====> Epoch: 309 Train Avg loss: 0.07670, Acc: 0.94138, F1: 0.94138#####> Valid Avg loss: 2.66557, Acc:0.37168, F1: 0.37168
====> Epoch: 310 Train Avg loss: 0.12295, Acc: 0.92069, F1: 0.92069#####> Valid Avg loss: 2.16258, Acc:0.38496, F1: 0.38496
====> Epoch: 311 Train Avg loss: 0.03680, Acc: 0.97241, F1: 0.97241#####> Valid Avg loss: 2.47912, Acc:0.37168, F1: 0.37168
====> Epoch: 312 Train Avg loss: 0.08342, Acc: 0.93724, F1: 0.93724#####> Valid Avg loss: 2.41575, Acc:0.38496, F1: 0.38496
====> Epoch: 313 Train Avg loss: 0.10187, Acc: 0.92828, F1: 0.92828#####> Valid Avg loss: 2.47557, Acc:0.41593, F1: 0.41593
====> Epoch: 314 Train Avg loss: 0.05398, Acc: 0.96207, F1: 0.96207#####> Valid Avg loss: 2.39781, Acc:0.35841, F1: 0.35841
====> Epoch: 315 Train Avg loss: 0.10419, Acc: 0.92828, F1: 0.92828#####> Valid Avg loss: 2.11329, Acc:0.33186, F1: 0.33186
====> Epoch: 316 Train Avg loss: 0.09869, Acc: 0.92276, F1: 0.92276#####> Valid Avg loss: 2.38206, Acc:0.42035, F1: 0.42035
====> Epoch: 317 Train Avg loss: 0.04757, Acc: 0.95931, F1: 0.95931#####> Valid Avg loss: 2.48775, Acc:0.36726, F1: 0.36726
====> Epoch: 318 Train Avg loss: 0.09215, Acc: 0.93793, F1: 0.93793#####> Valid Avg loss: 2.24719, Acc:0.37168, F1: 0.37168
====> Epoch: 319 Train Avg loss: 0.05569, Acc: 0.95517, F1: 0.95517#####> Valid Avg loss: 2.66228, Acc:0.39823, F1: 0.39823
====> Epoch: 320 Train Avg loss: 0.02050, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 2.84526, Acc:0.34513, F1: 0.34513
====> Epoch: 321 Train Avg loss: 0.17029, Acc: 0.88690, F1: 0.88690#####> Valid Avg loss: 2.56611, Acc:0.41150, F1: 0.41150
====> Epoch: 322 Train Avg loss: 0.09594, Acc: 0.93517, F1: 0.93517#####> Valid Avg loss: 1.95627, Acc:0.36726, F1: 0.36726
====> Epoch: 323 Train Avg loss: 0.05898, Acc: 0.95862, F1: 0.95862#####> Valid Avg loss: 2.10379, Acc:0.38938, F1: 0.38938
====> Epoch: 324 Train Avg loss: 0.06511, Acc: 0.94828, F1: 0.94828#####> Valid Avg loss: 2.75695, Acc:0.38496, F1: 0.38496
====> Epoch: 325 Train Avg loss: 0.11841, Acc: 0.91172, F1: 0.91172#####> Valid Avg loss: 2.35986, Acc:0.34956, F1: 0.34956
====> Epoch: 326 Train Avg loss: 0.03704, Acc: 0.96966, F1: 0.96966#####> Valid Avg loss: 2.57756, Acc:0.37168, F1: 0.37168
====> Epoch: 327 Train Avg loss: 0.16662, Acc: 0.86966, F1: 0.86966#####> Valid Avg loss: 2.05545, Acc:0.32301, F1: 0.32301
====> Epoch: 328 Train Avg loss: 0.04400, Acc: 0.96414, F1: 0.96414#####> Valid Avg loss: 2.42670, Acc:0.34956, F1: 0.34956
====> Epoch: 329 Train Avg loss: 0.04957, Acc: 0.96276, F1: 0.96276#####> Valid Avg loss: 2.17120, Acc:0.34956, F1: 0.34956
====> Epoch: 330 Train Avg loss: 0.08526, Acc: 0.93655, F1: 0.93655#####> Valid Avg loss: 2.41116, Acc:0.36283, F1: 0.36283
====> Epoch: 331 Train Avg loss: 0.06819, Acc: 0.94759, F1: 0.94759#####> Valid Avg loss: 2.40662, Acc:0.36726, F1: 0.36726
====> Epoch: 332 Train Avg loss: 0.09328, Acc: 0.92759, F1: 0.92759#####> Valid Avg loss: 2.30112, Acc:0.37611, F1: 0.37611
====> Epoch: 333 Train Avg loss: 0.03034, Acc: 0.97517, F1: 0.97517#####> Valid Avg loss: 2.63009, Acc:0.38496, F1: 0.38496
====> Epoch: 334 Train Avg loss: 0.09515, Acc: 0.93448, F1: 0.93448#####> Valid Avg loss: 2.16867, Acc:0.34956, F1: 0.34956
====> Epoch: 335 Train Avg loss: 0.09042, Acc: 0.92483, F1: 0.92483#####> Valid Avg loss: 2.12556, Acc:0.35398, F1: 0.35398
====> Epoch: 336 Train Avg loss: 0.04930, Acc: 0.96207, F1: 0.96207#####> Valid Avg loss: 2.28651, Acc:0.36726, F1: 0.36726
====> Epoch: 337 Train Avg loss: 0.08072, Acc: 0.93862, F1: 0.93862#####> Valid Avg loss: 2.12434, Acc:0.41150, F1: 0.41150
====> Epoch: 338 Train Avg loss: 0.06914, Acc: 0.95448, F1: 0.95448#####> Valid Avg loss: 2.23027, Acc:0.38053, F1: 0.38053
====> Epoch: 339 Train Avg loss: 0.09861, Acc: 0.92621, F1: 0.92621#####> Valid Avg loss: 2.38607, Acc:0.38053, F1: 0.38053
====> Epoch: 340 Train Avg loss: 0.03096, Acc: 0.97379, F1: 0.97379#####> Valid Avg loss: 2.65545, Acc:0.36726, F1: 0.36726
====> Epoch: 341 Train Avg loss: 0.10892, Acc: 0.92207, F1: 0.92207#####> Valid Avg loss: 2.23638, Acc:0.38053, F1: 0.38053
====> Epoch: 342 Train Avg loss: 0.06262, Acc: 0.95034, F1: 0.95034#####> Valid Avg loss: 2.39346, Acc:0.37611, F1: 0.37611
====> Epoch: 343 Train Avg loss: 0.03941, Acc: 0.96345, F1: 0.96345#####> Valid Avg loss: 2.35185, Acc:0.35398, F1: 0.35398
====> Epoch: 344 Train Avg loss: 0.10190, Acc: 0.92897, F1: 0.92897#####> Valid Avg loss: 2.21877, Acc:0.34513, F1: 0.34513
====> Epoch: 345 Train Avg loss: 0.04560, Acc: 0.96207, F1: 0.96207#####> Valid Avg loss: 2.42634, Acc:0.29204, F1: 0.29204
====> Epoch: 346 Train Avg loss: 0.08316, Acc: 0.93931, F1: 0.93931#####> Valid Avg loss: 2.15015, Acc:0.35841, F1: 0.35841
====> Epoch: 347 Train Avg loss: 0.06791, Acc: 0.95034, F1: 0.95034#####> Valid Avg loss: 2.56556, Acc:0.40708, F1: 0.40708
====> Epoch: 348 Train Avg loss: 0.02568, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 2.64380, Acc:0.40265, F1: 0.40265
====> Epoch: 349 Train Avg loss: 0.09329, Acc: 0.92966, F1: 0.92966#####> Valid Avg loss: 2.47084, Acc:0.39823, F1: 0.39823
====> Epoch: 350 Train Avg loss: 0.07269, Acc: 0.94966, F1: 0.94966#####> Valid Avg loss: 2.00390, Acc:0.36726, F1: 0.36726
====> Epoch: 351 Train Avg loss: 0.03554, Acc: 0.96966, F1: 0.96966#####> Valid Avg loss: 2.31373, Acc:0.32743, F1: 0.32743
====> Epoch: 352 Train Avg loss: 0.08622, Acc: 0.93517, F1: 0.93517#####> Valid Avg loss: 2.09821, Acc:0.34513, F1: 0.34513
====> Epoch: 353 Train Avg loss: 0.03558, Acc: 0.97448, F1: 0.97448#####> Valid Avg loss: 2.42343, Acc:0.32743, F1: 0.32743
====> Epoch: 354 Train Avg loss: 0.07029, Acc: 0.93931, F1: 0.93931#####> Valid Avg loss: 2.74311, Acc:0.38496, F1: 0.38496
====> Epoch: 355 Train Avg loss: 0.07643, Acc: 0.94621, F1: 0.94621#####> Valid Avg loss: 2.32561, Acc:0.36726, F1: 0.36726
====> Epoch: 356 Train Avg loss: 0.06407, Acc: 0.94966, F1: 0.94966#####> Valid Avg loss: 2.07230, Acc:0.35841, F1: 0.35841
====> Epoch: 357 Train Avg loss: 0.08928, Acc: 0.93517, F1: 0.93517#####> Valid Avg loss: 2.21666, Acc:0.35841, F1: 0.35841
====> Epoch: 358 Train Avg loss: 0.04717, Acc: 0.96690, F1: 0.96690#####> Valid Avg loss: 2.43418, Acc:0.36283, F1: 0.36283
====> Epoch: 359 Train Avg loss: 0.02492, Acc: 0.97931, F1: 0.97931#####> Valid Avg loss: 2.78224, Acc:0.42920, F1: 0.42920
====> Epoch: 360 Train Avg loss: 0.11258, Acc: 0.92345, F1: 0.92345#####> Valid Avg loss: 2.07816, Acc:0.40708, F1: 0.40708
====> Epoch: 361 Train Avg loss: 0.03723, Acc: 0.97034, F1: 0.97034#####> Valid Avg loss: 2.38658, Acc:0.40708, F1: 0.40708
====> Epoch: 362 Train Avg loss: 0.01801, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 2.49975, Acc:0.36726, F1: 0.36726
====> Epoch: 363 Train Avg loss: 0.06955, Acc: 0.95241, F1: 0.95241#####> Valid Avg loss: 2.16582, Acc:0.37611, F1: 0.37611
====> Epoch: 364 Train Avg loss: 0.05871, Acc: 0.95448, F1: 0.95448#####> Valid Avg loss: 2.53846, Acc:0.40265, F1: 0.40265
====> Epoch: 365 Train Avg loss: 0.07887, Acc: 0.92759, F1: 0.92759#####> Valid Avg loss: 2.17232, Acc:0.34956, F1: 0.34956
====> Epoch: 366 Train Avg loss: 0.06584, Acc: 0.95241, F1: 0.95241#####> Valid Avg loss: 2.20648, Acc:0.38938, F1: 0.38938
====> Epoch: 367 Train Avg loss: 0.04574, Acc: 0.96828, F1: 0.96828#####> Valid Avg loss: 2.28532, Acc:0.30973, F1: 0.30973
====> Epoch: 368 Train Avg loss: 0.03503, Acc: 0.96621, F1: 0.96621#####> Valid Avg loss: 2.42919, Acc:0.36283, F1: 0.36283
====> Epoch: 369 Train Avg loss: 0.10293, Acc: 0.93586, F1: 0.93586#####> Valid Avg loss: 2.22704, Acc:0.34071, F1: 0.34071
====> Epoch: 370 Train Avg loss: 0.04978, Acc: 0.96345, F1: 0.96345#####> Valid Avg loss: 2.62412, Acc:0.40708, F1: 0.40708
====> Epoch: 371 Train Avg loss: 0.06250, Acc: 0.94828, F1: 0.94828#####> Valid Avg loss: 2.19140, Acc:0.38053, F1: 0.38053
====> Epoch: 372 Train Avg loss: 0.06952, Acc: 0.95103, F1: 0.95103#####> Valid Avg loss: 2.58878, Acc:0.37168, F1: 0.37168
====> Epoch: 373 Train Avg loss: 0.03063, Acc: 0.97310, F1: 0.97310#####> Valid Avg loss: 2.87286, Acc:0.38938, F1: 0.38938
====> Epoch: 374 Train Avg loss: 0.09521, Acc: 0.93448, F1: 0.93448#####> Valid Avg loss: 2.27827, Acc:0.34071, F1: 0.34071
====> Epoch: 375 Train Avg loss: 0.04780, Acc: 0.96138, F1: 0.96138#####> Valid Avg loss: 2.54211, Acc:0.37611, F1: 0.37611
====> Epoch: 376 Train Avg loss: 0.03352, Acc: 0.97379, F1: 0.97379#####> Valid Avg loss: 2.82120, Acc:0.37168, F1: 0.37168
====> Epoch: 377 Train Avg loss: 0.09810, Acc: 0.92207, F1: 0.92207#####> Valid Avg loss: 2.50248, Acc:0.35841, F1: 0.35841
====> Epoch: 378 Train Avg loss: 0.04582, Acc: 0.96414, F1: 0.96414#####> Valid Avg loss: 2.51064, Acc:0.37168, F1: 0.37168
====> Epoch: 379 Train Avg loss: 0.03254, Acc: 0.97310, F1: 0.97310#####> Valid Avg loss: 2.68475, Acc:0.37168, F1: 0.37168
====> Epoch: 380 Train Avg loss: 0.05930, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 1.99361, Acc:0.34956, F1: 0.34956
====> Epoch: 381 Train Avg loss: 0.03304, Acc: 0.97103, F1: 0.97103#####> Valid Avg loss: 2.48506, Acc:0.33628, F1: 0.33628
====> Epoch: 382 Train Avg loss: 0.55962, Acc: 0.59655, F1: 0.59655#####> Valid Avg loss: 0.96959, Acc:0.38053, F1: 0.38053
====> Epoch: 383 Train Avg loss: 0.12632, Acc: 0.91448, F1: 0.91448#####> Valid Avg loss: 1.86948, Acc:0.37168, F1: 0.37168
====> Epoch: 384 Train Avg loss: 0.02088, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 2.17589, Acc:0.34956, F1: 0.34956
====> Epoch: 385 Train Avg loss: 0.01464, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 2.34941, Acc:0.38496, F1: 0.38496
====> Epoch: 386 Train Avg loss: 0.05612, Acc: 0.96276, F1: 0.96276#####> Valid Avg loss: 1.88388, Acc:0.30973, F1: 0.30973
====> Epoch: 387 Train Avg loss: 0.06815, Acc: 0.94828, F1: 0.94828#####> Valid Avg loss: 2.34487, Acc:0.33628, F1: 0.33628
====> Epoch: 388 Train Avg loss: 0.05638, Acc: 0.95310, F1: 0.95310#####> Valid Avg loss: 2.27254, Acc:0.35841, F1: 0.35841
====> Epoch: 389 Train Avg loss: 0.04368, Acc: 0.96621, F1: 0.96621#####> Valid Avg loss: 2.43273, Acc:0.40708, F1: 0.40708
====> Epoch: 390 Train Avg loss: 0.03352, Acc: 0.97103, F1: 0.97103#####> Valid Avg loss: 2.51639, Acc:0.38053, F1: 0.38053
====> Epoch: 391 Train Avg loss: 0.08201, Acc: 0.93103, F1: 0.93103#####> Valid Avg loss: 2.01722, Acc:0.36726, F1: 0.36726
====> Epoch: 392 Train Avg loss: 0.03076, Acc: 0.97724, F1: 0.97724#####> Valid Avg loss: 2.69443, Acc:0.38496, F1: 0.38496
====> Epoch: 393 Train Avg loss: 0.06652, Acc: 0.95448, F1: 0.95448#####> Valid Avg loss: 2.12431, Acc:0.42035, F1: 0.42035
====> Epoch: 394 Train Avg loss: 0.07047, Acc: 0.94759, F1: 0.94759#####> Valid Avg loss: 2.35985, Acc:0.34956, F1: 0.34956
====> Epoch: 395 Train Avg loss: 0.02201, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 2.40804, Acc:0.37611, F1: 0.37611
====> Epoch: 396 Train Avg loss: 0.07391, Acc: 0.94966, F1: 0.94966#####> Valid Avg loss: 2.29638, Acc:0.36283, F1: 0.36283
====> Epoch: 397 Train Avg loss: 0.02780, Acc: 0.97586, F1: 0.97586#####> Valid Avg loss: 2.31500, Acc:0.36283, F1: 0.36283
====> Epoch: 398 Train Avg loss: 0.02737, Acc: 0.97517, F1: 0.97517#####> Valid Avg loss: 2.34793, Acc:0.37168, F1: 0.37168
====> Epoch: 399 Train Avg loss: 0.07514, Acc: 0.94207, F1: 0.94207#####> Valid Avg loss: 2.43750, Acc:0.41150, F1: 0.41150
====> Epoch: 400 Train Avg loss: 0.03378, Acc: 0.97310, F1: 0.97310#####> Valid Avg loss: 2.44506, Acc:0.42035, F1: 0.42035
====> Epoch: 401 Train Avg loss: 0.05050, Acc: 0.95931, F1: 0.95931#####> Valid Avg loss: 2.48377, Acc:0.35398, F1: 0.35398
====> Epoch: 402 Train Avg loss: 0.07114, Acc: 0.94966, F1: 0.94966#####> Valid Avg loss: 2.40119, Acc:0.40265, F1: 0.40265
====> Epoch: 403 Train Avg loss: 0.02645, Acc: 0.97241, F1: 0.97241#####> Valid Avg loss: 2.60350, Acc:0.39823, F1: 0.39823
====> Epoch: 404 Train Avg loss: 0.04637, Acc: 0.96276, F1: 0.96276#####> Valid Avg loss: 2.43333, Acc:0.40265, F1: 0.40265
====> Epoch: 405 Train Avg loss: 0.02167, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.44981, Acc:0.37168, F1: 0.37168
====> Epoch: 406 Train Avg loss: 0.03577, Acc: 0.97103, F1: 0.97103#####> Valid Avg loss: 2.31381, Acc:0.30973, F1: 0.30973
====> Epoch: 407 Train Avg loss: 0.04430, Acc: 0.96552, F1: 0.96552#####> Valid Avg loss: 2.30021, Acc:0.34956, F1: 0.34956
====> Epoch: 408 Train Avg loss: 0.05828, Acc: 0.95034, F1: 0.95034#####> Valid Avg loss: 2.75079, Acc:0.38938, F1: 0.38938
====> Epoch: 409 Train Avg loss: 0.04175, Acc: 0.96276, F1: 0.96276#####> Valid Avg loss: 2.94054, Acc:0.42035, F1: 0.42035
====> Epoch: 410 Train Avg loss: 0.02408, Acc: 0.97448, F1: 0.97448#####> Valid Avg loss: 2.82403, Acc:0.39823, F1: 0.39823
====> Epoch: 411 Train Avg loss: 0.03737, Acc: 0.97448, F1: 0.97448#####> Valid Avg loss: 2.27713, Acc:0.36726, F1: 0.36726
====> Epoch: 412 Train Avg loss: 0.06297, Acc: 0.96000, F1: 0.96000#####> Valid Avg loss: 2.31072, Acc:0.33186, F1: 0.33186
====> Epoch: 413 Train Avg loss: 0.03246, Acc: 0.97310, F1: 0.97310#####> Valid Avg loss: 2.48977, Acc:0.38938, F1: 0.38938
====> Epoch: 414 Train Avg loss: 0.03146, Acc: 0.97241, F1: 0.97241#####> Valid Avg loss: 2.70364, Acc:0.34071, F1: 0.34071
====> Epoch: 415 Train Avg loss: 0.07135, Acc: 0.94966, F1: 0.94966#####> Valid Avg loss: 2.55652, Acc:0.38053, F1: 0.38053
====> Epoch: 416 Train Avg loss: 0.02213, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 2.61380, Acc:0.39381, F1: 0.39381
====> Epoch: 417 Train Avg loss: 0.01528, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 2.57820, Acc:0.38053, F1: 0.38053
====> Epoch: 418 Train Avg loss: 0.04936, Acc: 0.95793, F1: 0.95793#####> Valid Avg loss: 2.19187, Acc:0.32743, F1: 0.32743
====> Epoch: 419 Train Avg loss: 0.06885, Acc: 0.95172, F1: 0.95172#####> Valid Avg loss: 2.20318, Acc:0.33186, F1: 0.33186
====> Epoch: 420 Train Avg loss: 0.04487, Acc: 0.96138, F1: 0.96138#####> Valid Avg loss: 2.69772, Acc:0.39823, F1: 0.39823
====> Epoch: 421 Train Avg loss: 0.01760, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.81738, Acc:0.38053, F1: 0.38053
====> Epoch: 422 Train Avg loss: 0.01346, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 2.82781, Acc:0.39823, F1: 0.39823
====> Epoch: 423 Train Avg loss: 0.01288, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 2.82255, Acc:0.37168, F1: 0.37168
====> Epoch: 424 Train Avg loss: 0.01385, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 3.07356, Acc:0.38938, F1: 0.38938
====> Epoch: 425 Train Avg loss: 0.11554, Acc: 0.92966, F1: 0.92966#####> Valid Avg loss: 2.14397, Acc:0.38938, F1: 0.38938
====> Epoch: 426 Train Avg loss: 0.02111, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 2.46696, Acc:0.41150, F1: 0.41150
====> Epoch: 427 Train Avg loss: 0.01285, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 2.60622, Acc:0.39381, F1: 0.39381
====> Epoch: 428 Train Avg loss: 0.04495, Acc: 0.96345, F1: 0.96345#####> Valid Avg loss: 2.28618, Acc:0.42035, F1: 0.42035
====> Epoch: 429 Train Avg loss: 0.07589, Acc: 0.94276, F1: 0.94276#####> Valid Avg loss: 2.38044, Acc:0.39823, F1: 0.39823
====> Epoch: 430 Train Avg loss: 0.02093, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 2.34929, Acc:0.36726, F1: 0.36726
====> Epoch: 431 Train Avg loss: 0.01893, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 2.52196, Acc:0.38496, F1: 0.38496
====> Epoch: 432 Train Avg loss: 0.01117, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 2.63379, Acc:0.38938, F1: 0.38938
====> Epoch: 433 Train Avg loss: 0.01101, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 2.71851, Acc:0.36726, F1: 0.36726
====> Epoch: 434 Train Avg loss: 0.06926, Acc: 0.94966, F1: 0.94966#####> Valid Avg loss: 1.99287, Acc:0.28319, F1: 0.28319
====> Epoch: 435 Train Avg loss: 0.02639, Acc: 0.97724, F1: 0.97724#####> Valid Avg loss: 2.33091, Acc:0.40265, F1: 0.40265
====> Epoch: 436 Train Avg loss: 0.01532, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 2.46167, Acc:0.37611, F1: 0.37611
====> Epoch: 437 Train Avg loss: 0.08705, Acc: 0.94000, F1: 0.94000#####> Valid Avg loss: 2.33297, Acc:0.37168, F1: 0.37168
====> Epoch: 438 Train Avg loss: 0.02449, Acc: 0.97931, F1: 0.97931#####> Valid Avg loss: 2.55218, Acc:0.38938, F1: 0.38938
====> Epoch: 439 Train Avg loss: 0.01257, Acc: 0.98552, F1: 0.98552#####> Valid Avg loss: 2.51731, Acc:0.39381, F1: 0.39381
====> Epoch: 440 Train Avg loss: 0.01349, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 3.06727, Acc:0.39823, F1: 0.39823
====> Epoch: 441 Train Avg loss: 0.04505, Acc: 0.96138, F1: 0.96138#####> Valid Avg loss: 2.78794, Acc:0.37611, F1: 0.37611
====> Epoch: 442 Train Avg loss: 0.08615, Acc: 0.93310, F1: 0.93310#####> Valid Avg loss: 2.44078, Acc:0.40265, F1: 0.40265
====> Epoch: 443 Train Avg loss: 0.01402, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 2.55099, Acc:0.37168, F1: 0.37168
====> Epoch: 444 Train Avg loss: 0.01199, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 2.79045, Acc:0.39381, F1: 0.39381
====> Epoch: 445 Train Avg loss: 0.01086, Acc: 0.98690, F1: 0.98690#####> Valid Avg loss: 2.87691, Acc:0.40265, F1: 0.40265
====> Epoch: 446 Train Avg loss: 0.06935, Acc: 0.94414, F1: 0.94414#####> Valid Avg loss: 2.00016, Acc:0.34071, F1: 0.34071
====> Epoch: 447 Train Avg loss: 0.03067, Acc: 0.97517, F1: 0.97517#####> Valid Avg loss: 2.32153, Acc:0.36726, F1: 0.36726
====> Epoch: 448 Train Avg loss: 0.01942, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 2.65525, Acc:0.35398, F1: 0.35398
====> Epoch: 449 Train Avg loss: 0.01146, Acc: 0.98483, F1: 0.98483#####> Valid Avg loss: 2.84682, Acc:0.37611, F1: 0.37611
====> Epoch: 450 Train Avg loss: 0.01194, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 2.85276, Acc:0.35841, F1: 0.35841
====> Epoch: 451 Train Avg loss: 0.04440, Acc: 0.96483, F1: 0.96483#####> Valid Avg loss: 2.05606, Acc:0.37168, F1: 0.37168
====> Epoch: 452 Train Avg loss: 0.05987, Acc: 0.96069, F1: 0.96069#####> Valid Avg loss: 2.36695, Acc:0.36726, F1: 0.36726
====> Epoch: 453 Train Avg loss: 0.01771, Acc: 0.97931, F1: 0.97931#####> Valid Avg loss: 2.80898, Acc:0.38053, F1: 0.38053
====> Epoch: 454 Train Avg loss: 0.07104, Acc: 0.94000, F1: 0.94000#####> Valid Avg loss: 2.67048, Acc:0.38053, F1: 0.38053
====> Epoch: 455 Train Avg loss: 0.01815, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 2.62836, Acc:0.35841, F1: 0.35841
====> Epoch: 456 Train Avg loss: 0.01133, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 2.76453, Acc:0.35398, F1: 0.35398
====> Epoch: 457 Train Avg loss: 0.09108, Acc: 0.93862, F1: 0.93862#####> Valid Avg loss: 1.86270, Acc:0.33186, F1: 0.33186
====> Epoch: 458 Train Avg loss: 0.02523, Acc: 0.97724, F1: 0.97724#####> Valid Avg loss: 2.36175, Acc:0.36283, F1: 0.36283
====> Epoch: 459 Train Avg loss: 0.01595, Acc: 0.97793, F1: 0.97793#####> Valid Avg loss: 2.60552, Acc:0.34513, F1: 0.34513
====> Epoch: 460 Train Avg loss: 0.01300, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 2.72795, Acc:0.36283, F1: 0.36283
====> Epoch: 461 Train Avg loss: 0.01686, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 2.77531, Acc:0.32743, F1: 0.32743
====> Epoch: 462 Train Avg loss: 0.05506, Acc: 0.95655, F1: 0.95655#####> Valid Avg loss: 2.38792, Acc:0.35841, F1: 0.35841
====> Epoch: 463 Train Avg loss: 0.01657, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 2.41429, Acc:0.37168, F1: 0.37168
====> Epoch: 464 Train Avg loss: 0.04048, Acc: 0.97034, F1: 0.97034#####> Valid Avg loss: 2.28309, Acc:0.34513, F1: 0.34513
====> Epoch: 465 Train Avg loss: 0.02955, Acc: 0.97379, F1: 0.97379#####> Valid Avg loss: 2.78727, Acc:0.38053, F1: 0.38053
====> Epoch: 466 Train Avg loss: 0.01141, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 2.91975, Acc:0.35841, F1: 0.35841
====> Epoch: 467 Train Avg loss: 0.01647, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 3.01754, Acc:0.39381, F1: 0.39381
====> Epoch: 468 Train Avg loss: 0.04173, Acc: 0.96483, F1: 0.96483#####> Valid Avg loss: 2.42814, Acc:0.37611, F1: 0.37611
====> Epoch: 469 Train Avg loss: 0.02085, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 2.51048, Acc:0.38938, F1: 0.38938
====> Epoch: 470 Train Avg loss: 0.01044, Acc: 0.98966, F1: 0.98966#####> Valid Avg loss: 2.57810, Acc:0.40708, F1: 0.40708
====> Epoch: 471 Train Avg loss: 0.01116, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 2.77134, Acc:0.36283, F1: 0.36283
====> Epoch: 472 Train Avg loss: 0.06839, Acc: 0.95034, F1: 0.95034#####> Valid Avg loss: 2.29303, Acc:0.34071, F1: 0.34071
====> Epoch: 473 Train Avg loss: 0.01552, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 2.45218, Acc:0.34513, F1: 0.34513
====> Epoch: 474 Train Avg loss: 0.01160, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 2.74594, Acc:0.34513, F1: 0.34513
====> Epoch: 475 Train Avg loss: 0.01176, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 2.55452, Acc:0.35398, F1: 0.35398
====> Epoch: 476 Train Avg loss: 0.03310, Acc: 0.97103, F1: 0.97103#####> Valid Avg loss: 2.37925, Acc:0.34956, F1: 0.34956
====> Epoch: 477 Train Avg loss: 0.06901, Acc: 0.95034, F1: 0.95034#####> Valid Avg loss: 2.35981, Acc:0.38053, F1: 0.38053
====> Epoch: 478 Train Avg loss: 0.01351, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 2.61864, Acc:0.37611, F1: 0.37611
====> Epoch: 479 Train Avg loss: 0.01592, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 2.72603, Acc:0.37168, F1: 0.37168
====> Epoch: 480 Train Avg loss: 0.04039, Acc: 0.96552, F1: 0.96552#####> Valid Avg loss: 2.71392, Acc:0.38053, F1: 0.38053
====> Epoch: 481 Train Avg loss: 0.01385, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 2.67678, Acc:0.36726, F1: 0.36726
====> Epoch: 482 Train Avg loss: 0.01324, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 2.70587, Acc:0.38938, F1: 0.38938
====> Epoch: 483 Train Avg loss: 0.02398, Acc: 0.96966, F1: 0.96966#####> Valid Avg loss: 2.67366, Acc:0.37168, F1: 0.37168
====> Epoch: 484 Train Avg loss: 0.01067, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 2.86199, Acc:0.36726, F1: 0.36726
====> Epoch: 485 Train Avg loss: 0.01006, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 2.92405, Acc:0.36726, F1: 0.36726
====> Epoch: 486 Train Avg loss: 0.01314, Acc: 0.98207, F1: 0.98207#####> Valid Avg loss: 2.81219, Acc:0.35398, F1: 0.35398
====> Epoch: 487 Train Avg loss: 0.06990, Acc: 0.94897, F1: 0.94897#####> Valid Avg loss: 2.78233, Acc:0.39381, F1: 0.39381
====> Epoch: 488 Train Avg loss: 0.01184, Acc: 0.98000, F1: 0.98000#####> Valid Avg loss: 2.99925, Acc:0.38938, F1: 0.38938
====> Epoch: 489 Train Avg loss: 0.01035, Acc: 0.98483, F1: 0.98483#####> Valid Avg loss: 2.98607, Acc:0.39381, F1: 0.39381
====> Epoch: 490 Train Avg loss: 0.00991, Acc: 0.98621, F1: 0.98621#####> Valid Avg loss: 3.06645, Acc:0.37611, F1: 0.37611
====> Epoch: 491 Train Avg loss: 0.01083, Acc: 0.98276, F1: 0.98276#####> Valid Avg loss: 2.90622, Acc:0.38053, F1: 0.38053
====> Epoch: 492 Train Avg loss: 0.01029, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 3.19736, Acc:0.40708, F1: 0.40708
====> Epoch: 493 Train Avg loss: 0.07692, Acc: 0.94690, F1: 0.94690#####> Valid Avg loss: 2.51862, Acc:0.40708, F1: 0.40708
====> Epoch: 494 Train Avg loss: 0.01978, Acc: 0.98138, F1: 0.98138#####> Valid Avg loss: 2.45716, Acc:0.37168, F1: 0.37168
====> Epoch: 495 Train Avg loss: 0.01194, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 2.52194, Acc:0.38938, F1: 0.38938
====> Epoch: 496 Train Avg loss: 0.01065, Acc: 0.98345, F1: 0.98345#####> Valid Avg loss: 2.55849, Acc:0.37611, F1: 0.37611
====> Epoch: 497 Train Avg loss: 0.00991, Acc: 0.98414, F1: 0.98414#####> Valid Avg loss: 2.68196, Acc:0.38938, F1: 0.38938
====> Epoch: 498 Train Avg loss: 0.00990, Acc: 0.98690, F1: 0.98690#####> Valid Avg loss: 2.52866, Acc:0.34513, F1: 0.34513
====> Epoch: 499 Train Avg loss: 0.05881, Acc: 0.95724, F1: 0.95724#####> Valid Avg loss: 2.25096, Acc:0.39823, F1: 0.39823
====> Epoch: 500 Train Avg loss: 0.01545, Acc: 0.98069, F1: 0.98069#####> Valid Avg loss: 2.44997, Acc:0.39823, F1: 0.39823
#####> Valid Avg loss: 2.31948, Acc:0.52500, F1: 0.52500


$$$$$$> Test it 4: (from train best model) Final Test Avg loss:2.31948, Acc:0.52500, F1:0.52500\n
#####> Valid Avg loss: 0.60747, Acc:0.69286, F1: 0.69286


$$$$$$> Test it 4: (from max acc valid model) Final Test Avg loss:0.60747, Acc:0.69286, F1:0.69286\n
#####> Valid Avg loss: 0.57639, Acc:0.71071, F1: 0.71071


$$$$$$> Test it 4: (from min loss valid model) Final Test Avg loss:0.57639, Acc:0.71071, F1:0.71071\n


	Start execution training validation it 5 

train_dataloader len: 786
valid_dataloader len: 113
test_dataloader len: 79
train performers ids: [2, 4, 5]
valid performers ids: [1]
test performers ids: [6]
train dataset len: 1572, train dataloader len: 786
valid dataset len: 226, valid dataloader len: 113
valid dataset len: 158, test dataloader len: 113
====> Epoch: 1 Train Avg loss: 0.69935, Acc: 0.47519, F1: 0.47519#####> Valid Avg loss: 0.70819, Acc:0.47345, F1: 0.47345
===> Epoch: 1: Training loss decreased (inf --> 0.69935), Acc: (0.00000 --> 0.47519), F1: (0.00000 --> 0.47519).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5

####> Epoch: 1: validation loss decreased (inf --> 0.70819), Acc: (0.00000 --> 0.47345), F1: (0.00000 --> 0.47345).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5

####> Epoch: 1: validation acc increase (inf --> 0.70819), Acc: (0.00000 --> 0.47345), F1: (0.00000 --> 0.47345).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 2 Train Avg loss: 0.67127, Acc: 0.49746, F1: 0.49746#####> Valid Avg loss: 0.70931, Acc:0.47345, F1: 0.47345
===> Epoch: 2: Training loss decreased (0.69935 --> 0.67127), Acc: (0.47519 --> 0.49746), F1: (0.47519 --> 0.49746).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 3 Train Avg loss: 0.65165, Acc: 0.48919, F1: 0.48919#####> Valid Avg loss: 0.72709, Acc:0.29646, F1: 0.29646
===> Epoch: 3: Training loss decreased (0.67127 --> 0.65165), Acc: (0.49746 --> 0.48919), F1: (0.49746 --> 0.48919).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 4 Train Avg loss: 0.65161, Acc: 0.49682, F1: 0.49682#####> Valid Avg loss: 0.69313, Acc:0.47345, F1: 0.47345
===> Epoch: 4: Training loss decreased (0.65165 --> 0.65161), Acc: (0.48919 --> 0.49682), F1: (0.48919 --> 0.49682).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5

####> Epoch: 4: validation loss decreased (0.70819 --> 0.69313), Acc: (0.47345 --> 0.47345), F1: (0.47345 --> 0.47345).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 5 Train Avg loss: 0.63687, Acc: 0.50636, F1: 0.50636#####> Valid Avg loss: 0.69534, Acc:0.45575, F1: 0.45575
===> Epoch: 5: Training loss decreased (0.65161 --> 0.63687), Acc: (0.49682 --> 0.50636), F1: (0.49682 --> 0.50636).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 6 Train Avg loss: 0.62783, Acc: 0.51145, F1: 0.51145#####> Valid Avg loss: 0.70777, Acc:0.46460, F1: 0.46460
===> Epoch: 6: Training loss decreased (0.63687 --> 0.62783), Acc: (0.50636 --> 0.51145), F1: (0.50636 --> 0.51145).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 7 Train Avg loss: 0.62763, Acc: 0.52735, F1: 0.52735#####> Valid Avg loss: 0.72432, Acc:0.47345, F1: 0.47345
===> Epoch: 7: Training loss decreased (0.62783 --> 0.62763), Acc: (0.51145 --> 0.52735), F1: (0.51145 --> 0.52735).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 8 Train Avg loss: 0.61458, Acc: 0.51399, F1: 0.51399#####> Valid Avg loss: 0.78058, Acc:0.47345, F1: 0.47345
===> Epoch: 8: Training loss decreased (0.62763 --> 0.61458), Acc: (0.52735 --> 0.51399), F1: (0.52735 --> 0.51399).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 9 Train Avg loss: 0.61212, Acc: 0.51209, F1: 0.51209#####> Valid Avg loss: 0.70862, Acc:0.39823, F1: 0.39823
===> Epoch: 9: Training loss decreased (0.61458 --> 0.61212), Acc: (0.51399 --> 0.51209), F1: (0.51399 --> 0.51209).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 10 Train Avg loss: 0.60441, Acc: 0.51654, F1: 0.51654#####> Valid Avg loss: 0.77745, Acc:0.26991, F1: 0.26991
===> Epoch: 10: Training loss decreased (0.61212 --> 0.60441), Acc: (0.51209 --> 0.51654), F1: (0.51209 --> 0.51654).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 11 Train Avg loss: 0.59479, Acc: 0.52735, F1: 0.52735#####> Valid Avg loss: 0.78756, Acc:0.47345, F1: 0.47345
===> Epoch: 11: Training loss decreased (0.60441 --> 0.59479), Acc: (0.51654 --> 0.52735), F1: (0.51654 --> 0.52735).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 12 Train Avg loss: 0.58826, Acc: 0.52481, F1: 0.52481#####> Valid Avg loss: 0.77092, Acc:0.47345, F1: 0.47345
===> Epoch: 12: Training loss decreased (0.59479 --> 0.58826), Acc: (0.52735 --> 0.52481), F1: (0.52735 --> 0.52481).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 13 Train Avg loss: 0.58585, Acc: 0.53880, F1: 0.53880#####> Valid Avg loss: 0.70455, Acc:0.46018, F1: 0.46018
===> Epoch: 13: Training loss decreased (0.58826 --> 0.58585), Acc: (0.52481 --> 0.53880), F1: (0.52481 --> 0.53880).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 14 Train Avg loss: 0.58486, Acc: 0.53626, F1: 0.53626#####> Valid Avg loss: 0.87390, Acc:0.47345, F1: 0.47345
===> Epoch: 14: Training loss decreased (0.58585 --> 0.58486), Acc: (0.53880 --> 0.53626), F1: (0.53880 --> 0.53626).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 15 Train Avg loss: 0.57543, Acc: 0.54962, F1: 0.54962#####> Valid Avg loss: 0.76101, Acc:0.46460, F1: 0.46460
===> Epoch: 15: Training loss decreased (0.58486 --> 0.57543), Acc: (0.53626 --> 0.54962), F1: (0.53626 --> 0.54962).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 16 Train Avg loss: 0.56508, Acc: 0.54517, F1: 0.54517#####> Valid Avg loss: 0.76770, Acc:0.46903, F1: 0.46903
===> Epoch: 16: Training loss decreased (0.57543 --> 0.56508), Acc: (0.54962 --> 0.54517), F1: (0.54962 --> 0.54517).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 17 Train Avg loss: 0.56395, Acc: 0.56552, F1: 0.56552#####> Valid Avg loss: 0.75481, Acc:0.47345, F1: 0.47345
===> Epoch: 17: Training loss decreased (0.56508 --> 0.56395), Acc: (0.54517 --> 0.56552), F1: (0.54517 --> 0.56552).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 18 Train Avg loss: 0.55340, Acc: 0.56489, F1: 0.56489#####> Valid Avg loss: 0.79461, Acc:0.46903, F1: 0.46903
===> Epoch: 18: Training loss decreased (0.56395 --> 0.55340), Acc: (0.56552 --> 0.56489), F1: (0.56552 --> 0.56489).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 19 Train Avg loss: 0.55518, Acc: 0.55916, F1: 0.55916#####> Valid Avg loss: 0.79540, Acc:0.47345, F1: 0.47345
====> Epoch: 20 Train Avg loss: 0.55195, Acc: 0.56170, F1: 0.56170#####> Valid Avg loss: 0.81230, Acc:0.47345, F1: 0.47345
===> Epoch: 20: Training loss decreased (0.55340 --> 0.55195), Acc: (0.56489 --> 0.56170), F1: (0.56489 --> 0.56170).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 21 Train Avg loss: 0.54223, Acc: 0.57379, F1: 0.57379#####> Valid Avg loss: 0.81800, Acc:0.45133, F1: 0.45133
===> Epoch: 21: Training loss decreased (0.55195 --> 0.54223), Acc: (0.56170 --> 0.57379), F1: (0.56170 --> 0.57379).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 22 Train Avg loss: 0.53759, Acc: 0.56298, F1: 0.56298#####> Valid Avg loss: 0.80166, Acc:0.45133, F1: 0.45133
===> Epoch: 22: Training loss decreased (0.54223 --> 0.53759), Acc: (0.57379 --> 0.56298), F1: (0.57379 --> 0.56298).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 23 Train Avg loss: 0.52915, Acc: 0.57888, F1: 0.57888#####> Valid Avg loss: 0.87230, Acc:0.46018, F1: 0.46018
===> Epoch: 23: Training loss decreased (0.53759 --> 0.52915), Acc: (0.56298 --> 0.57888), F1: (0.56298 --> 0.57888).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 24 Train Avg loss: 0.51498, Acc: 0.59033, F1: 0.59033#####> Valid Avg loss: 0.82153, Acc:0.47345, F1: 0.47345
===> Epoch: 24: Training loss decreased (0.52915 --> 0.51498), Acc: (0.57888 --> 0.59033), F1: (0.57888 --> 0.59033).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 25 Train Avg loss: 0.51287, Acc: 0.58906, F1: 0.58906#####> Valid Avg loss: 0.89783, Acc:0.46460, F1: 0.46460
===> Epoch: 25: Training loss decreased (0.51498 --> 0.51287), Acc: (0.59033 --> 0.58906), F1: (0.59033 --> 0.58906).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 26 Train Avg loss: 0.50482, Acc: 0.59924, F1: 0.59924#####> Valid Avg loss: 0.84275, Acc:0.40708, F1: 0.40708
===> Epoch: 26: Training loss decreased (0.51287 --> 0.50482), Acc: (0.58906 --> 0.59924), F1: (0.58906 --> 0.59924).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 27 Train Avg loss: 0.49987, Acc: 0.60878, F1: 0.60878#####> Valid Avg loss: 0.82998, Acc:0.47345, F1: 0.47345
===> Epoch: 27: Training loss decreased (0.50482 --> 0.49987), Acc: (0.59924 --> 0.60878), F1: (0.59924 --> 0.60878).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 28 Train Avg loss: 0.48841, Acc: 0.59987, F1: 0.59987#####> Valid Avg loss: 0.96858, Acc:0.47788, F1: 0.47788
===> Epoch: 28: Training loss decreased (0.49987 --> 0.48841), Acc: (0.60878 --> 0.59987), F1: (0.60878 --> 0.59987).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5

####> Epoch: 28: validation acc increase (0.70819 --> 0.96858), Acc: (0.47345 --> 0.47788), F1: (0.47345 --> 0.47788).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 29 Train Avg loss: 0.48555, Acc: 0.61323, F1: 0.61323#####> Valid Avg loss: 0.86558, Acc:0.44248, F1: 0.44248
===> Epoch: 29: Training loss decreased (0.48841 --> 0.48555), Acc: (0.59987 --> 0.61323), F1: (0.59987 --> 0.61323).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 30 Train Avg loss: 0.46772, Acc: 0.62023, F1: 0.62023#####> Valid Avg loss: 0.94687, Acc:0.46018, F1: 0.46018
===> Epoch: 30: Training loss decreased (0.48555 --> 0.46772), Acc: (0.61323 --> 0.62023), F1: (0.61323 --> 0.62023).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 31 Train Avg loss: 0.45451, Acc: 0.62150, F1: 0.62150#####> Valid Avg loss: 0.91934, Acc:0.41150, F1: 0.41150
===> Epoch: 31: Training loss decreased (0.46772 --> 0.45451), Acc: (0.62023 --> 0.62150), F1: (0.62023 --> 0.62150).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 32 Train Avg loss: 0.44545, Acc: 0.63168, F1: 0.63168#####> Valid Avg loss: 0.93025, Acc:0.42920, F1: 0.42920
===> Epoch: 32: Training loss decreased (0.45451 --> 0.44545), Acc: (0.62150 --> 0.63168), F1: (0.62150 --> 0.63168).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 33 Train Avg loss: 0.43600, Acc: 0.64186, F1: 0.64186#####> Valid Avg loss: 1.10299, Acc:0.46018, F1: 0.46018
===> Epoch: 33: Training loss decreased (0.44545 --> 0.43600), Acc: (0.63168 --> 0.64186), F1: (0.63168 --> 0.64186).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 34 Train Avg loss: 0.42729, Acc: 0.66221, F1: 0.66221#####> Valid Avg loss: 1.22041, Acc:0.45575, F1: 0.45575
===> Epoch: 34: Training loss decreased (0.43600 --> 0.42729), Acc: (0.64186 --> 0.66221), F1: (0.64186 --> 0.66221).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 35 Train Avg loss: 0.41482, Acc: 0.67176, F1: 0.67176#####> Valid Avg loss: 1.06372, Acc:0.43363, F1: 0.43363
===> Epoch: 35: Training loss decreased (0.42729 --> 0.41482), Acc: (0.66221 --> 0.67176), F1: (0.66221 --> 0.67176).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 36 Train Avg loss: 0.40019, Acc: 0.67875, F1: 0.67875#####> Valid Avg loss: 1.04551, Acc:0.40265, F1: 0.40265
===> Epoch: 36: Training loss decreased (0.41482 --> 0.40019), Acc: (0.67176 --> 0.67875), F1: (0.67176 --> 0.67875).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 37 Train Avg loss: 0.39110, Acc: 0.68511, F1: 0.68511#####> Valid Avg loss: 1.04826, Acc:0.41150, F1: 0.41150
===> Epoch: 37: Training loss decreased (0.40019 --> 0.39110), Acc: (0.67875 --> 0.68511), F1: (0.67875 --> 0.68511).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 38 Train Avg loss: 0.37333, Acc: 0.68830, F1: 0.68830#####> Valid Avg loss: 1.19405, Acc:0.44690, F1: 0.44690
===> Epoch: 38: Training loss decreased (0.39110 --> 0.37333), Acc: (0.68511 --> 0.68830), F1: (0.68511 --> 0.68830).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 39 Train Avg loss: 0.35383, Acc: 0.71120, F1: 0.71120#####> Valid Avg loss: 1.11785, Acc:0.39823, F1: 0.39823
===> Epoch: 39: Training loss decreased (0.37333 --> 0.35383), Acc: (0.68830 --> 0.71120), F1: (0.68830 --> 0.71120).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 40 Train Avg loss: 0.34698, Acc: 0.70802, F1: 0.70802#####> Valid Avg loss: 1.53289, Acc:0.46903, F1: 0.46903
===> Epoch: 40: Training loss decreased (0.35383 --> 0.34698), Acc: (0.71120 --> 0.70802), F1: (0.71120 --> 0.70802).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 41 Train Avg loss: 0.32484, Acc: 0.73473, F1: 0.73473#####> Valid Avg loss: 1.40907, Acc:0.43363, F1: 0.43363
===> Epoch: 41: Training loss decreased (0.34698 --> 0.32484), Acc: (0.70802 --> 0.73473), F1: (0.70802 --> 0.73473).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 42 Train Avg loss: 0.30924, Acc: 0.75763, F1: 0.75763#####> Valid Avg loss: 1.32677, Acc:0.42920, F1: 0.42920
===> Epoch: 42: Training loss decreased (0.32484 --> 0.30924), Acc: (0.73473 --> 0.75763), F1: (0.73473 --> 0.75763).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 43 Train Avg loss: 0.28563, Acc: 0.76272, F1: 0.76272#####> Valid Avg loss: 1.54021, Acc:0.45133, F1: 0.45133
===> Epoch: 43: Training loss decreased (0.30924 --> 0.28563), Acc: (0.75763 --> 0.76272), F1: (0.75763 --> 0.76272).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 44 Train Avg loss: 0.27363, Acc: 0.78181, F1: 0.78181#####> Valid Avg loss: 1.40649, Acc:0.42035, F1: 0.42035
===> Epoch: 44: Training loss decreased (0.28563 --> 0.27363), Acc: (0.76272 --> 0.78181), F1: (0.76272 --> 0.78181).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 45 Train Avg loss: 0.25099, Acc: 0.79835, F1: 0.79835#####> Valid Avg loss: 1.62898, Acc:0.39381, F1: 0.39381
===> Epoch: 45: Training loss decreased (0.27363 --> 0.25099), Acc: (0.78181 --> 0.79835), F1: (0.78181 --> 0.79835).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 46 Train Avg loss: 0.22983, Acc: 0.81425, F1: 0.81425#####> Valid Avg loss: 1.63064, Acc:0.39381, F1: 0.39381
===> Epoch: 46: Training loss decreased (0.25099 --> 0.22983), Acc: (0.79835 --> 0.81425), F1: (0.79835 --> 0.81425).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 47 Train Avg loss: 0.20874, Acc: 0.83333, F1: 0.83333#####> Valid Avg loss: 1.86469, Acc:0.45133, F1: 0.45133
===> Epoch: 47: Training loss decreased (0.22983 --> 0.20874), Acc: (0.81425 --> 0.83333), F1: (0.81425 --> 0.83333).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 48 Train Avg loss: 0.20446, Acc: 0.83461, F1: 0.83461#####> Valid Avg loss: 1.72432, Acc:0.40708, F1: 0.40708
===> Epoch: 48: Training loss decreased (0.20874 --> 0.20446), Acc: (0.83333 --> 0.83461), F1: (0.83333 --> 0.83461).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 49 Train Avg loss: 0.16773, Acc: 0.86832, F1: 0.86832#####> Valid Avg loss: 2.28306, Acc:0.44690, F1: 0.44690
===> Epoch: 49: Training loss decreased (0.20446 --> 0.16773), Acc: (0.83461 --> 0.86832), F1: (0.83461 --> 0.86832).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 50 Train Avg loss: 0.17314, Acc: 0.86260, F1: 0.86260#####> Valid Avg loss: 2.10068, Acc:0.43805, F1: 0.43805
====> Epoch: 51 Train Avg loss: 0.15031, Acc: 0.87595, F1: 0.87595#####> Valid Avg loss: 2.14185, Acc:0.38053, F1: 0.38053
===> Epoch: 51: Training loss decreased (0.16773 --> 0.15031), Acc: (0.86832 --> 0.87595), F1: (0.86832 --> 0.87595).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 52 Train Avg loss: 0.12846, Acc: 0.89758, F1: 0.89758#####> Valid Avg loss: 2.43169, Acc:0.43363, F1: 0.43363
===> Epoch: 52: Training loss decreased (0.15031 --> 0.12846), Acc: (0.87595 --> 0.89758), F1: (0.87595 --> 0.89758).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 53 Train Avg loss: 0.13291, Acc: 0.89249, F1: 0.89249#####> Valid Avg loss: 2.46779, Acc:0.42920, F1: 0.42920
====> Epoch: 54 Train Avg loss: 0.11025, Acc: 0.91794, F1: 0.91794#####> Valid Avg loss: 2.40350, Acc:0.43363, F1: 0.43363
===> Epoch: 54: Training loss decreased (0.12846 --> 0.11025), Acc: (0.89758 --> 0.91794), F1: (0.89758 --> 0.91794).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 55 Train Avg loss: 0.09824, Acc: 0.91921, F1: 0.91921#####> Valid Avg loss: 2.44073, Acc:0.40265, F1: 0.40265
===> Epoch: 55: Training loss decreased (0.11025 --> 0.09824), Acc: (0.91794 --> 0.91921), F1: (0.91794 --> 0.91921).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 56 Train Avg loss: 0.10474, Acc: 0.91539, F1: 0.91539#####> Valid Avg loss: 2.81961, Acc:0.44248, F1: 0.44248
====> Epoch: 57 Train Avg loss: 0.09476, Acc: 0.92748, F1: 0.92748#####> Valid Avg loss: 2.64176, Acc:0.42478, F1: 0.42478
===> Epoch: 57: Training loss decreased (0.09824 --> 0.09476), Acc: (0.91921 --> 0.92748), F1: (0.91921 --> 0.92748).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 58 Train Avg loss: 0.08165, Acc: 0.93384, F1: 0.93384#####> Valid Avg loss: 2.66978, Acc:0.42920, F1: 0.42920
===> Epoch: 58: Training loss decreased (0.09476 --> 0.08165), Acc: (0.92748 --> 0.93384), F1: (0.92748 --> 0.93384).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 59 Train Avg loss: 0.06566, Acc: 0.95674, F1: 0.95674#####> Valid Avg loss: 2.81299, Acc:0.43363, F1: 0.43363
===> Epoch: 59: Training loss decreased (0.08165 --> 0.06566), Acc: (0.93384 --> 0.95674), F1: (0.93384 --> 0.95674).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 60 Train Avg loss: 0.06285, Acc: 0.95356, F1: 0.95356#####> Valid Avg loss: 3.10376, Acc:0.41593, F1: 0.41593
===> Epoch: 60: Training loss decreased (0.06566 --> 0.06285), Acc: (0.95674 --> 0.95356), F1: (0.95674 --> 0.95356).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 61 Train Avg loss: 0.06702, Acc: 0.95102, F1: 0.95102#####> Valid Avg loss: 2.89588, Acc:0.42478, F1: 0.42478
====> Epoch: 62 Train Avg loss: 0.04379, Acc: 0.96692, F1: 0.96692#####> Valid Avg loss: 3.07311, Acc:0.40265, F1: 0.40265
===> Epoch: 62: Training loss decreased (0.06285 --> 0.04379), Acc: (0.95356 --> 0.96692), F1: (0.95356 --> 0.96692).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 63 Train Avg loss: 0.05281, Acc: 0.96374, F1: 0.96374#####> Valid Avg loss: 3.24416, Acc:0.41150, F1: 0.41150
====> Epoch: 64 Train Avg loss: 0.04650, Acc: 0.96692, F1: 0.96692#####> Valid Avg loss: 3.12879, Acc:0.41593, F1: 0.41593
====> Epoch: 65 Train Avg loss: 0.04234, Acc: 0.97137, F1: 0.97137#####> Valid Avg loss: 3.52365, Acc:0.41593, F1: 0.41593
===> Epoch: 65: Training loss decreased (0.04379 --> 0.04234), Acc: (0.96692 --> 0.97137), F1: (0.96692 --> 0.97137).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 66 Train Avg loss: 0.04694, Acc: 0.96883, F1: 0.96883#####> Valid Avg loss: 3.09481, Acc:0.39381, F1: 0.39381
====> Epoch: 67 Train Avg loss: 0.03984, Acc: 0.97137, F1: 0.97137#####> Valid Avg loss: 3.21095, Acc:0.41150, F1: 0.41150
===> Epoch: 67: Training loss decreased (0.04234 --> 0.03984), Acc: (0.97137 --> 0.97137), F1: (0.97137 --> 0.97137).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 68 Train Avg loss: 0.03235, Acc: 0.97392, F1: 0.97392#####> Valid Avg loss: 3.31172, Acc:0.42035, F1: 0.42035
===> Epoch: 68: Training loss decreased (0.03984 --> 0.03235), Acc: (0.97137 --> 0.97392), F1: (0.97137 --> 0.97392).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 69 Train Avg loss: 0.03293, Acc: 0.97392, F1: 0.97392#####> Valid Avg loss: 3.61639, Acc:0.41593, F1: 0.41593
====> Epoch: 70 Train Avg loss: 0.02872, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 3.26516, Acc:0.41593, F1: 0.41593
===> Epoch: 70: Training loss decreased (0.03235 --> 0.02872), Acc: (0.97392 --> 0.97901), F1: (0.97392 --> 0.97901).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 71 Train Avg loss: 0.03114, Acc: 0.97201, F1: 0.97201#####> Valid Avg loss: 3.58568, Acc:0.42478, F1: 0.42478
====> Epoch: 72 Train Avg loss: 0.02442, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 3.50808, Acc:0.41150, F1: 0.41150
===> Epoch: 72: Training loss decreased (0.02872 --> 0.02442), Acc: (0.97901 --> 0.97583), F1: (0.97901 --> 0.97583).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 73 Train Avg loss: 0.02465, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 3.22182, Acc:0.38938, F1: 0.38938
====> Epoch: 74 Train Avg loss: 0.03142, Acc: 0.97265, F1: 0.97265#####> Valid Avg loss: 3.99026, Acc:0.46018, F1: 0.46018
====> Epoch: 75 Train Avg loss: 0.02476, Acc: 0.97519, F1: 0.97519#####> Valid Avg loss: 3.57044, Acc:0.41593, F1: 0.41593
====> Epoch: 76 Train Avg loss: 0.02164, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 3.54382, Acc:0.41150, F1: 0.41150
===> Epoch: 76: Training loss decreased (0.02442 --> 0.02164), Acc: (0.97583 --> 0.97583), F1: (0.97583 --> 0.97583).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 77 Train Avg loss: 0.01885, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 3.66668, Acc:0.40708, F1: 0.40708
===> Epoch: 77: Training loss decreased (0.02164 --> 0.01885), Acc: (0.97583 --> 0.97901), F1: (0.97583 --> 0.97901).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 78 Train Avg loss: 0.02327, Acc: 0.97710, F1: 0.97710#####> Valid Avg loss: 3.50790, Acc:0.40708, F1: 0.40708
====> Epoch: 79 Train Avg loss: 0.01903, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.86610, Acc:0.39823, F1: 0.39823
====> Epoch: 80 Train Avg loss: 0.01986, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 3.65333, Acc:0.41150, F1: 0.41150
====> Epoch: 81 Train Avg loss: 0.01770, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.64423, Acc:0.39823, F1: 0.39823
===> Epoch: 81: Training loss decreased (0.01885 --> 0.01770), Acc: (0.97901 --> 0.97964), F1: (0.97901 --> 0.97964).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 82 Train Avg loss: 0.01745, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 3.78954, Acc:0.40708, F1: 0.40708
===> Epoch: 82: Training loss decreased (0.01770 --> 0.01745), Acc: (0.97964 --> 0.97901), F1: (0.97964 --> 0.97901).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 83 Train Avg loss: 0.01440, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.63395, Acc:0.41150, F1: 0.41150
===> Epoch: 83: Training loss decreased (0.01745 --> 0.01440), Acc: (0.97901 --> 0.98219), F1: (0.97901 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 84 Train Avg loss: 0.01544, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.71463, Acc:0.41593, F1: 0.41593
====> Epoch: 85 Train Avg loss: 0.01748, Acc: 0.97837, F1: 0.97837#####> Valid Avg loss: 3.70804, Acc:0.41593, F1: 0.41593
====> Epoch: 86 Train Avg loss: 0.01587, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.78259, Acc:0.43363, F1: 0.43363
====> Epoch: 87 Train Avg loss: 0.01360, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.81169, Acc:0.41593, F1: 0.41593
===> Epoch: 87: Training loss decreased (0.01440 --> 0.01360), Acc: (0.98219 --> 0.98028), F1: (0.98219 --> 0.98028).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 88 Train Avg loss: 0.01640, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.50351, Acc:0.41150, F1: 0.41150
====> Epoch: 89 Train Avg loss: 0.01603, Acc: 0.97837, F1: 0.97837#####> Valid Avg loss: 3.83411, Acc:0.42035, F1: 0.42035
====> Epoch: 90 Train Avg loss: 0.01447, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.81732, Acc:0.41593, F1: 0.41593
====> Epoch: 91 Train Avg loss: 0.01336, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.67161, Acc:0.41593, F1: 0.41593
===> Epoch: 91: Training loss decreased (0.01360 --> 0.01336), Acc: (0.98028 --> 0.97964), F1: (0.98028 --> 0.97964).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 92 Train Avg loss: 0.01501, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 3.82321, Acc:0.41593, F1: 0.41593
====> Epoch: 93 Train Avg loss: 0.01229, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.91524, Acc:0.41593, F1: 0.41593
===> Epoch: 93: Training loss decreased (0.01336 --> 0.01229), Acc: (0.97964 --> 0.98219), F1: (0.97964 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 94 Train Avg loss: 0.01251, Acc: 0.98410, F1: 0.98410#####> Valid Avg loss: 3.84918, Acc:0.41593, F1: 0.41593
====> Epoch: 95 Train Avg loss: 0.01250, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 3.82310, Acc:0.41593, F1: 0.41593
====> Epoch: 96 Train Avg loss: 0.01315, Acc: 0.98282, F1: 0.98282#####> Valid Avg loss: 3.87216, Acc:0.41593, F1: 0.41593
====> Epoch: 97 Train Avg loss: 0.01363, Acc: 0.98282, F1: 0.98282#####> Valid Avg loss: 3.68937, Acc:0.41593, F1: 0.41593
====> Epoch: 98 Train Avg loss: 0.01222, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 3.72741, Acc:0.41593, F1: 0.41593
===> Epoch: 98: Training loss decreased (0.01229 --> 0.01222), Acc: (0.98219 --> 0.98346), F1: (0.98219 --> 0.98346).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 99 Train Avg loss: 0.01145, Acc: 0.98728, F1: 0.98728#####> Valid Avg loss: 3.80915, Acc:0.41593, F1: 0.41593
===> Epoch: 99: Training loss decreased (0.01222 --> 0.01145), Acc: (0.98346 --> 0.98728), F1: (0.98346 --> 0.98728).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 100 Train Avg loss: 0.67207, Acc: 0.51336, F1: 0.51336#####> Valid Avg loss: 0.85380, Acc:0.47788, F1: 0.47788
====> Epoch: 101 Train Avg loss: 0.56301, Acc: 0.54707, F1: 0.54707#####> Valid Avg loss: 0.87085, Acc:0.47345, F1: 0.47345
====> Epoch: 102 Train Avg loss: 0.53771, Acc: 0.57125, F1: 0.57125#####> Valid Avg loss: 0.80885, Acc:0.47345, F1: 0.47345
====> Epoch: 103 Train Avg loss: 0.52615, Acc: 0.58651, F1: 0.58651#####> Valid Avg loss: 0.81152, Acc:0.47345, F1: 0.47345
====> Epoch: 104 Train Avg loss: 0.51942, Acc: 0.58015, F1: 0.58015#####> Valid Avg loss: 0.87455, Acc:0.38496, F1: 0.38496
====> Epoch: 105 Train Avg loss: 0.50300, Acc: 0.59860, F1: 0.59860#####> Valid Avg loss: 0.85795, Acc:0.47345, F1: 0.47345
====> Epoch: 106 Train Avg loss: 0.50569, Acc: 0.60305, F1: 0.60305#####> Valid Avg loss: 0.88660, Acc:0.44248, F1: 0.44248
====> Epoch: 107 Train Avg loss: 0.49125, Acc: 0.60878, F1: 0.60878#####> Valid Avg loss: 0.86224, Acc:0.46903, F1: 0.46903
====> Epoch: 108 Train Avg loss: 0.47242, Acc: 0.62214, F1: 0.62214#####> Valid Avg loss: 0.89770, Acc:0.45133, F1: 0.45133
====> Epoch: 109 Train Avg loss: 0.47247, Acc: 0.61896, F1: 0.61896#####> Valid Avg loss: 1.00839, Acc:0.48230, F1: 0.48230

####> Epoch: 109: validation acc increase (0.96858 --> 1.00839), Acc: (0.47788 --> 0.48230), F1: (0.47788 --> 0.48230).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 110 Train Avg loss: 0.45138, Acc: 0.63613, F1: 0.63613#####> Valid Avg loss: 1.09320, Acc:0.46460, F1: 0.46460
====> Epoch: 111 Train Avg loss: 0.43745, Acc: 0.62341, F1: 0.62341#####> Valid Avg loss: 0.96656, Acc:0.47345, F1: 0.47345
====> Epoch: 112 Train Avg loss: 0.41742, Acc: 0.67430, F1: 0.67430#####> Valid Avg loss: 1.18054, Acc:0.46903, F1: 0.46903
====> Epoch: 113 Train Avg loss: 0.41035, Acc: 0.66730, F1: 0.66730#####> Valid Avg loss: 1.08553, Acc:0.46018, F1: 0.46018
====> Epoch: 114 Train Avg loss: 0.39413, Acc: 0.67048, F1: 0.67048#####> Valid Avg loss: 1.12699, Acc:0.46018, F1: 0.46018
====> Epoch: 115 Train Avg loss: 0.39515, Acc: 0.67366, F1: 0.67366#####> Valid Avg loss: 1.16812, Acc:0.42035, F1: 0.42035
====> Epoch: 116 Train Avg loss: 0.37439, Acc: 0.69529, F1: 0.69529#####> Valid Avg loss: 1.22214, Acc:0.45575, F1: 0.45575
====> Epoch: 117 Train Avg loss: 0.36264, Acc: 0.70865, F1: 0.70865#####> Valid Avg loss: 1.15266, Acc:0.45133, F1: 0.45133
====> Epoch: 118 Train Avg loss: 0.35912, Acc: 0.71501, F1: 0.71501#####> Valid Avg loss: 1.08250, Acc:0.42920, F1: 0.42920
====> Epoch: 119 Train Avg loss: 0.35233, Acc: 0.71819, F1: 0.71819#####> Valid Avg loss: 1.29065, Acc:0.43363, F1: 0.43363
====> Epoch: 120 Train Avg loss: 0.32922, Acc: 0.74555, F1: 0.74555#####> Valid Avg loss: 1.14312, Acc:0.40708, F1: 0.40708
====> Epoch: 121 Train Avg loss: 0.30480, Acc: 0.75191, F1: 0.75191#####> Valid Avg loss: 1.23620, Acc:0.42035, F1: 0.42035
====> Epoch: 122 Train Avg loss: 0.30557, Acc: 0.75891, F1: 0.75891#####> Valid Avg loss: 1.47394, Acc:0.42478, F1: 0.42478
====> Epoch: 123 Train Avg loss: 0.29979, Acc: 0.74873, F1: 0.74873#####> Valid Avg loss: 1.45318, Acc:0.39823, F1: 0.39823
====> Epoch: 124 Train Avg loss: 0.28194, Acc: 0.77099, F1: 0.77099#####> Valid Avg loss: 1.51177, Acc:0.41593, F1: 0.41593
====> Epoch: 125 Train Avg loss: 0.28048, Acc: 0.77863, F1: 0.77863#####> Valid Avg loss: 1.88301, Acc:0.45133, F1: 0.45133
====> Epoch: 126 Train Avg loss: 0.26146, Acc: 0.78690, F1: 0.78690#####> Valid Avg loss: 1.68924, Acc:0.42478, F1: 0.42478
====> Epoch: 127 Train Avg loss: 0.25077, Acc: 0.80216, F1: 0.80216#####> Valid Avg loss: 1.59509, Acc:0.44690, F1: 0.44690
====> Epoch: 128 Train Avg loss: 0.21531, Acc: 0.82379, F1: 0.82379#####> Valid Avg loss: 1.58609, Acc:0.40265, F1: 0.40265
====> Epoch: 129 Train Avg loss: 0.22016, Acc: 0.82952, F1: 0.82952#####> Valid Avg loss: 1.67671, Acc:0.42035, F1: 0.42035
====> Epoch: 130 Train Avg loss: 0.20171, Acc: 0.83461, F1: 0.83461#####> Valid Avg loss: 1.86258, Acc:0.41150, F1: 0.41150
====> Epoch: 131 Train Avg loss: 0.21266, Acc: 0.83715, F1: 0.83715#####> Valid Avg loss: 1.54656, Acc:0.39823, F1: 0.39823
====> Epoch: 132 Train Avg loss: 0.19039, Acc: 0.85623, F1: 0.85623#####> Valid Avg loss: 1.96025, Acc:0.39381, F1: 0.39381
====> Epoch: 133 Train Avg loss: 0.21591, Acc: 0.82634, F1: 0.82634#####> Valid Avg loss: 1.82826, Acc:0.42478, F1: 0.42478
====> Epoch: 134 Train Avg loss: 0.18814, Acc: 0.84415, F1: 0.84415#####> Valid Avg loss: 1.94252, Acc:0.39381, F1: 0.39381
====> Epoch: 135 Train Avg loss: 0.17721, Acc: 0.85751, F1: 0.85751#####> Valid Avg loss: 1.93444, Acc:0.45575, F1: 0.45575
====> Epoch: 136 Train Avg loss: 0.16779, Acc: 0.88104, F1: 0.88104#####> Valid Avg loss: 2.32561, Acc:0.41593, F1: 0.41593
====> Epoch: 137 Train Avg loss: 0.16900, Acc: 0.86323, F1: 0.86323#####> Valid Avg loss: 2.01080, Acc:0.41593, F1: 0.41593
====> Epoch: 138 Train Avg loss: 0.15225, Acc: 0.88359, F1: 0.88359#####> Valid Avg loss: 2.01743, Acc:0.41593, F1: 0.41593
====> Epoch: 139 Train Avg loss: 0.16354, Acc: 0.87023, F1: 0.87023#####> Valid Avg loss: 2.14044, Acc:0.42478, F1: 0.42478
====> Epoch: 140 Train Avg loss: 0.16066, Acc: 0.87850, F1: 0.87850#####> Valid Avg loss: 1.96743, Acc:0.39823, F1: 0.39823
====> Epoch: 141 Train Avg loss: 0.13995, Acc: 0.89313, F1: 0.89313#####> Valid Avg loss: 2.06142, Acc:0.42920, F1: 0.42920
====> Epoch: 142 Train Avg loss: 0.13083, Acc: 0.89567, F1: 0.89567#####> Valid Avg loss: 2.12876, Acc:0.44248, F1: 0.44248
====> Epoch: 143 Train Avg loss: 0.15106, Acc: 0.88677, F1: 0.88677#####> Valid Avg loss: 1.99170, Acc:0.38053, F1: 0.38053
====> Epoch: 144 Train Avg loss: 0.16549, Acc: 0.87405, F1: 0.87405#####> Valid Avg loss: 1.91468, Acc:0.41150, F1: 0.41150
====> Epoch: 145 Train Avg loss: 0.12740, Acc: 0.91094, F1: 0.91094#####> Valid Avg loss: 2.27242, Acc:0.40265, F1: 0.40265
====> Epoch: 146 Train Avg loss: 0.13632, Acc: 0.90776, F1: 0.90776#####> Valid Avg loss: 1.96240, Acc:0.41593, F1: 0.41593
====> Epoch: 147 Train Avg loss: 0.13315, Acc: 0.90267, F1: 0.90267#####> Valid Avg loss: 2.02637, Acc:0.40708, F1: 0.40708
====> Epoch: 148 Train Avg loss: 0.12372, Acc: 0.91158, F1: 0.91158#####> Valid Avg loss: 2.08394, Acc:0.42920, F1: 0.42920
====> Epoch: 149 Train Avg loss: 0.10960, Acc: 0.91603, F1: 0.91603#####> Valid Avg loss: 2.42206, Acc:0.42920, F1: 0.42920
====> Epoch: 150 Train Avg loss: 0.12629, Acc: 0.90522, F1: 0.90522#####> Valid Avg loss: 2.47106, Acc:0.41593, F1: 0.41593
====> Epoch: 151 Train Avg loss: 0.10344, Acc: 0.92366, F1: 0.92366#####> Valid Avg loss: 2.42760, Acc:0.40708, F1: 0.40708
====> Epoch: 152 Train Avg loss: 0.09783, Acc: 0.92812, F1: 0.92812#####> Valid Avg loss: 2.44293, Acc:0.44248, F1: 0.44248
====> Epoch: 153 Train Avg loss: 0.09917, Acc: 0.93321, F1: 0.93321#####> Valid Avg loss: 2.30339, Acc:0.42478, F1: 0.42478
====> Epoch: 154 Train Avg loss: 0.07888, Acc: 0.94784, F1: 0.94784#####> Valid Avg loss: 2.35845, Acc:0.40265, F1: 0.40265
====> Epoch: 155 Train Avg loss: 0.14616, Acc: 0.89695, F1: 0.89695#####> Valid Avg loss: 2.02535, Acc:0.42920, F1: 0.42920
====> Epoch: 156 Train Avg loss: 0.09193, Acc: 0.93448, F1: 0.93448#####> Valid Avg loss: 2.17280, Acc:0.40708, F1: 0.40708
====> Epoch: 157 Train Avg loss: 0.12009, Acc: 0.91412, F1: 0.91412#####> Valid Avg loss: 2.13315, Acc:0.45133, F1: 0.45133
====> Epoch: 158 Train Avg loss: 0.08821, Acc: 0.93893, F1: 0.93893#####> Valid Avg loss: 2.16061, Acc:0.41150, F1: 0.41150
====> Epoch: 159 Train Avg loss: 0.06332, Acc: 0.95611, F1: 0.95611#####> Valid Avg loss: 2.69744, Acc:0.40708, F1: 0.40708
====> Epoch: 160 Train Avg loss: 0.10934, Acc: 0.91921, F1: 0.91921#####> Valid Avg loss: 2.34861, Acc:0.37611, F1: 0.37611
====> Epoch: 161 Train Avg loss: 0.09246, Acc: 0.93830, F1: 0.93830#####> Valid Avg loss: 2.38658, Acc:0.40708, F1: 0.40708
====> Epoch: 162 Train Avg loss: 0.07493, Acc: 0.94148, F1: 0.94148#####> Valid Avg loss: 1.95507, Acc:0.37168, F1: 0.37168
====> Epoch: 163 Train Avg loss: 0.10096, Acc: 0.92684, F1: 0.92684#####> Valid Avg loss: 2.25193, Acc:0.42035, F1: 0.42035
====> Epoch: 164 Train Avg loss: 0.05095, Acc: 0.95865, F1: 0.95865#####> Valid Avg loss: 2.53209, Acc:0.36283, F1: 0.36283
====> Epoch: 165 Train Avg loss: 0.09437, Acc: 0.92112, F1: 0.92112#####> Valid Avg loss: 2.66621, Acc:0.42035, F1: 0.42035
====> Epoch: 166 Train Avg loss: 0.06956, Acc: 0.95038, F1: 0.95038#####> Valid Avg loss: 2.86265, Acc:0.44690, F1: 0.44690
====> Epoch: 167 Train Avg loss: 0.06550, Acc: 0.95038, F1: 0.95038#####> Valid Avg loss: 2.89800, Acc:0.44248, F1: 0.44248
====> Epoch: 168 Train Avg loss: 0.07570, Acc: 0.95102, F1: 0.95102#####> Valid Avg loss: 2.52112, Acc:0.37611, F1: 0.37611
====> Epoch: 169 Train Avg loss: 0.07609, Acc: 0.94020, F1: 0.94020#####> Valid Avg loss: 2.32005, Acc:0.42478, F1: 0.42478
====> Epoch: 170 Train Avg loss: 0.07477, Acc: 0.94338, F1: 0.94338#####> Valid Avg loss: 2.20811, Acc:0.39823, F1: 0.39823
====> Epoch: 171 Train Avg loss: 0.08888, Acc: 0.93766, F1: 0.93766#####> Valid Avg loss: 2.56927, Acc:0.44248, F1: 0.44248
====> Epoch: 172 Train Avg loss: 0.07261, Acc: 0.94402, F1: 0.94402#####> Valid Avg loss: 2.32233, Acc:0.38938, F1: 0.38938
====> Epoch: 173 Train Avg loss: 0.05406, Acc: 0.95992, F1: 0.95992#####> Valid Avg loss: 2.39949, Acc:0.34513, F1: 0.34513
====> Epoch: 174 Train Avg loss: 0.05640, Acc: 0.95102, F1: 0.95102#####> Valid Avg loss: 2.55041, Acc:0.37168, F1: 0.37168
====> Epoch: 175 Train Avg loss: 0.07886, Acc: 0.94529, F1: 0.94529#####> Valid Avg loss: 2.90705, Acc:0.44248, F1: 0.44248
====> Epoch: 176 Train Avg loss: 0.04036, Acc: 0.96692, F1: 0.96692#####> Valid Avg loss: 2.85322, Acc:0.38496, F1: 0.38496
====> Epoch: 177 Train Avg loss: 0.04254, Acc: 0.96565, F1: 0.96565#####> Valid Avg loss: 2.96852, Acc:0.42920, F1: 0.42920
====> Epoch: 178 Train Avg loss: 0.06890, Acc: 0.94275, F1: 0.94275#####> Valid Avg loss: 2.86419, Acc:0.40708, F1: 0.40708
====> Epoch: 179 Train Avg loss: 0.08470, Acc: 0.93702, F1: 0.93702#####> Valid Avg loss: 2.51784, Acc:0.40265, F1: 0.40265
====> Epoch: 180 Train Avg loss: 0.03891, Acc: 0.96628, F1: 0.96628#####> Valid Avg loss: 2.65008, Acc:0.42478, F1: 0.42478
====> Epoch: 181 Train Avg loss: 0.06603, Acc: 0.95038, F1: 0.95038#####> Valid Avg loss: 2.93227, Acc:0.39381, F1: 0.39381
====> Epoch: 182 Train Avg loss: 0.04070, Acc: 0.96501, F1: 0.96501#####> Valid Avg loss: 2.90549, Acc:0.40708, F1: 0.40708
====> Epoch: 183 Train Avg loss: 0.03998, Acc: 0.97201, F1: 0.97201#####> Valid Avg loss: 2.74838, Acc:0.39381, F1: 0.39381
====> Epoch: 184 Train Avg loss: 0.04948, Acc: 0.96374, F1: 0.96374#####> Valid Avg loss: 3.04816, Acc:0.41593, F1: 0.41593
====> Epoch: 185 Train Avg loss: 0.06889, Acc: 0.94720, F1: 0.94720#####> Valid Avg loss: 2.89718, Acc:0.38053, F1: 0.38053
====> Epoch: 186 Train Avg loss: 0.04056, Acc: 0.96883, F1: 0.96883#####> Valid Avg loss: 2.69081, Acc:0.39381, F1: 0.39381
====> Epoch: 187 Train Avg loss: 0.04184, Acc: 0.97137, F1: 0.97137#####> Valid Avg loss: 2.83038, Acc:0.39381, F1: 0.39381
====> Epoch: 188 Train Avg loss: 0.08281, Acc: 0.94402, F1: 0.94402#####> Valid Avg loss: 2.41511, Acc:0.38496, F1: 0.38496
====> Epoch: 189 Train Avg loss: 0.03267, Acc: 0.97392, F1: 0.97392#####> Valid Avg loss: 2.46265, Acc:0.38053, F1: 0.38053
====> Epoch: 190 Train Avg loss: 0.05002, Acc: 0.95738, F1: 0.95738#####> Valid Avg loss: 2.44133, Acc:0.40265, F1: 0.40265
====> Epoch: 191 Train Avg loss: 0.02762, Acc: 0.97837, F1: 0.97837#####> Valid Avg loss: 3.16572, Acc:0.42035, F1: 0.42035
====> Epoch: 192 Train Avg loss: 0.03000, Acc: 0.97519, F1: 0.97519#####> Valid Avg loss: 2.66049, Acc:0.41150, F1: 0.41150
====> Epoch: 193 Train Avg loss: 0.05758, Acc: 0.95420, F1: 0.95420#####> Valid Avg loss: 2.57408, Acc:0.37611, F1: 0.37611
====> Epoch: 194 Train Avg loss: 0.03201, Acc: 0.97010, F1: 0.97010#####> Valid Avg loss: 3.10025, Acc:0.41150, F1: 0.41150
====> Epoch: 195 Train Avg loss: 0.03290, Acc: 0.96947, F1: 0.96947#####> Valid Avg loss: 2.98888, Acc:0.40265, F1: 0.40265
====> Epoch: 196 Train Avg loss: 0.03916, Acc: 0.96756, F1: 0.96756#####> Valid Avg loss: 2.98377, Acc:0.39381, F1: 0.39381
====> Epoch: 197 Train Avg loss: 0.04051, Acc: 0.96628, F1: 0.96628#####> Valid Avg loss: 2.81867, Acc:0.39381, F1: 0.39381
====> Epoch: 198 Train Avg loss: 0.02826, Acc: 0.97774, F1: 0.97774#####> Valid Avg loss: 2.67472, Acc:0.40265, F1: 0.40265
====> Epoch: 199 Train Avg loss: 0.03423, Acc: 0.97328, F1: 0.97328#####> Valid Avg loss: 3.08725, Acc:0.41593, F1: 0.41593
====> Epoch: 200 Train Avg loss: 0.03626, Acc: 0.97392, F1: 0.97392#####> Valid Avg loss: 2.62050, Acc:0.41150, F1: 0.41150
====> Epoch: 201 Train Avg loss: 0.03719, Acc: 0.96692, F1: 0.96692#####> Valid Avg loss: 3.00507, Acc:0.43363, F1: 0.43363
====> Epoch: 202 Train Avg loss: 0.03614, Acc: 0.96819, F1: 0.96819#####> Valid Avg loss: 2.72350, Acc:0.40708, F1: 0.40708
====> Epoch: 203 Train Avg loss: 0.02534, Acc: 0.97455, F1: 0.97455#####> Valid Avg loss: 3.15873, Acc:0.41593, F1: 0.41593
====> Epoch: 204 Train Avg loss: 0.04202, Acc: 0.96501, F1: 0.96501#####> Valid Avg loss: 2.63157, Acc:0.40265, F1: 0.40265
====> Epoch: 205 Train Avg loss: 0.01954, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.89285, Acc:0.40708, F1: 0.40708
====> Epoch: 206 Train Avg loss: 0.03154, Acc: 0.97328, F1: 0.97328#####> Valid Avg loss: 2.70162, Acc:0.44248, F1: 0.44248
====> Epoch: 207 Train Avg loss: 0.03238, Acc: 0.96947, F1: 0.96947#####> Valid Avg loss: 3.14239, Acc:0.38496, F1: 0.38496
====> Epoch: 208 Train Avg loss: 0.04015, Acc: 0.96374, F1: 0.96374#####> Valid Avg loss: 2.73104, Acc:0.39823, F1: 0.39823
====> Epoch: 209 Train Avg loss: 0.01962, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 2.87479, Acc:0.39381, F1: 0.39381
====> Epoch: 210 Train Avg loss: 0.03826, Acc: 0.96628, F1: 0.96628#####> Valid Avg loss: 2.99403, Acc:0.40708, F1: 0.40708
====> Epoch: 211 Train Avg loss: 0.02469, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 2.81687, Acc:0.40265, F1: 0.40265
====> Epoch: 212 Train Avg loss: 0.02194, Acc: 0.97774, F1: 0.97774#####> Valid Avg loss: 2.94350, Acc:0.40708, F1: 0.40708
====> Epoch: 213 Train Avg loss: 0.01866, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.96479, Acc:0.42035, F1: 0.42035
====> Epoch: 214 Train Avg loss: 0.01812, Acc: 0.97710, F1: 0.97710#####> Valid Avg loss: 2.96963, Acc:0.40265, F1: 0.40265
====> Epoch: 215 Train Avg loss: 0.03220, Acc: 0.97201, F1: 0.97201#####> Valid Avg loss: 2.86344, Acc:0.40265, F1: 0.40265
====> Epoch: 216 Train Avg loss: 0.02567, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 2.86293, Acc:0.42478, F1: 0.42478
====> Epoch: 217 Train Avg loss: 0.02107, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 2.91302, Acc:0.41593, F1: 0.41593
====> Epoch: 218 Train Avg loss: 0.01813, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.86004, Acc:0.41593, F1: 0.41593
====> Epoch: 219 Train Avg loss: 0.02385, Acc: 0.97201, F1: 0.97201#####> Valid Avg loss: 2.63667, Acc:0.38053, F1: 0.38053
====> Epoch: 220 Train Avg loss: 0.02419, Acc: 0.97455, F1: 0.97455#####> Valid Avg loss: 3.12152, Acc:0.39823, F1: 0.39823
====> Epoch: 221 Train Avg loss: 0.01839, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 3.07032, Acc:0.37611, F1: 0.37611
====> Epoch: 222 Train Avg loss: 0.02080, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.04973, Acc:0.39823, F1: 0.39823
====> Epoch: 223 Train Avg loss: 0.01694, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.01827, Acc:0.41593, F1: 0.41593
====> Epoch: 224 Train Avg loss: 0.01575, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.06373, Acc:0.39381, F1: 0.39381
====> Epoch: 225 Train Avg loss: 0.01759, Acc: 0.97837, F1: 0.97837#####> Valid Avg loss: 3.01190, Acc:0.38496, F1: 0.38496
====> Epoch: 226 Train Avg loss: 0.01825, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.02959, Acc:0.36283, F1: 0.36283
====> Epoch: 227 Train Avg loss: 0.02380, Acc: 0.97201, F1: 0.97201#####> Valid Avg loss: 2.96446, Acc:0.39381, F1: 0.39381
====> Epoch: 228 Train Avg loss: 0.01530, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.13844, Acc:0.40265, F1: 0.40265
====> Epoch: 229 Train Avg loss: 0.01529, Acc: 0.97837, F1: 0.97837#####> Valid Avg loss: 3.20052, Acc:0.40265, F1: 0.40265
====> Epoch: 230 Train Avg loss: 0.01716, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 3.18430, Acc:0.38053, F1: 0.38053
====> Epoch: 231 Train Avg loss: 0.01565, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 3.36304, Acc:0.41593, F1: 0.41593
====> Epoch: 232 Train Avg loss: 0.01444, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 3.06389, Acc:0.40708, F1: 0.40708
====> Epoch: 233 Train Avg loss: 0.01494, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 3.17288, Acc:0.38496, F1: 0.38496
====> Epoch: 234 Train Avg loss: 0.01498, Acc: 0.97774, F1: 0.97774#####> Valid Avg loss: 3.03498, Acc:0.38496, F1: 0.38496
====> Epoch: 235 Train Avg loss: 0.01406, Acc: 0.98282, F1: 0.98282#####> Valid Avg loss: 3.39741, Acc:0.40265, F1: 0.40265
====> Epoch: 236 Train Avg loss: 0.02053, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 3.38171, Acc:0.41150, F1: 0.41150
====> Epoch: 237 Train Avg loss: 0.01367, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.29902, Acc:0.40265, F1: 0.40265
====> Epoch: 238 Train Avg loss: 0.01552, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 3.21932, Acc:0.40708, F1: 0.40708
====> Epoch: 239 Train Avg loss: 0.01234, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.04144, Acc:0.38938, F1: 0.38938
====> Epoch: 240 Train Avg loss: 0.01278, Acc: 0.98410, F1: 0.98410#####> Valid Avg loss: 3.30686, Acc:0.40265, F1: 0.40265
====> Epoch: 241 Train Avg loss: 0.01392, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 3.25078, Acc:0.39823, F1: 0.39823
====> Epoch: 242 Train Avg loss: 0.01466, Acc: 0.97710, F1: 0.97710#####> Valid Avg loss: 3.34095, Acc:0.40708, F1: 0.40708
====> Epoch: 243 Train Avg loss: 0.01486, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.45687, Acc:0.41150, F1: 0.41150
====> Epoch: 244 Train Avg loss: 0.01351, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.42754, Acc:0.40265, F1: 0.40265
====> Epoch: 245 Train Avg loss: 0.01169, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.39072, Acc:0.38938, F1: 0.38938
====> Epoch: 246 Train Avg loss: 0.01234, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 3.42098, Acc:0.39823, F1: 0.39823
====> Epoch: 247 Train Avg loss: 0.01301, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 3.35905, Acc:0.38496, F1: 0.38496
====> Epoch: 248 Train Avg loss: 0.01296, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.18204, Acc:0.38496, F1: 0.38496
====> Epoch: 249 Train Avg loss: 0.01227, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.58452, Acc:0.39823, F1: 0.39823
====> Epoch: 250 Train Avg loss: 0.01399, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 3.36299, Acc:0.40708, F1: 0.40708
====> Epoch: 251 Train Avg loss: 0.01297, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 3.41220, Acc:0.41593, F1: 0.41593
====> Epoch: 252 Train Avg loss: 0.01242, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 3.37660, Acc:0.39823, F1: 0.39823
====> Epoch: 253 Train Avg loss: 0.01125, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 3.06974, Acc:0.39381, F1: 0.39381
===> Epoch: 253: Training loss decreased (0.01145 --> 0.01125), Acc: (0.98728 --> 0.98092), F1: (0.98728 --> 0.98092).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 254 Train Avg loss: 0.01123, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 3.39645, Acc:0.41150, F1: 0.41150
===> Epoch: 254: Training loss decreased (0.01125 --> 0.01123), Acc: (0.98092 --> 0.98155), F1: (0.98092 --> 0.98155).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 255 Train Avg loss: 0.01111, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 3.28960, Acc:0.39381, F1: 0.39381
===> Epoch: 255: Training loss decreased (0.01123 --> 0.01111), Acc: (0.98155 --> 0.97901), F1: (0.98155 --> 0.97901).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 256 Train Avg loss: 0.01158, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 3.29886, Acc:0.40265, F1: 0.40265
====> Epoch: 257 Train Avg loss: 0.01415, Acc: 0.97774, F1: 0.97774#####> Valid Avg loss: 3.30964, Acc:0.40708, F1: 0.40708
====> Epoch: 258 Train Avg loss: 0.01087, Acc: 0.98410, F1: 0.98410#####> Valid Avg loss: 3.24538, Acc:0.40265, F1: 0.40265
===> Epoch: 258: Training loss decreased (0.01111 --> 0.01087), Acc: (0.97901 --> 0.98410), F1: (0.97901 --> 0.98410).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 259 Train Avg loss: 0.01094, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.39459, Acc:0.39823, F1: 0.39823
====> Epoch: 260 Train Avg loss: 0.01065, Acc: 0.98410, F1: 0.98410#####> Valid Avg loss: 3.55168, Acc:0.39823, F1: 0.39823
===> Epoch: 260: Training loss decreased (0.01087 --> 0.01065), Acc: (0.98410 --> 0.98410), F1: (0.98410 --> 0.98410).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 261 Train Avg loss: 0.01121, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 3.53272, Acc:0.39823, F1: 0.39823
====> Epoch: 262 Train Avg loss: 0.01076, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.36093, Acc:0.39823, F1: 0.39823
====> Epoch: 263 Train Avg loss: 0.01167, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 3.48586, Acc:0.38496, F1: 0.38496
====> Epoch: 264 Train Avg loss: 0.01048, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 3.38987, Acc:0.39823, F1: 0.39823
===> Epoch: 264: Training loss decreased (0.01065 --> 0.01048), Acc: (0.98410 --> 0.98155), F1: (0.98410 --> 0.98155).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 265 Train Avg loss: 0.01043, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 3.37111, Acc:0.39823, F1: 0.39823
===> Epoch: 265: Training loss decreased (0.01048 --> 0.01043), Acc: (0.98155 --> 0.98092), F1: (0.98155 --> 0.98092).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 266 Train Avg loss: 0.01052, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 3.45700, Acc:0.41150, F1: 0.41150
====> Epoch: 267 Train Avg loss: 0.01057, Acc: 0.98410, F1: 0.98410#####> Valid Avg loss: 3.46616, Acc:0.39823, F1: 0.39823
====> Epoch: 268 Train Avg loss: 0.01051, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.25575, Acc:0.40708, F1: 0.40708
====> Epoch: 269 Train Avg loss: 0.01048, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.46505, Acc:0.41150, F1: 0.41150
====> Epoch: 270 Train Avg loss: 0.01167, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 3.50464, Acc:0.39381, F1: 0.39381
====> Epoch: 271 Train Avg loss: 0.01127, Acc: 0.98282, F1: 0.98282#####> Valid Avg loss: 3.58783, Acc:0.40265, F1: 0.40265
====> Epoch: 272 Train Avg loss: 0.00974, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 3.45055, Acc:0.39823, F1: 0.39823
===> Epoch: 272: Training loss decreased (0.01043 --> 0.00974), Acc: (0.98092 --> 0.98346), F1: (0.98092 --> 0.98346).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 273 Train Avg loss: 0.01015, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.50071, Acc:0.40265, F1: 0.40265
====> Epoch: 274 Train Avg loss: 0.00997, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 3.42725, Acc:0.39381, F1: 0.39381
====> Epoch: 275 Train Avg loss: 0.00986, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 3.37036, Acc:0.39823, F1: 0.39823
====> Epoch: 276 Train Avg loss: 0.01018, Acc: 0.98410, F1: 0.98410#####> Valid Avg loss: 3.49647, Acc:0.39823, F1: 0.39823
====> Epoch: 277 Train Avg loss: 0.00986, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 3.47253, Acc:0.40708, F1: 0.40708
====> Epoch: 278 Train Avg loss: 0.01068, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 3.47052, Acc:0.39823, F1: 0.39823
====> Epoch: 279 Train Avg loss: 0.01029, Acc: 0.98601, F1: 0.98601#####> Valid Avg loss: 3.47827, Acc:0.39381, F1: 0.39381
====> Epoch: 280 Train Avg loss: 0.00995, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 3.55213, Acc:0.39823, F1: 0.39823
====> Epoch: 281 Train Avg loss: 0.00967, Acc: 0.98473, F1: 0.98473#####> Valid Avg loss: 3.63940, Acc:0.39823, F1: 0.39823
===> Epoch: 281: Training loss decreased (0.00974 --> 0.00967), Acc: (0.98346 --> 0.98473), F1: (0.98346 --> 0.98473).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 282 Train Avg loss: 0.00975, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.55389, Acc:0.39823, F1: 0.39823
====> Epoch: 283 Train Avg loss: 0.00986, Acc: 0.98282, F1: 0.98282#####> Valid Avg loss: 3.50217, Acc:0.39823, F1: 0.39823
====> Epoch: 284 Train Avg loss: 0.01061, Acc: 0.98282, F1: 0.98282#####> Valid Avg loss: 3.53783, Acc:0.40265, F1: 0.40265
====> Epoch: 285 Train Avg loss: 0.00960, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.53798, Acc:0.40265, F1: 0.40265
===> Epoch: 285: Training loss decreased (0.00967 --> 0.00960), Acc: (0.98473 --> 0.98219), F1: (0.98473 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 286 Train Avg loss: 0.00935, Acc: 0.98473, F1: 0.98473#####> Valid Avg loss: 3.49917, Acc:0.40265, F1: 0.40265
===> Epoch: 286: Training loss decreased (0.00960 --> 0.00935), Acc: (0.98219 --> 0.98473), F1: (0.98219 --> 0.98473).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 287 Train Avg loss: 0.00952, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 3.52989, Acc:0.40265, F1: 0.40265
====> Epoch: 288 Train Avg loss: 0.01022, Acc: 0.98410, F1: 0.98410#####> Valid Avg loss: 3.45239, Acc:0.40265, F1: 0.40265
====> Epoch: 289 Train Avg loss: 0.00957, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.61290, Acc:0.40265, F1: 0.40265
====> Epoch: 290 Train Avg loss: 0.00951, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.48947, Acc:0.40265, F1: 0.40265
====> Epoch: 291 Train Avg loss: 0.00950, Acc: 0.98537, F1: 0.98537#####> Valid Avg loss: 3.49506, Acc:0.40708, F1: 0.40708
====> Epoch: 292 Train Avg loss: 0.00930, Acc: 0.98728, F1: 0.98728#####> Valid Avg loss: 3.58621, Acc:0.40708, F1: 0.40708
===> Epoch: 292: Training loss decreased (0.00935 --> 0.00930), Acc: (0.98473 --> 0.98728), F1: (0.98473 --> 0.98728).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1585725058.893029.pth_5
====> Epoch: 293 Train Avg loss: 0.00933, Acc: 0.98601, F1: 0.98601#####> Valid Avg loss: 3.57771, Acc:0.40265, F1: 0.40265
====> Epoch: 294 Train Avg loss: 0.00947, Acc: 0.98473, F1: 0.98473#####> Valid Avg loss: 3.52374, Acc:0.40265, F1: 0.40265
====> Epoch: 295 Train Avg loss: 0.00948, Acc: 0.98664, F1: 0.98664#####> Valid Avg loss: 3.57496, Acc:0.40708, F1: 0.40708
====> Epoch: 296 Train Avg loss: 0.00948, Acc: 0.98537, F1: 0.98537#####> Valid Avg loss: 3.46176, Acc:0.40708, F1: 0.40708
====> Epoch: 297 Train Avg loss: 0.00941, Acc: 0.98791, F1: 0.98791#####> Valid Avg loss: 3.59327, Acc:0.40708, F1: 0.40708
====> Epoch: 298 Train Avg loss: 0.00948, Acc: 0.98855, F1: 0.98855#####> Valid Avg loss: 3.55265, Acc:0.40708, F1: 0.40708
====> Epoch: 299 Train Avg loss: 0.00945, Acc: 0.98728, F1: 0.98728#####> Valid Avg loss: 3.54674, Acc:0.40708, F1: 0.40708
====> Epoch: 300 Train Avg loss: 0.61444, Acc: 0.55471, F1: 0.55471#####> Valid Avg loss: 0.87946, Acc:0.41150, F1: 0.41150
====> Epoch: 301 Train Avg loss: 0.52096, Acc: 0.60178, F1: 0.60178#####> Valid Avg loss: 0.94095, Acc:0.46018, F1: 0.46018
====> Epoch: 302 Train Avg loss: 0.47631, Acc: 0.62659, F1: 0.62659#####> Valid Avg loss: 0.87327, Acc:0.46460, F1: 0.46460
====> Epoch: 303 Train Avg loss: 0.44843, Acc: 0.63804, F1: 0.63804#####> Valid Avg loss: 1.05125, Acc:0.39381, F1: 0.39381
====> Epoch: 304 Train Avg loss: 0.39805, Acc: 0.67239, F1: 0.67239#####> Valid Avg loss: 0.96440, Acc:0.42478, F1: 0.42478
====> Epoch: 305 Train Avg loss: 0.34980, Acc: 0.72519, F1: 0.72519#####> Valid Avg loss: 1.17900, Acc:0.42035, F1: 0.42035
====> Epoch: 306 Train Avg loss: 0.27118, Acc: 0.79771, F1: 0.79771#####> Valid Avg loss: 1.44897, Acc:0.32743, F1: 0.32743
====> Epoch: 307 Train Avg loss: 0.18047, Acc: 0.86323, F1: 0.86323#####> Valid Avg loss: 1.63190, Acc:0.38053, F1: 0.38053
====> Epoch: 308 Train Avg loss: 0.16916, Acc: 0.87532, F1: 0.87532#####> Valid Avg loss: 1.97027, Acc:0.42920, F1: 0.42920
====> Epoch: 309 Train Avg loss: 0.11943, Acc: 0.90776, F1: 0.90776#####> Valid Avg loss: 1.90964, Acc:0.37168, F1: 0.37168
====> Epoch: 310 Train Avg loss: 0.11780, Acc: 0.92239, F1: 0.92239#####> Valid Avg loss: 1.80614, Acc:0.40265, F1: 0.40265
====> Epoch: 311 Train Avg loss: 0.09682, Acc: 0.92812, F1: 0.92812#####> Valid Avg loss: 2.13368, Acc:0.40265, F1: 0.40265
====> Epoch: 312 Train Avg loss: 0.10484, Acc: 0.92112, F1: 0.92112#####> Valid Avg loss: 2.17727, Acc:0.36726, F1: 0.36726
====> Epoch: 313 Train Avg loss: 0.09679, Acc: 0.93003, F1: 0.93003#####> Valid Avg loss: 2.25937, Acc:0.40708, F1: 0.40708
====> Epoch: 314 Train Avg loss: 0.08345, Acc: 0.93639, F1: 0.93639#####> Valid Avg loss: 2.12686, Acc:0.39381, F1: 0.39381
====> Epoch: 315 Train Avg loss: 0.10195, Acc: 0.92048, F1: 0.92048#####> Valid Avg loss: 2.63846, Acc:0.40265, F1: 0.40265
====> Epoch: 316 Train Avg loss: 0.11134, Acc: 0.92048, F1: 0.92048#####> Valid Avg loss: 2.39654, Acc:0.44248, F1: 0.44248
====> Epoch: 317 Train Avg loss: 0.07211, Acc: 0.95038, F1: 0.95038#####> Valid Avg loss: 2.40979, Acc:0.39823, F1: 0.39823
====> Epoch: 318 Train Avg loss: 0.13438, Acc: 0.90204, F1: 0.90204#####> Valid Avg loss: 2.08724, Acc:0.35398, F1: 0.35398
====> Epoch: 319 Train Avg loss: 0.11100, Acc: 0.91603, F1: 0.91603#####> Valid Avg loss: 2.10257, Acc:0.42478, F1: 0.42478
====> Epoch: 320 Train Avg loss: 0.07903, Acc: 0.94084, F1: 0.94084#####> Valid Avg loss: 2.20185, Acc:0.38053, F1: 0.38053
====> Epoch: 321 Train Avg loss: 0.10070, Acc: 0.91794, F1: 0.91794#####> Valid Avg loss: 2.27017, Acc:0.39381, F1: 0.39381
====> Epoch: 322 Train Avg loss: 0.09550, Acc: 0.93066, F1: 0.93066#####> Valid Avg loss: 2.38993, Acc:0.40265, F1: 0.40265
====> Epoch: 323 Train Avg loss: 0.09453, Acc: 0.92621, F1: 0.92621#####> Valid Avg loss: 2.22778, Acc:0.36726, F1: 0.36726
====> Epoch: 324 Train Avg loss: 0.08378, Acc: 0.94275, F1: 0.94275#####> Valid Avg loss: 1.89228, Acc:0.41593, F1: 0.41593
====> Epoch: 325 Train Avg loss: 0.08474, Acc: 0.93702, F1: 0.93702#####> Valid Avg loss: 2.20411, Acc:0.38938, F1: 0.38938
====> Epoch: 326 Train Avg loss: 0.09134, Acc: 0.92875, F1: 0.92875#####> Valid Avg loss: 2.42524, Acc:0.40708, F1: 0.40708
====> Epoch: 327 Train Avg loss: 0.07642, Acc: 0.94466, F1: 0.94466#####> Valid Avg loss: 2.28534, Acc:0.43363, F1: 0.43363
====> Epoch: 328 Train Avg loss: 0.08911, Acc: 0.92939, F1: 0.92939#####> Valid Avg loss: 2.11782, Acc:0.39823, F1: 0.39823
====> Epoch: 329 Train Avg loss: 0.06278, Acc: 0.95229, F1: 0.95229#####> Valid Avg loss: 2.25620, Acc:0.38496, F1: 0.38496
====> Epoch: 330 Train Avg loss: 0.11118, Acc: 0.92366, F1: 0.92366#####> Valid Avg loss: 2.18334, Acc:0.40265, F1: 0.40265
====> Epoch: 331 Train Avg loss: 0.07970, Acc: 0.93893, F1: 0.93893#####> Valid Avg loss: 2.13793, Acc:0.40708, F1: 0.40708
====> Epoch: 332 Train Avg loss: 0.05553, Acc: 0.95483, F1: 0.95483#####> Valid Avg loss: 2.56341, Acc:0.40265, F1: 0.40265
====> Epoch: 333 Train Avg loss: 0.12468, Acc: 0.90903, F1: 0.90903#####> Valid Avg loss: 1.96252, Acc:0.37611, F1: 0.37611
====> Epoch: 334 Train Avg loss: 0.07600, Acc: 0.93702, F1: 0.93702#####> Valid Avg loss: 2.01281, Acc:0.37168, F1: 0.37168
====> Epoch: 335 Train Avg loss: 0.09959, Acc: 0.93130, F1: 0.93130#####> Valid Avg loss: 2.43357, Acc:0.39381, F1: 0.39381
====> Epoch: 336 Train Avg loss: 0.04610, Acc: 0.96310, F1: 0.96310#####> Valid Avg loss: 2.17165, Acc:0.39823, F1: 0.39823
====> Epoch: 337 Train Avg loss: 0.08628, Acc: 0.92875, F1: 0.92875#####> Valid Avg loss: 2.27947, Acc:0.38496, F1: 0.38496
====> Epoch: 338 Train Avg loss: 0.07089, Acc: 0.94084, F1: 0.94084#####> Valid Avg loss: 2.58661, Acc:0.42920, F1: 0.42920
====> Epoch: 339 Train Avg loss: 0.09167, Acc: 0.94084, F1: 0.94084#####> Valid Avg loss: 1.96917, Acc:0.28319, F1: 0.28319
====> Epoch: 340 Train Avg loss: 0.10820, Acc: 0.91730, F1: 0.91730#####> Valid Avg loss: 2.56430, Acc:0.41593, F1: 0.41593
====> Epoch: 341 Train Avg loss: 0.06626, Acc: 0.95229, F1: 0.95229#####> Valid Avg loss: 2.47499, Acc:0.39381, F1: 0.39381
====> Epoch: 342 Train Avg loss: 0.05995, Acc: 0.95293, F1: 0.95293#####> Valid Avg loss: 2.54446, Acc:0.39381, F1: 0.39381
====> Epoch: 343 Train Avg loss: 0.07805, Acc: 0.94593, F1: 0.94593#####> Valid Avg loss: 2.42287, Acc:0.40708, F1: 0.40708
====> Epoch: 344 Train Avg loss: 0.10965, Acc: 0.92494, F1: 0.92494#####> Valid Avg loss: 2.44545, Acc:0.42920, F1: 0.42920
====> Epoch: 345 Train Avg loss: 0.07456, Acc: 0.94211, F1: 0.94211#####> Valid Avg loss: 2.14716, Acc:0.32301, F1: 0.32301
====> Epoch: 346 Train Avg loss: 0.07951, Acc: 0.93957, F1: 0.93957#####> Valid Avg loss: 2.43119, Acc:0.39381, F1: 0.39381
====> Epoch: 347 Train Avg loss: 0.03574, Acc: 0.97519, F1: 0.97519#####> Valid Avg loss: 2.44188, Acc:0.37611, F1: 0.37611
====> Epoch: 348 Train Avg loss: 0.07485, Acc: 0.94338, F1: 0.94338#####> Valid Avg loss: 2.59115, Acc:0.39823, F1: 0.39823
====> Epoch: 349 Train Avg loss: 0.09399, Acc: 0.93066, F1: 0.93066#####> Valid Avg loss: 2.07509, Acc:0.40265, F1: 0.40265
====> Epoch: 350 Train Avg loss: 0.06325, Acc: 0.94911, F1: 0.94911#####> Valid Avg loss: 2.41165, Acc:0.38053, F1: 0.38053
====> Epoch: 351 Train Avg loss: 0.09347, Acc: 0.92875, F1: 0.92875#####> Valid Avg loss: 2.21258, Acc:0.39823, F1: 0.39823
====> Epoch: 352 Train Avg loss: 0.08187, Acc: 0.93766, F1: 0.93766#####> Valid Avg loss: 2.15996, Acc:0.35398, F1: 0.35398
====> Epoch: 353 Train Avg loss: 0.11642, Acc: 0.91094, F1: 0.91094#####> Valid Avg loss: 2.11716, Acc:0.38496, F1: 0.38496
====> Epoch: 354 Train Avg loss: 0.07613, Acc: 0.94148, F1: 0.94148#####> Valid Avg loss: 2.13196, Acc:0.40265, F1: 0.40265
====> Epoch: 355 Train Avg loss: 0.05182, Acc: 0.95738, F1: 0.95738#####> Valid Avg loss: 2.40562, Acc:0.37611, F1: 0.37611
====> Epoch: 356 Train Avg loss: 0.06363, Acc: 0.95802, F1: 0.95802#####> Valid Avg loss: 1.99533, Acc:0.38053, F1: 0.38053
====> Epoch: 357 Train Avg loss: 0.08174, Acc: 0.93893, F1: 0.93893#####> Valid Avg loss: 2.24619, Acc:0.38938, F1: 0.38938
====> Epoch: 358 Train Avg loss: 0.05113, Acc: 0.96247, F1: 0.96247#####> Valid Avg loss: 2.16531, Acc:0.31858, F1: 0.31858
====> Epoch: 359 Train Avg loss: 0.06255, Acc: 0.95356, F1: 0.95356#####> Valid Avg loss: 2.25010, Acc:0.37611, F1: 0.37611
====> Epoch: 360 Train Avg loss: 0.05351, Acc: 0.96120, F1: 0.96120#####> Valid Avg loss: 2.40426, Acc:0.41593, F1: 0.41593
====> Epoch: 361 Train Avg loss: 0.11481, Acc: 0.92112, F1: 0.92112#####> Valid Avg loss: 1.97824, Acc:0.36726, F1: 0.36726
====> Epoch: 362 Train Avg loss: 0.04022, Acc: 0.96310, F1: 0.96310#####> Valid Avg loss: 2.41746, Acc:0.41593, F1: 0.41593
====> Epoch: 363 Train Avg loss: 0.09088, Acc: 0.93448, F1: 0.93448#####> Valid Avg loss: 1.90219, Acc:0.41150, F1: 0.41150
====> Epoch: 364 Train Avg loss: 0.06474, Acc: 0.94975, F1: 0.94975#####> Valid Avg loss: 2.41107, Acc:0.33186, F1: 0.33186
====> Epoch: 365 Train Avg loss: 0.06795, Acc: 0.94656, F1: 0.94656#####> Valid Avg loss: 2.17414, Acc:0.35841, F1: 0.35841
====> Epoch: 366 Train Avg loss: 0.06742, Acc: 0.94466, F1: 0.94466#####> Valid Avg loss: 2.42825, Acc:0.33186, F1: 0.33186
====> Epoch: 367 Train Avg loss: 0.07584, Acc: 0.93702, F1: 0.93702#####> Valid Avg loss: 2.28741, Acc:0.38496, F1: 0.38496
====> Epoch: 368 Train Avg loss: 0.06467, Acc: 0.95038, F1: 0.95038#####> Valid Avg loss: 2.36084, Acc:0.36726, F1: 0.36726
====> Epoch: 369 Train Avg loss: 0.05879, Acc: 0.95420, F1: 0.95420#####> Valid Avg loss: 2.40449, Acc:0.40265, F1: 0.40265
====> Epoch: 370 Train Avg loss: 0.02959, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 2.65247, Acc:0.39823, F1: 0.39823
====> Epoch: 371 Train Avg loss: 0.10019, Acc: 0.93066, F1: 0.93066#####> Valid Avg loss: 2.37581, Acc:0.36726, F1: 0.36726
====> Epoch: 372 Train Avg loss: 0.07913, Acc: 0.93957, F1: 0.93957#####> Valid Avg loss: 2.09224, Acc:0.37168, F1: 0.37168
====> Epoch: 373 Train Avg loss: 0.07340, Acc: 0.94466, F1: 0.94466#####> Valid Avg loss: 2.12154, Acc:0.39381, F1: 0.39381
====> Epoch: 374 Train Avg loss: 0.04596, Acc: 0.96628, F1: 0.96628#####> Valid Avg loss: 2.28847, Acc:0.37168, F1: 0.37168
====> Epoch: 375 Train Avg loss: 0.05435, Acc: 0.95865, F1: 0.95865#####> Valid Avg loss: 2.41939, Acc:0.40708, F1: 0.40708
====> Epoch: 376 Train Avg loss: 0.07999, Acc: 0.94466, F1: 0.94466#####> Valid Avg loss: 2.26841, Acc:0.37168, F1: 0.37168
====> Epoch: 377 Train Avg loss: 0.06301, Acc: 0.94975, F1: 0.94975#####> Valid Avg loss: 2.31850, Acc:0.30973, F1: 0.30973
====> Epoch: 378 Train Avg loss: 0.04373, Acc: 0.96501, F1: 0.96501#####> Valid Avg loss: 2.28141, Acc:0.36726, F1: 0.36726
====> Epoch: 379 Train Avg loss: 0.05613, Acc: 0.95865, F1: 0.95865#####> Valid Avg loss: 2.35631, Acc:0.33628, F1: 0.33628
====> Epoch: 380 Train Avg loss: 0.09293, Acc: 0.92557, F1: 0.92557#####> Valid Avg loss: 2.23628, Acc:0.36726, F1: 0.36726
====> Epoch: 381 Train Avg loss: 0.02636, Acc: 0.97774, F1: 0.97774#####> Valid Avg loss: 2.51991, Acc:0.39823, F1: 0.39823
====> Epoch: 382 Train Avg loss: 0.04929, Acc: 0.95738, F1: 0.95738#####> Valid Avg loss: 2.23510, Acc:0.41593, F1: 0.41593
====> Epoch: 383 Train Avg loss: 0.07064, Acc: 0.94402, F1: 0.94402#####> Valid Avg loss: 2.28596, Acc:0.40265, F1: 0.40265
====> Epoch: 384 Train Avg loss: 0.02981, Acc: 0.97201, F1: 0.97201#####> Valid Avg loss: 2.63981, Acc:0.38496, F1: 0.38496
====> Epoch: 385 Train Avg loss: 0.04669, Acc: 0.96120, F1: 0.96120#####> Valid Avg loss: 2.67477, Acc:0.38496, F1: 0.38496
====> Epoch: 386 Train Avg loss: 0.07141, Acc: 0.94466, F1: 0.94466#####> Valid Avg loss: 2.44033, Acc:0.38938, F1: 0.38938
====> Epoch: 387 Train Avg loss: 0.04316, Acc: 0.96628, F1: 0.96628#####> Valid Avg loss: 2.55598, Acc:0.38496, F1: 0.38496
====> Epoch: 388 Train Avg loss: 0.07932, Acc: 0.93702, F1: 0.93702#####> Valid Avg loss: 2.15175, Acc:0.42478, F1: 0.42478
====> Epoch: 389 Train Avg loss: 0.05199, Acc: 0.95420, F1: 0.95420#####> Valid Avg loss: 2.29485, Acc:0.36283, F1: 0.36283
====> Epoch: 390 Train Avg loss: 0.03517, Acc: 0.97010, F1: 0.97010#####> Valid Avg loss: 2.38328, Acc:0.38496, F1: 0.38496
====> Epoch: 391 Train Avg loss: 0.02783, Acc: 0.97519, F1: 0.97519#####> Valid Avg loss: 2.40282, Acc:0.27876, F1: 0.27876
====> Epoch: 392 Train Avg loss: 0.10001, Acc: 0.92939, F1: 0.92939#####> Valid Avg loss: 2.18220, Acc:0.41150, F1: 0.41150
====> Epoch: 393 Train Avg loss: 0.03077, Acc: 0.97201, F1: 0.97201#####> Valid Avg loss: 2.52996, Acc:0.38938, F1: 0.38938
====> Epoch: 394 Train Avg loss: 0.08732, Acc: 0.94084, F1: 0.94084#####> Valid Avg loss: 2.36256, Acc:0.35841, F1: 0.35841
====> Epoch: 395 Train Avg loss: 0.03315, Acc: 0.97074, F1: 0.97074#####> Valid Avg loss: 2.50859, Acc:0.41593, F1: 0.41593
====> Epoch: 396 Train Avg loss: 0.04957, Acc: 0.95802, F1: 0.95802#####> Valid Avg loss: 2.57570, Acc:0.35398, F1: 0.35398
====> Epoch: 397 Train Avg loss: 0.05126, Acc: 0.96056, F1: 0.96056#####> Valid Avg loss: 2.32154, Acc:0.42920, F1: 0.42920
====> Epoch: 398 Train Avg loss: 0.09068, Acc: 0.93321, F1: 0.93321#####> Valid Avg loss: 1.80763, Acc:0.35841, F1: 0.35841
====> Epoch: 399 Train Avg loss: 0.03251, Acc: 0.97137, F1: 0.97137#####> Valid Avg loss: 2.38716, Acc:0.39823, F1: 0.39823
====> Epoch: 400 Train Avg loss: 0.02348, Acc: 0.97519, F1: 0.97519#####> Valid Avg loss: 2.78164, Acc:0.39381, F1: 0.39381
====> Epoch: 401 Train Avg loss: 0.07094, Acc: 0.94847, F1: 0.94847#####> Valid Avg loss: 2.49086, Acc:0.36726, F1: 0.36726
====> Epoch: 402 Train Avg loss: 0.02361, Acc: 0.97710, F1: 0.97710#####> Valid Avg loss: 2.48137, Acc:0.34513, F1: 0.34513
====> Epoch: 403 Train Avg loss: 0.02545, Acc: 0.97837, F1: 0.97837#####> Valid Avg loss: 2.89338, Acc:0.35841, F1: 0.35841
====> Epoch: 404 Train Avg loss: 0.09887, Acc: 0.92939, F1: 0.92939#####> Valid Avg loss: 2.36068, Acc:0.42478, F1: 0.42478
====> Epoch: 405 Train Avg loss: 0.04660, Acc: 0.96183, F1: 0.96183#####> Valid Avg loss: 2.28965, Acc:0.37168, F1: 0.37168
====> Epoch: 406 Train Avg loss: 0.02559, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 2.55235, Acc:0.36283, F1: 0.36283
====> Epoch: 407 Train Avg loss: 0.11096, Acc: 0.92748, F1: 0.92748#####> Valid Avg loss: 1.51759, Acc:0.38938, F1: 0.38938
====> Epoch: 408 Train Avg loss: 0.05995, Acc: 0.95165, F1: 0.95165#####> Valid Avg loss: 2.14599, Acc:0.37611, F1: 0.37611
====> Epoch: 409 Train Avg loss: 0.04396, Acc: 0.96692, F1: 0.96692#####> Valid Avg loss: 2.33905, Acc:0.40265, F1: 0.40265
====> Epoch: 410 Train Avg loss: 0.02657, Acc: 0.97392, F1: 0.97392#####> Valid Avg loss: 2.91054, Acc:0.38496, F1: 0.38496
====> Epoch: 411 Train Avg loss: 0.07606, Acc: 0.93957, F1: 0.93957#####> Valid Avg loss: 1.95597, Acc:0.40265, F1: 0.40265
====> Epoch: 412 Train Avg loss: 0.04113, Acc: 0.97010, F1: 0.97010#####> Valid Avg loss: 2.49587, Acc:0.38496, F1: 0.38496
====> Epoch: 413 Train Avg loss: 0.04514, Acc: 0.96247, F1: 0.96247#####> Valid Avg loss: 2.47415, Acc:0.40265, F1: 0.40265
====> Epoch: 414 Train Avg loss: 0.05267, Acc: 0.95802, F1: 0.95802#####> Valid Avg loss: 2.51519, Acc:0.37611, F1: 0.37611
====> Epoch: 415 Train Avg loss: 0.01951, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.63679, Acc:0.38053, F1: 0.38053
====> Epoch: 416 Train Avg loss: 0.05120, Acc: 0.95865, F1: 0.95865#####> Valid Avg loss: 2.37526, Acc:0.36283, F1: 0.36283
====> Epoch: 417 Train Avg loss: 0.04530, Acc: 0.96438, F1: 0.96438#####> Valid Avg loss: 2.77478, Acc:0.41593, F1: 0.41593
====> Epoch: 418 Train Avg loss: 0.03903, Acc: 0.96501, F1: 0.96501#####> Valid Avg loss: 2.51626, Acc:0.37168, F1: 0.37168
====> Epoch: 419 Train Avg loss: 0.04231, Acc: 0.96247, F1: 0.96247#####> Valid Avg loss: 2.71932, Acc:0.38053, F1: 0.38053
====> Epoch: 420 Train Avg loss: 0.04070, Acc: 0.96374, F1: 0.96374#####> Valid Avg loss: 2.66590, Acc:0.37168, F1: 0.37168
====> Epoch: 421 Train Avg loss: 0.02577, Acc: 0.97455, F1: 0.97455#####> Valid Avg loss: 2.88456, Acc:0.39823, F1: 0.39823
====> Epoch: 422 Train Avg loss: 0.02546, Acc: 0.97837, F1: 0.97837#####> Valid Avg loss: 2.69608, Acc:0.38938, F1: 0.38938
====> Epoch: 423 Train Avg loss: 0.01962, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 2.91623, Acc:0.38053, F1: 0.38053
====> Epoch: 424 Train Avg loss: 0.09228, Acc: 0.93257, F1: 0.93257#####> Valid Avg loss: 2.56989, Acc:0.40265, F1: 0.40265
====> Epoch: 425 Train Avg loss: 0.03855, Acc: 0.96756, F1: 0.96756#####> Valid Avg loss: 2.57651, Acc:0.39823, F1: 0.39823
====> Epoch: 426 Train Avg loss: 0.01741, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.84979, Acc:0.41150, F1: 0.41150
====> Epoch: 427 Train Avg loss: 0.06332, Acc: 0.94975, F1: 0.94975#####> Valid Avg loss: 2.22816, Acc:0.38938, F1: 0.38938
====> Epoch: 428 Train Avg loss: 0.04695, Acc: 0.95992, F1: 0.95992#####> Valid Avg loss: 2.35140, Acc:0.36726, F1: 0.36726
====> Epoch: 429 Train Avg loss: 0.04815, Acc: 0.96056, F1: 0.96056#####> Valid Avg loss: 2.53114, Acc:0.38053, F1: 0.38053
====> Epoch: 430 Train Avg loss: 0.05793, Acc: 0.96183, F1: 0.96183#####> Valid Avg loss: 2.47946, Acc:0.44690, F1: 0.44690
====> Epoch: 431 Train Avg loss: 0.02549, Acc: 0.97392, F1: 0.97392#####> Valid Avg loss: 2.39869, Acc:0.40265, F1: 0.40265
====> Epoch: 432 Train Avg loss: 0.05475, Acc: 0.95547, F1: 0.95547#####> Valid Avg loss: 2.51943, Acc:0.36283, F1: 0.36283
====> Epoch: 433 Train Avg loss: 0.05301, Acc: 0.95674, F1: 0.95674#####> Valid Avg loss: 2.56697, Acc:0.38938, F1: 0.38938
====> Epoch: 434 Train Avg loss: 0.03302, Acc: 0.96756, F1: 0.96756#####> Valid Avg loss: 2.55032, Acc:0.38053, F1: 0.38053
====> Epoch: 435 Train Avg loss: 0.01754, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 2.69343, Acc:0.40265, F1: 0.40265
====> Epoch: 436 Train Avg loss: 0.06523, Acc: 0.95102, F1: 0.95102#####> Valid Avg loss: 2.50793, Acc:0.40265, F1: 0.40265
====> Epoch: 437 Train Avg loss: 0.02311, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.84918, Acc:0.40265, F1: 0.40265
====> Epoch: 438 Train Avg loss: 0.03553, Acc: 0.96819, F1: 0.96819#####> Valid Avg loss: 2.99388, Acc:0.40708, F1: 0.40708
====> Epoch: 439 Train Avg loss: 0.01996, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.78972, Acc:0.40265, F1: 0.40265
====> Epoch: 440 Train Avg loss: 0.06993, Acc: 0.94975, F1: 0.94975#####> Valid Avg loss: 2.12340, Acc:0.41593, F1: 0.41593
====> Epoch: 441 Train Avg loss: 0.02878, Acc: 0.97201, F1: 0.97201#####> Valid Avg loss: 2.60602, Acc:0.42478, F1: 0.42478
====> Epoch: 442 Train Avg loss: 0.01929, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.76787, Acc:0.38496, F1: 0.38496
====> Epoch: 443 Train Avg loss: 0.03669, Acc: 0.96819, F1: 0.96819#####> Valid Avg loss: 2.89096, Acc:0.39381, F1: 0.39381
====> Epoch: 444 Train Avg loss: 0.05012, Acc: 0.96120, F1: 0.96120#####> Valid Avg loss: 2.40926, Acc:0.41593, F1: 0.41593
====> Epoch: 445 Train Avg loss: 0.03821, Acc: 0.96692, F1: 0.96692#####> Valid Avg loss: 2.49087, Acc:0.38053, F1: 0.38053
====> Epoch: 446 Train Avg loss: 0.01406, Acc: 0.98282, F1: 0.98282#####> Valid Avg loss: 2.68891, Acc:0.42478, F1: 0.42478
====> Epoch: 447 Train Avg loss: 0.12153, Acc: 0.91349, F1: 0.91349#####> Valid Avg loss: 2.01029, Acc:0.41593, F1: 0.41593
====> Epoch: 448 Train Avg loss: 0.02191, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 2.37158, Acc:0.38053, F1: 0.38053
====> Epoch: 449 Train Avg loss: 0.01934, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 2.43597, Acc:0.38496, F1: 0.38496
====> Epoch: 450 Train Avg loss: 0.04957, Acc: 0.96056, F1: 0.96056#####> Valid Avg loss: 2.47135, Acc:0.41150, F1: 0.41150
====> Epoch: 451 Train Avg loss: 0.02239, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 2.53033, Acc:0.42035, F1: 0.42035
====> Epoch: 452 Train Avg loss: 0.01634, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.09077, Acc:0.41593, F1: 0.41593
====> Epoch: 453 Train Avg loss: 0.13055, Acc: 0.90776, F1: 0.90776#####> Valid Avg loss: 2.26387, Acc:0.37168, F1: 0.37168
====> Epoch: 454 Train Avg loss: 0.01998, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 2.44204, Acc:0.40708, F1: 0.40708
====> Epoch: 455 Train Avg loss: 0.04522, Acc: 0.96374, F1: 0.96374#####> Valid Avg loss: 2.23541, Acc:0.38938, F1: 0.38938
====> Epoch: 456 Train Avg loss: 0.03031, Acc: 0.97265, F1: 0.97265#####> Valid Avg loss: 2.79024, Acc:0.38496, F1: 0.38496
====> Epoch: 457 Train Avg loss: 0.02868, Acc: 0.97010, F1: 0.97010#####> Valid Avg loss: 2.71226, Acc:0.39381, F1: 0.39381
====> Epoch: 458 Train Avg loss: 0.01949, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.86948, Acc:0.39381, F1: 0.39381
====> Epoch: 459 Train Avg loss: 0.03655, Acc: 0.96501, F1: 0.96501#####> Valid Avg loss: 2.81718, Acc:0.39381, F1: 0.39381
====> Epoch: 460 Train Avg loss: 0.03981, Acc: 0.96374, F1: 0.96374#####> Valid Avg loss: 2.59729, Acc:0.40265, F1: 0.40265
====> Epoch: 461 Train Avg loss: 0.01739, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 2.60811, Acc:0.38053, F1: 0.38053
====> Epoch: 462 Train Avg loss: 0.01868, Acc: 0.97583, F1: 0.97583#####> Valid Avg loss: 2.58340, Acc:0.35841, F1: 0.35841
====> Epoch: 463 Train Avg loss: 0.04006, Acc: 0.96756, F1: 0.96756#####> Valid Avg loss: 3.23081, Acc:0.40265, F1: 0.40265
====> Epoch: 464 Train Avg loss: 0.02574, Acc: 0.97455, F1: 0.97455#####> Valid Avg loss: 2.53842, Acc:0.40265, F1: 0.40265
====> Epoch: 465 Train Avg loss: 0.02560, Acc: 0.97328, F1: 0.97328#####> Valid Avg loss: 3.26806, Acc:0.39381, F1: 0.39381
====> Epoch: 466 Train Avg loss: 0.02663, Acc: 0.97137, F1: 0.97137#####> Valid Avg loss: 3.00346, Acc:0.38938, F1: 0.38938
====> Epoch: 467 Train Avg loss: 0.01601, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.97524, Acc:0.40265, F1: 0.40265
====> Epoch: 468 Train Avg loss: 0.04892, Acc: 0.96310, F1: 0.96310#####> Valid Avg loss: 2.37233, Acc:0.37168, F1: 0.37168
====> Epoch: 469 Train Avg loss: 0.04662, Acc: 0.96438, F1: 0.96438#####> Valid Avg loss: 2.63097, Acc:0.38053, F1: 0.38053
====> Epoch: 470 Train Avg loss: 0.01411, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 2.55995, Acc:0.34956, F1: 0.34956
====> Epoch: 471 Train Avg loss: 0.01369, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.80081, Acc:0.38938, F1: 0.38938
====> Epoch: 472 Train Avg loss: 0.01730, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.80739, Acc:0.38938, F1: 0.38938
====> Epoch: 473 Train Avg loss: 0.01324, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 2.91611, Acc:0.38496, F1: 0.38496
====> Epoch: 474 Train Avg loss: 0.02766, Acc: 0.97074, F1: 0.97074#####> Valid Avg loss: 2.65698, Acc:0.39823, F1: 0.39823
====> Epoch: 475 Train Avg loss: 0.04494, Acc: 0.96120, F1: 0.96120#####> Valid Avg loss: 2.80151, Acc:0.38496, F1: 0.38496
====> Epoch: 476 Train Avg loss: 0.02801, Acc: 0.97519, F1: 0.97519#####> Valid Avg loss: 2.58405, Acc:0.37611, F1: 0.37611
====> Epoch: 477 Train Avg loss: 0.01613, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 2.63469, Acc:0.39381, F1: 0.39381
====> Epoch: 478 Train Avg loss: 0.01923, Acc: 0.98028, F1: 0.98028#####> Valid Avg loss: 2.92690, Acc:0.40708, F1: 0.40708
====> Epoch: 479 Train Avg loss: 0.04248, Acc: 0.96183, F1: 0.96183#####> Valid Avg loss: 2.50747, Acc:0.37168, F1: 0.37168
====> Epoch: 480 Train Avg loss: 0.01918, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 2.79458, Acc:0.38496, F1: 0.38496
====> Epoch: 481 Train Avg loss: 0.01846, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.97415, Acc:0.36283, F1: 0.36283
====> Epoch: 482 Train Avg loss: 0.01515, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 3.02500, Acc:0.38053, F1: 0.38053
====> Epoch: 483 Train Avg loss: 0.01409, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.79761, Acc:0.37611, F1: 0.37611
====> Epoch: 484 Train Avg loss: 0.04495, Acc: 0.96501, F1: 0.96501#####> Valid Avg loss: 2.57937, Acc:0.37611, F1: 0.37611
====> Epoch: 485 Train Avg loss: 0.01826, Acc: 0.97774, F1: 0.97774#####> Valid Avg loss: 2.87130, Acc:0.41150, F1: 0.41150
====> Epoch: 486 Train Avg loss: 0.01296, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.90318, Acc:0.40265, F1: 0.40265
====> Epoch: 487 Train Avg loss: 0.01225, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 2.69348, Acc:0.37168, F1: 0.37168
====> Epoch: 488 Train Avg loss: 0.01264, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 3.14001, Acc:0.40708, F1: 0.40708
====> Epoch: 489 Train Avg loss: 0.06475, Acc: 0.95483, F1: 0.95483#####> Valid Avg loss: 2.91158, Acc:0.39381, F1: 0.39381
====> Epoch: 490 Train Avg loss: 0.01406, Acc: 0.98346, F1: 0.98346#####> Valid Avg loss: 2.83187, Acc:0.38496, F1: 0.38496
====> Epoch: 491 Train Avg loss: 0.01422, Acc: 0.97964, F1: 0.97964#####> Valid Avg loss: 2.70498, Acc:0.35398, F1: 0.35398
====> Epoch: 492 Train Avg loss: 0.01364, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.97048, Acc:0.38053, F1: 0.38053
====> Epoch: 493 Train Avg loss: 0.01229, Acc: 0.97837, F1: 0.97837#####> Valid Avg loss: 2.94556, Acc:0.37611, F1: 0.37611
====> Epoch: 494 Train Avg loss: 0.04805, Acc: 0.95929, F1: 0.95929#####> Valid Avg loss: 2.36113, Acc:0.37611, F1: 0.37611
====> Epoch: 495 Train Avg loss: 0.01411, Acc: 0.98155, F1: 0.98155#####> Valid Avg loss: 2.78580, Acc:0.40708, F1: 0.40708
====> Epoch: 496 Train Avg loss: 0.01237, Acc: 0.98092, F1: 0.98092#####> Valid Avg loss: 2.96306, Acc:0.40708, F1: 0.40708
====> Epoch: 497 Train Avg loss: 0.01534, Acc: 0.97901, F1: 0.97901#####> Valid Avg loss: 2.92017, Acc:0.41150, F1: 0.41150
====> Epoch: 498 Train Avg loss: 0.03013, Acc: 0.96947, F1: 0.96947#####> Valid Avg loss: 3.10584, Acc:0.40265, F1: 0.40265
====> Epoch: 499 Train Avg loss: 0.03048, Acc: 0.96756, F1: 0.96756#####> Valid Avg loss: 2.89699, Acc:0.37611, F1: 0.37611
====> Epoch: 500 Train Avg loss: 0.01248, Acc: 0.98219, F1: 0.98219#####> Valid Avg loss: 2.70631, Acc:0.40265, F1: 0.40265
#####> Valid Avg loss: 1.97168, Acc:0.58228, F1: 0.58228


$$$$$$> Test it 5: (from train best model) Final Test Avg loss:1.97168, Acc:0.58228, F1:0.58228\n
#####> Valid Avg loss: 0.54797, Acc:0.71519, F1: 0.71519


$$$$$$> Test it 5: (from max acc valid model) Final Test Avg loss:0.54797, Acc:0.71519, F1:0.71519\n
#####> Valid Avg loss: 0.48017, Acc:0.72785, F1: 0.72785


$$$$$$> Test it 5: (from min loss valid model) Final Test Avg loss:0.48017, Acc:0.72785, F1:0.72785\n


 Final average test accuracy:0.564501017332077, avg f1_score 0.564501017886043 

validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595962938.189262.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:1, no_gpus: 1
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595963439.340258.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:1, no_gpus: 1
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595964035.288241.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:1, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3411
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 3411
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595964305.970102.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:1, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3411
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 3411
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595964336.126741.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:1, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3411
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 3411
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595964417.222219.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:1, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3411
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 3411
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595964480.380969.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:1, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3411
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 3411
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595964554.098851.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3411
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 3411
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3411
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 3411
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
====> Epoch: 1 Train Avg loss: 0.82101, Acc: 0.48358, F1: 0.48358#####> Valid Avg loss: 1.12915, Acc:0.37126, F1: 0.37094
===> Epoch: 1: Training loss decreased (inf --> 0.82101), Acc: (0.00000 --> 0.48358), F1: (0.00000 --> 0.48358).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.12915), Acc: (0.00000 --> 0.37126), F1: (0.00000 --> 0.37094).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1

####> Epoch: 1: validation acc increase (inf --> 1.12915), Acc: (0.00000 --> 0.37126), F1: (0.00000 --> 0.37094).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 2 Train Avg loss: 0.66523, Acc: 0.59220, F1: 0.59220#####> Valid Avg loss: 1.45608, Acc:0.24893, F1: 0.24872
===> Epoch: 2: Training loss decreased (0.82101 --> 0.66523), Acc: (0.48358 --> 0.59220), F1: (0.48358 --> 0.59220).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 3 Train Avg loss: 0.61586, Acc: 0.61111, F1: 0.61111#####> Valid Avg loss: 1.32112, Acc:0.38837, F1: 0.38803
===> Epoch: 3: Training loss decreased (0.66523 --> 0.61586), Acc: (0.59220 --> 0.61111), F1: (0.59220 --> 0.61111).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1

####> Epoch: 3: validation acc increase (1.12915 --> 1.32112), Acc: (0.37126 --> 0.38837), F1: (0.37094 --> 0.38803).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 4 Train Avg loss: 0.58360, Acc: 0.62841, F1: 0.62841#####> Valid Avg loss: 1.30784, Acc:0.37810, F1: 0.37778
===> Epoch: 4: Training loss decreased (0.61586 --> 0.58360), Acc: (0.61111 --> 0.62841), F1: (0.61111 --> 0.62841).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 5 Train Avg loss: 0.55981, Acc: 0.63588, F1: 0.63588#####> Valid Avg loss: 1.35620, Acc:0.31908, F1: 0.31880
===> Epoch: 5: Training loss decreased (0.58360 --> 0.55981), Acc: (0.62841 --> 0.63588), F1: (0.62841 --> 0.63588).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 6 Train Avg loss: 0.54721, Acc: 0.64966, F1: 0.64966#####> Valid Avg loss: 1.38413, Acc:0.37382, F1: 0.37350
===> Epoch: 6: Training loss decreased (0.55981 --> 0.54721), Acc: (0.63588 --> 0.64966), F1: (0.63588 --> 0.64966).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 7 Train Avg loss: 0.53106, Acc: 0.65641, F1: 0.65641#####> Valid Avg loss: 1.54000, Acc:0.38152, F1: 0.38120
===> Epoch: 7: Training loss decreased (0.54721 --> 0.53106), Acc: (0.64966 --> 0.65641), F1: (0.64966 --> 0.65641).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 8 Train Avg loss: 0.51541, Acc: 0.66124, F1: 0.66124#####> Valid Avg loss: 1.61615, Acc:0.28486, F1: 0.28462
===> Epoch: 8: Training loss decreased (0.53106 --> 0.51541), Acc: (0.65641 --> 0.66124), F1: (0.65641 --> 0.66124).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 9 Train Avg loss: 0.50548, Acc: 0.66315, F1: 0.66315#####> Valid Avg loss: 1.72156, Acc:0.30624, F1: 0.30598
===> Epoch: 9: Training loss decreased (0.51541 --> 0.50548), Acc: (0.66124 --> 0.66315), F1: (0.66124 --> 0.66315).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 10 Train Avg loss: 0.49840, Acc: 0.66887, F1: 0.66887#####> Valid Avg loss: 1.54005, Acc:0.36612, F1: 0.36581
===> Epoch: 10: Training loss decreased (0.50548 --> 0.49840), Acc: (0.66315 --> 0.66887), F1: (0.66315 --> 0.66887).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 11 Train Avg loss: 0.49231, Acc: 0.67282, F1: 0.67282#####> Valid Avg loss: 1.60680, Acc:0.35415, F1: 0.35385
===> Epoch: 11: Training loss decreased (0.49840 --> 0.49231), Acc: (0.66887 --> 0.67282), F1: (0.66887 --> 0.67282).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 12 Train Avg loss: 0.47617, Acc: 0.67619, F1: 0.67619#####> Valid Avg loss: 1.67544, Acc:0.38323, F1: 0.38291
===> Epoch: 12: Training loss decreased (0.49231 --> 0.47617), Acc: (0.67282 --> 0.67619), F1: (0.67282 --> 0.67619).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 13 Train Avg loss: 0.47091, Acc: 0.68323, F1: 0.68323#####> Valid Avg loss: 1.46393, Acc:0.35843, F1: 0.35812
===> Epoch: 13: Training loss decreased (0.47617 --> 0.47091), Acc: (0.67619 --> 0.68323), F1: (0.67619 --> 0.68323).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 14 Train Avg loss: 0.47141, Acc: 0.68264, F1: 0.68264#####> Valid Avg loss: 1.59092, Acc:0.34731, F1: 0.34701
====> Epoch: 15 Train Avg loss: 0.45415, Acc: 0.69554, F1: 0.69554#####> Valid Avg loss: 1.52258, Acc:0.38580, F1: 0.38547
===> Epoch: 15: Training loss decreased (0.47091 --> 0.45415), Acc: (0.68323 --> 0.69554), F1: (0.68323 --> 0.69554).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 16 Train Avg loss: 0.45218, Acc: 0.68968, F1: 0.68968#####> Valid Avg loss: 1.46948, Acc:0.29085, F1: 0.29060
===> Epoch: 16: Training loss decreased (0.45415 --> 0.45218), Acc: (0.69554 --> 0.68968), F1: (0.69554 --> 0.68968).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 17 Train Avg loss: 0.44744, Acc: 0.69642, F1: 0.69642#####> Valid Avg loss: 1.61912, Acc:0.32934, F1: 0.32906
===> Epoch: 17: Training loss decreased (0.45218 --> 0.44744), Acc: (0.68968 --> 0.69642), F1: (0.68968 --> 0.69642).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 18 Train Avg loss: 0.44076, Acc: 0.70170, F1: 0.70170#####> Valid Avg loss: 1.54117, Acc:0.29427, F1: 0.29402
===> Epoch: 18: Training loss decreased (0.44744 --> 0.44076), Acc: (0.69642 --> 0.70170), F1: (0.69642 --> 0.70170).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 19 Train Avg loss: 0.43566, Acc: 0.70390, F1: 0.70390#####> Valid Avg loss: 1.54176, Acc:0.34303, F1: 0.34274
===> Epoch: 19: Training loss decreased (0.44076 --> 0.43566), Acc: (0.70170 --> 0.70390), F1: (0.70170 --> 0.70390).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 20 Train Avg loss: 0.42363, Acc: 0.70551, F1: 0.70551#####> Valid Avg loss: 1.48319, Acc:0.36527, F1: 0.36496
===> Epoch: 20: Training loss decreased (0.43566 --> 0.42363), Acc: (0.70390 --> 0.70551), F1: (0.70390 --> 0.70551).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 21 Train Avg loss: 0.41544, Acc: 0.71885, F1: 0.71885#####> Valid Avg loss: 1.71805, Acc:0.37211, F1: 0.37179
===> Epoch: 21: Training loss decreased (0.42363 --> 0.41544), Acc: (0.70551 --> 0.71885), F1: (0.70551 --> 0.71885).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 22 Train Avg loss: 0.41812, Acc: 0.71269, F1: 0.71269#####> Valid Avg loss: 1.56155, Acc:0.31822, F1: 0.31795
====> Epoch: 23 Train Avg loss: 0.41289, Acc: 0.71533, F1: 0.71533#####> Valid Avg loss: 1.57998, Acc:0.36185, F1: 0.36154
===> Epoch: 23: Training loss decreased (0.41544 --> 0.41289), Acc: (0.71885 --> 0.71533), F1: (0.71885 --> 0.71533).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 24 Train Avg loss: 0.40418, Acc: 0.72237, F1: 0.72237#####> Valid Avg loss: 1.59147, Acc:0.37126, F1: 0.37094
===> Epoch: 24: Training loss decreased (0.41289 --> 0.40418), Acc: (0.71533 --> 0.72237), F1: (0.71533 --> 0.72237).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 25 Train Avg loss: 0.40078, Acc: 0.72369, F1: 0.72369#####> Valid Avg loss: 1.62247, Acc:0.35843, F1: 0.35812
===> Epoch: 25: Training loss decreased (0.40418 --> 0.40078), Acc: (0.72237 --> 0.72369), F1: (0.72237 --> 0.72369).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 26 Train Avg loss: 0.39354, Acc: 0.72633, F1: 0.72633#####> Valid Avg loss: 1.65532, Acc:0.36185, F1: 0.36154
===> Epoch: 26: Training loss decreased (0.40078 --> 0.39354), Acc: (0.72369 --> 0.72633), F1: (0.72369 --> 0.72633).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 27 Train Avg loss: 0.38313, Acc: 0.72955, F1: 0.72955#####> Valid Avg loss: 1.70965, Acc:0.30624, F1: 0.30598
===> Epoch: 27: Training loss decreased (0.39354 --> 0.38313), Acc: (0.72633 --> 0.72955), F1: (0.72633 --> 0.72955).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 28 Train Avg loss: 0.37609, Acc: 0.73747, F1: 0.73747#####> Valid Avg loss: 1.75323, Acc:0.28229, F1: 0.28205
===> Epoch: 28: Training loss decreased (0.38313 --> 0.37609), Acc: (0.72955 --> 0.73747), F1: (0.72955 --> 0.73747).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 29 Train Avg loss: 0.36653, Acc: 0.73937, F1: 0.73937#####> Valid Avg loss: 1.67304, Acc:0.29170, F1: 0.29145
===> Epoch: 29: Training loss decreased (0.37609 --> 0.36653), Acc: (0.73747 --> 0.73937), F1: (0.73747 --> 0.73937).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 30 Train Avg loss: 0.36474, Acc: 0.74406, F1: 0.74406#####> Valid Avg loss: 1.69567, Acc:0.36270, F1: 0.36239
===> Epoch: 30: Training loss decreased (0.36653 --> 0.36474), Acc: (0.73937 --> 0.74406), F1: (0.73937 --> 0.74406).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 31 Train Avg loss: 0.35542, Acc: 0.74890, F1: 0.74890#####> Valid Avg loss: 1.66116, Acc:0.26518, F1: 0.26496
===> Epoch: 31: Training loss decreased (0.36474 --> 0.35542), Acc: (0.74406 --> 0.74890), F1: (0.74406 --> 0.74890).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 32 Train Avg loss: 0.34986, Acc: 0.75638, F1: 0.75638#####> Valid Avg loss: 1.81826, Acc:0.28743, F1: 0.28718
===> Epoch: 32: Training loss decreased (0.35542 --> 0.34986), Acc: (0.74890 --> 0.75638), F1: (0.74890 --> 0.75638).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 33 Train Avg loss: 0.34429, Acc: 0.75491, F1: 0.75491#####> Valid Avg loss: 1.88977, Acc:0.29341, F1: 0.29316
===> Epoch: 33: Training loss decreased (0.34986 --> 0.34429), Acc: (0.75638 --> 0.75491), F1: (0.75638 --> 0.75491).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 34 Train Avg loss: 0.33074, Acc: 0.76151, F1: 0.76151#####> Valid Avg loss: 1.96839, Acc:0.30967, F1: 0.30940
===> Epoch: 34: Training loss decreased (0.34429 --> 0.33074), Acc: (0.75491 --> 0.76151), F1: (0.75491 --> 0.76151).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 35 Train Avg loss: 0.32498, Acc: 0.76561, F1: 0.76561#####> Valid Avg loss: 2.06247, Acc:0.36527, F1: 0.36496
===> Epoch: 35: Training loss decreased (0.33074 --> 0.32498), Acc: (0.76151 --> 0.76561), F1: (0.76151 --> 0.76561).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 36 Train Avg loss: 0.31426, Acc: 0.77778, F1: 0.77778#####> Valid Avg loss: 1.79660, Acc:0.31651, F1: 0.31624
===> Epoch: 36: Training loss decreased (0.32498 --> 0.31426), Acc: (0.76561 --> 0.77778), F1: (0.76561 --> 0.77778).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 37 Train Avg loss: 0.31058, Acc: 0.77514, F1: 0.77514#####> Valid Avg loss: 1.85348, Acc:0.33533, F1: 0.33504
===> Epoch: 37: Training loss decreased (0.31426 --> 0.31058), Acc: (0.77778 --> 0.77514), F1: (0.77778 --> 0.77514).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 38 Train Avg loss: 0.29951, Acc: 0.78437, F1: 0.78437#####> Valid Avg loss: 1.95582, Acc:0.33191, F1: 0.33162
===> Epoch: 38: Training loss decreased (0.31058 --> 0.29951), Acc: (0.77514 --> 0.78437), F1: (0.77514 --> 0.78437).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 39 Train Avg loss: 0.28933, Acc: 0.78613, F1: 0.78613#####> Valid Avg loss: 2.19226, Acc:0.34645, F1: 0.34615
===> Epoch: 39: Training loss decreased (0.29951 --> 0.28933), Acc: (0.78437 --> 0.78613), F1: (0.78437 --> 0.78613).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 40 Train Avg loss: 0.27694, Acc: 0.79654, F1: 0.79654#####> Valid Avg loss: 1.94970, Acc:0.29512, F1: 0.29487
===> Epoch: 40: Training loss decreased (0.28933 --> 0.27694), Acc: (0.78613 --> 0.79654), F1: (0.78613 --> 0.79654).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 41 Train Avg loss: 0.27032, Acc: 0.80064, F1: 0.80064#####> Valid Avg loss: 2.09246, Acc:0.31480, F1: 0.31453
===> Epoch: 41: Training loss decreased (0.27694 --> 0.27032), Acc: (0.79654 --> 0.80064), F1: (0.79654 --> 0.80064).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 42 Train Avg loss: 0.25955, Acc: 0.80973, F1: 0.80973#####> Valid Avg loss: 2.18979, Acc:0.33362, F1: 0.33333
===> Epoch: 42: Training loss decreased (0.27032 --> 0.25955), Acc: (0.80064 --> 0.80973), F1: (0.80064 --> 0.80973).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 43 Train Avg loss: 0.24738, Acc: 0.82219, F1: 0.82219#####> Valid Avg loss: 2.30783, Acc:0.36356, F1: 0.36325
===> Epoch: 43: Training loss decreased (0.25955 --> 0.24738), Acc: (0.80973 --> 0.82219), F1: (0.80973 --> 0.82219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 44 Train Avg loss: 0.23989, Acc: 0.82249, F1: 0.82249#####> Valid Avg loss: 2.34224, Acc:0.32934, F1: 0.32906
===> Epoch: 44: Training loss decreased (0.24738 --> 0.23989), Acc: (0.82219 --> 0.82249), F1: (0.82219 --> 0.82249).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 45 Train Avg loss: 0.22739, Acc: 0.83055, F1: 0.83055#####> Valid Avg loss: 2.35467, Acc:0.34987, F1: 0.34957
===> Epoch: 45: Training loss decreased (0.23989 --> 0.22739), Acc: (0.82249 --> 0.83055), F1: (0.82249 --> 0.83055).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 46 Train Avg loss: 0.21672, Acc: 0.83568, F1: 0.83568#####> Valid Avg loss: 2.42124, Acc:0.29683, F1: 0.29658
===> Epoch: 46: Training loss decreased (0.22739 --> 0.21672), Acc: (0.83055 --> 0.83568), F1: (0.83055 --> 0.83568).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 47 Train Avg loss: 0.20005, Acc: 0.84609, F1: 0.84609#####> Valid Avg loss: 2.41315, Acc:0.30796, F1: 0.30855
===> Epoch: 47: Training loss decreased (0.21672 --> 0.20005), Acc: (0.83568 --> 0.84609), F1: (0.83568 --> 0.84609).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 48 Train Avg loss: 0.19650, Acc: 0.85210, F1: 0.85210#####> Valid Avg loss: 2.56321, Acc:0.30967, F1: 0.30940
===> Epoch: 48: Training loss decreased (0.20005 --> 0.19650), Acc: (0.84609 --> 0.85210), F1: (0.84609 --> 0.85210).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 49 Train Avg loss: 0.18320, Acc: 0.85591, F1: 0.85591#####> Valid Avg loss: 2.89909, Acc:0.35928, F1: 0.35897
===> Epoch: 49: Training loss decreased (0.19650 --> 0.18320), Acc: (0.85210 --> 0.85591), F1: (0.85210 --> 0.85591).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 50 Train Avg loss: 0.17260, Acc: 0.86837, F1: 0.86837#####> Valid Avg loss: 2.91531, Acc:0.33533, F1: 0.33590
===> Epoch: 50: Training loss decreased (0.18320 --> 0.17260), Acc: (0.85591 --> 0.86837), F1: (0.85591 --> 0.86837).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 51 Train Avg loss: 0.16347, Acc: 0.87101, F1: 0.87101#####> Valid Avg loss: 2.80649, Acc:0.32164, F1: 0.32222
===> Epoch: 51: Training loss decreased (0.17260 --> 0.16347), Acc: (0.86837 --> 0.87101), F1: (0.86837 --> 0.87101).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 52 Train Avg loss: 0.14703, Acc: 0.88508, F1: 0.88508#####> Valid Avg loss: 2.89081, Acc:0.31052, F1: 0.31111
===> Epoch: 52: Training loss decreased (0.16347 --> 0.14703), Acc: (0.87101 --> 0.88508), F1: (0.87101 --> 0.88508).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 53 Train Avg loss: 0.13768, Acc: 0.89592, F1: 0.89592#####> Valid Avg loss: 3.01294, Acc:0.32421, F1: 0.32479
===> Epoch: 53: Training loss decreased (0.14703 --> 0.13768), Acc: (0.88508 --> 0.89592), F1: (0.88508 --> 0.89592).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 54 Train Avg loss: 0.12661, Acc: 0.90032, F1: 0.90032#####> Valid Avg loss: 3.27092, Acc:0.32421, F1: 0.32393
===> Epoch: 54: Training loss decreased (0.13768 --> 0.12661), Acc: (0.89592 --> 0.90032), F1: (0.89592 --> 0.90032).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 55 Train Avg loss: 0.11758, Acc: 0.90633, F1: 0.90633#####> Valid Avg loss: 3.50732, Acc:0.32763, F1: 0.32735
===> Epoch: 55: Training loss decreased (0.12661 --> 0.11758), Acc: (0.90032 --> 0.90633), F1: (0.90032 --> 0.90633).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 56 Train Avg loss: 0.10886, Acc: 0.91337, F1: 0.91337#####> Valid Avg loss: 3.37236, Acc:0.29427, F1: 0.29402
===> Epoch: 56: Training loss decreased (0.11758 --> 0.10886), Acc: (0.90633 --> 0.91337), F1: (0.90633 --> 0.91337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 57 Train Avg loss: 0.09846, Acc: 0.91601, F1: 0.91601#####> Valid Avg loss: 3.36143, Acc:0.28058, F1: 0.28120
===> Epoch: 57: Training loss decreased (0.10886 --> 0.09846), Acc: (0.91337 --> 0.91601), F1: (0.91337 --> 0.91601).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 58 Train Avg loss: 0.09037, Acc: 0.92612, F1: 0.92612#####> Valid Avg loss: 3.61617, Acc:0.32678, F1: 0.32650
===> Epoch: 58: Training loss decreased (0.09846 --> 0.09037), Acc: (0.91601 --> 0.92612), F1: (0.91601 --> 0.92612).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 59 Train Avg loss: 0.07833, Acc: 0.93741, F1: 0.93741#####> Valid Avg loss: 3.62817, Acc:0.29769, F1: 0.29829
===> Epoch: 59: Training loss decreased (0.09037 --> 0.07833), Acc: (0.92612 --> 0.93741), F1: (0.92612 --> 0.93741).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 60 Train Avg loss: 0.07663, Acc: 0.94137, F1: 0.94137#####> Valid Avg loss: 3.76494, Acc:0.29940, F1: 0.30000
===> Epoch: 60: Training loss decreased (0.07833 --> 0.07663), Acc: (0.93741 --> 0.94137), F1: (0.93741 --> 0.94137).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 61 Train Avg loss: 0.06571, Acc: 0.94664, F1: 0.94664#####> Valid Avg loss: 3.76035, Acc:0.28058, F1: 0.28034
===> Epoch: 61: Training loss decreased (0.07663 --> 0.06571), Acc: (0.94137 --> 0.94664), F1: (0.94137 --> 0.94664).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 62 Train Avg loss: 0.06627, Acc: 0.94591, F1: 0.94591#####> Valid Avg loss: 4.04995, Acc:0.33191, F1: 0.33162
====> Epoch: 63 Train Avg loss: 0.06012, Acc: 0.94811, F1: 0.94811#####> Valid Avg loss: 3.90603, Acc:0.32250, F1: 0.32308
===> Epoch: 63: Training loss decreased (0.06571 --> 0.06012), Acc: (0.94664 --> 0.94811), F1: (0.94664 --> 0.94811).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 64 Train Avg loss: 0.05210, Acc: 0.95544, F1: 0.95544#####> Valid Avg loss: 4.10339, Acc:0.31737, F1: 0.31795
===> Epoch: 64: Training loss decreased (0.06012 --> 0.05210), Acc: (0.94811 --> 0.95544), F1: (0.94811 --> 0.95544).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 65 Train Avg loss: 0.05047, Acc: 0.96028, F1: 0.96028#####> Valid Avg loss: 4.15671, Acc:0.30796, F1: 0.30855
===> Epoch: 65: Training loss decreased (0.05210 --> 0.05047), Acc: (0.95544 --> 0.96028), F1: (0.95544 --> 0.96028).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 66 Train Avg loss: 0.04445, Acc: 0.96086, F1: 0.96086#####> Valid Avg loss: 4.18873, Acc:0.30539, F1: 0.30598
===> Epoch: 66: Training loss decreased (0.05047 --> 0.04445), Acc: (0.96028 --> 0.96086), F1: (0.96028 --> 0.96086).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 67 Train Avg loss: 0.04313, Acc: 0.96218, F1: 0.96218#####> Valid Avg loss: 4.17810, Acc:0.31565, F1: 0.31624
===> Epoch: 67: Training loss decreased (0.04445 --> 0.04313), Acc: (0.96086 --> 0.96218), F1: (0.96086 --> 0.96218).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 68 Train Avg loss: 0.03814, Acc: 0.96673, F1: 0.96673#####> Valid Avg loss: 4.25900, Acc:0.30197, F1: 0.30256
===> Epoch: 68: Training loss decreased (0.04313 --> 0.03814), Acc: (0.96218 --> 0.96673), F1: (0.96218 --> 0.96673).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 69 Train Avg loss: 0.03532, Acc: 0.97068, F1: 0.97068#####> Valid Avg loss: 4.35509, Acc:0.29769, F1: 0.29829
===> Epoch: 69: Training loss decreased (0.03814 --> 0.03532), Acc: (0.96673 --> 0.97068), F1: (0.96673 --> 0.97068).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 70 Train Avg loss: 0.03379, Acc: 0.96804, F1: 0.96804#####> Valid Avg loss: 4.60358, Acc:0.29683, F1: 0.29744
===> Epoch: 70: Training loss decreased (0.03532 --> 0.03379), Acc: (0.97068 --> 0.96804), F1: (0.97068 --> 0.96804).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 71 Train Avg loss: 0.03054, Acc: 0.97010, F1: 0.97010#####> Valid Avg loss: 4.46086, Acc:0.28828, F1: 0.28889
===> Epoch: 71: Training loss decreased (0.03379 --> 0.03054), Acc: (0.96804 --> 0.97010), F1: (0.96804 --> 0.97010).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 72 Train Avg loss: 0.02944, Acc: 0.97259, F1: 0.97259#####> Valid Avg loss: 4.48492, Acc:0.31565, F1: 0.31624
===> Epoch: 72: Training loss decreased (0.03054 --> 0.02944), Acc: (0.97010 --> 0.97259), F1: (0.97010 --> 0.97259).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 73 Train Avg loss: 0.02679, Acc: 0.97435, F1: 0.97435#####> Valid Avg loss: 4.53916, Acc:0.30197, F1: 0.30256
===> Epoch: 73: Training loss decreased (0.02944 --> 0.02679), Acc: (0.97259 --> 0.97435), F1: (0.97259 --> 0.97435).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 74 Train Avg loss: 0.02434, Acc: 0.97449, F1: 0.97449#####> Valid Avg loss: 4.69076, Acc:0.29256, F1: 0.29316
===> Epoch: 74: Training loss decreased (0.02679 --> 0.02434), Acc: (0.97435 --> 0.97449), F1: (0.97435 --> 0.97449).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 75 Train Avg loss: 0.02610, Acc: 0.97318, F1: 0.97318#####> Valid Avg loss: 4.55112, Acc:0.28743, F1: 0.28803
====> Epoch: 76 Train Avg loss: 0.02338, Acc: 0.97537, F1: 0.97537#####> Valid Avg loss: 4.61470, Acc:0.30026, F1: 0.30085
===> Epoch: 76: Training loss decreased (0.02434 --> 0.02338), Acc: (0.97449 --> 0.97537), F1: (0.97449 --> 0.97537).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 77 Train Avg loss: 0.02179, Acc: 0.97420, F1: 0.97420#####> Valid Avg loss: 4.52684, Acc:0.30282, F1: 0.30342
===> Epoch: 77: Training loss decreased (0.02338 --> 0.02179), Acc: (0.97537 --> 0.97420), F1: (0.97537 --> 0.97420).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 78 Train Avg loss: 0.02119, Acc: 0.97728, F1: 0.97728#####> Valid Avg loss: 4.75031, Acc:0.27973, F1: 0.28034
===> Epoch: 78: Training loss decreased (0.02179 --> 0.02119), Acc: (0.97420 --> 0.97728), F1: (0.97420 --> 0.97728).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 79 Train Avg loss: 0.02103, Acc: 0.97449, F1: 0.97449#####> Valid Avg loss: 4.74531, Acc:0.30111, F1: 0.30171
===> Epoch: 79: Training loss decreased (0.02119 --> 0.02103), Acc: (0.97728 --> 0.97449), F1: (0.97728 --> 0.97449).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 80 Train Avg loss: 0.01983, Acc: 0.97757, F1: 0.97757#####> Valid Avg loss: 4.86275, Acc:0.31737, F1: 0.31795
===> Epoch: 80: Training loss decreased (0.02103 --> 0.01983), Acc: (0.97449 --> 0.97757), F1: (0.97449 --> 0.97757).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 81 Train Avg loss: 0.01925, Acc: 0.97728, F1: 0.97728#####> Valid Avg loss: 4.80874, Acc:0.30967, F1: 0.31026
===> Epoch: 81: Training loss decreased (0.01983 --> 0.01925), Acc: (0.97757 --> 0.97728), F1: (0.97757 --> 0.97728).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 82 Train Avg loss: 0.01809, Acc: 0.97464, F1: 0.97464#####> Valid Avg loss: 4.89516, Acc:0.30539, F1: 0.30598
===> Epoch: 82: Training loss decreased (0.01925 --> 0.01809), Acc: (0.97728 --> 0.97464), F1: (0.97728 --> 0.97464).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 83 Train Avg loss: 0.01786, Acc: 0.97860, F1: 0.97860#####> Valid Avg loss: 4.66422, Acc:0.29683, F1: 0.29744
===> Epoch: 83: Training loss decreased (0.01809 --> 0.01786), Acc: (0.97464 --> 0.97860), F1: (0.97464 --> 0.97860).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 84 Train Avg loss: 0.01732, Acc: 0.97787, F1: 0.97787#####> Valid Avg loss: 4.62474, Acc:0.29683, F1: 0.29744
===> Epoch: 84: Training loss decreased (0.01786 --> 0.01732), Acc: (0.97860 --> 0.97787), F1: (0.97860 --> 0.97787).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 85 Train Avg loss: 0.01720, Acc: 0.97743, F1: 0.97743#####> Valid Avg loss: 4.80292, Acc:0.29598, F1: 0.29658
===> Epoch: 85: Training loss decreased (0.01732 --> 0.01720), Acc: (0.97787 --> 0.97743), F1: (0.97787 --> 0.97743).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 86 Train Avg loss: 0.01579, Acc: 0.97977, F1: 0.97977#####> Valid Avg loss: 4.80329, Acc:0.30710, F1: 0.30769
===> Epoch: 86: Training loss decreased (0.01720 --> 0.01579), Acc: (0.97743 --> 0.97977), F1: (0.97743 --> 0.97977).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 87 Train Avg loss: 0.01639, Acc: 0.97713, F1: 0.97713#####> Valid Avg loss: 4.94329, Acc:0.31993, F1: 0.32051
====> Epoch: 88 Train Avg loss: 0.01570, Acc: 0.97919, F1: 0.97918#####> Valid Avg loss: 4.79732, Acc:0.30881, F1: 0.30940
===> Epoch: 88: Training loss decreased (0.01579 --> 0.01570), Acc: (0.97977 --> 0.97919), F1: (0.97977 --> 0.97918).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 89 Train Avg loss: 0.01566, Acc: 0.97787, F1: 0.97787#####> Valid Avg loss: 4.88029, Acc:0.31223, F1: 0.31282
===> Epoch: 89: Training loss decreased (0.01570 --> 0.01566), Acc: (0.97919 --> 0.97787), F1: (0.97918 --> 0.97787).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 90 Train Avg loss: 0.01514, Acc: 0.97787, F1: 0.97787#####> Valid Avg loss: 5.03317, Acc:0.30796, F1: 0.30855
===> Epoch: 90: Training loss decreased (0.01566 --> 0.01514), Acc: (0.97787 --> 0.97787), F1: (0.97787 --> 0.97787).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 91 Train Avg loss: 0.01497, Acc: 0.97757, F1: 0.97757#####> Valid Avg loss: 4.96450, Acc:0.30539, F1: 0.30598
===> Epoch: 91: Training loss decreased (0.01514 --> 0.01497), Acc: (0.97787 --> 0.97757), F1: (0.97787 --> 0.97757).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 92 Train Avg loss: 0.01483, Acc: 0.97875, F1: 0.97875#####> Valid Avg loss: 5.00823, Acc:0.30881, F1: 0.30940
===> Epoch: 92: Training loss decreased (0.01497 --> 0.01483), Acc: (0.97757 --> 0.97875), F1: (0.97757 --> 0.97875).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 93 Train Avg loss: 0.01454, Acc: 0.97728, F1: 0.97728#####> Valid Avg loss: 5.00551, Acc:0.30453, F1: 0.30513
===> Epoch: 93: Training loss decreased (0.01483 --> 0.01454), Acc: (0.97875 --> 0.97728), F1: (0.97875 --> 0.97728).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 94 Train Avg loss: 0.01448, Acc: 0.97889, F1: 0.97889#####> Valid Avg loss: 4.99986, Acc:0.30796, F1: 0.30855
===> Epoch: 94: Training loss decreased (0.01454 --> 0.01448), Acc: (0.97728 --> 0.97889), F1: (0.97728 --> 0.97889).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 95 Train Avg loss: 0.01401, Acc: 0.98080, F1: 0.98080#####> Valid Avg loss: 4.98044, Acc:0.30881, F1: 0.30940
===> Epoch: 95: Training loss decreased (0.01448 --> 0.01401), Acc: (0.97889 --> 0.98080), F1: (0.97889 --> 0.98080).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595964695.310983.pth_1
====> Epoch: 96 Train Avg loss: 0.01402, Acc: 0.97948, F1: 0.97948#####> Valid Avg loss: 4.92978, Acc:0.30967, F1: 0.31026
====> Epoch: 97 Train Avg loss: 0.01396, Acc: 0.98050, F1: 0.98050validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595978730.021355.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 8train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 2650
valid_dataloader len: 562
test_dataloader len: 531
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5300, train dataloader len: 2650
valid dataset len: 1124, valid dataloader len: 562
valid dataset len: 1062, test dataloader len: 562
====> Epoch: 1 Train Avg loss: 0.73229, Acc: 0.52094, F1: 0.52094#####> Valid Avg loss: 0.88710, Acc:0.40569, F1: 0.40569
===> Epoch: 1: Training loss decreased (inf --> 0.73229), Acc: (0.00000 --> 0.52094), F1: (0.00000 --> 0.52094).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.88710), Acc: (0.00000 --> 0.40569), F1: (0.00000 --> 0.40569).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.88710), Acc: (0.00000 --> 0.40569), F1: (0.00000 --> 0.40569).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 2 Train Avg loss: 0.61073, Acc: 0.59736, F1: 0.59736#####> Valid Avg loss: 1.04082, Acc:0.40569, F1: 0.40569
===> Epoch: 2: Training loss decreased (0.73229 --> 0.61073), Acc: (0.52094 --> 0.59736), F1: (0.52094 --> 0.59736).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 3 Train Avg loss: 0.56982, Acc: 0.61774, F1: 0.61774#####> Valid Avg loss: 1.05491, Acc:0.40569, F1: 0.40569
===> Epoch: 3: Training loss decreased (0.61073 --> 0.56982), Acc: (0.59736 --> 0.61774), F1: (0.59736 --> 0.61774).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 4 Train Avg loss: 0.53818, Acc: 0.63283, F1: 0.63283#####> Valid Avg loss: 1.13039, Acc:0.40214, F1: 0.40214
===> Epoch: 4: Training loss decreased (0.56982 --> 0.53818), Acc: (0.61774 --> 0.63283), F1: (0.61774 --> 0.63283).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 5 Train Avg loss: 0.51797, Acc: 0.63887, F1: 0.63887#####> Valid Avg loss: 1.11540, Acc:0.40569, F1: 0.40569
===> Epoch: 5: Training loss decreased (0.53818 --> 0.51797), Acc: (0.63283 --> 0.63887), F1: (0.63283 --> 0.63887).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 6 Train Avg loss: 0.50676, Acc: 0.64604, F1: 0.64604#####> Valid Avg loss: 0.95748, Acc:0.40036, F1: 0.40036
===> Epoch: 6: Training loss decreased (0.51797 --> 0.50676), Acc: (0.63887 --> 0.64604), F1: (0.63887 --> 0.64604).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 7 Train Avg loss: 0.49294, Acc: 0.65528, F1: 0.65528#####> Valid Avg loss: 1.06682, Acc:0.39413, F1: 0.39413
===> Epoch: 7: Training loss decreased (0.50676 --> 0.49294), Acc: (0.64604 --> 0.65528), F1: (0.64604 --> 0.65528).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 8 Train Avg loss: 0.47891, Acc: 0.66302, F1: 0.66302#####> Valid Avg loss: 1.11711, Acc:0.40569, F1: 0.40569
===> Epoch: 8: Training loss decreased (0.49294 --> 0.47891), Acc: (0.65528 --> 0.66302), F1: (0.65528 --> 0.66302).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 9 Train Avg loss: 0.47008, Acc: 0.66811, F1: 0.66811#####> Valid Avg loss: 1.01935, Acc:0.38968, F1: 0.38968
===> Epoch: 9: Training loss decreased (0.47891 --> 0.47008), Acc: (0.66302 --> 0.66811), F1: (0.66302 --> 0.66811).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 10 Train Avg loss: 0.46154, Acc: 0.67170, F1: 0.67170#####> Valid Avg loss: 0.98539, Acc:0.39413, F1: 0.39413
===> Epoch: 10: Training loss decreased (0.47008 --> 0.46154), Acc: (0.66811 --> 0.67170), F1: (0.66811 --> 0.67170).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 11 Train Avg loss: 0.45431, Acc: 0.68264, F1: 0.68264#####> Valid Avg loss: 1.10803, Acc:0.39502, F1: 0.39502
===> Epoch: 11: Training loss decreased (0.46154 --> 0.45431), Acc: (0.67170 --> 0.68264), F1: (0.67170 --> 0.68264).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 12 Train Avg loss: 0.44421, Acc: 0.68491, F1: 0.68491#####> Valid Avg loss: 1.06459, Acc:0.35765, F1: 0.35765
===> Epoch: 12: Training loss decreased (0.45431 --> 0.44421), Acc: (0.68264 --> 0.68491), F1: (0.68264 --> 0.68491).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 13 Train Avg loss: 0.43884, Acc: 0.68509, F1: 0.68509#####> Valid Avg loss: 1.09882, Acc:0.38167, F1: 0.38167
===> Epoch: 13: Training loss decreased (0.44421 --> 0.43884), Acc: (0.68491 --> 0.68509), F1: (0.68491 --> 0.68509).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 14 Train Avg loss: 0.42801, Acc: 0.68660, F1: 0.68660#####> Valid Avg loss: 1.10302, Acc:0.39502, F1: 0.39502
===> Epoch: 14: Training loss decreased (0.43884 --> 0.42801), Acc: (0.68509 --> 0.68660), F1: (0.68509 --> 0.68660).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 15 Train Avg loss: 0.42575, Acc: 0.69132, F1: 0.69132#####> Valid Avg loss: 1.06804, Acc:0.38612, F1: 0.38612
===> Epoch: 15: Training loss decreased (0.42801 --> 0.42575), Acc: (0.68660 --> 0.69132), F1: (0.68660 --> 0.69132).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 16 Train Avg loss: 0.42014, Acc: 0.70094, F1: 0.70094#####> Valid Avg loss: 1.15832, Acc:0.39057, F1: 0.39057
===> Epoch: 16: Training loss decreased (0.42575 --> 0.42014), Acc: (0.69132 --> 0.70094), F1: (0.69132 --> 0.70094).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 17 Train Avg loss: 0.41268, Acc: 0.70283, F1: 0.70283#####> Valid Avg loss: 1.20172, Acc:0.40569, F1: 0.40569
===> Epoch: 17: Training loss decreased (0.42014 --> 0.41268), Acc: (0.70094 --> 0.70283), F1: (0.70094 --> 0.70283).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 18 Train Avg loss: 0.39919, Acc: 0.70925, F1: 0.70925#####> Valid Avg loss: 1.17842, Acc:0.39057, F1: 0.39057
===> Epoch: 18: Training loss decreased (0.41268 --> 0.39919), Acc: (0.70283 --> 0.70925), F1: (0.70283 --> 0.70925).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 19 Train Avg loss: 0.40790, Acc: 0.70472, F1: 0.70472#####> Valid Avg loss: 1.17225, Acc:0.35854, F1: 0.35854
====> Epoch: 20 Train Avg loss: 0.39653, Acc: 0.71774, F1: 0.71774#####> Valid Avg loss: 1.39262, Acc:0.40480, F1: 0.40480
===> Epoch: 20: Training loss decreased (0.39919 --> 0.39653), Acc: (0.70925 --> 0.71774), F1: (0.70925 --> 0.71774).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 21 Train Avg loss: 0.38567, Acc: 0.71962, F1: 0.71962#####> Valid Avg loss: 1.25709, Acc:0.40480, F1: 0.40480
===> Epoch: 21: Training loss decreased (0.39653 --> 0.38567), Acc: (0.71774 --> 0.71962), F1: (0.71774 --> 0.71962).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 22 Train Avg loss: 0.38246, Acc: 0.72849, F1: 0.72849#####> Valid Avg loss: 1.24119, Acc:0.39858, F1: 0.39858
===> Epoch: 22: Training loss decreased (0.38567 --> 0.38246), Acc: (0.71962 --> 0.72849), F1: (0.71962 --> 0.72849).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 23 Train Avg loss: 0.37502, Acc: 0.73132, F1: 0.73132#####> Valid Avg loss: 1.28700, Acc:0.40569, F1: 0.40569
===> Epoch: 23: Training loss decreased (0.38246 --> 0.37502), Acc: (0.72849 --> 0.73132), F1: (0.72849 --> 0.73132).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 24 Train Avg loss: 0.37148, Acc: 0.73038, F1: 0.73038#####> Valid Avg loss: 1.37897, Acc:0.39858, F1: 0.39858
===> Epoch: 24: Training loss decreased (0.37502 --> 0.37148), Acc: (0.73132 --> 0.73038), F1: (0.73132 --> 0.73038).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 25 Train Avg loss: 0.36075, Acc: 0.73981, F1: 0.73981#####> Valid Avg loss: 1.23108, Acc:0.36922, F1: 0.36922
===> Epoch: 25: Training loss decreased (0.37148 --> 0.36075), Acc: (0.73038 --> 0.73981), F1: (0.73038 --> 0.73981).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 26 Train Avg loss: 0.35929, Acc: 0.73566, F1: 0.73566#####> Valid Avg loss: 1.36213, Acc:0.39502, F1: 0.39502
===> Epoch: 26: Training loss decreased (0.36075 --> 0.35929), Acc: (0.73981 --> 0.73566), F1: (0.73981 --> 0.73566).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 27 Train Avg loss: 0.35049, Acc: 0.74038, F1: 0.74038#####> Valid Avg loss: 1.52473, Acc:0.38523, F1: 0.38523
===> Epoch: 27: Training loss decreased (0.35929 --> 0.35049), Acc: (0.73566 --> 0.74038), F1: (0.73566 --> 0.74038).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 28 Train Avg loss: 0.34862, Acc: 0.74113, F1: 0.74113#####> Valid Avg loss: 1.37232, Acc:0.37722, F1: 0.37722
===> Epoch: 28: Training loss decreased (0.35049 --> 0.34862), Acc: (0.74038 --> 0.74113), F1: (0.74038 --> 0.74113).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 29 Train Avg loss: 0.33794, Acc: 0.74887, F1: 0.74887#####> Valid Avg loss: 1.46758, Acc:0.39858, F1: 0.39858
===> Epoch: 29: Training loss decreased (0.34862 --> 0.33794), Acc: (0.74113 --> 0.74887), F1: (0.74113 --> 0.74887).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 30 Train Avg loss: 0.32680, Acc: 0.75396, F1: 0.75396#####> Valid Avg loss: 1.28888, Acc:0.34164, F1: 0.34164
===> Epoch: 30: Training loss decreased (0.33794 --> 0.32680), Acc: (0.74887 --> 0.75396), F1: (0.74887 --> 0.75396).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 31 Train Avg loss: 0.32891, Acc: 0.75491, F1: 0.75491#####> Valid Avg loss: 1.36330, Acc:0.37278, F1: 0.37278
====> Epoch: 32 Train Avg loss: 0.30672, Acc: 0.77189, F1: 0.77189#####> Valid Avg loss: 1.55744, Acc:0.37989, F1: 0.37989
===> Epoch: 32: Training loss decreased (0.32680 --> 0.30672), Acc: (0.75396 --> 0.77189), F1: (0.75396 --> 0.77189).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 33 Train Avg loss: 0.30709, Acc: 0.76943, F1: 0.76943#####> Valid Avg loss: 1.55284, Acc:0.40302, F1: 0.40302
====> Epoch: 34 Train Avg loss: 0.29372, Acc: 0.77736, F1: 0.77736#####> Valid Avg loss: 1.68832, Acc:0.38523, F1: 0.38523
===> Epoch: 34: Training loss decreased (0.30672 --> 0.29372), Acc: (0.77189 --> 0.77736), F1: (0.77189 --> 0.77736).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 35 Train Avg loss: 0.29276, Acc: 0.77038, F1: 0.77038#####> Valid Avg loss: 1.44301, Acc:0.35676, F1: 0.35676
===> Epoch: 35: Training loss decreased (0.29372 --> 0.29276), Acc: (0.77736 --> 0.77038), F1: (0.77736 --> 0.77038).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 36 Train Avg loss: 0.28022, Acc: 0.78830, F1: 0.78830#####> Valid Avg loss: 1.34405, Acc:0.34431, F1: 0.34431
===> Epoch: 36: Training loss decreased (0.29276 --> 0.28022), Acc: (0.77038 --> 0.78830), F1: (0.77038 --> 0.78830).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 37 Train Avg loss: 0.27390, Acc: 0.79189, F1: 0.79189#####> Valid Avg loss: 1.59402, Acc:0.37989, F1: 0.37989
===> Epoch: 37: Training loss decreased (0.28022 --> 0.27390), Acc: (0.78830 --> 0.79189), F1: (0.78830 --> 0.79189).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 38 Train Avg loss: 0.26651, Acc: 0.79189, F1: 0.79189#####> Valid Avg loss: 1.50997, Acc:0.39057, F1: 0.39057
===> Epoch: 38: Training loss decreased (0.27390 --> 0.26651), Acc: (0.79189 --> 0.79189), F1: (0.79189 --> 0.79189).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 39 Train Avg loss: 0.25394, Acc: 0.80075, F1: 0.80075#####> Valid Avg loss: 1.69488, Acc:0.35587, F1: 0.35587
===> Epoch: 39: Training loss decreased (0.26651 --> 0.25394), Acc: (0.79189 --> 0.80075), F1: (0.79189 --> 0.80075).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 40 Train Avg loss: 0.24500, Acc: 0.81453, F1: 0.81453#####> Valid Avg loss: 1.77178, Acc:0.38434, F1: 0.38434
===> Epoch: 40: Training loss decreased (0.25394 --> 0.24500), Acc: (0.80075 --> 0.81453), F1: (0.80075 --> 0.81453).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 41 Train Avg loss: 0.23263, Acc: 0.81906, F1: 0.81906#####> Valid Avg loss: 1.80995, Acc:0.33808, F1: 0.33808
===> Epoch: 41: Training loss decreased (0.24500 --> 0.23263), Acc: (0.81453 --> 0.81906), F1: (0.81453 --> 0.81906).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 42 Train Avg loss: 0.22674, Acc: 0.82566, F1: 0.82566#####> Valid Avg loss: 1.71132, Acc:0.33808, F1: 0.33808
===> Epoch: 42: Training loss decreased (0.23263 --> 0.22674), Acc: (0.81906 --> 0.82566), F1: (0.81906 --> 0.82566).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 43 Train Avg loss: 0.21093, Acc: 0.83774, F1: 0.83774#####> Valid Avg loss: 1.93229, Acc:0.37544, F1: 0.37544
===> Epoch: 43: Training loss decreased (0.22674 --> 0.21093), Acc: (0.82566 --> 0.83774), F1: (0.82566 --> 0.83774).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 44 Train Avg loss: 0.20368, Acc: 0.84170, F1: 0.84170#####> Valid Avg loss: 2.13047, Acc:0.37278, F1: 0.37278
===> Epoch: 44: Training loss decreased (0.21093 --> 0.20368), Acc: (0.83774 --> 0.84170), F1: (0.83774 --> 0.84170).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 45 Train Avg loss: 0.19070, Acc: 0.85264, F1: 0.85264#####> Valid Avg loss: 2.00576, Acc:0.34342, F1: 0.34342
===> Epoch: 45: Training loss decreased (0.20368 --> 0.19070), Acc: (0.84170 --> 0.85264), F1: (0.84170 --> 0.85264).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 46 Train Avg loss: 0.17518, Acc: 0.86321, F1: 0.86321#####> Valid Avg loss: 2.27175, Acc:0.31584, F1: 0.31584
===> Epoch: 46: Training loss decreased (0.19070 --> 0.17518), Acc: (0.85264 --> 0.86321), F1: (0.85264 --> 0.86321).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 47 Train Avg loss: 0.16047, Acc: 0.86642, F1: 0.86642#####> Valid Avg loss: 2.22164, Acc:0.34164, F1: 0.34164
===> Epoch: 47: Training loss decreased (0.17518 --> 0.16047), Acc: (0.86321 --> 0.86642), F1: (0.86321 --> 0.86642).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 48 Train Avg loss: 0.15218, Acc: 0.87849, F1: 0.87849#####> Valid Avg loss: 2.27682, Acc:0.34609, F1: 0.34609
===> Epoch: 48: Training loss decreased (0.16047 --> 0.15218), Acc: (0.86642 --> 0.87849), F1: (0.86642 --> 0.87849).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 49 Train Avg loss: 0.14623, Acc: 0.88038, F1: 0.88038#####> Valid Avg loss: 2.57536, Acc:0.37100, F1: 0.37100
===> Epoch: 49: Training loss decreased (0.15218 --> 0.14623), Acc: (0.87849 --> 0.88038), F1: (0.87849 --> 0.88038).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 50 Train Avg loss: 0.13527, Acc: 0.88736, F1: 0.88736#####> Valid Avg loss: 2.32964, Acc:0.34964, F1: 0.34964
===> Epoch: 50: Training loss decreased (0.14623 --> 0.13527), Acc: (0.88038 --> 0.88736), F1: (0.88038 --> 0.88736).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 51 Train Avg loss: 0.13152, Acc: 0.89226, F1: 0.89226#####> Valid Avg loss: 2.44058, Acc:0.33541, F1: 0.33541
===> Epoch: 51: Training loss decreased (0.13527 --> 0.13152), Acc: (0.88736 --> 0.89226), F1: (0.88736 --> 0.89226).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 52 Train Avg loss: 0.11411, Acc: 0.90981, F1: 0.90981#####> Valid Avg loss: 2.68410, Acc:0.31228, F1: 0.31228
===> Epoch: 52: Training loss decreased (0.13152 --> 0.11411), Acc: (0.89226 --> 0.90981), F1: (0.89226 --> 0.90981).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 53 Train Avg loss: 0.10787, Acc: 0.91358, F1: 0.91358#####> Valid Avg loss: 2.61144, Acc:0.34431, F1: 0.34431
===> Epoch: 53: Training loss decreased (0.11411 --> 0.10787), Acc: (0.90981 --> 0.91358), F1: (0.90981 --> 0.91358).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 54 Train Avg loss: 0.09963, Acc: 0.91547, F1: 0.91547#####> Valid Avg loss: 2.91062, Acc:0.34964, F1: 0.34964
===> Epoch: 54: Training loss decreased (0.10787 --> 0.09963), Acc: (0.91358 --> 0.91547), F1: (0.91358 --> 0.91547).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 55 Train Avg loss: 0.09563, Acc: 0.92075, F1: 0.92075#####> Valid Avg loss: 3.00503, Acc:0.31495, F1: 0.31495
===> Epoch: 55: Training loss decreased (0.09963 --> 0.09563), Acc: (0.91547 --> 0.92075), F1: (0.91547 --> 0.92075).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 56 Train Avg loss: 0.08634, Acc: 0.92906, F1: 0.92906#####> Valid Avg loss: 2.98455, Acc:0.32829, F1: 0.32829
===> Epoch: 56: Training loss decreased (0.09563 --> 0.08634), Acc: (0.92075 --> 0.92906), F1: (0.92075 --> 0.92906).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 57 Train Avg loss: 0.07819, Acc: 0.93302, F1: 0.93302#####> Valid Avg loss: 2.78539, Acc:0.30249, F1: 0.30249
===> Epoch: 57: Training loss decreased (0.08634 --> 0.07819), Acc: (0.92906 --> 0.93302), F1: (0.92906 --> 0.93302).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 58 Train Avg loss: 0.06983, Acc: 0.93868, F1: 0.93868#####> Valid Avg loss: 2.92517, Acc:0.33541, F1: 0.33541
===> Epoch: 58: Training loss decreased (0.07819 --> 0.06983), Acc: (0.93302 --> 0.93868), F1: (0.93302 --> 0.93868).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 59 Train Avg loss: 0.06431, Acc: 0.94283, F1: 0.94283#####> Valid Avg loss: 2.98752, Acc:0.31673, F1: 0.31673
===> Epoch: 59: Training loss decreased (0.06983 --> 0.06431), Acc: (0.93868 --> 0.94283), F1: (0.93868 --> 0.94283).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 60 Train Avg loss: 0.05727, Acc: 0.94981, F1: 0.94981#####> Valid Avg loss: 3.25755, Acc:0.31762, F1: 0.31762
===> Epoch: 60: Training loss decreased (0.06431 --> 0.05727), Acc: (0.94283 --> 0.94981), F1: (0.94283 --> 0.94981).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 61 Train Avg loss: 0.05825, Acc: 0.94849, F1: 0.94849#####> Valid Avg loss: 2.98539, Acc:0.32740, F1: 0.32740
====> Epoch: 62 Train Avg loss: 0.05070, Acc: 0.95453, F1: 0.95453#####> Valid Avg loss: 3.26374, Acc:0.28292, F1: 0.28292
===> Epoch: 62: Training loss decreased (0.05727 --> 0.05070), Acc: (0.94981 --> 0.95453), F1: (0.94981 --> 0.95453).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 63 Train Avg loss: 0.04689, Acc: 0.95453, F1: 0.95453#####> Valid Avg loss: 3.48825, Acc:0.31495, F1: 0.31495
===> Epoch: 63: Training loss decreased (0.05070 --> 0.04689), Acc: (0.95453 --> 0.95453), F1: (0.95453 --> 0.95453).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 64 Train Avg loss: 0.04453, Acc: 0.95830, F1: 0.95830#####> Valid Avg loss: 3.56985, Acc:0.32740, F1: 0.32740
===> Epoch: 64: Training loss decreased (0.04689 --> 0.04453), Acc: (0.95453 --> 0.95830), F1: (0.95453 --> 0.95830).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 65 Train Avg loss: 0.03664, Acc: 0.96623, F1: 0.96623#####> Valid Avg loss: 3.66966, Acc:0.31762, F1: 0.31762
===> Epoch: 65: Training loss decreased (0.04453 --> 0.03664), Acc: (0.95830 --> 0.96623), F1: (0.95830 --> 0.96623).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 66 Train Avg loss: 0.03580, Acc: 0.96774, F1: 0.96774#####> Valid Avg loss: 3.71220, Acc:0.29715, F1: 0.29715
===> Epoch: 66: Training loss decreased (0.03664 --> 0.03580), Acc: (0.96623 --> 0.96774), F1: (0.96623 --> 0.96774).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 67 Train Avg loss: 0.03473, Acc: 0.96377, F1: 0.96377#####> Valid Avg loss: 3.79058, Acc:0.32740, F1: 0.32740
===> Epoch: 67: Training loss decreased (0.03580 --> 0.03473), Acc: (0.96774 --> 0.96377), F1: (0.96774 --> 0.96377).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 68 Train Avg loss: 0.03125, Acc: 0.96906, F1: 0.96906#####> Valid Avg loss: 4.07634, Acc:0.27847, F1: 0.27847
===> Epoch: 68: Training loss decreased (0.03473 --> 0.03125), Acc: (0.96377 --> 0.96906), F1: (0.96377 --> 0.96906).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 69 Train Avg loss: 0.03157, Acc: 0.97000, F1: 0.97000#####> Valid Avg loss: 3.95236, Acc:0.31673, F1: 0.31673
====> Epoch: 70 Train Avg loss: 0.03098, Acc: 0.96962, F1: 0.96962#####> Valid Avg loss: 3.96962, Acc:0.33363, F1: 0.33363
===> Epoch: 70: Training loss decreased (0.03125 --> 0.03098), Acc: (0.96906 --> 0.96962), F1: (0.96906 --> 0.96962).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 71 Train Avg loss: 0.02544, Acc: 0.97491, F1: 0.97491#####> Valid Avg loss: 3.92400, Acc:0.30160, F1: 0.30160
===> Epoch: 71: Training loss decreased (0.03098 --> 0.02544), Acc: (0.96962 --> 0.97491), F1: (0.96962 --> 0.97491).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 72 Train Avg loss: 0.02460, Acc: 0.97358, F1: 0.97358#####> Valid Avg loss: 4.00497, Acc:0.33452, F1: 0.33452
===> Epoch: 72: Training loss decreased (0.02544 --> 0.02460), Acc: (0.97491 --> 0.97358), F1: (0.97491 --> 0.97358).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 73 Train Avg loss: 0.02420, Acc: 0.97340, F1: 0.97340#####> Valid Avg loss: 3.97043, Acc:0.32028, F1: 0.32028
===> Epoch: 73: Training loss decreased (0.02460 --> 0.02420), Acc: (0.97358 --> 0.97340), F1: (0.97358 --> 0.97340).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 74 Train Avg loss: 0.02307, Acc: 0.97491, F1: 0.97491#####> Valid Avg loss: 3.76657, Acc:0.32473, F1: 0.32473
===> Epoch: 74: Training loss decreased (0.02420 --> 0.02307), Acc: (0.97340 --> 0.97491), F1: (0.97340 --> 0.97491).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 75 Train Avg loss: 0.02303, Acc: 0.97358, F1: 0.97358#####> Valid Avg loss: 4.02316, Acc:0.30605, F1: 0.30605
===> Epoch: 75: Training loss decreased (0.02307 --> 0.02303), Acc: (0.97491 --> 0.97358), F1: (0.97491 --> 0.97358).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 76 Train Avg loss: 0.02187, Acc: 0.97358, F1: 0.97358#####> Valid Avg loss: 3.98815, Acc:0.32473, F1: 0.32473
===> Epoch: 76: Training loss decreased (0.02303 --> 0.02187), Acc: (0.97358 --> 0.97358), F1: (0.97358 --> 0.97358).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 77 Train Avg loss: 0.02190, Acc: 0.97358, F1: 0.97358#####> Valid Avg loss: 4.31087, Acc:0.34609, F1: 0.34609
====> Epoch: 78 Train Avg loss: 0.02037, Acc: 0.97472, F1: 0.97472#####> Valid Avg loss: 4.16652, Acc:0.31228, F1: 0.31228
===> Epoch: 78: Training loss decreased (0.02187 --> 0.02037), Acc: (0.97358 --> 0.97472), F1: (0.97358 --> 0.97472).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 79 Train Avg loss: 0.01907, Acc: 0.97528, F1: 0.97528#####> Valid Avg loss: 4.36379, Acc:0.33452, F1: 0.33452
===> Epoch: 79: Training loss decreased (0.02037 --> 0.01907), Acc: (0.97472 --> 0.97528), F1: (0.97472 --> 0.97528).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 80 Train Avg loss: 0.01897, Acc: 0.97604, F1: 0.97604#####> Valid Avg loss: 4.17397, Acc:0.33274, F1: 0.33274
===> Epoch: 80: Training loss decreased (0.01907 --> 0.01897), Acc: (0.97528 --> 0.97604), F1: (0.97528 --> 0.97604).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 81 Train Avg loss: 0.01847, Acc: 0.97585, F1: 0.97585#####> Valid Avg loss: 3.96772, Acc:0.33808, F1: 0.33808
===> Epoch: 81: Training loss decreased (0.01897 --> 0.01847), Acc: (0.97604 --> 0.97585), F1: (0.97604 --> 0.97585).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 82 Train Avg loss: 0.01792, Acc: 0.97679, F1: 0.97679#####> Valid Avg loss: 4.32229, Acc:0.33096, F1: 0.33096
===> Epoch: 82: Training loss decreased (0.01847 --> 0.01792), Acc: (0.97585 --> 0.97679), F1: (0.97585 --> 0.97679).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 83 Train Avg loss: 0.01764, Acc: 0.97717, F1: 0.97717#####> Valid Avg loss: 4.23627, Acc:0.33452, F1: 0.33452
===> Epoch: 83: Training loss decreased (0.01792 --> 0.01764), Acc: (0.97679 --> 0.97717), F1: (0.97679 --> 0.97717).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 84 Train Avg loss: 0.01692, Acc: 0.97774, F1: 0.97774#####> Valid Avg loss: 4.32341, Acc:0.33808, F1: 0.33808
===> Epoch: 84: Training loss decreased (0.01764 --> 0.01692), Acc: (0.97717 --> 0.97774), F1: (0.97717 --> 0.97774).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 85 Train Avg loss: 0.01705, Acc: 0.97358, F1: 0.97358#####> Valid Avg loss: 4.32145, Acc:0.33541, F1: 0.33541
====> Epoch: 86 Train Avg loss: 0.01644, Acc: 0.97642, F1: 0.97642#####> Valid Avg loss: 4.12734, Acc:0.33185, F1: 0.33185
===> Epoch: 86: Training loss decreased (0.01692 --> 0.01644), Acc: (0.97774 --> 0.97642), F1: (0.97774 --> 0.97642).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 87 Train Avg loss: 0.01624, Acc: 0.97698, F1: 0.97698#####> Valid Avg loss: 4.29487, Acc:0.33007, F1: 0.33007
===> Epoch: 87: Training loss decreased (0.01644 --> 0.01624), Acc: (0.97642 --> 0.97698), F1: (0.97642 --> 0.97698).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 88 Train Avg loss: 0.01585, Acc: 0.97736, F1: 0.97736#####> Valid Avg loss: 4.44656, Acc:0.32740, F1: 0.32740
===> Epoch: 88: Training loss decreased (0.01624 --> 0.01585), Acc: (0.97698 --> 0.97736), F1: (0.97698 --> 0.97736).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 89 Train Avg loss: 0.01565, Acc: 0.97830, F1: 0.97830#####> Valid Avg loss: 4.48974, Acc:0.33541, F1: 0.33541
===> Epoch: 89: Training loss decreased (0.01585 --> 0.01565), Acc: (0.97736 --> 0.97830), F1: (0.97736 --> 0.97830).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 90 Train Avg loss: 0.01570, Acc: 0.97755, F1: 0.97755#####> Valid Avg loss: 4.46228, Acc:0.33541, F1: 0.33541
====> Epoch: 91 Train Avg loss: 0.01542, Acc: 0.97698, F1: 0.97698#####> Valid Avg loss: 4.40072, Acc:0.34164, F1: 0.34164
===> Epoch: 91: Training loss decreased (0.01565 --> 0.01542), Acc: (0.97830 --> 0.97698), F1: (0.97830 --> 0.97698).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 92 Train Avg loss: 0.01516, Acc: 0.97774, F1: 0.97774#####> Valid Avg loss: 4.35866, Acc:0.33719, F1: 0.33719
===> Epoch: 92: Training loss decreased (0.01542 --> 0.01516), Acc: (0.97698 --> 0.97774), F1: (0.97698 --> 0.97774).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 93 Train Avg loss: 0.01505, Acc: 0.97925, F1: 0.97925#####> Valid Avg loss: 4.41545, Acc:0.33986, F1: 0.33986
===> Epoch: 93: Training loss decreased (0.01516 --> 0.01505), Acc: (0.97774 --> 0.97925), F1: (0.97774 --> 0.97925).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 94 Train Avg loss: 0.01497, Acc: 0.97943, F1: 0.97943#####> Valid Avg loss: 4.53481, Acc:0.33719, F1: 0.33719
===> Epoch: 94: Training loss decreased (0.01505 --> 0.01497), Acc: (0.97925 --> 0.97943), F1: (0.97925 --> 0.97943).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
====> Epoch: 95 Train Avg loss: 0.01473, Acc: 0.97962, F1: 0.97962#####> Valid Avg loss: 4.42383, Acc:0.33808, F1: 0.33808
===> Epoch: 95: Training loss decreased (0.01497 --> 0.01473), Acc: (0.97943 --> 0.97962), F1: (0.97943 --> 0.97962).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595978762.058738.pth_1
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 2591
valid_dataloader len: 561
test_dataloader len: 525
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 2591
valid dataset len: 1121, valid dataloader len: 561
valid dataset len: 1050, test dataloader len: 561
====> Epoch: 1 Train Avg loss: 0.70041, Acc: 0.52007, F1: 0.52007#####> Valid Avg loss: 0.87073, Acc:0.39697, F1: 0.39661
===> Epoch: 1: Training loss decreased (inf --> 0.70041), Acc: (0.00000 --> 0.52007), F1: (0.00000 --> 0.52007).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.87073), Acc: (0.00000 --> 0.39697), F1: (0.00000 --> 0.39661).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.87073), Acc: (0.00000 --> 0.39697), F1: (0.00000 --> 0.39661).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 2 Train Avg loss: 0.58107, Acc: 0.61308, F1: 0.61308#####> Valid Avg loss: 0.94169, Acc:0.40410, F1: 0.40374
===> Epoch: 2: Training loss decreased (0.70041 --> 0.58107), Acc: (0.52007 --> 0.61308), F1: (0.52007 --> 0.61308).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1

####> Epoch: 2: validation acc increase (0.87073 --> 0.94169), Acc: (0.39697 --> 0.40410), F1: (0.39661 --> 0.40374).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 3 Train Avg loss: 0.54372, Acc: 0.63875, F1: 0.63875#####> Valid Avg loss: 0.91221, Acc:0.40678, F1: 0.40642
===> Epoch: 3: Training loss decreased (0.58107 --> 0.54372), Acc: (0.61308 --> 0.63875), F1: (0.61308 --> 0.63875).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1

####> Epoch: 3: validation acc increase (0.94169 --> 0.91221), Acc: (0.40410 --> 0.40678), F1: (0.40374 --> 0.40642).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 4 Train Avg loss: 0.52539, Acc: 0.63991, F1: 0.63991#####> Valid Avg loss: 1.12184, Acc:0.40678, F1: 0.40642
===> Epoch: 4: Training loss decreased (0.54372 --> 0.52539), Acc: (0.63875 --> 0.63991), F1: (0.63875 --> 0.63991).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 5 Train Avg loss: 0.50271, Acc: 0.65399, F1: 0.65399#####> Valid Avg loss: 0.86995, Acc:0.40589, F1: 0.40553
===> Epoch: 5: Training loss decreased (0.52539 --> 0.50271), Acc: (0.63991 --> 0.65399), F1: (0.63991 --> 0.65399).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1

####> Epoch: 5: validation loss decreased (0.87073 --> 0.86995), Acc: (0.39697 --> 0.40589), F1: (0.39661 --> 0.40553).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 6 Train Avg loss: 0.49172, Acc: 0.66345, F1: 0.66345#####> Valid Avg loss: 1.07125, Acc:0.40767, F1: 0.40731
===> Epoch: 6: Training loss decreased (0.50271 --> 0.49172), Acc: (0.65399 --> 0.66345), F1: (0.65399 --> 0.66345).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1

####> Epoch: 6: validation acc increase (0.91221 --> 1.07125), Acc: (0.40678 --> 0.40767), F1: (0.40642 --> 0.40731).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 7 Train Avg loss: 0.47452, Acc: 0.66943, F1: 0.66943#####> Valid Avg loss: 0.93673, Acc:0.40143, F1: 0.40107
===> Epoch: 7: Training loss decreased (0.49172 --> 0.47452), Acc: (0.66345 --> 0.66943), F1: (0.66345 --> 0.66943).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 8 Train Avg loss: 0.46670, Acc: 0.67252, F1: 0.67252#####> Valid Avg loss: 0.95161, Acc:0.39251, F1: 0.39216
===> Epoch: 8: Training loss decreased (0.47452 --> 0.46670), Acc: (0.66943 --> 0.67252), F1: (0.66943 --> 0.67252).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 9 Train Avg loss: 0.45698, Acc: 0.67252, F1: 0.67252#####> Valid Avg loss: 1.09437, Acc:0.40589, F1: 0.40553
===> Epoch: 9: Training loss decreased (0.46670 --> 0.45698), Acc: (0.67252 --> 0.67252), F1: (0.67252 --> 0.67252).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 10 Train Avg loss: 0.44734, Acc: 0.68063, F1: 0.68063#####> Valid Avg loss: 1.01388, Acc:0.40589, F1: 0.40553
===> Epoch: 10: Training loss decreased (0.45698 --> 0.44734), Acc: (0.67252 --> 0.68063), F1: (0.67252 --> 0.68063).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 11 Train Avg loss: 0.44272, Acc: 0.68352, F1: 0.68352#####> Valid Avg loss: 1.12349, Acc:0.40678, F1: 0.40642
===> Epoch: 11: Training loss decreased (0.44734 --> 0.44272), Acc: (0.68063 --> 0.68352), F1: (0.68063 --> 0.68352).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 12 Train Avg loss: 0.43579, Acc: 0.69105, F1: 0.69105#####> Valid Avg loss: 1.06344, Acc:0.41035, F1: 0.40998
===> Epoch: 12: Training loss decreased (0.44272 --> 0.43579), Acc: (0.68352 --> 0.69105), F1: (0.68352 --> 0.69105).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1

####> Epoch: 12: validation acc increase (1.07125 --> 1.06344), Acc: (0.40767 --> 0.41035), F1: (0.40731 --> 0.40998).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 13 Train Avg loss: 0.43057, Acc: 0.69182, F1: 0.69182#####> Valid Avg loss: 1.20840, Acc:0.40678, F1: 0.40642
===> Epoch: 13: Training loss decreased (0.43579 --> 0.43057), Acc: (0.69105 --> 0.69182), F1: (0.69105 --> 0.69182).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 14 Train Avg loss: 0.42581, Acc: 0.69413, F1: 0.69413#####> Valid Avg loss: 1.24278, Acc:0.40678, F1: 0.40642
===> Epoch: 14: Training loss decreased (0.43057 --> 0.42581), Acc: (0.69182 --> 0.69413), F1: (0.69182 --> 0.69413).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 15 Train Avg loss: 0.42345, Acc: 0.69973, F1: 0.69973#####> Valid Avg loss: 1.11142, Acc:0.39161, F1: 0.39127
===> Epoch: 15: Training loss decreased (0.42581 --> 0.42345), Acc: (0.69413 --> 0.69973), F1: (0.69413 --> 0.69973).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 16 Train Avg loss: 0.41870, Acc: 0.70417, F1: 0.70417#####> Valid Avg loss: 1.08343, Acc:0.40589, F1: 0.40553
===> Epoch: 16: Training loss decreased (0.42345 --> 0.41870), Acc: (0.69973 --> 0.70417), F1: (0.69973 --> 0.70417).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 17 Train Avg loss: 0.41486, Acc: 0.69934, F1: 0.69934#####> Valid Avg loss: 1.10324, Acc:0.39964, F1: 0.39929
===> Epoch: 17: Training loss decreased (0.41870 --> 0.41486), Acc: (0.70417 --> 0.69934), F1: (0.70417 --> 0.69934).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 18 Train Avg loss: 0.40792, Acc: 0.71343, F1: 0.71343#####> Valid Avg loss: 1.16057, Acc:0.40232, F1: 0.40196
===> Epoch: 18: Training loss decreased (0.41486 --> 0.40792), Acc: (0.69934 --> 0.71343), F1: (0.69934 --> 0.71343).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 19 Train Avg loss: 0.40202, Acc: 0.70976, F1: 0.70976#####> Valid Avg loss: 1.29668, Acc:0.40500, F1: 0.40463
===> Epoch: 19: Training loss decreased (0.40792 --> 0.40202), Acc: (0.71343 --> 0.70976), F1: (0.71343 --> 0.70976).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 20 Train Avg loss: 0.39359, Acc: 0.71440, F1: 0.71440#####> Valid Avg loss: 1.24385, Acc:0.40232, F1: 0.40196
===> Epoch: 20: Training loss decreased (0.40202 --> 0.39359), Acc: (0.70976 --> 0.71440), F1: (0.70976 --> 0.71440).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 21 Train Avg loss: 0.39422, Acc: 0.71768, F1: 0.71768#####> Valid Avg loss: 1.30817, Acc:0.40678, F1: 0.40642
====> Epoch: 22 Train Avg loss: 0.38662, Acc: 0.72655, F1: 0.72655#####> Valid Avg loss: 1.20114, Acc:0.40589, F1: 0.40553
===> Epoch: 22: Training loss decreased (0.39359 --> 0.38662), Acc: (0.71440 --> 0.72655), F1: (0.71440 --> 0.72655).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 23 Train Avg loss: 0.38377, Acc: 0.72559, F1: 0.72559#####> Valid Avg loss: 1.22097, Acc:0.40054, F1: 0.40018
===> Epoch: 23: Training loss decreased (0.38662 --> 0.38377), Acc: (0.72655 --> 0.72559), F1: (0.72655 --> 0.72559).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 24 Train Avg loss: 0.38364, Acc: 0.72327, F1: 0.72327#####> Valid Avg loss: 1.30720, Acc:0.39786, F1: 0.39750
===> Epoch: 24: Training loss decreased (0.38377 --> 0.38364), Acc: (0.72559 --> 0.72327), F1: (0.72559 --> 0.72327).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 25 Train Avg loss: 0.37831, Acc: 0.72076, F1: 0.72076#####> Valid Avg loss: 1.18945, Acc:0.39964, F1: 0.39929
===> Epoch: 25: Training loss decreased (0.38364 --> 0.37831), Acc: (0.72327 --> 0.72076), F1: (0.72327 --> 0.72076).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 26 Train Avg loss: 0.36742, Acc: 0.73485, F1: 0.73485#####> Valid Avg loss: 1.29616, Acc:0.40054, F1: 0.40018
===> Epoch: 26: Training loss decreased (0.37831 --> 0.36742), Acc: (0.72076 --> 0.73485), F1: (0.72076 --> 0.73485).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 27 Train Avg loss: 0.36858, Acc: 0.73543, F1: 0.73543#####> Valid Avg loss: 1.32502, Acc:0.39697, F1: 0.39661
====> Epoch: 28 Train Avg loss: 0.36174, Acc: 0.72926, F1: 0.72926#####> Valid Avg loss: 1.12371, Acc:0.40143, F1: 0.40107
===> Epoch: 28: Training loss decreased (0.36742 --> 0.36174), Acc: (0.73485 --> 0.72926), F1: (0.73485 --> 0.72926).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 29 Train Avg loss: 0.36185, Acc: 0.73504, F1: 0.73504#####> Valid Avg loss: 1.17465, Acc:0.38983, F1: 0.38948
====> Epoch: 30 Train Avg loss: 0.35064, Acc: 0.74122, F1: 0.74122#####> Valid Avg loss: 1.39423, Acc:0.39340, F1: 0.39305
===> Epoch: 30: Training loss decreased (0.36174 --> 0.35064), Acc: (0.72926 --> 0.74122), F1: (0.72926 --> 0.74122).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 31 Train Avg loss: 0.34644, Acc: 0.74199, F1: 0.74199#####> Valid Avg loss: 1.34031, Acc:0.39340, F1: 0.39305
===> Epoch: 31: Training loss decreased (0.35064 --> 0.34644), Acc: (0.74122 --> 0.74199), F1: (0.74122 --> 0.74199).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 32 Train Avg loss: 0.33226, Acc: 0.75492, F1: 0.75492#####> Valid Avg loss: 1.44784, Acc:0.39697, F1: 0.39661
===> Epoch: 32: Training loss decreased (0.34644 --> 0.33226), Acc: (0.74199 --> 0.75492), F1: (0.74199 --> 0.75492).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 33 Train Avg loss: 0.34067, Acc: 0.74952, F1: 0.74952#####> Valid Avg loss: 1.32473, Acc:0.38983, F1: 0.38948
====> Epoch: 34 Train Avg loss: 0.33229, Acc: 0.74913, F1: 0.74913#####> Valid Avg loss: 1.30680, Acc:0.39251, F1: 0.39216
====> Epoch: 35 Train Avg loss: 0.31930, Acc: 0.76457, F1: 0.76457#####> Valid Avg loss: 1.33342, Acc:0.37734, F1: 0.37701
===> Epoch: 35: Training loss decreased (0.33226 --> 0.31930), Acc: (0.75492 --> 0.76457), F1: (0.75492 --> 0.76457).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 36 Train Avg loss: 0.31885, Acc: 0.76052, F1: 0.76052#####> Valid Avg loss: 1.28830, Acc:0.39161, F1: 0.39127
===> Epoch: 36: Training loss decreased (0.31930 --> 0.31885), Acc: (0.76457 --> 0.76052), F1: (0.76457 --> 0.76052).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 37 Train Avg loss: 0.31637, Acc: 0.76785, F1: 0.76785#####> Valid Avg loss: 1.29130, Acc:0.39875, F1: 0.39929
===> Epoch: 37: Training loss decreased (0.31885 --> 0.31637), Acc: (0.76052 --> 0.76785), F1: (0.76052 --> 0.76785).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 38 Train Avg loss: 0.30908, Acc: 0.76708, F1: 0.76708#####> Valid Avg loss: 1.43071, Acc:0.40143, F1: 0.40107
===> Epoch: 38: Training loss decreased (0.31637 --> 0.30908), Acc: (0.76785 --> 0.76708), F1: (0.76785 --> 0.76708).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 39 Train Avg loss: 0.30049, Acc: 0.77325, F1: 0.77325#####> Valid Avg loss: 1.36097, Acc:0.39429, F1: 0.39394
===> Epoch: 39: Training loss decreased (0.30908 --> 0.30049), Acc: (0.76708 --> 0.77325), F1: (0.76708 --> 0.77325).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 40 Train Avg loss: 0.29256, Acc: 0.78310, F1: 0.78310#####> Valid Avg loss: 1.64780, Acc:0.40500, F1: 0.40463
===> Epoch: 40: Training loss decreased (0.30049 --> 0.29256), Acc: (0.77325 --> 0.78310), F1: (0.77325 --> 0.78310).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 41 Train Avg loss: 0.28237, Acc: 0.78946, F1: 0.78946#####> Valid Avg loss: 1.43870, Acc:0.37021, F1: 0.36988
===> Epoch: 41: Training loss decreased (0.29256 --> 0.28237), Acc: (0.78310 --> 0.78946), F1: (0.78310 --> 0.78946).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 42 Train Avg loss: 0.27691, Acc: 0.79159, F1: 0.79159#####> Valid Avg loss: 1.48193, Acc:0.37110, F1: 0.37077
===> Epoch: 42: Training loss decreased (0.28237 --> 0.27691), Acc: (0.78946 --> 0.79159), F1: (0.78946 --> 0.79159).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 43 Train Avg loss: 0.26782, Acc: 0.79313, F1: 0.79313#####> Valid Avg loss: 1.51025, Acc:0.38180, F1: 0.38146
===> Epoch: 43: Training loss decreased (0.27691 --> 0.26782), Acc: (0.79159 --> 0.79313), F1: (0.79159 --> 0.79313).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 44 Train Avg loss: 0.25669, Acc: 0.80432, F1: 0.80432#####> Valid Avg loss: 1.50851, Acc:0.33363, F1: 0.33333
===> Epoch: 44: Training loss decreased (0.26782 --> 0.25669), Acc: (0.79313 --> 0.80432), F1: (0.79313 --> 0.80432).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 45 Train Avg loss: 0.24967, Acc: 0.80625, F1: 0.80625#####> Valid Avg loss: 1.74576, Acc:0.39072, F1: 0.39037
===> Epoch: 45: Training loss decreased (0.25669 --> 0.24967), Acc: (0.80432 --> 0.80625), F1: (0.80432 --> 0.80625).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 46 Train Avg loss: 0.24280, Acc: 0.81802, F1: 0.81802#####> Valid Avg loss: 1.57666, Acc:0.34344, F1: 0.34314
===> Epoch: 46: Training loss decreased (0.24967 --> 0.24280), Acc: (0.80625 --> 0.81802), F1: (0.80625 --> 0.81802).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 47 Train Avg loss: 0.23275, Acc: 0.82381, F1: 0.82381#####> Valid Avg loss: 1.71923, Acc:0.37021, F1: 0.36988
===> Epoch: 47: Training loss decreased (0.24280 --> 0.23275), Acc: (0.81802 --> 0.82381), F1: (0.81802 --> 0.82381).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 48 Train Avg loss: 0.22015, Acc: 0.82922, F1: 0.82922#####> Valid Avg loss: 1.73237, Acc:0.34612, F1: 0.34670
===> Epoch: 48: Training loss decreased (0.23275 --> 0.22015), Acc: (0.82381 --> 0.82922), F1: (0.82381 --> 0.82922).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 49 Train Avg loss: 0.21330, Acc: 0.83327, F1: 0.83327#####> Valid Avg loss: 1.95336, Acc:0.37734, F1: 0.37701
===> Epoch: 49: Training loss decreased (0.22015 --> 0.21330), Acc: (0.82922 --> 0.83327), F1: (0.82922 --> 0.83327).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 50 Train Avg loss: 0.20495, Acc: 0.83925, F1: 0.83925#####> Valid Avg loss: 1.90758, Acc:0.37199, F1: 0.37255
===> Epoch: 50: Training loss decreased (0.21330 --> 0.20495), Acc: (0.83327 --> 0.83925), F1: (0.83327 --> 0.83925).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 51 Train Avg loss: 0.18807, Acc: 0.85411, F1: 0.85411#####> Valid Avg loss: 2.07113, Acc:0.36218, F1: 0.36185
===> Epoch: 51: Training loss decreased (0.20495 --> 0.18807), Acc: (0.83925 --> 0.85411), F1: (0.83925 --> 0.85411).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 52 Train Avg loss: 0.18228, Acc: 0.85372, F1: 0.85372#####> Valid Avg loss: 2.07196, Acc:0.36664, F1: 0.36631
===> Epoch: 52: Training loss decreased (0.18807 --> 0.18228), Acc: (0.85411 --> 0.85372), F1: (0.85411 --> 0.85372).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 53 Train Avg loss: 0.16982, Acc: 0.86897, F1: 0.86897#####> Valid Avg loss: 2.05626, Acc:0.34434, F1: 0.34492
===> Epoch: 53: Training loss decreased (0.18228 --> 0.16982), Acc: (0.85372 --> 0.86897), F1: (0.85372 --> 0.86897).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 54 Train Avg loss: 0.15936, Acc: 0.86550, F1: 0.86550#####> Valid Avg loss: 2.11307, Acc:0.34523, F1: 0.34492
===> Epoch: 54: Training loss decreased (0.16982 --> 0.15936), Acc: (0.86897 --> 0.86550), F1: (0.86897 --> 0.86550).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 55 Train Avg loss: 0.14191, Acc: 0.88421, F1: 0.88421#####> Valid Avg loss: 2.18559, Acc:0.33452, F1: 0.33512
===> Epoch: 55: Training loss decreased (0.15936 --> 0.14191), Acc: (0.86550 --> 0.88421), F1: (0.86550 --> 0.88421).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 56 Train Avg loss: 0.13257, Acc: 0.89058, F1: 0.89058#####> Valid Avg loss: 2.41904, Acc:0.35326, F1: 0.35294
===> Epoch: 56: Training loss decreased (0.14191 --> 0.13257), Acc: (0.88421 --> 0.89058), F1: (0.88421 --> 0.89058).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 57 Train Avg loss: 0.12385, Acc: 0.89676, F1: 0.89676#####> Valid Avg loss: 2.79114, Acc:0.35326, F1: 0.35294
===> Epoch: 57: Training loss decreased (0.13257 --> 0.12385), Acc: (0.89058 --> 0.89676), F1: (0.89058 --> 0.89676).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 58 Train Avg loss: 0.11398, Acc: 0.90563, F1: 0.90563#####> Valid Avg loss: 2.84903, Acc:0.33185, F1: 0.33155
===> Epoch: 58: Training loss decreased (0.12385 --> 0.11398), Acc: (0.89676 --> 0.90563), F1: (0.89676 --> 0.90563).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 59 Train Avg loss: 0.10365, Acc: 0.91085, F1: 0.91085#####> Valid Avg loss: 2.71603, Acc:0.34434, F1: 0.34492
===> Epoch: 59: Training loss decreased (0.11398 --> 0.10365), Acc: (0.90563 --> 0.91085), F1: (0.90563 --> 0.91085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 60 Train Avg loss: 0.09386, Acc: 0.92184, F1: 0.92184#####> Valid Avg loss: 2.80781, Acc:0.32203, F1: 0.32175
===> Epoch: 60: Training loss decreased (0.10365 --> 0.09386), Acc: (0.91085 --> 0.92184), F1: (0.91085 --> 0.92184).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 61 Train Avg loss: 0.08443, Acc: 0.92513, F1: 0.92513#####> Valid Avg loss: 2.90256, Acc:0.35147, F1: 0.35116
===> Epoch: 61: Training loss decreased (0.09386 --> 0.08443), Acc: (0.92184 --> 0.92513), F1: (0.92184 --> 0.92513).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 62 Train Avg loss: 0.08167, Acc: 0.93207, F1: 0.93207#####> Valid Avg loss: 2.91615, Acc:0.34344, F1: 0.34403
===> Epoch: 62: Training loss decreased (0.08443 --> 0.08167), Acc: (0.92513 --> 0.93207), F1: (0.92513 --> 0.93207).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 63 Train Avg loss: 0.07121, Acc: 0.93825, F1: 0.93825#####> Valid Avg loss: 3.40221, Acc:0.33095, F1: 0.33066
===> Epoch: 63: Training loss decreased (0.08167 --> 0.07121), Acc: (0.93207 --> 0.93825), F1: (0.93207 --> 0.93825).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 64 Train Avg loss: 0.06301, Acc: 0.94828, F1: 0.94828#####> Valid Avg loss: 3.50808, Acc:0.30598, F1: 0.30660
===> Epoch: 64: Training loss decreased (0.07121 --> 0.06301), Acc: (0.93825 --> 0.94828), F1: (0.93825 --> 0.94828).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 65 Train Avg loss: 0.05963, Acc: 0.94384, F1: 0.94384#####> Valid Avg loss: 3.28729, Acc:0.34434, F1: 0.34492
===> Epoch: 65: Training loss decreased (0.06301 --> 0.05963), Acc: (0.94828 --> 0.94384), F1: (0.94828 --> 0.94384).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 66 Train Avg loss: 0.05116, Acc: 0.95774, F1: 0.95774#####> Valid Avg loss: 3.48019, Acc:0.31847, F1: 0.31907
===> Epoch: 66: Training loss decreased (0.05963 --> 0.05116), Acc: (0.94384 --> 0.95774), F1: (0.94384 --> 0.95774).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 67 Train Avg loss: 0.04684, Acc: 0.95851, F1: 0.95851#####> Valid Avg loss: 3.90507, Acc:0.34701, F1: 0.34670
===> Epoch: 67: Training loss decreased (0.05116 --> 0.04684), Acc: (0.95774 --> 0.95851), F1: (0.95774 --> 0.95851).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 68 Train Avg loss: 0.04540, Acc: 0.95909, F1: 0.95909#####> Valid Avg loss: 3.78178, Acc:0.33898, F1: 0.33868
===> Epoch: 68: Training loss decreased (0.04684 --> 0.04540), Acc: (0.95851 --> 0.95909), F1: (0.95851 --> 0.95909).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 69 Train Avg loss: 0.04204, Acc: 0.96121, F1: 0.96121#####> Valid Avg loss: 3.89519, Acc:0.34255, F1: 0.34314
===> Epoch: 69: Training loss decreased (0.04540 --> 0.04204), Acc: (0.95909 --> 0.96121), F1: (0.95909 --> 0.96121).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 70 Train Avg loss: 0.03722, Acc: 0.96526, F1: 0.96526#####> Valid Avg loss: 3.69588, Acc:0.32828, F1: 0.32888
===> Epoch: 70: Training loss decreased (0.04204 --> 0.03722), Acc: (0.96121 --> 0.96526), F1: (0.96121 --> 0.96526).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 71 Train Avg loss: 0.03497, Acc: 0.96700, F1: 0.96700#####> Valid Avg loss: 4.06646, Acc:0.34077, F1: 0.34135
===> Epoch: 71: Training loss decreased (0.03722 --> 0.03497), Acc: (0.96526 --> 0.96700), F1: (0.96526 --> 0.96700).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 72 Train Avg loss: 0.03246, Acc: 0.96604, F1: 0.96604#####> Valid Avg loss: 4.08285, Acc:0.35682, F1: 0.35740
===> Epoch: 72: Training loss decreased (0.03497 --> 0.03246), Acc: (0.96700 --> 0.96604), F1: (0.96700 --> 0.96604).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 73 Train Avg loss: 0.02989, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 4.08072, Acc:0.34434, F1: 0.34492
===> Epoch: 73: Training loss decreased (0.03246 --> 0.02989), Acc: (0.96604 --> 0.96912), F1: (0.96604 --> 0.96912).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 74 Train Avg loss: 0.02621, Acc: 0.97260, F1: 0.97260#####> Valid Avg loss: 4.22707, Acc:0.32025, F1: 0.32086
===> Epoch: 74: Training loss decreased (0.02989 --> 0.02621), Acc: (0.96912 --> 0.97260), F1: (0.96912 --> 0.97260).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 75 Train Avg loss: 0.02509, Acc: 0.97221, F1: 0.97221#####> Valid Avg loss: 4.65629, Acc:0.33720, F1: 0.33690
===> Epoch: 75: Training loss decreased (0.02621 --> 0.02509), Acc: (0.97260 --> 0.97221), F1: (0.97260 --> 0.97221).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 76 Train Avg loss: 0.02384, Acc: 0.97067, F1: 0.97067#####> Valid Avg loss: 4.42285, Acc:0.34434, F1: 0.34492
===> Epoch: 76: Training loss decreased (0.02509 --> 0.02384), Acc: (0.97221 --> 0.97067), F1: (0.97221 --> 0.97067).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 77 Train Avg loss: 0.02356, Acc: 0.97279, F1: 0.97279#####> Valid Avg loss: 4.65132, Acc:0.33809, F1: 0.33779
===> Epoch: 77: Training loss decreased (0.02384 --> 0.02356), Acc: (0.97067 --> 0.97279), F1: (0.97067 --> 0.97279).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 78 Train Avg loss: 0.02221, Acc: 0.97472, F1: 0.97472#####> Valid Avg loss: 4.46498, Acc:0.34612, F1: 0.34670
===> Epoch: 78: Training loss decreased (0.02356 --> 0.02221), Acc: (0.97279 --> 0.97472), F1: (0.97279 --> 0.97472).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 79 Train Avg loss: 0.02087, Acc: 0.97530, F1: 0.97530#####> Valid Avg loss: 4.52968, Acc:0.32203, F1: 0.32175
===> Epoch: 79: Training loss decreased (0.02221 --> 0.02087), Acc: (0.97472 --> 0.97530), F1: (0.97472 --> 0.97530).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 80 Train Avg loss: 0.02011, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 4.38303, Acc:0.32739, F1: 0.32799
===> Epoch: 80: Training loss decreased (0.02087 --> 0.02011), Acc: (0.97530 --> 0.97684), F1: (0.97530 --> 0.97684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 81 Train Avg loss: 0.01969, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 4.77788, Acc:0.34166, F1: 0.34135
===> Epoch: 81: Training loss decreased (0.02011 --> 0.01969), Acc: (0.97684 --> 0.97684), F1: (0.97684 --> 0.97684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 82 Train Avg loss: 0.01887, Acc: 0.97414, F1: 0.97414#####> Valid Avg loss: 4.63234, Acc:0.33631, F1: 0.33690
===> Epoch: 82: Training loss decreased (0.01969 --> 0.01887), Acc: (0.97684 --> 0.97414), F1: (0.97684 --> 0.97414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 83 Train Avg loss: 0.01837, Acc: 0.97761, F1: 0.97761#####> Valid Avg loss: 4.82166, Acc:0.34344, F1: 0.34403
===> Epoch: 83: Training loss decreased (0.01887 --> 0.01837), Acc: (0.97414 --> 0.97761), F1: (0.97414 --> 0.97761).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 84 Train Avg loss: 0.01829, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 4.64443, Acc:0.34255, F1: 0.34314
===> Epoch: 84: Training loss decreased (0.01837 --> 0.01829), Acc: (0.97761 --> 0.97511), F1: (0.97761 --> 0.97511).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 85 Train Avg loss: 0.01792, Acc: 0.97414, F1: 0.97414#####> Valid Avg loss: 4.90098, Acc:0.34255, F1: 0.34314
===> Epoch: 85: Training loss decreased (0.01829 --> 0.01792), Acc: (0.97511 --> 0.97414), F1: (0.97511 --> 0.97414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 86 Train Avg loss: 0.01716, Acc: 0.97472, F1: 0.97472#####> Valid Avg loss: 4.83745, Acc:0.33988, F1: 0.33957
===> Epoch: 86: Training loss decreased (0.01792 --> 0.01716), Acc: (0.97414 --> 0.97472), F1: (0.97414 --> 0.97472).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 87 Train Avg loss: 0.01686, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 4.99347, Acc:0.34701, F1: 0.34670
===> Epoch: 87: Training loss decreased (0.01716 --> 0.01686), Acc: (0.97472 --> 0.97607), F1: (0.97472 --> 0.97607).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 88 Train Avg loss: 0.01649, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 4.75739, Acc:0.35058, F1: 0.35116
===> Epoch: 88: Training loss decreased (0.01686 --> 0.01649), Acc: (0.97607 --> 0.97588), F1: (0.97607 --> 0.97588).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 89 Train Avg loss: 0.01624, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 4.88428, Acc:0.33898, F1: 0.33957
===> Epoch: 89: Training loss decreased (0.01649 --> 0.01624), Acc: (0.97588 --> 0.97704), F1: (0.97588 --> 0.97704).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 90 Train Avg loss: 0.01604, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 4.88321, Acc:0.33274, F1: 0.33244
===> Epoch: 90: Training loss decreased (0.01624 --> 0.01604), Acc: (0.97704 --> 0.97704), F1: (0.97704 --> 0.97704).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 91 Train Avg loss: 0.01591, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 5.03293, Acc:0.34790, F1: 0.34759
===> Epoch: 91: Training loss decreased (0.01604 --> 0.01591), Acc: (0.97704 --> 0.97511), F1: (0.97704 --> 0.97511).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 92 Train Avg loss: 0.01566, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.83515, Acc:0.34255, F1: 0.34225
===> Epoch: 92: Training loss decreased (0.01591 --> 0.01566), Acc: (0.97511 --> 0.97819), F1: (0.97511 --> 0.97819).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 93 Train Avg loss: 0.01552, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 4.82686, Acc:0.34344, F1: 0.34314
===> Epoch: 93: Training loss decreased (0.01566 --> 0.01552), Acc: (0.97819 --> 0.97800), F1: (0.97819 --> 0.97800).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 94 Train Avg loss: 0.01516, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.88601, Acc:0.34790, F1: 0.34759
===> Epoch: 94: Training loss decreased (0.01552 --> 0.01516), Acc: (0.97800 --> 0.97819), F1: (0.97800 --> 0.97819).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 95 Train Avg loss: 0.01520, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 4.93933, Acc:0.34344, F1: 0.34314
====> Epoch: 96 Train Avg loss: 0.01485, Acc: 0.98012, F1: 0.98012#####> Valid Avg loss: 4.91469, Acc:0.34434, F1: 0.34403
===> Epoch: 96: Training loss decreased (0.01516 --> 0.01485), Acc: (0.97819 --> 0.98012), F1: (0.97819 --> 0.98012).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 97 Train Avg loss: 0.01487, Acc: 0.98070, F1: 0.98070#####> Valid Avg loss: 5.00376, Acc:0.34880, F1: 0.34848
====> Epoch: 98 Train Avg loss: 0.01488, Acc: 0.98128, F1: 0.98128#####> Valid Avg loss: 5.04863, Acc:0.34344, F1: 0.34314
====> Epoch: 99 Train Avg loss: 0.01494, Acc: 0.98051, F1: 0.98051#####> Valid Avg loss: 5.00052, Acc:0.34434, F1: 0.34403
====> Epoch: 100 Train Avg loss: 0.55101, Acc: 0.64454, F1: 0.64454#####> Valid Avg loss: 1.11746, Acc:0.39964, F1: 0.39929
====> Epoch: 101 Train Avg loss: 0.43912, Acc: 0.68352, F1: 0.68352#####> Valid Avg loss: 1.26164, Acc:0.40589, F1: 0.40553
====> Epoch: 102 Train Avg loss: 0.41123, Acc: 0.70957, F1: 0.70957#####> Valid Avg loss: 1.21620, Acc:0.39875, F1: 0.39840
====> Epoch: 103 Train Avg loss: 0.38465, Acc: 0.72192, F1: 0.72192#####> Valid Avg loss: 1.35314, Acc:0.40321, F1: 0.40285
====> Epoch: 104 Train Avg loss: 0.36476, Acc: 0.73157, F1: 0.73157#####> Valid Avg loss: 1.42579, Acc:0.40232, F1: 0.40196
====> Epoch: 105 Train Avg loss: 0.36190, Acc: 0.73447, F1: 0.73447#####> Valid Avg loss: 1.56189, Acc:0.40589, F1: 0.40553
====> Epoch: 106 Train Avg loss: 0.34994, Acc: 0.73582, F1: 0.73582#####> Valid Avg loss: 1.29960, Acc:0.39429, F1: 0.39394
====> Epoch: 107 Train Avg loss: 0.33410, Acc: 0.75704, F1: 0.75704#####> Valid Avg loss: 1.44291, Acc:0.38805, F1: 0.38770
====> Epoch: 108 Train Avg loss: 0.33083, Acc: 0.74855, F1: 0.74855#####> Valid Avg loss: 1.25737, Acc:0.38715, F1: 0.38681
====> Epoch: 109 Train Avg loss: 0.32613, Acc: 0.75569, F1: 0.75569#####> Valid Avg loss: 1.56127, Acc:0.39161, F1: 0.39127
====> Epoch: 110 Train Avg loss: 0.31323, Acc: 0.76341, F1: 0.76341#####> Valid Avg loss: 1.51531, Acc:0.37199, F1: 0.37166
====> Epoch: 111 Train Avg loss: 0.30670, Acc: 0.76920, F1: 0.76920#####> Valid Avg loss: 1.32265, Acc:0.36485, F1: 0.36453
====> Epoch: 112 Train Avg loss: 0.29942, Acc: 0.77480, F1: 0.77480#####> Valid Avg loss: 1.52706, Acc:0.39607, F1: 0.39572
====> Epoch: 113 Train Avg loss: 0.29206, Acc: 0.78117, F1: 0.78117#####> Valid Avg loss: 1.53531, Acc:0.39964, F1: 0.39929
====> Epoch: 114 Train Avg loss: 0.29396, Acc: 0.77441, F1: 0.77441#####> Valid Avg loss: 1.56947, Acc:0.34790, F1: 0.34848
====> Epoch: 115 Train Avg loss: 0.27691, Acc: 0.79217, F1: 0.79217#####> Valid Avg loss: 1.38719, Acc:0.38269, F1: 0.38235
====> Epoch: 116 Train Avg loss: 0.27494, Acc: 0.79409, F1: 0.79409#####> Valid Avg loss: 1.51490, Acc:0.39964, F1: 0.39929
====> Epoch: 117 Train Avg loss: 0.27467, Acc: 0.78753, F1: 0.78753#####> Valid Avg loss: 1.58708, Acc:0.39786, F1: 0.39750
====> Epoch: 118 Train Avg loss: 0.28197, Acc: 0.78078, F1: 0.78078#####> Valid Avg loss: 1.61903, Acc:0.40232, F1: 0.40196
====> Epoch: 119 Train Avg loss: 0.26935, Acc: 0.79525, F1: 0.79525#####> Valid Avg loss: 1.48421, Acc:0.37377, F1: 0.37344
====> Epoch: 120 Train Avg loss: 0.26255, Acc: 0.80741, F1: 0.80741#####> Valid Avg loss: 1.54771, Acc:0.37734, F1: 0.37701
====> Epoch: 121 Train Avg loss: 0.25072, Acc: 0.80953, F1: 0.80953#####> Valid Avg loss: 1.72909, Acc:0.35504, F1: 0.35472
====> Epoch: 122 Train Avg loss: 0.25144, Acc: 0.80895, F1: 0.80895#####> Valid Avg loss: 1.61754, Acc:0.33363, F1: 0.33333
====> Epoch: 123 Train Avg loss: 0.23933, Acc: 0.81436, F1: 0.81436#####> Valid Avg loss: 1.69977, Acc:0.38002, F1: 0.38057
====> Epoch: 124 Train Avg loss: 0.23852, Acc: 0.81474, F1: 0.81474#####> Valid Avg loss: 1.84338, Acc:0.38626, F1: 0.38592
====> Epoch: 125 Train Avg loss: 0.22281, Acc: 0.82864, F1: 0.82864#####> Valid Avg loss: 1.80785, Acc:0.37021, F1: 0.36988
====> Epoch: 126 Train Avg loss: 0.22602, Acc: 0.82671, F1: 0.82671#####> Valid Avg loss: 1.69112, Acc:0.38715, F1: 0.38681
====> Epoch: 127 Train Avg loss: 0.22747, Acc: 0.82594, F1: 0.82594#####> Valid Avg loss: 1.62389, Acc:0.37645, F1: 0.37611
====> Epoch: 128 Train Avg loss: 0.21671, Acc: 0.82729, F1: 0.82729#####> Valid Avg loss: 1.58660, Acc:0.34255, F1: 0.34225
====> Epoch: 129 Train Avg loss: 0.21489, Acc: 0.83713, F1: 0.83713#####> Valid Avg loss: 1.89255, Acc:0.37377, F1: 0.37344
====> Epoch: 130 Train Avg loss: 0.20792, Acc: 0.83964, F1: 0.83964#####> Valid Avg loss: 2.00979, Acc:0.38537, F1: 0.38503
====> Epoch: 131 Train Avg loss: 0.21240, Acc: 0.83308, F1: 0.83308#####> Valid Avg loss: 1.82422, Acc:0.30152, F1: 0.30125
====> Epoch: 132 Train Avg loss: 0.19862, Acc: 0.84543, F1: 0.84543#####> Valid Avg loss: 1.81618, Acc:0.37913, F1: 0.37879
====> Epoch: 133 Train Avg loss: 0.19972, Acc: 0.84099, F1: 0.84099#####> Valid Avg loss: 1.47249, Acc:0.30598, F1: 0.30660
====> Epoch: 134 Train Avg loss: 0.20634, Acc: 0.84176, F1: 0.84176#####> Valid Avg loss: 1.80964, Acc:0.36128, F1: 0.36185
====> Epoch: 135 Train Avg loss: 0.19682, Acc: 0.84543, F1: 0.84543#####> Valid Avg loss: 1.70818, Acc:0.35861, F1: 0.35829
====> Epoch: 136 Train Avg loss: 0.19289, Acc: 0.85044, F1: 0.85044#####> Valid Avg loss: 2.08093, Acc:0.36574, F1: 0.36542
====> Epoch: 137 Train Avg loss: 0.18025, Acc: 0.85855, F1: 0.85855#####> Valid Avg loss: 1.58868, Acc:0.37734, F1: 0.37790
====> Epoch: 138 Train Avg loss: 0.18381, Acc: 0.85083, F1: 0.85083#####> Valid Avg loss: 1.96417, Acc:0.36842, F1: 0.36809
====> Epoch: 139 Train Avg loss: 0.17414, Acc: 0.86279, F1: 0.86279#####> Valid Avg loss: 1.74202, Acc:0.30598, F1: 0.30660
====> Epoch: 140 Train Avg loss: 0.17623, Acc: 0.86086, F1: 0.86086#####> Valid Avg loss: 2.04806, Acc:0.38180, F1: 0.38146
====> Epoch: 141 Train Avg loss: 0.16508, Acc: 0.86993, F1: 0.86993#####> Valid Avg loss: 1.93252, Acc:0.34701, F1: 0.34670
====> Epoch: 142 Train Avg loss: 0.16476, Acc: 0.86936, F1: 0.86936#####> Valid Avg loss: 2.11876, Acc:0.38269, F1: 0.38235
====> Epoch: 143 Train Avg loss: 0.15414, Acc: 0.87630, F1: 0.87630#####> Valid Avg loss: 1.84088, Acc:0.30152, F1: 0.30125
====> Epoch: 144 Train Avg loss: 0.15962, Acc: 0.87920, F1: 0.87920#####> Valid Avg loss: 2.02333, Acc:0.36485, F1: 0.36542
====> Epoch: 145 Train Avg loss: 0.16089, Acc: 0.87437, F1: 0.87437#####> Valid Avg loss: 1.90340, Acc:0.33631, F1: 0.33601
====> Epoch: 146 Train Avg loss: 0.15857, Acc: 0.87148, F1: 0.87148#####> Valid Avg loss: 1.90541, Acc:0.36218, F1: 0.36185
====> Epoch: 147 Train Avg loss: 0.15119, Acc: 0.88518, F1: 0.88518#####> Valid Avg loss: 1.96500, Acc:0.35415, F1: 0.35383
====> Epoch: 148 Train Avg loss: 0.15403, Acc: 0.87958, F1: 0.87958#####> Valid Avg loss: 1.96193, Acc:0.36128, F1: 0.36096
====> Epoch: 149 Train Avg loss: 0.13934, Acc: 0.88653, F1: 0.88653#####> Valid Avg loss: 1.97840, Acc:0.32471, F1: 0.32442
====> Epoch: 150 Train Avg loss: 0.13619, Acc: 0.89251, F1: 0.89251#####> Valid Avg loss: 2.20850, Acc:0.34255, F1: 0.34225
====> Epoch: 151 Train Avg loss: 0.13195, Acc: 0.89155, F1: 0.89155#####> Valid Avg loss: 1.97267, Acc:0.32114, F1: 0.32086
====> Epoch: 152 Train Avg loss: 0.13914, Acc: 0.88923, F1: 0.88923#####> Valid Avg loss: 2.21177, Acc:0.36218, F1: 0.36185
====> Epoch: 153 Train Avg loss: 0.12376, Acc: 0.89965, F1: 0.89965#####> Valid Avg loss: 2.33503, Acc:0.36485, F1: 0.36453
====> Epoch: 154 Train Avg loss: 0.12877, Acc: 0.89290, F1: 0.89290#####> Valid Avg loss: 1.96400, Acc:0.34880, F1: 0.34938
====> Epoch: 155 Train Avg loss: 0.12178, Acc: 0.89734, F1: 0.89734#####> Valid Avg loss: 2.42047, Acc:0.33720, F1: 0.33690
====> Epoch: 156 Train Avg loss: 0.12705, Acc: 0.89965, F1: 0.89965#####> Valid Avg loss: 2.00809, Acc:0.32114, F1: 0.32086
====> Epoch: 157 Train Avg loss: 0.11660, Acc: 0.90448, F1: 0.90448#####> Valid Avg loss: 2.36655, Acc:0.31133, F1: 0.31105
====> Epoch: 158 Train Avg loss: 0.11911, Acc: 0.90544, F1: 0.90544#####> Valid Avg loss: 2.29953, Acc:0.30330, F1: 0.30392
====> Epoch: 159 Train Avg loss: 0.11925, Acc: 0.89907, F1: 0.89907#####> Valid Avg loss: 2.29883, Acc:0.35326, F1: 0.35294
====> Epoch: 160 Train Avg loss: 0.10556, Acc: 0.91413, F1: 0.91413#####> Valid Avg loss: 2.24678, Acc:0.34612, F1: 0.34670
====> Epoch: 161 Train Avg loss: 0.10232, Acc: 0.91799, F1: 0.91799#####> Valid Avg loss: 2.19138, Acc:0.30152, F1: 0.30214
====> Epoch: 162 Train Avg loss: 0.11560, Acc: 0.91355, F1: 0.91355#####> Valid Avg loss: 2.38774, Acc:0.34880, F1: 0.34848
====> Epoch: 163 Train Avg loss: 0.10147, Acc: 0.92088, F1: 0.92088#####> Valid Avg loss: 2.50383, Acc:0.35236, F1: 0.35205
====> Epoch: 164 Train Avg loss: 0.10480, Acc: 0.91007, F1: 0.91007#####> Valid Avg loss: 2.29355, Acc:0.34255, F1: 0.34225
====> Epoch: 165 Train Avg loss: 0.09760, Acc: 0.91895, F1: 0.91895#####> Valid Avg loss: 2.25005, Acc:0.35593, F1: 0.35561
====> Epoch: 166 Train Avg loss: 0.08512, Acc: 0.92918, F1: 0.92918#####> Valid Avg loss: 2.27797, Acc:0.32114, F1: 0.32175
====> Epoch: 167 Train Avg loss: 0.09949, Acc: 0.91914, F1: 0.91914#####> Valid Avg loss: 2.45124, Acc:0.34612, F1: 0.34670
====> Epoch: 168 Train Avg loss: 0.10007, Acc: 0.92242, F1: 0.92242#####> Valid Avg loss: 2.33488, Acc:0.30062, F1: 0.30125
====> Epoch: 169 Train Avg loss: 0.09253, Acc: 0.92146, F1: 0.92146#####> Valid Avg loss: 2.31593, Acc:0.31757, F1: 0.31729
====> Epoch: 170 Train Avg loss: 0.09003, Acc: 0.92667, F1: 0.92667#####> Valid Avg loss: 2.42558, Acc:0.34612, F1: 0.34581
====> Epoch: 171 Train Avg loss: 0.08383, Acc: 0.92898, F1: 0.92898#####> Valid Avg loss: 2.89626, Acc:0.37199, F1: 0.37166
====> Epoch: 172 Train Avg loss: 0.08177, Acc: 0.93458, F1: 0.93458#####> Valid Avg loss: 2.73008, Acc:0.37288, F1: 0.37255
====> Epoch: 173 Train Avg loss: 0.07893, Acc: 0.93149, F1: 0.93149#####> Valid Avg loss: 2.54709, Acc:0.33363, F1: 0.33333
====> Epoch: 174 Train Avg loss: 0.07730, Acc: 0.93998, F1: 0.93998#####> Valid Avg loss: 2.40353, Acc:0.36307, F1: 0.36275
====> Epoch: 175 Train Avg loss: 0.07645, Acc: 0.93188, F1: 0.93188#####> Valid Avg loss: 2.76827, Acc:0.34523, F1: 0.34492
====> Epoch: 176 Train Avg loss: 0.08242, Acc: 0.93516, F1: 0.93516#####> Valid Avg loss: 2.58966, Acc:0.34880, F1: 0.34848
====> Epoch: 177 Train Avg loss: 0.07801, Acc: 0.93902, F1: 0.93902#####> Valid Avg loss: 2.85222, Acc:0.35772, F1: 0.35740
====> Epoch: 178 Train Avg loss: 0.06381, Acc: 0.94500, F1: 0.94500#####> Valid Avg loss: 3.13032, Acc:0.34434, F1: 0.34403
====> Epoch: 179 Train Avg loss: 0.06322, Acc: 0.94828, F1: 0.94828#####> Valid Avg loss: 2.96051, Acc:0.35326, F1: 0.35294
====> Epoch: 180 Train Avg loss: 0.07979, Acc: 0.93400, F1: 0.93400#####> Valid Avg loss: 2.47055, Acc:0.34434, F1: 0.34492
====> Epoch: 181 Train Avg loss: 0.06323, Acc: 0.94635, F1: 0.94635#####> Valid Avg loss: 2.42408, Acc:0.32382, F1: 0.32442
====> Epoch: 182 Train Avg loss: 0.06909, Acc: 0.93979, F1: 0.93979#####> Valid Avg loss: 2.39777, Acc:0.34166, F1: 0.34135
====> Epoch: 183 Train Avg loss: 0.06758, Acc: 0.94288, F1: 0.94288#####> Valid Avg loss: 2.79806, Acc:0.34344, F1: 0.34314
====> Epoch: 184 Train Avg loss: 0.06137, Acc: 0.94867, F1: 0.94867#####> Valid Avg loss: 2.60242, Acc:0.35236, F1: 0.35294
====> Epoch: 185 Train Avg loss: 0.05524, Acc: 0.95156, F1: 0.95156#####> Valid Avg loss: 2.94387, Acc:0.34701, F1: 0.34670
====> Epoch: 186 Train Avg loss: 0.05743, Acc: 0.95137, F1: 0.95137#####> Valid Avg loss: 3.25757, Acc:0.36485, F1: 0.36453
====> Epoch: 187 Train Avg loss: 0.05472, Acc: 0.95214, F1: 0.95214#####> Valid Avg loss: 2.90832, Acc:0.35326, F1: 0.35294
====> Epoch: 188 Train Avg loss: 0.05490, Acc: 0.95272, F1: 0.95272#####> Valid Avg loss: 2.72881, Acc:0.35682, F1: 0.35651
====> Epoch: 189 Train Avg loss: 0.05661, Acc: 0.95002, F1: 0.95002#####> Valid Avg loss: 2.95259, Acc:0.36574, F1: 0.36542
====> Epoch: 190 Train Avg loss: 0.05718, Acc: 0.95098, F1: 0.95098#####> Valid Avg loss: 2.70840, Acc:0.34880, F1: 0.34848
====> Epoch: 191 Train Avg loss: 0.04972, Acc: 0.95639, F1: 0.95639#####> Valid Avg loss: 3.18358, Acc:0.34969, F1: 0.34938
====> Epoch: 192 Train Avg loss: 0.05101, Acc: 0.95426, F1: 0.95426#####> Valid Avg loss: 2.99989, Acc:0.35326, F1: 0.35383
====> Epoch: 193 Train Avg loss: 0.04740, Acc: 0.95928, F1: 0.95928#####> Valid Avg loss: 2.94765, Acc:0.33541, F1: 0.33601
====> Epoch: 194 Train Avg loss: 0.04967, Acc: 0.95735, F1: 0.95735#####> Valid Avg loss: 3.01656, Acc:0.34434, F1: 0.34403
====> Epoch: 195 Train Avg loss: 0.04781, Acc: 0.95562, F1: 0.95562#####> Valid Avg loss: 2.77647, Acc:0.34790, F1: 0.34848
====> Epoch: 196 Train Avg loss: 0.04950, Acc: 0.95890, F1: 0.95890#####> Valid Avg loss: 2.85465, Acc:0.36396, F1: 0.36364
====> Epoch: 197 Train Avg loss: 0.04255, Acc: 0.95967, F1: 0.95967#####> Valid Avg loss: 3.15060, Acc:0.34880, F1: 0.34848
====> Epoch: 198 Train Avg loss: 0.04644, Acc: 0.95812, F1: 0.95812#####> Valid Avg loss: 3.08300, Acc:0.36574, F1: 0.36542
====> Epoch: 199 Train Avg loss: 0.04613, Acc: 0.95735, F1: 0.95735#####> Valid Avg loss: 2.95318, Acc:0.34612, F1: 0.34581
====> Epoch: 200 Train Avg loss: 0.04015, Acc: 0.96430, F1: 0.96430#####> Valid Avg loss: 2.65685, Acc:0.36664, F1: 0.36631
====> Epoch: 201 Train Avg loss: 0.03942, Acc: 0.96256, F1: 0.96256#####> Valid Avg loss: 3.04949, Acc:0.33452, F1: 0.33422
====> Epoch: 202 Train Avg loss: 0.04226, Acc: 0.95967, F1: 0.95967#####> Valid Avg loss: 3.14640, Acc:0.36307, F1: 0.36275
====> Epoch: 203 Train Avg loss: 0.04078, Acc: 0.96314, F1: 0.96314#####> Valid Avg loss: 3.19293, Acc:0.37288, F1: 0.37255
====> Epoch: 204 Train Avg loss: 0.03832, Acc: 0.96295, F1: 0.96295#####> Valid Avg loss: 2.98534, Acc:0.34790, F1: 0.34759
====> Epoch: 205 Train Avg loss: 0.03731, Acc: 0.96314, F1: 0.96314#####> Valid Avg loss: 2.99123, Acc:0.33006, F1: 0.33066
====> Epoch: 206 Train Avg loss: 0.03957, Acc: 0.96295, F1: 0.96295#####> Valid Avg loss: 3.27672, Acc:0.34077, F1: 0.34046
====> Epoch: 207 Train Avg loss: 0.03141, Acc: 0.96835, F1: 0.96835#####> Valid Avg loss: 3.30530, Acc:0.37288, F1: 0.37255
====> Epoch: 208 Train Avg loss: 0.03406, Acc: 0.96681, F1: 0.96681#####> Valid Avg loss: 2.93451, Acc:0.33631, F1: 0.33690
====> Epoch: 209 Train Avg loss: 0.03213, Acc: 0.96932, F1: 0.96932#####> Valid Avg loss: 2.97281, Acc:0.33988, F1: 0.34046
====> Epoch: 210 Train Avg loss: 0.03747, Acc: 0.96121, F1: 0.96121#####> Valid Avg loss: 3.41384, Acc:0.36664, F1: 0.36631
====> Epoch: 211 Train Avg loss: 0.02668, Acc: 0.97144, F1: 0.97144#####> Valid Avg loss: 3.10452, Acc:0.35147, F1: 0.35116
====> Epoch: 212 Train Avg loss: 0.03408, Acc: 0.96642, F1: 0.96642#####> Valid Avg loss: 3.81749, Acc:0.36753, F1: 0.36720
====> Epoch: 213 Train Avg loss: 0.03000, Acc: 0.97028, F1: 0.97028#####> Valid Avg loss: 3.88341, Acc:0.37021, F1: 0.36988
====> Epoch: 214 Train Avg loss: 0.02447, Acc: 0.97221, F1: 0.97221#####> Valid Avg loss: 3.99959, Acc:0.37377, F1: 0.37344
====> Epoch: 215 Train Avg loss: 0.03021, Acc: 0.97047, F1: 0.97047#####> Valid Avg loss: 3.62930, Acc:0.36128, F1: 0.36096
====> Epoch: 216 Train Avg loss: 0.02392, Acc: 0.97356, F1: 0.97356#####> Valid Avg loss: 3.24958, Acc:0.35326, F1: 0.35294
====> Epoch: 217 Train Avg loss: 0.02969, Acc: 0.97395, F1: 0.97395#####> Valid Avg loss: 3.21707, Acc:0.33274, F1: 0.33333
====> Epoch: 218 Train Avg loss: 0.02588, Acc: 0.97028, F1: 0.97028#####> Valid Avg loss: 3.17781, Acc:0.32917, F1: 0.32888
====> Epoch: 219 Train Avg loss: 0.02401, Acc: 0.97183, F1: 0.97183#####> Valid Avg loss: 3.30505, Acc:0.33006, F1: 0.33066
====> Epoch: 220 Train Avg loss: 0.02464, Acc: 0.97453, F1: 0.97453#####> Valid Avg loss: 3.38565, Acc:0.33452, F1: 0.33422
====> Epoch: 221 Train Avg loss: 0.02829, Acc: 0.97105, F1: 0.97105#####> Valid Avg loss: 3.36311, Acc:0.33185, F1: 0.33155
====> Epoch: 222 Train Avg loss: 0.02379, Acc: 0.97453, F1: 0.97453#####> Valid Avg loss: 3.40498, Acc:0.34434, F1: 0.34403
====> Epoch: 223 Train Avg loss: 0.02495, Acc: 0.97086, F1: 0.97086#####> Valid Avg loss: 3.77063, Acc:0.36396, F1: 0.36453
====> Epoch: 224 Train Avg loss: 0.02453, Acc: 0.97395, F1: 0.97395#####> Valid Avg loss: 3.46006, Acc:0.35861, F1: 0.35918
====> Epoch: 225 Train Avg loss: 0.02578, Acc: 0.97125, F1: 0.97125#####> Valid Avg loss: 3.34433, Acc:0.33720, F1: 0.33690
====> Epoch: 226 Train Avg loss: 0.02155, Acc: 0.97453, F1: 0.97453#####> Valid Avg loss: 3.50361, Acc:0.36128, F1: 0.36185
====> Epoch: 227 Train Avg loss: 0.01932, Acc: 0.97491, F1: 0.97491#####> Valid Avg loss: 3.72408, Acc:0.35772, F1: 0.35740
====> Epoch: 228 Train Avg loss: 0.02321, Acc: 0.97337, F1: 0.97337#####> Valid Avg loss: 3.50509, Acc:0.35326, F1: 0.35294
====> Epoch: 229 Train Avg loss: 0.02058, Acc: 0.97472, F1: 0.97472#####> Valid Avg loss: 3.54487, Acc:0.36664, F1: 0.36631
====> Epoch: 230 Train Avg loss: 0.02154, Acc: 0.97221, F1: 0.97221#####> Valid Avg loss: 3.98246, Acc:0.35861, F1: 0.35829
====> Epoch: 231 Train Avg loss: 0.01975, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 3.60563, Acc:0.36574, F1: 0.36542
====> Epoch: 232 Train Avg loss: 0.02128, Acc: 0.97144, F1: 0.97144#####> Valid Avg loss: 3.37638, Acc:0.34344, F1: 0.34314
====> Epoch: 233 Train Avg loss: 0.01992, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 3.61001, Acc:0.34612, F1: 0.34581
====> Epoch: 234 Train Avg loss: 0.01946, Acc: 0.97491, F1: 0.97491#####> Valid Avg loss: 3.73133, Acc:0.36485, F1: 0.36453
====> Epoch: 235 Train Avg loss: 0.02028, Acc: 0.97491, F1: 0.97491#####> Valid Avg loss: 3.68215, Acc:0.36307, F1: 0.36275
====> Epoch: 236 Train Avg loss: 0.01848, Acc: 0.97472, F1: 0.97472#####> Valid Avg loss: 3.38633, Acc:0.34701, F1: 0.34670
====> Epoch: 237 Train Avg loss: 0.01776, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 3.42227, Acc:0.33988, F1: 0.33957
====> Epoch: 238 Train Avg loss: 0.01882, Acc: 0.97569, F1: 0.97569#####> Valid Avg loss: 3.74490, Acc:0.35415, F1: 0.35383
====> Epoch: 239 Train Avg loss: 0.01743, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 3.62800, Acc:0.35861, F1: 0.35829
====> Epoch: 240 Train Avg loss: 0.01986, Acc: 0.97453, F1: 0.97453#####> Valid Avg loss: 3.47872, Acc:0.34434, F1: 0.34403
====> Epoch: 241 Train Avg loss: 0.01675, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 3.55709, Acc:0.34523, F1: 0.34492
====> Epoch: 242 Train Avg loss: 0.01677, Acc: 0.97530, F1: 0.97530#####> Valid Avg loss: 3.60247, Acc:0.36753, F1: 0.36720
====> Epoch: 243 Train Avg loss: 0.01716, Acc: 0.97549, F1: 0.97549#####> Valid Avg loss: 3.70969, Acc:0.34969, F1: 0.34938
====> Epoch: 244 Train Avg loss: 0.01885, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 3.79106, Acc:0.33274, F1: 0.33244
====> Epoch: 245 Train Avg loss: 0.01639, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 3.78219, Acc:0.35236, F1: 0.35294
====> Epoch: 246 Train Avg loss: 0.01845, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 3.57851, Acc:0.34701, F1: 0.34670
====> Epoch: 247 Train Avg loss: 0.01736, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 3.65080, Acc:0.34255, F1: 0.34225
====> Epoch: 248 Train Avg loss: 0.01583, Acc: 0.97974, F1: 0.97974#####> Valid Avg loss: 3.95405, Acc:0.36218, F1: 0.36185
====> Epoch: 249 Train Avg loss: 0.01709, Acc: 0.97163, F1: 0.97163#####> Valid Avg loss: 3.26897, Acc:0.34523, F1: 0.34492
====> Epoch: 250 Train Avg loss: 0.01575, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 4.09741, Acc:0.36307, F1: 0.36275
====> Epoch: 251 Train Avg loss: 0.01630, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 3.60356, Acc:0.35147, F1: 0.35116
====> Epoch: 252 Train Avg loss: 0.01546, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 3.76433, Acc:0.35326, F1: 0.35383
====> Epoch: 253 Train Avg loss: 0.01594, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 3.61947, Acc:0.35504, F1: 0.35472
====> Epoch: 254 Train Avg loss: 0.01593, Acc: 0.97569, F1: 0.97569#####> Valid Avg loss: 3.63412, Acc:0.34880, F1: 0.34848
====> Epoch: 255 Train Avg loss: 0.01592, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 3.83224, Acc:0.33185, F1: 0.33155
====> Epoch: 256 Train Avg loss: 0.01533, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 3.67465, Acc:0.35772, F1: 0.35740
====> Epoch: 257 Train Avg loss: 0.01523, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 3.83402, Acc:0.35861, F1: 0.35829
====> Epoch: 258 Train Avg loss: 0.01567, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 3.90190, Acc:0.35326, F1: 0.35294
====> Epoch: 259 Train Avg loss: 0.01518, Acc: 0.97916, F1: 0.97916#####> Valid Avg loss: 3.82796, Acc:0.35236, F1: 0.35205
====> Epoch: 260 Train Avg loss: 0.01504, Acc: 0.97877, F1: 0.97877#####> Valid Avg loss: 3.93360, Acc:0.35415, F1: 0.35383
====> Epoch: 261 Train Avg loss: 0.01513, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 4.03219, Acc:0.35772, F1: 0.35740
====> Epoch: 262 Train Avg loss: 0.01508, Acc: 0.97974, F1: 0.97974#####> Valid Avg loss: 3.74324, Acc:0.35326, F1: 0.35294
====> Epoch: 263 Train Avg loss: 0.01559, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 3.75942, Acc:0.35682, F1: 0.35651
====> Epoch: 264 Train Avg loss: 0.01526, Acc: 0.97761, F1: 0.97761#####> Valid Avg loss: 3.86048, Acc:0.35415, F1: 0.35383
====> Epoch: 265 Train Avg loss: 0.01518, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 3.91183, Acc:0.35326, F1: 0.35294
====> Epoch: 266 Train Avg loss: 0.01471, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 3.66202, Acc:0.35772, F1: 0.35829
===> Epoch: 266: Training loss decreased (0.01485 --> 0.01471), Acc: (0.98012 --> 0.97819), F1: (0.98012 --> 0.97819).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 267 Train Avg loss: 0.01497, Acc: 0.97569, F1: 0.97569#####> Valid Avg loss: 3.94878, Acc:0.36128, F1: 0.36096
====> Epoch: 268 Train Avg loss: 0.01452, Acc: 0.98032, F1: 0.98032#####> Valid Avg loss: 3.74935, Acc:0.35058, F1: 0.35027
===> Epoch: 268: Training loss decreased (0.01471 --> 0.01452), Acc: (0.97819 --> 0.98032), F1: (0.97819 --> 0.98032).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 269 Train Avg loss: 0.01464, Acc: 0.97530, F1: 0.97530#####> Valid Avg loss: 3.89089, Acc:0.34790, F1: 0.34759
====> Epoch: 270 Train Avg loss: 0.01487, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 4.23493, Acc:0.35861, F1: 0.35829
====> Epoch: 271 Train Avg loss: 0.01468, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 3.91908, Acc:0.34701, F1: 0.34670
====> Epoch: 272 Train Avg loss: 0.01457, Acc: 0.97781, F1: 0.97781#####> Valid Avg loss: 4.04207, Acc:0.36128, F1: 0.36096
====> Epoch: 273 Train Avg loss: 0.01456, Acc: 0.97858, F1: 0.97858#####> Valid Avg loss: 4.19132, Acc:0.36218, F1: 0.36185
====> Epoch: 274 Train Avg loss: 0.01439, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 4.11405, Acc:0.35950, F1: 0.35918
===> Epoch: 274: Training loss decreased (0.01452 --> 0.01439), Acc: (0.98032 --> 0.97723), F1: (0.98032 --> 0.97723).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 275 Train Avg loss: 0.01475, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 4.07825, Acc:0.35861, F1: 0.35829
====> Epoch: 276 Train Avg loss: 0.01440, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 4.06087, Acc:0.35861, F1: 0.35829
====> Epoch: 277 Train Avg loss: 0.01432, Acc: 0.97781, F1: 0.97781#####> Valid Avg loss: 4.08172, Acc:0.35772, F1: 0.35740
===> Epoch: 277: Training loss decreased (0.01439 --> 0.01432), Acc: (0.97723 --> 0.97781), F1: (0.97723 --> 0.97781).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 278 Train Avg loss: 0.01479, Acc: 0.97935, F1: 0.97935#####> Valid Avg loss: 4.01835, Acc:0.35593, F1: 0.35561
====> Epoch: 279 Train Avg loss: 0.01423, Acc: 0.97761, F1: 0.97761#####> Valid Avg loss: 3.96820, Acc:0.35950, F1: 0.35918
===> Epoch: 279: Training loss decreased (0.01432 --> 0.01423), Acc: (0.97781 --> 0.97761), F1: (0.97781 --> 0.97761).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 280 Train Avg loss: 0.01421, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 3.98693, Acc:0.35326, F1: 0.35294
===> Epoch: 280: Training loss decreased (0.01423 --> 0.01421), Acc: (0.97761 --> 0.97704), F1: (0.97761 --> 0.97704).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 281 Train Avg loss: 0.01424, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 4.21159, Acc:0.36218, F1: 0.36185
====> Epoch: 282 Train Avg loss: 0.01417, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 4.06522, Acc:0.35593, F1: 0.35561
===> Epoch: 282: Training loss decreased (0.01421 --> 0.01417), Acc: (0.97704 --> 0.97684), F1: (0.97704 --> 0.97684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 283 Train Avg loss: 0.01417, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 4.22263, Acc:0.35682, F1: 0.35651
===> Epoch: 283: Training loss decreased (0.01417 --> 0.01417), Acc: (0.97684 --> 0.97800), F1: (0.97684 --> 0.97800).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 284 Train Avg loss: 0.01420, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.09046, Acc:0.35593, F1: 0.35561
====> Epoch: 285 Train Avg loss: 0.01415, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.04497, Acc:0.35950, F1: 0.35918
===> Epoch: 285: Training loss decreased (0.01417 --> 0.01415), Acc: (0.97800 --> 0.97819), F1: (0.97800 --> 0.97819).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 286 Train Avg loss: 0.01418, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 4.13883, Acc:0.35504, F1: 0.35472
====> Epoch: 287 Train Avg loss: 0.01409, Acc: 0.97916, F1: 0.97916#####> Valid Avg loss: 4.13833, Acc:0.35415, F1: 0.35383
===> Epoch: 287: Training loss decreased (0.01415 --> 0.01409), Acc: (0.97819 --> 0.97916), F1: (0.97819 --> 0.97916).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 288 Train Avg loss: 0.01414, Acc: 0.97761, F1: 0.97761#####> Valid Avg loss: 4.23561, Acc:0.35593, F1: 0.35561
====> Epoch: 289 Train Avg loss: 0.01403, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.10409, Acc:0.35593, F1: 0.35561
===> Epoch: 289: Training loss decreased (0.01409 --> 0.01403), Acc: (0.97916 --> 0.97819), F1: (0.97916 --> 0.97819).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 290 Train Avg loss: 0.01415, Acc: 0.97935, F1: 0.97935#####> Valid Avg loss: 4.15938, Acc:0.35415, F1: 0.35383
====> Epoch: 291 Train Avg loss: 0.01408, Acc: 0.97761, F1: 0.97761#####> Valid Avg loss: 4.11217, Acc:0.35415, F1: 0.35383
====> Epoch: 292 Train Avg loss: 0.01393, Acc: 0.98012, F1: 0.98012#####> Valid Avg loss: 4.08491, Acc:0.35415, F1: 0.35383
===> Epoch: 292: Training loss decreased (0.01403 --> 0.01393), Acc: (0.97819 --> 0.98012), F1: (0.97819 --> 0.98012).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_1
====> Epoch: 293 Train Avg loss: 0.01399, Acc: 0.97974, F1: 0.97974#####> Valid Avg loss: 4.10867, Acc:0.35415, F1: 0.35383
====> Epoch: 294 Train Avg loss: 0.01404, Acc: 0.97935, F1: 0.97935#####> Valid Avg loss: 4.24869, Acc:0.35415, F1: 0.35383
====> Epoch: 295 Train Avg loss: 0.01404, Acc: 0.97993, F1: 0.97993#####> Valid Avg loss: 4.17147, Acc:0.35504, F1: 0.35472
====> Epoch: 296 Train Avg loss: 0.01400, Acc: 0.97877, F1: 0.97877#####> Valid Avg loss: 4.07072, Acc:0.35415, F1: 0.35383
====> Epoch: 297 Train Avg loss: 0.01398, Acc: 0.97974, F1: 0.97974#####> Valid Avg loss: 4.14199, Acc:0.35504, F1: 0.35472
====> Epoch: 298 Train Avg loss: 0.01399, Acc: 0.97954, F1: 0.97954#####> Valid Avg loss: 4.17565, Acc:0.35504, F1: 0.35472
====> Epoch: 299 Train Avg loss: 0.01395, Acc: 0.98109, F1: 0.98109#####> Valid Avg loss: 4.22020, Acc:0.35415, F1: 0.35383
====> Epoch: 300 Train Avg loss: 0.50411, Acc: 0.66731, F1: 0.66731#####> Valid Avg loss: 1.03482, Acc:0.38537, F1: 0.38503
====> Epoch: 301 Train Avg loss: 0.41907, Acc: 0.69606, F1: 0.69606#####> Valid Avg loss: 1.14732, Acc:0.36218, F1: 0.36185
====> Epoch: 302 Train Avg loss: 0.37564, Acc: 0.72327, F1: 0.72327#####> Valid Avg loss: 1.33141, Acc:0.37110, F1: 0.37077
====> Epoch: 303 Train Avg loss: 0.28009, Acc: 0.79236, F1: 0.79236#####> Valid Avg loss: 1.68530, Acc:0.37021, F1: 0.36988
====> Epoch: 304 Train Avg loss: 0.19790, Acc: 0.84678, F1: 0.84678#####> Valid Avg loss: 2.08778, Acc:0.36218, F1: 0.36185
====> Epoch: 305 Train Avg loss: 0.17767, Acc: 0.86202, F1: 0.86202#####> Valid Avg loss: 1.70644, Acc:0.35950, F1: 0.35918
====> Epoch: 306 Train Avg loss: 0.15387, Acc: 0.87920, F1: 0.87920#####> Valid Avg loss: 1.75302, Acc:0.34880, F1: 0.34938
====> Epoch: 307 Train Avg loss: 0.15777, Acc: 0.87553, F1: 0.87553#####> Valid Avg loss: 2.11366, Acc:0.32917, F1: 0.32977
====> Epoch: 308 Train Avg loss: 0.15299, Acc: 0.87900, F1: 0.87900#####> Valid Avg loss: 2.13063, Acc:0.37556, F1: 0.37611
====> Epoch: 309 Train Avg loss: 0.14683, Acc: 0.88286, F1: 0.88286#####> Valid Avg loss: 2.07921, Acc:0.33631, F1: 0.33601
====> Epoch: 310 Train Avg loss: 0.14609, Acc: 0.88981, F1: 0.88981#####> Valid Avg loss: 2.17607, Acc:0.37377, F1: 0.37344
====> Epoch: 311 Train Avg loss: 0.15544, Acc: 0.87881, F1: 0.87881#####> Valid Avg loss: 1.92859, Acc:0.35326, F1: 0.35294
====> Epoch: 312 Train Avg loss: 0.13919, Acc: 0.89444, F1: 0.89444#####> Valid Avg loss: 1.85104, Acc:0.34523, F1: 0.34581
====> Epoch: 313 Train Avg loss: 0.13704, Acc: 0.89290, F1: 0.89290#####> Valid Avg loss: 2.04971, Acc:0.37199, F1: 0.37166
====> Epoch: 314 Train Avg loss: 0.13649, Acc: 0.89213, F1: 0.89213#####> Valid Avg loss: 2.06033, Acc:0.35861, F1: 0.35829
====> Epoch: 315 Train Avg loss: 0.12812, Acc: 0.90235, F1: 0.90235#####> Valid Avg loss: 2.03983, Acc:0.34523, F1: 0.34492
====> Epoch: 316 Train Avg loss: 0.12719, Acc: 0.90158, F1: 0.90158#####> Valid Avg loss: 1.94177, Acc:0.34790, F1: 0.34759
====> Epoch: 317 Train Avg loss: 0.12867, Acc: 0.89869, F1: 0.89869#####> Valid Avg loss: 1.89288, Acc:0.31936, F1: 0.31907
====> Epoch: 318 Train Avg loss: 0.12965, Acc: 0.89888, F1: 0.89888#####> Valid Avg loss: 2.00671, Acc:0.33185, F1: 0.33155
====> Epoch: 319 Train Avg loss: 0.14615, Acc: 0.89251, F1: 0.89251#####> Valid Avg loss: 2.09726, Acc:0.32917, F1: 0.32888
====> Epoch: 320 Train Avg loss: 0.12560, Acc: 0.90544, F1: 0.90544#####> Valid Avg loss: 1.95935, Acc:0.33363, F1: 0.33333
====> Epoch: 321 Train Avg loss: 0.12826, Acc: 0.89502, F1: 0.89502#####> Valid Avg loss: 2.36944, Acc:0.37199, F1: 0.37166
====> Epoch: 322 Train Avg loss: 0.12958, Acc: 0.89907, F1: 0.89907#####> Valid Avg loss: 2.18972, Acc:0.36931, F1: 0.36898
====> Epoch: 323 Train Avg loss: 0.12419, Acc: 0.90486, F1: 0.90486#####> Valid Avg loss: 2.07242, Acc:0.32917, F1: 0.32888
====> Epoch: 324 Train Avg loss: 0.12394, Acc: 0.90718, F1: 0.90718#####> Valid Avg loss: 1.66455, Acc:0.33095, F1: 0.33155
====> Epoch: 325 Train Avg loss: 0.12004, Acc: 0.90583, F1: 0.90583#####> Valid Avg loss: 2.08202, Acc:0.36664, F1: 0.36720
====> Epoch: 326 Train Avg loss: 0.12202, Acc: 0.90332, F1: 0.90332#####> Valid Avg loss: 2.02869, Acc:0.35058, F1: 0.35027
====> Epoch: 327 Train Avg loss: 0.11895, Acc: 0.90197, F1: 0.90197#####> Valid Avg loss: 2.22773, Acc:0.39072, F1: 0.39037
====> Epoch: 328 Train Avg loss: 0.12447, Acc: 0.90139, F1: 0.90139#####> Valid Avg loss: 2.18289, Acc:0.32203, F1: 0.32264
====> Epoch: 329 Train Avg loss: 0.12858, Acc: 0.89965, F1: 0.89965#####> Valid Avg loss: 2.11540, Acc:0.35682, F1: 0.35651
====> Epoch: 330 Train Avg loss: 0.12195, Acc: 0.90158, F1: 0.90158#####> Valid Avg loss: 2.20834, Acc:0.37288, F1: 0.37255
====> Epoch: 331 Train Avg loss: 0.11213, Acc: 0.91200, F1: 0.91200#####> Valid Avg loss: 2.40192, Acc:0.35682, F1: 0.35651
====> Epoch: 332 Train Avg loss: 0.11604, Acc: 0.90699, F1: 0.90699#####> Valid Avg loss: 2.17939, Acc:0.33631, F1: 0.33601
====> Epoch: 333 Train Avg loss: 0.11509, Acc: 0.91104, F1: 0.91104#####> Valid Avg loss: 2.32334, Acc:0.33631, F1: 0.33601
====> Epoch: 334 Train Avg loss: 0.11474, Acc: 0.91355, F1: 0.91355#####> Valid Avg loss: 2.15788, Acc:0.32471, F1: 0.32442
====> Epoch: 335 Train Avg loss: 0.12306, Acc: 0.90216, F1: 0.90216#####> Valid Avg loss: 2.13659, Acc:0.35147, F1: 0.35205
====> Epoch: 336 Train Avg loss: 0.12429, Acc: 0.90004, F1: 0.90004#####> Valid Avg loss: 1.80774, Acc:0.35593, F1: 0.35561
====> Epoch: 337 Train Avg loss: 0.10791, Acc: 0.91683, F1: 0.91683#####> Valid Avg loss: 2.12478, Acc:0.32828, F1: 0.32888
====> Epoch: 338 Train Avg loss: 0.11230, Acc: 0.90621, F1: 0.90621#####> Valid Avg loss: 1.88015, Acc:0.38002, F1: 0.37968
====> Epoch: 339 Train Avg loss: 0.11120, Acc: 0.91355, F1: 0.91355#####> Valid Avg loss: 2.11866, Acc:0.32739, F1: 0.32709
====> Epoch: 340 Train Avg loss: 0.11578, Acc: 0.90911, F1: 0.90911#####> Valid Avg loss: 2.05436, Acc:0.33809, F1: 0.33779
====> Epoch: 341 Train Avg loss: 0.11041, Acc: 0.91625, F1: 0.91625#####> Valid Avg loss: 2.19655, Acc:0.34255, F1: 0.34225
====> Epoch: 342 Train Avg loss: 0.10391, Acc: 0.91972, F1: 0.91972#####> Valid Avg loss: 2.36823, Acc:0.34612, F1: 0.34670
====> Epoch: 343 Train Avg loss: 0.10221, Acc: 0.91548, F1: 0.91548#####> Valid Avg loss: 2.01079, Acc:0.31936, F1: 0.31996
====> Epoch: 344 Train Avg loss: 0.09859, Acc: 0.92242, F1: 0.92242#####> Valid Avg loss: 2.48455, Acc:0.32828, F1: 0.32799
====> Epoch: 345 Train Avg loss: 0.12607, Acc: 0.90293, F1: 0.90293#####> Valid Avg loss: 2.37234, Acc:0.36218, F1: 0.36185
====> Epoch: 346 Train Avg loss: 0.10906, Acc: 0.91258, F1: 0.91258#####> Valid Avg loss: 2.16105, Acc:0.35772, F1: 0.35829
====> Epoch: 347 Train Avg loss: 0.08859, Acc: 0.92898, F1: 0.92898#####> Valid Avg loss: 2.35850, Acc:0.34701, F1: 0.34759
====> Epoch: 348 Train Avg loss: 0.11827, Acc: 0.91046, F1: 0.91046#####> Valid Avg loss: 1.97603, Acc:0.36753, F1: 0.36809
====> Epoch: 349 Train Avg loss: 0.10687, Acc: 0.91818, F1: 0.91818#####> Valid Avg loss: 2.32803, Acc:0.32382, F1: 0.32442
====> Epoch: 350 Train Avg loss: 0.10942, Acc: 0.91277, F1: 0.91277#####> Valid Avg loss: 1.88950, Acc:0.32560, F1: 0.32620
====> Epoch: 351 Train Avg loss: 0.09703, Acc: 0.92667, F1: 0.92667#####> Valid Avg loss: 1.90554, Acc:0.33095, F1: 0.33155
====> Epoch: 352 Train Avg loss: 0.10976, Acc: 0.91123, F1: 0.91123#####> Valid Avg loss: 1.93250, Acc:0.32025, F1: 0.32086
====> Epoch: 353 Train Avg loss: 0.09567, Acc: 0.92204, F1: 0.92204#####> Valid Avg loss: 2.28150, Acc:0.33809, F1: 0.33868
====> Epoch: 354 Train Avg loss: 0.10334, Acc: 0.92242, F1: 0.92242#####> Valid Avg loss: 2.02439, Acc:0.35147, F1: 0.35205
====> Epoch: 355 Train Avg loss: 0.11122, Acc: 0.90756, F1: 0.90756#####> Valid Avg loss: 2.29966, Acc:0.30419, F1: 0.30392
====> Epoch: 356 Train Avg loss: 0.10100, Acc: 0.92030, F1: 0.92030#####> Valid Avg loss: 2.05166, Acc:0.34701, F1: 0.34670
====> Epoch: 357 Train Avg loss: 0.09982, Acc: 0.91895, F1: 0.91895#####> Valid Avg loss: 2.04785, Acc:0.36218, F1: 0.36275
====> Epoch: 358 Train Avg loss: 0.10224, Acc: 0.92397, F1: 0.92397#####> Valid Avg loss: 2.14616, Acc:0.35058, F1: 0.35027
====> Epoch: 359 Train Avg loss: 0.09829, Acc: 0.91799, F1: 0.91799#####> Valid Avg loss: 2.17345, Acc:0.28992, F1: 0.28966
====> Epoch: 360 Train Avg loss: 0.09659, Acc: 0.92397, F1: 0.92397#####> Valid Avg loss: 2.22085, Acc:0.34523, F1: 0.34492
====> Epoch: 361 Train Avg loss: 0.09826, Acc: 0.92358, F1: 0.92358#####> Valid Avg loss: 2.12189, Acc:0.34255, F1: 0.34314
====> Epoch: 362 Train Avg loss: 0.09518, Acc: 0.92011, F1: 0.92011#####> Valid Avg loss: 2.11063, Acc:0.33095, F1: 0.33066
====> Epoch: 363 Train Avg loss: 0.09060, Acc: 0.92879, F1: 0.92879#####> Valid Avg loss: 2.22917, Acc:0.32917, F1: 0.32977
====> Epoch: 364 Train Avg loss: 0.09851, Acc: 0.92242, F1: 0.92242#####> Valid Avg loss: 2.22308, Acc:0.36307, F1: 0.36275
====> Epoch: 365 Train Avg loss: 0.09267, Acc: 0.92397, F1: 0.92397#####> Valid Avg loss: 2.07060, Acc:0.33541, F1: 0.33601
====> Epoch: 366 Train Avg loss: 0.08633, Acc: 0.93111, F1: 0.93111#####> Valid Avg loss: 2.12293, Acc:0.32293, F1: 0.32353
====> Epoch: 367 Train Avg loss: 0.08841, Acc: 0.92802, F1: 0.92802#####> Valid Avg loss: 2.29247, Acc:0.34969, F1: 0.35027
====> Epoch: 368 Train Avg loss: 0.08412, Acc: 0.92686, F1: 0.92686#####> Valid Avg loss: 2.75793, Acc:0.37377, F1: 0.37344
====> Epoch: 369 Train Avg loss: 0.09028, Acc: 0.92860, F1: 0.92860#####> Valid Avg loss: 2.34015, Acc:0.34344, F1: 0.34314
====> Epoch: 370 Train Avg loss: 0.09312, Acc: 0.92628, F1: 0.92628#####> Valid Avg loss: 2.17189, Acc:0.37467, F1: 0.37433
====> Epoch: 371 Train Avg loss: 0.10223, Acc: 0.91992, F1: 0.91992#####> Valid Avg loss: 2.07800, Acc:0.33631, F1: 0.33601
====> Epoch: 372 Train Avg loss: 0.08427, Acc: 0.93246, F1: 0.93246#####> Valid Avg loss: 2.08942, Acc:0.33541, F1: 0.33512
====> Epoch: 373 Train Avg loss: 0.10617, Acc: 0.91837, F1: 0.91837#####> Valid Avg loss: 2.07467, Acc:0.33274, F1: 0.33244
====> Epoch: 374 Train Avg loss: 0.08224, Acc: 0.93420, F1: 0.93420#####> Valid Avg loss: 2.46823, Acc:0.36574, F1: 0.36542
====> Epoch: 375 Train Avg loss: 0.09225, Acc: 0.92763, F1: 0.92763#####> Valid Avg loss: 2.14323, Acc:0.36842, F1: 0.36898
====> Epoch: 376 Train Avg loss: 0.09179, Acc: 0.92609, F1: 0.92609#####> Valid Avg loss: 1.78857, Acc:0.31936, F1: 0.31907
====> Epoch: 377 Train Avg loss: 0.08464, Acc: 0.93053, F1: 0.93053#####> Valid Avg loss: 2.47846, Acc:0.33363, F1: 0.33333
====> Epoch: 378 Train Avg loss: 0.09205, Acc: 0.92609, F1: 0.92609#####> Valid Avg loss: 2.17630, Acc:0.37288, F1: 0.37344
====> Epoch: 379 Train Avg loss: 0.08642, Acc: 0.93207, F1: 0.93207#####> Valid Avg loss: 2.20060, Acc:0.31668, F1: 0.31640
====> Epoch: 380 Train Avg loss: 0.08417, Acc: 0.93342, F1: 0.93342#####> Valid Avg loss: 2.41316, Acc:0.37377, F1: 0.37344
====> Epoch: 381 Train Avg loss: 0.08094, Acc: 0.93574, F1: 0.93574#####> Valid Avg loss: 2.78400, Acc:0.34790, F1: 0.34759
====> Epoch: 382 Train Avg loss: 0.09167, Acc: 0.92397, F1: 0.92397#####> Valid Avg loss: 2.58092, Acc:0.33185, F1: 0.33155
====> Epoch: 383 Train Avg loss: 0.08629, Acc: 0.93323, F1: 0.93323#####> Valid Avg loss: 2.49608, Acc:0.35058, F1: 0.35027
====> Epoch: 384 Train Avg loss: 0.08851, Acc: 0.93014, F1: 0.93014#####> Valid Avg loss: 2.19079, Acc:0.32293, F1: 0.32264
====> Epoch: 385 Train Avg loss: 0.08622, Acc: 0.93188, F1: 0.93188#####> Valid Avg loss: 2.62548, Acc:0.33898, F1: 0.33868
====> Epoch: 386 Train Avg loss: 0.08362, Acc: 0.93149, F1: 0.93149#####> Valid Avg loss: 2.22210, Acc:0.32739, F1: 0.32799
====> Epoch: 387 Train Avg loss: 0.07852, Acc: 0.94191, F1: 0.94191#####> Valid Avg loss: 2.63951, Acc:0.33631, F1: 0.33601
====> Epoch: 388 Train Avg loss: 0.08318, Acc: 0.92956, F1: 0.92956#####> Valid Avg loss: 2.21679, Acc:0.33898, F1: 0.33868
====> Epoch: 389 Train Avg loss: 0.07514, Acc: 0.93998, F1: 0.93998#####> Valid Avg loss: 2.19035, Acc:0.35236, F1: 0.35205
====> Epoch: 390 Train Avg loss: 0.07971, Acc: 0.93670, F1: 0.93670#####> Valid Avg loss: 2.44408, Acc:0.33720, F1: 0.33690
====> Epoch: 391 Train Avg loss: 0.07883, Acc: 0.93458, F1: 0.93458#####> Valid Avg loss: 2.37132, Acc:0.33720, F1: 0.33779
====> Epoch: 392 Train Avg loss: 0.07057, Acc: 0.93979, F1: 0.93979#####> Valid Avg loss: 2.19710, Acc:0.32560, F1: 0.32531
====> Epoch: 393 Train Avg loss: 0.07571, Acc: 0.93497, F1: 0.93497#####> Valid Avg loss: 2.38829, Acc:0.36307, F1: 0.36275
====> Epoch: 394 Train Avg loss: 0.08160, Acc: 0.93149, F1: 0.93149#####> Valid Avg loss: 2.18806, Acc:0.33363, F1: 0.33333
====> Epoch: 395 Train Avg loss: 0.08131, Acc: 0.93593, F1: 0.93593#####> Valid Avg loss: 2.36490, Acc:0.34166, F1: 0.34135
====> Epoch: 396 Train Avg loss: 0.07841, Acc: 0.93709, F1: 0.93709#####> Valid Avg loss: 2.17427, Acc:0.35058, F1: 0.35027
====> Epoch: 397 Train Avg loss: 0.07695, Acc: 0.93690, F1: 0.93690#####> Valid Avg loss: 2.30110, Acc:0.32739, F1: 0.32709
====> Epoch: 398 Train Avg loss: 0.07386, Acc: 0.93748, F1: 0.93748#####> Valid Avg loss: 2.40054, Acc:0.33631, F1: 0.33601
====> Epoch: 399 Train Avg loss: 0.06153, Acc: 0.94732, F1: 0.94732#####> Valid Avg loss: 2.38771, Acc:0.33095, F1: 0.33155
====> Epoch: 400 Train Avg loss: 0.09123, Acc: 0.92841, F1: 0.92841#####> Valid Avg loss: 2.24402, Acc:0.35861, F1: 0.35829
====> Epoch: 401 Train Avg loss: 0.07690, Acc: 0.93670, F1: 0.93670#####> Valid Avg loss: 2.42040, Acc:0.35058, F1: 0.35027
====> Epoch: 402 Train Avg loss: 0.06780, Acc: 0.94674, F1: 0.94674#####> Valid Avg loss: 2.32987, Acc:0.36931, F1: 0.36988
====> Epoch: 403 Train Avg loss: 0.07130, Acc: 0.94095, F1: 0.94095#####> Valid Avg loss: 2.56170, Acc:0.35861, F1: 0.35829
====> Epoch: 404 Train Avg loss: 0.07186, Acc: 0.94134, F1: 0.94134#####> Valid Avg loss: 2.55053, Acc:0.30152, F1: 0.30125
====> Epoch: 405 Train Avg loss: 0.07438, Acc: 0.93593, F1: 0.93593#####> Valid Avg loss: 2.52690, Acc:0.33720, F1: 0.33690
====> Epoch: 406 Train Avg loss: 0.07387, Acc: 0.94153, F1: 0.94153#####> Valid Avg loss: 2.32325, Acc:0.35326, F1: 0.35383
====> Epoch: 407 Train Avg loss: 0.07803, Acc: 0.93593, F1: 0.93593#####> Valid Avg loss: 2.21398, Acc:0.31847, F1: 0.31818
====> Epoch: 408 Train Avg loss: 0.06462, Acc: 0.94770, F1: 0.94770#####> Valid Avg loss: 2.64685, Acc:0.35147, F1: 0.35116
====> Epoch: 409 Train Avg loss: 0.06940, Acc: 0.93960, F1: 0.93960#####> Valid Avg loss: 1.93092, Acc:0.32471, F1: 0.32442
====> Epoch: 410 Train Avg loss: 0.07490, Acc: 0.93863, F1: 0.93863#####> Valid Avg loss: 1.96458, Acc:0.33274, F1: 0.33244
====> Epoch: 411 Train Avg loss: 0.06194, Acc: 0.94481, F1: 0.94481#####> Valid Avg loss: 2.34771, Acc:0.32739, F1: 0.32799
====> Epoch: 412 Train Avg loss: 0.06428, Acc: 0.94693, F1: 0.94693#####> Valid Avg loss: 2.54299, Acc:0.34523, F1: 0.34492
====> Epoch: 413 Train Avg loss: 0.06566, Acc: 0.94211, F1: 0.94211#####> Valid Avg loss: 2.43934, Acc:0.35772, F1: 0.35740
====> Epoch: 414 Train Avg loss: 0.06742, Acc: 0.94481, F1: 0.94481#####> Valid Avg loss: 2.06329, Acc:0.32203, F1: 0.32175
====> Epoch: 415 Train Avg loss: 0.07136, Acc: 0.93902, F1: 0.93902#####> Valid Avg loss: 2.47000, Acc:0.34523, F1: 0.34492
====> Epoch: 416 Train Avg loss: 0.06215, Acc: 0.94616, F1: 0.94616#####> Valid Avg loss: 2.35677, Acc:0.35326, F1: 0.35294
====> Epoch: 417 Train Avg loss: 0.06359, Acc: 0.94500, F1: 0.94500#####> Valid Avg loss: 2.61785, Acc:0.32471, F1: 0.32442
====> Epoch: 418 Train Avg loss: 0.06776, Acc: 0.94616, F1: 0.94616#####> Valid Avg loss: 2.07118, Acc:0.32025, F1: 0.32086
====> Epoch: 419 Train Avg loss: 0.06044, Acc: 0.94886, F1: 0.94886#####> Valid Avg loss: 2.59714, Acc:0.32114, F1: 0.32086
====> Epoch: 420 Train Avg loss: 0.07240, Acc: 0.94384, F1: 0.94384#####> Valid Avg loss: 2.36590, Acc:0.33095, F1: 0.33066
====> Epoch: 421 Train Avg loss: 0.06082, Acc: 0.94886, F1: 0.94886#####> Valid Avg loss: 2.27497, Acc:0.33988, F1: 0.34046
====> Epoch: 422 Train Avg loss: 0.06535, Acc: 0.94481, F1: 0.94481#####> Valid Avg loss: 2.38928, Acc:0.33898, F1: 0.33868
====> Epoch: 423 Train Avg loss: 0.06170, Acc: 0.94597, F1: 0.94597#####> Valid Avg loss: 2.35006, Acc:0.32739, F1: 0.32709
====> Epoch: 424 Train Avg loss: 0.05285, Acc: 0.95291, F1: 0.95291#####> Valid Avg loss: 2.53432, Acc:0.33185, F1: 0.33155
====> Epoch: 425 Train Avg loss: 0.06390, Acc: 0.94635, F1: 0.94635#####> Valid Avg loss: 2.62484, Acc:0.38269, F1: 0.38235
====> Epoch: 426 Train Avg loss: 0.06131, Acc: 0.95060, F1: 0.95060#####> Valid Avg loss: 2.30866, Acc:0.36574, F1: 0.36542
====> Epoch: 427 Train Avg loss: 0.05911, Acc: 0.95234, F1: 0.95234#####> Valid Avg loss: 2.49546, Acc:0.34523, F1: 0.34581
====> Epoch: 428 Train Avg loss: 0.05929, Acc: 0.94886, F1: 0.94886#####> Valid Avg loss: 2.20347, Acc:0.33898, F1: 0.33868
====> Epoch: 429 Train Avg loss: 0.06420, Acc: 0.94423, F1: 0.94423#####> Valid Avg loss: 2.49573, Acc:0.34166, F1: 0.34135
====> Epoch: 430 Train Avg loss: 0.06021, Acc: 0.94751, F1: 0.94751#####> Valid Avg loss: 2.53967, Acc:0.35415, F1: 0.35383
====> Epoch: 431 Train Avg loss: 0.04788, Acc: 0.95755, F1: 0.95755#####> Valid Avg loss: 2.68602, Acc:0.33720, F1: 0.33690
====> Epoch: 432 Train Avg loss: 0.06881, Acc: 0.94597, F1: 0.94597#####> Valid Avg loss: 2.47571, Acc:0.35593, F1: 0.35561
====> Epoch: 433 Train Avg loss: 0.05658, Acc: 0.95156, F1: 0.95156#####> Valid Avg loss: 2.61564, Acc:0.34434, F1: 0.34403
====> Epoch: 434 Train Avg loss: 0.05420, Acc: 0.95369, F1: 0.95369#####> Valid Avg loss: 2.49721, Acc:0.29884, F1: 0.29857
====> Epoch: 435 Train Avg loss: 0.06356, Acc: 0.94635, F1: 0.94635#####> Valid Avg loss: 2.39290, Acc:0.33541, F1: 0.33512
====> Epoch: 436 Train Avg loss: 0.05192, Acc: 0.95562, F1: 0.95562#####> Valid Avg loss: 2.67038, Acc:0.34969, F1: 0.34938
====> Epoch: 437 Train Avg loss: 0.06394, Acc: 0.94655, F1: 0.94655#####> Valid Avg loss: 2.54011, Acc:0.35236, F1: 0.35294
====> Epoch: 438 Train Avg loss: 0.05024, Acc: 0.95832, F1: 0.95832#####> Valid Avg loss: 2.58612, Acc:0.34969, F1: 0.35027
====> Epoch: 439 Train Avg loss: 0.05807, Acc: 0.95369, F1: 0.95369#####> Valid Avg loss: 2.53381, Acc:0.35147, F1: 0.35116
====> Epoch: 440 Train Avg loss: 0.05225, Acc: 0.95214, F1: 0.95214#####> Valid Avg loss: 2.55576, Acc:0.33898, F1: 0.33868
====> Epoch: 441 Train Avg loss: 0.05052, Acc: 0.95677, F1: 0.95677#####> Valid Avg loss: 2.23784, Acc:0.32025, F1: 0.32086
====> Epoch: 442 Train Avg loss: 0.05521, Acc: 0.95407, F1: 0.95407#####> Valid Avg loss: 2.34253, Acc:0.31847, F1: 0.31818
====> Epoch: 443 Train Avg loss: 0.05636, Acc: 0.95523, F1: 0.95523#####> Valid Avg loss: 2.46104, Acc:0.34612, F1: 0.34670
====> Epoch: 444 Train Avg loss: 0.05109, Acc: 0.95890, F1: 0.95890#####> Valid Avg loss: 2.77292, Acc:0.36396, F1: 0.36364
====> Epoch: 445 Train Avg loss: 0.05308, Acc: 0.95446, F1: 0.95446#####> Valid Avg loss: 2.56797, Acc:0.32828, F1: 0.32799
====> Epoch: 446 Train Avg loss: 0.05131, Acc: 0.95446, F1: 0.95446#####> Valid Avg loss: 2.64450, Acc:0.33809, F1: 0.33868
====> Epoch: 447 Train Avg loss: 0.05025, Acc: 0.95562, F1: 0.95562#####> Valid Avg loss: 2.52344, Acc:0.35950, F1: 0.36007
====> Epoch: 448 Train Avg loss: 0.04997, Acc: 0.95774, F1: 0.95774#####> Valid Avg loss: 2.65086, Acc:0.34969, F1: 0.34938
====> Epoch: 449 Train Avg loss: 0.04811, Acc: 0.95600, F1: 0.95600#####> Valid Avg loss: 2.89602, Acc:0.36307, F1: 0.36275
====> Epoch: 450 Train Avg loss: 0.05342, Acc: 0.95098, F1: 0.95098#####> Valid Avg loss: 2.71865, Acc:0.35504, F1: 0.35472
====> Epoch: 451 Train Avg loss: 0.04700, Acc: 0.95948, F1: 0.95948#####> Valid Avg loss: 2.90835, Acc:0.34077, F1: 0.34046
====> Epoch: 452 Train Avg loss: 0.05735, Acc: 0.95234, F1: 0.95234#####> Valid Avg loss: 2.64703, Acc:0.37288, F1: 0.37255
====> Epoch: 453 Train Avg loss: 0.04364, Acc: 0.96121, F1: 0.96121#####> Valid Avg loss: 2.25600, Acc:0.34880, F1: 0.34938
====> Epoch: 454 Train Avg loss: 0.04444, Acc: 0.95697, F1: 0.95697#####> Valid Avg loss: 2.52921, Acc:0.36664, F1: 0.36631
====> Epoch: 455 Train Avg loss: 0.05210, Acc: 0.95697, F1: 0.95697#####> Valid Avg loss: 2.79202, Acc:0.36931, F1: 0.36898
====> Epoch: 456 Train Avg loss: 0.04205, Acc: 0.96044, F1: 0.96044#####> Valid Avg loss: 2.46825, Acc:0.30330, F1: 0.30303
====> Epoch: 457 Train Avg loss: 0.04624, Acc: 0.96140, F1: 0.96140#####> Valid Avg loss: 2.69812, Acc:0.34344, F1: 0.34314
====> Epoch: 458 Train Avg loss: 0.04815, Acc: 0.95909, F1: 0.95909#####> Valid Avg loss: 2.50711, Acc:0.34880, F1: 0.34938
====> Epoch: 459 Train Avg loss: 0.05125, Acc: 0.95465, F1: 0.95465#####> Valid Avg loss: 2.38425, Acc:0.32739, F1: 0.32799
====> Epoch: 460 Train Avg loss: 0.04690, Acc: 0.95774, F1: 0.95774#####> Valid Avg loss: 2.51949, Acc:0.34790, F1: 0.34759
====> Epoch: 461 Train Avg loss: 0.04538, Acc: 0.95600, F1: 0.95600#####> Valid Avg loss: 2.62371, Acc:0.36396, F1: 0.36453
====> Epoch: 462 Train Avg loss: 0.04223, Acc: 0.96083, F1: 0.96083#####> Valid Avg loss: 2.79318, Acc:0.31936, F1: 0.31907
====> Epoch: 463 Train Avg loss: 0.04310, Acc: 0.96140, F1: 0.96140#####> Valid Avg loss: 3.07923, Acc:0.32203, F1: 0.32175
====> Epoch: 464 Train Avg loss: 0.03886, Acc: 0.96295, F1: 0.96295#####> Valid Avg loss: 3.16740, Acc:0.36485, F1: 0.36453
====> Epoch: 465 Train Avg loss: 0.04326, Acc: 0.96083, F1: 0.96083#####> Valid Avg loss: 2.58305, Acc:0.33631, F1: 0.33601
====> Epoch: 466 Train Avg loss: 0.04433, Acc: 0.96102, F1: 0.96102#####> Valid Avg loss: 2.31263, Acc:0.31490, F1: 0.31551
====> Epoch: 467 Train Avg loss: 0.04583, Acc: 0.95909, F1: 0.95909#####> Valid Avg loss: 2.77999, Acc:0.34344, F1: 0.34403
====> Epoch: 468 Train Avg loss: 0.04590, Acc: 0.95870, F1: 0.95870#####> Valid Avg loss: 3.14370, Acc:0.35326, F1: 0.35294
====> Epoch: 469 Train Avg loss: 0.03479, Acc: 0.96488, F1: 0.96488#####> Valid Avg loss: 2.59421, Acc:0.35326, F1: 0.35383
====> Epoch: 470 Train Avg loss: 0.05090, Acc: 0.95735, F1: 0.95735#####> Valid Avg loss: 2.76031, Acc:0.36128, F1: 0.36185
====> Epoch: 471 Train Avg loss: 0.04338, Acc: 0.96353, F1: 0.96353#####> Valid Avg loss: 2.81469, Acc:0.34701, F1: 0.34759
====> Epoch: 472 Train Avg loss: 0.03699, Acc: 0.96449, F1: 0.96449#####> Valid Avg loss: 2.87609, Acc:0.37110, F1: 0.37166
====> Epoch: 473 Train Avg loss: 0.04485, Acc: 0.95716, F1: 0.95716#####> Valid Avg loss: 2.58026, Acc:0.35236, F1: 0.35294
====> Epoch: 474 Train Avg loss: 0.04094, Acc: 0.96063, F1: 0.96063#####> Valid Avg loss: 2.64436, Acc:0.34255, F1: 0.34225
====> Epoch: 475 Train Avg loss: 0.04234, Acc: 0.96102, F1: 0.96102#####> Valid Avg loss: 2.31384, Acc:0.27654, F1: 0.27718
====> Epoch: 476 Train Avg loss: 0.04290, Acc: 0.96121, F1: 0.96121#####> Valid Avg loss: 2.58350, Acc:0.33898, F1: 0.33868
====> Epoch: 477 Train Avg loss: 0.03784, Acc: 0.96565, F1: 0.96565#####> Valid Avg loss: 2.43289, Acc:0.31847, F1: 0.31907
====> Epoch: 478 Train Avg loss: 0.03728, Acc: 0.96546, F1: 0.96546#####> Valid Avg loss: 2.74958, Acc:0.33095, F1: 0.33066
====> Epoch: 479 Train Avg loss: 0.03551, Acc: 0.96391, F1: 0.96391#####> Valid Avg loss: 3.12214, Acc:0.33631, F1: 0.33601
====> Epoch: 480 Train Avg loss: 0.04064, Acc: 0.96179, F1: 0.96179#####> Valid Avg loss: 2.65085, Acc:0.34880, F1: 0.34848
====> Epoch: 481 Train Avg loss: 0.03803, Acc: 0.96333, F1: 0.96333#####> Valid Avg loss: 2.73330, Acc:0.32203, F1: 0.32175
====> Epoch: 482 Train Avg loss: 0.03807, Acc: 0.96526, F1: 0.96526#####> Valid Avg loss: 2.72575, Acc:0.35772, F1: 0.35740
====> Epoch: 483 Train Avg loss: 0.03603, Acc: 0.96488, F1: 0.96488#####> Valid Avg loss: 2.88717, Acc:0.34523, F1: 0.34492
====> Epoch: 484 Train Avg loss: 0.03802, Acc: 0.96353, F1: 0.96353#####> Valid Avg loss: 2.82065, Acc:0.35682, F1: 0.35651
====> Epoch: 485 Train Avg loss: 0.03397, Acc: 0.96604, F1: 0.96604#####> Valid Avg loss: 2.78166, Acc:0.33988, F1: 0.33957
====> Epoch: 486 Train Avg loss: 0.03978, Acc: 0.96333, F1: 0.96333#####> Valid Avg loss: 2.77967, Acc:0.36307, F1: 0.36275
====> Epoch: 487 Train Avg loss: 0.02779, Acc: 0.97067, F1: 0.97067#####> Valid Avg loss: 3.08403, Acc:0.35415, F1: 0.35383
====> Epoch: 488 Train Avg loss: 0.04059, Acc: 0.95851, F1: 0.95851#####> Valid Avg loss: 2.26225, Acc:0.31311, F1: 0.31373
====> Epoch: 489 Train Avg loss: 0.03101, Acc: 0.96681, F1: 0.96681#####> Valid Avg loss: 2.66063, Acc:0.29438, F1: 0.29412
====> Epoch: 490 Train Avg loss: 0.03282, Acc: 0.96623, F1: 0.96623#####> Valid Avg loss: 3.09597, Acc:0.34790, F1: 0.34759
====> Epoch: 491 Train Avg loss: 0.03277, Acc: 0.96488, F1: 0.96488#####> Valid Avg loss: 2.57697, Acc:0.35415, F1: 0.35472
====> Epoch: 492 Train Avg loss: 0.03592, Acc: 0.96526, F1: 0.96526#####> Valid Avg loss: 2.64342, Acc:0.31133, F1: 0.31105
====> Epoch: 493 Train Avg loss: 0.03615, Acc: 0.96295, F1: 0.96295#####> Valid Avg loss: 2.86995, Acc:0.30687, F1: 0.30660
====> Epoch: 494 Train Avg loss: 0.02788, Acc: 0.96835, F1: 0.96835#####> Valid Avg loss: 2.57748, Acc:0.31490, F1: 0.31462
====> Epoch: 495 Train Avg loss: 0.03229, Acc: 0.96604, F1: 0.96604#####> Valid Avg loss: 2.69209, Acc:0.32828, F1: 0.32799
====> Epoch: 496 Train Avg loss: 0.03137, Acc: 0.97221, F1: 0.97221#####> Valid Avg loss: 2.56162, Acc:0.31044, F1: 0.31016
====> Epoch: 497 Train Avg loss: 0.03408, Acc: 0.96758, F1: 0.96758#####> Valid Avg loss: 2.56021, Acc:0.34434, F1: 0.34403
====> Epoch: 498 Train Avg loss: 0.03117, Acc: 0.97047, F1: 0.97047#####> Valid Avg loss: 2.70000, Acc:0.35415, F1: 0.35383
====> Epoch: 499 Train Avg loss: 0.03121, Acc: 0.96739, F1: 0.96739#####> Valid Avg loss: 2.55167, Acc:0.34166, F1: 0.34135
====> Epoch: 500 Train Avg loss: 0.03392, Acc: 0.96584, F1: 0.96584#####> Valid Avg loss: 2.51641, Acc:0.34880, F1: 0.34848
#####> Valid Avg loss: 4.85765, Acc:0.26857, F1: 0.26857


$$$$$$> Test it 1: (from train best model) Final Test Avg loss:4.85765, Acc:0.26857, F1:0.26857\n
#####> Valid Avg loss: 1.98319, Acc:0.24190, F1: 0.24190


$$$$$$> Test it 1: (from max acc valid model) Final Test Avg loss:1.98319, Acc:0.24190, F1:0.24190\n
#####> Valid Avg loss: 0.97963, Acc:0.38476, F1: 0.38476


$$$$$$> Test it 1: (from min loss valid model) Final Test Avg loss:0.97963, Acc:0.38476, F1:0.38476\n


	Start execution training validation it 2 

train_dataloader len: 2591
valid_dataloader len: 525
test_dataloader len: 561
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [1]
test performers ids: [2]
train dataset len: 5182, train dataloader len: 2591
valid dataset len: 1050, valid dataloader len: 525
valid dataset len: 1121, test dataloader len: 525
====> Epoch: 1 Train Avg loss: 0.70722, Acc: 0.50695, F1: 0.50695#####> Valid Avg loss: 0.85870, Acc:0.35619, F1: 0.35619
===> Epoch: 1: Training loss decreased (inf --> 0.70722), Acc: (0.00000 --> 0.50695), F1: (0.00000 --> 0.50695).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2

####> Epoch: 1: validation loss decreased (inf --> 0.85870), Acc: (0.00000 --> 0.35619), F1: (0.00000 --> 0.35619).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2

####> Epoch: 1: validation acc increase (inf --> 0.85870), Acc: (0.00000 --> 0.35619), F1: (0.00000 --> 0.35619).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 2 Train Avg loss: 0.58274, Acc: 0.61501, F1: 0.61501#####> Valid Avg loss: 0.84687, Acc:0.47810, F1: 0.47810
===> Epoch: 2: Training loss decreased (0.70722 --> 0.58274), Acc: (0.50695 --> 0.61501), F1: (0.50695 --> 0.61501).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2

####> Epoch: 2: validation loss decreased (0.85870 --> 0.84687), Acc: (0.35619 --> 0.47810), F1: (0.35619 --> 0.47810).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2

####> Epoch: 2: validation acc increase (0.85870 --> 0.84687), Acc: (0.35619 --> 0.47810), F1: (0.35619 --> 0.47810).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 3 Train Avg loss: 0.53869, Acc: 0.63431, F1: 0.63431#####> Valid Avg loss: 1.13204, Acc:0.41619, F1: 0.41619
===> Epoch: 3: Training loss decreased (0.58274 --> 0.53869), Acc: (0.61501 --> 0.63431), F1: (0.61501 --> 0.63431).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 4 Train Avg loss: 0.51956, Acc: 0.64531, F1: 0.64531#####> Valid Avg loss: 1.33831, Acc:0.27524, F1: 0.27524
===> Epoch: 4: Training loss decreased (0.53869 --> 0.51956), Acc: (0.63431 --> 0.64531), F1: (0.63431 --> 0.64531).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 5 Train Avg loss: 0.50472, Acc: 0.65535, F1: 0.65535#####> Valid Avg loss: 1.49516, Acc:0.29619, F1: 0.29619
===> Epoch: 5: Training loss decreased (0.51956 --> 0.50472), Acc: (0.64531 --> 0.65535), F1: (0.64531 --> 0.65535).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 6 Train Avg loss: 0.48895, Acc: 0.66075, F1: 0.66075#####> Valid Avg loss: 1.47141, Acc:0.27810, F1: 0.27810
===> Epoch: 6: Training loss decreased (0.50472 --> 0.48895), Acc: (0.65535 --> 0.66075), F1: (0.65535 --> 0.66075).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 7 Train Avg loss: 0.47340, Acc: 0.66924, F1: 0.66924#####> Valid Avg loss: 1.39530, Acc:0.27905, F1: 0.27905
===> Epoch: 7: Training loss decreased (0.48895 --> 0.47340), Acc: (0.66075 --> 0.66924), F1: (0.66075 --> 0.66924).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 8 Train Avg loss: 0.46513, Acc: 0.67271, F1: 0.67271#####> Valid Avg loss: 1.02158, Acc:0.40857, F1: 0.40857
===> Epoch: 8: Training loss decreased (0.47340 --> 0.46513), Acc: (0.66924 --> 0.67271), F1: (0.66924 --> 0.67271).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 9 Train Avg loss: 0.45872, Acc: 0.67349, F1: 0.67349#####> Valid Avg loss: 1.32666, Acc:0.31905, F1: 0.31905
===> Epoch: 9: Training loss decreased (0.46513 --> 0.45872), Acc: (0.67271 --> 0.67349), F1: (0.67271 --> 0.67349).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 10 Train Avg loss: 0.44564, Acc: 0.68217, F1: 0.68217#####> Valid Avg loss: 1.41635, Acc:0.29238, F1: 0.29238
===> Epoch: 10: Training loss decreased (0.45872 --> 0.44564), Acc: (0.67349 --> 0.68217), F1: (0.67349 --> 0.68217).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 11 Train Avg loss: 0.43702, Acc: 0.69085, F1: 0.69085#####> Valid Avg loss: 1.18602, Acc:0.35714, F1: 0.35714
===> Epoch: 11: Training loss decreased (0.44564 --> 0.43702), Acc: (0.68217 --> 0.69085), F1: (0.68217 --> 0.69085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 12 Train Avg loss: 0.43566, Acc: 0.68120, F1: 0.68120#####> Valid Avg loss: 1.46804, Acc:0.31429, F1: 0.31429
===> Epoch: 12: Training loss decreased (0.43702 --> 0.43566), Acc: (0.69085 --> 0.68120), F1: (0.69085 --> 0.68120).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 13 Train Avg loss: 0.42489, Acc: 0.69780, F1: 0.69780#####> Valid Avg loss: 1.86497, Acc:0.25429, F1: 0.25429
===> Epoch: 13: Training loss decreased (0.43566 --> 0.42489), Acc: (0.68120 --> 0.69780), F1: (0.68120 --> 0.69780).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 14 Train Avg loss: 0.41557, Acc: 0.69471, F1: 0.69471#####> Valid Avg loss: 1.79812, Acc:0.34952, F1: 0.34952
===> Epoch: 14: Training loss decreased (0.42489 --> 0.41557), Acc: (0.69780 --> 0.69471), F1: (0.69780 --> 0.69471).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 15 Train Avg loss: 0.41356, Acc: 0.70282, F1: 0.70282#####> Valid Avg loss: 1.74342, Acc:0.26857, F1: 0.26857
===> Epoch: 15: Training loss decreased (0.41557 --> 0.41356), Acc: (0.69471 --> 0.70282), F1: (0.69471 --> 0.70282).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 16 Train Avg loss: 0.40673, Acc: 0.70861, F1: 0.70861#####> Valid Avg loss: 2.04843, Acc:0.27143, F1: 0.27143
===> Epoch: 16: Training loss decreased (0.41356 --> 0.40673), Acc: (0.70282 --> 0.70861), F1: (0.70282 --> 0.70861).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 17 Train Avg loss: 0.39880, Acc: 0.71189, F1: 0.71189#####> Valid Avg loss: 1.58579, Acc:0.29429, F1: 0.29429
===> Epoch: 17: Training loss decreased (0.40673 --> 0.39880), Acc: (0.70861 --> 0.71189), F1: (0.70861 --> 0.71189).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 18 Train Avg loss: 0.39792, Acc: 0.71150, F1: 0.71150#####> Valid Avg loss: 1.29882, Acc:0.39048, F1: 0.39048
===> Epoch: 18: Training loss decreased (0.39880 --> 0.39792), Acc: (0.71189 --> 0.71150), F1: (0.71189 --> 0.71150).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 19 Train Avg loss: 0.39421, Acc: 0.71748, F1: 0.71748#####> Valid Avg loss: 1.73758, Acc:0.24952, F1: 0.24952
===> Epoch: 19: Training loss decreased (0.39792 --> 0.39421), Acc: (0.71150 --> 0.71748), F1: (0.71150 --> 0.71748).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 20 Train Avg loss: 0.38570, Acc: 0.72154, F1: 0.72154#####> Valid Avg loss: 2.70547, Acc:0.24286, F1: 0.24286
===> Epoch: 20: Training loss decreased (0.39421 --> 0.38570), Acc: (0.71748 --> 0.72154), F1: (0.71748 --> 0.72154).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 21 Train Avg loss: 0.38285, Acc: 0.72578, F1: 0.72578#####> Valid Avg loss: 1.59537, Acc:0.25810, F1: 0.25810
===> Epoch: 21: Training loss decreased (0.38570 --> 0.38285), Acc: (0.72154 --> 0.72578), F1: (0.72154 --> 0.72578).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 22 Train Avg loss: 0.37065, Acc: 0.73389, F1: 0.73389#####> Valid Avg loss: 2.33468, Acc:0.22952, F1: 0.22952
===> Epoch: 22: Training loss decreased (0.38285 --> 0.37065), Acc: (0.72578 --> 0.73389), F1: (0.72578 --> 0.73389).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 23 Train Avg loss: 0.36454, Acc: 0.73736, F1: 0.73736#####> Valid Avg loss: 1.80669, Acc:0.33619, F1: 0.33619
===> Epoch: 23: Training loss decreased (0.37065 --> 0.36454), Acc: (0.73389 --> 0.73736), F1: (0.73389 --> 0.73736).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 24 Train Avg loss: 0.36715, Acc: 0.73176, F1: 0.73176#####> Valid Avg loss: 1.72986, Acc:0.36762, F1: 0.36762
====> Epoch: 25 Train Avg loss: 0.35968, Acc: 0.74083, F1: 0.74083#####> Valid Avg loss: 1.99168, Acc:0.26952, F1: 0.26952
===> Epoch: 25: Training loss decreased (0.36454 --> 0.35968), Acc: (0.73736 --> 0.74083), F1: (0.73736 --> 0.74083).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 26 Train Avg loss: 0.35207, Acc: 0.74315, F1: 0.74315#####> Valid Avg loss: 1.90148, Acc:0.23810, F1: 0.23810
===> Epoch: 26: Training loss decreased (0.35968 --> 0.35207), Acc: (0.74083 --> 0.74315), F1: (0.74083 --> 0.74315).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 27 Train Avg loss: 0.34056, Acc: 0.75318, F1: 0.75318#####> Valid Avg loss: 1.98663, Acc:0.32667, F1: 0.32667
===> Epoch: 27: Training loss decreased (0.35207 --> 0.34056), Acc: (0.74315 --> 0.75318), F1: (0.74315 --> 0.75318).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 28 Train Avg loss: 0.34401, Acc: 0.74469, F1: 0.74469#####> Valid Avg loss: 1.53089, Acc:0.32190, F1: 0.32190
====> Epoch: 29 Train Avg loss: 0.33497, Acc: 0.75646, F1: 0.75646#####> Valid Avg loss: 1.90377, Acc:0.27143, F1: 0.27143
===> Epoch: 29: Training loss decreased (0.34056 --> 0.33497), Acc: (0.75318 --> 0.75646), F1: (0.75318 --> 0.75646).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 30 Train Avg loss: 0.33473, Acc: 0.75357, F1: 0.75357#####> Valid Avg loss: 1.76883, Acc:0.34762, F1: 0.34762
===> Epoch: 30: Training loss decreased (0.33497 --> 0.33473), Acc: (0.75646 --> 0.75357), F1: (0.75646 --> 0.75357).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 31 Train Avg loss: 0.32754, Acc: 0.76013, F1: 0.76013#####> Valid Avg loss: 2.08038, Acc:0.33810, F1: 0.33810
===> Epoch: 31: Training loss decreased (0.33473 --> 0.32754), Acc: (0.75357 --> 0.76013), F1: (0.75357 --> 0.76013).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 32 Train Avg loss: 0.31809, Acc: 0.75975, F1: 0.75975#####> Valid Avg loss: 2.51424, Acc:0.24857, F1: 0.24857
===> Epoch: 32: Training loss decreased (0.32754 --> 0.31809), Acc: (0.76013 --> 0.75975), F1: (0.76013 --> 0.75975).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 33 Train Avg loss: 0.31620, Acc: 0.76553, F1: 0.76553#####> Valid Avg loss: 1.92932, Acc:0.28571, F1: 0.28571
===> Epoch: 33: Training loss decreased (0.31809 --> 0.31620), Acc: (0.75975 --> 0.76553), F1: (0.75975 --> 0.76553).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 34 Train Avg loss: 0.30336, Acc: 0.77673, F1: 0.77673#####> Valid Avg loss: 2.32343, Acc:0.31238, F1: 0.31238
===> Epoch: 34: Training loss decreased (0.31620 --> 0.30336), Acc: (0.76553 --> 0.77673), F1: (0.76553 --> 0.77673).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 35 Train Avg loss: 0.29956, Acc: 0.77499, F1: 0.77499#####> Valid Avg loss: 1.94606, Acc:0.32000, F1: 0.32000
===> Epoch: 35: Training loss decreased (0.30336 --> 0.29956), Acc: (0.77673 --> 0.77499), F1: (0.77673 --> 0.77499).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 36 Train Avg loss: 0.29041, Acc: 0.78252, F1: 0.78252#####> Valid Avg loss: 2.07057, Acc:0.31048, F1: 0.31048
===> Epoch: 36: Training loss decreased (0.29956 --> 0.29041), Acc: (0.77499 --> 0.78252), F1: (0.77499 --> 0.78252).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 37 Train Avg loss: 0.28185, Acc: 0.78580, F1: 0.78580#####> Valid Avg loss: 1.59634, Acc:0.38952, F1: 0.38952
===> Epoch: 37: Training loss decreased (0.29041 --> 0.28185), Acc: (0.78252 --> 0.78580), F1: (0.78252 --> 0.78580).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 38 Train Avg loss: 0.27291, Acc: 0.79159, F1: 0.79159#####> Valid Avg loss: 1.90109, Acc:0.33333, F1: 0.33333
===> Epoch: 38: Training loss decreased (0.28185 --> 0.27291), Acc: (0.78580 --> 0.79159), F1: (0.78580 --> 0.79159).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 39 Train Avg loss: 0.26442, Acc: 0.79602, F1: 0.79602#####> Valid Avg loss: 2.09827, Acc:0.32476, F1: 0.32476
===> Epoch: 39: Training loss decreased (0.27291 --> 0.26442), Acc: (0.79159 --> 0.79602), F1: (0.79159 --> 0.79602).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 40 Train Avg loss: 0.25929, Acc: 0.79873, F1: 0.79873#####> Valid Avg loss: 2.49883, Acc:0.26190, F1: 0.26190
===> Epoch: 40: Training loss decreased (0.26442 --> 0.25929), Acc: (0.79602 --> 0.79873), F1: (0.79602 --> 0.79873).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 41 Train Avg loss: 0.24798, Acc: 0.80973, F1: 0.80973#####> Valid Avg loss: 2.37785, Acc:0.33810, F1: 0.33810
===> Epoch: 41: Training loss decreased (0.25929 --> 0.24798), Acc: (0.79873 --> 0.80973), F1: (0.79873 --> 0.80973).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 42 Train Avg loss: 0.23682, Acc: 0.82188, F1: 0.82188#####> Valid Avg loss: 2.43251, Acc:0.32286, F1: 0.32286
===> Epoch: 42: Training loss decreased (0.24798 --> 0.23682), Acc: (0.80973 --> 0.82188), F1: (0.80973 --> 0.82188).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 43 Train Avg loss: 0.22950, Acc: 0.82304, F1: 0.82304#####> Valid Avg loss: 2.50283, Acc:0.32190, F1: 0.32190
===> Epoch: 43: Training loss decreased (0.23682 --> 0.22950), Acc: (0.82188 --> 0.82304), F1: (0.82188 --> 0.82304).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 44 Train Avg loss: 0.21177, Acc: 0.83230, F1: 0.83230#####> Valid Avg loss: 2.36823, Acc:0.32952, F1: 0.32952
===> Epoch: 44: Training loss decreased (0.22950 --> 0.21177), Acc: (0.82304 --> 0.83230), F1: (0.82304 --> 0.83230).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 45 Train Avg loss: 0.20407, Acc: 0.84234, F1: 0.84234#####> Valid Avg loss: 3.42154, Acc:0.22762, F1: 0.22762
===> Epoch: 45: Training loss decreased (0.21177 --> 0.20407), Acc: (0.83230 --> 0.84234), F1: (0.83230 --> 0.84234).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 46 Train Avg loss: 0.19926, Acc: 0.84427, F1: 0.84427#####> Valid Avg loss: 2.60397, Acc:0.31714, F1: 0.31714
===> Epoch: 46: Training loss decreased (0.20407 --> 0.19926), Acc: (0.84234 --> 0.84427), F1: (0.84234 --> 0.84427).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 47 Train Avg loss: 0.18288, Acc: 0.85508, F1: 0.85508#####> Valid Avg loss: 2.67313, Acc:0.31048, F1: 0.31048
===> Epoch: 47: Training loss decreased (0.19926 --> 0.18288), Acc: (0.84427 --> 0.85508), F1: (0.84427 --> 0.85508).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 48 Train Avg loss: 0.16855, Acc: 0.86260, F1: 0.86260#####> Valid Avg loss: 2.96916, Acc:0.32857, F1: 0.32857
===> Epoch: 48: Training loss decreased (0.18288 --> 0.16855), Acc: (0.85508 --> 0.86260), F1: (0.85508 --> 0.86260).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 49 Train Avg loss: 0.15664, Acc: 0.87360, F1: 0.87360#####> Valid Avg loss: 3.20793, Acc:0.32571, F1: 0.32571
===> Epoch: 49: Training loss decreased (0.16855 --> 0.15664), Acc: (0.86260 --> 0.87360), F1: (0.86260 --> 0.87360).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 50 Train Avg loss: 0.14582, Acc: 0.88344, F1: 0.88344#####> Valid Avg loss: 3.13127, Acc:0.29429, F1: 0.29429
===> Epoch: 50: Training loss decreased (0.15664 --> 0.14582), Acc: (0.87360 --> 0.88344), F1: (0.87360 --> 0.88344).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 51 Train Avg loss: 0.13960, Acc: 0.88421, F1: 0.88421#####> Valid Avg loss: 3.30894, Acc:0.32762, F1: 0.32762
===> Epoch: 51: Training loss decreased (0.14582 --> 0.13960), Acc: (0.88344 --> 0.88421), F1: (0.88344 --> 0.88421).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 52 Train Avg loss: 0.12686, Acc: 0.89232, F1: 0.89232#####> Valid Avg loss: 2.80046, Acc:0.34571, F1: 0.34571
===> Epoch: 52: Training loss decreased (0.13960 --> 0.12686), Acc: (0.88421 --> 0.89232), F1: (0.88421 --> 0.89232).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 53 Train Avg loss: 0.11430, Acc: 0.90776, F1: 0.90776#####> Valid Avg loss: 4.21617, Acc:0.28667, F1: 0.28667
===> Epoch: 53: Training loss decreased (0.12686 --> 0.11430), Acc: (0.89232 --> 0.90776), F1: (0.89232 --> 0.90776).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 54 Train Avg loss: 0.11423, Acc: 0.90525, F1: 0.90525#####> Valid Avg loss: 3.69003, Acc:0.32000, F1: 0.32000
===> Epoch: 54: Training loss decreased (0.11430 --> 0.11423), Acc: (0.90776 --> 0.90525), F1: (0.90776 --> 0.90525).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 55 Train Avg loss: 0.09651, Acc: 0.92262, F1: 0.92262#####> Valid Avg loss: 3.44216, Acc:0.33714, F1: 0.33714
===> Epoch: 55: Training loss decreased (0.11423 --> 0.09651), Acc: (0.90525 --> 0.92262), F1: (0.90525 --> 0.92262).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 56 Train Avg loss: 0.09051, Acc: 0.92551, F1: 0.92551#####> Valid Avg loss: 4.30535, Acc:0.30381, F1: 0.30381
===> Epoch: 56: Training loss decreased (0.09651 --> 0.09051), Acc: (0.92262 --> 0.92551), F1: (0.92262 --> 0.92551).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 57 Train Avg loss: 0.08576, Acc: 0.92841, F1: 0.92841#####> Valid Avg loss: 3.64467, Acc:0.31524, F1: 0.31524
===> Epoch: 57: Training loss decreased (0.09051 --> 0.08576), Acc: (0.92551 --> 0.92841), F1: (0.92551 --> 0.92841).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 58 Train Avg loss: 0.07783, Acc: 0.92841, F1: 0.92841#####> Valid Avg loss: 4.03393, Acc:0.31524, F1: 0.31524
===> Epoch: 58: Training loss decreased (0.08576 --> 0.07783), Acc: (0.92841 --> 0.92841), F1: (0.92841 --> 0.92841).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 59 Train Avg loss: 0.06408, Acc: 0.94616, F1: 0.94616#####> Valid Avg loss: 3.91484, Acc:0.32286, F1: 0.32286
===> Epoch: 59: Training loss decreased (0.07783 --> 0.06408), Acc: (0.92841 --> 0.94616), F1: (0.92841 --> 0.94616).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 60 Train Avg loss: 0.06722, Acc: 0.94442, F1: 0.94442#####> Valid Avg loss: 4.14078, Acc:0.32952, F1: 0.32952
====> Epoch: 61 Train Avg loss: 0.06296, Acc: 0.94481, F1: 0.94481#####> Valid Avg loss: 3.78497, Acc:0.34857, F1: 0.34857
===> Epoch: 61: Training loss decreased (0.06408 --> 0.06296), Acc: (0.94616 --> 0.94481), F1: (0.94616 --> 0.94481).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 62 Train Avg loss: 0.05286, Acc: 0.95272, F1: 0.95272#####> Valid Avg loss: 4.31898, Acc:0.29429, F1: 0.29429
===> Epoch: 62: Training loss decreased (0.06296 --> 0.05286), Acc: (0.94481 --> 0.95272), F1: (0.94481 --> 0.95272).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 63 Train Avg loss: 0.04876, Acc: 0.95677, F1: 0.95677#####> Valid Avg loss: 3.97473, Acc:0.32381, F1: 0.32381
===> Epoch: 63: Training loss decreased (0.05286 --> 0.04876), Acc: (0.95272 --> 0.95677), F1: (0.95272 --> 0.95677).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 64 Train Avg loss: 0.04756, Acc: 0.95967, F1: 0.95967#####> Valid Avg loss: 4.40910, Acc:0.32190, F1: 0.32190
===> Epoch: 64: Training loss decreased (0.04876 --> 0.04756), Acc: (0.95677 --> 0.95967), F1: (0.95677 --> 0.95967).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 65 Train Avg loss: 0.04017, Acc: 0.96160, F1: 0.96160#####> Valid Avg loss: 4.38516, Acc:0.33619, F1: 0.33619
===> Epoch: 65: Training loss decreased (0.04756 --> 0.04017), Acc: (0.95967 --> 0.96160), F1: (0.95967 --> 0.96160).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 66 Train Avg loss: 0.04193, Acc: 0.96333, F1: 0.96333#####> Valid Avg loss: 4.36971, Acc:0.35524, F1: 0.35524
====> Epoch: 67 Train Avg loss: 0.03881, Acc: 0.96198, F1: 0.96198#####> Valid Avg loss: 4.50927, Acc:0.32095, F1: 0.32095
===> Epoch: 67: Training loss decreased (0.04017 --> 0.03881), Acc: (0.96160 --> 0.96198), F1: (0.96160 --> 0.96198).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 68 Train Avg loss: 0.03278, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 4.99040, Acc:0.31714, F1: 0.31714
===> Epoch: 68: Training loss decreased (0.03881 --> 0.03278), Acc: (0.96198 --> 0.96912), F1: (0.96198 --> 0.96912).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 69 Train Avg loss: 0.03222, Acc: 0.96681, F1: 0.96681#####> Valid Avg loss: 4.80054, Acc:0.32667, F1: 0.32667
===> Epoch: 69: Training loss decreased (0.03278 --> 0.03222), Acc: (0.96912 --> 0.96681), F1: (0.96912 --> 0.96681).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 70 Train Avg loss: 0.02605, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 4.91988, Acc:0.31905, F1: 0.31905
===> Epoch: 70: Training loss decreased (0.03222 --> 0.02605), Acc: (0.96681 --> 0.97511), F1: (0.96681 --> 0.97511).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 71 Train Avg loss: 0.02742, Acc: 0.97202, F1: 0.97202#####> Valid Avg loss: 4.89471, Acc:0.33619, F1: 0.33619
====> Epoch: 72 Train Avg loss: 0.02842, Acc: 0.97221, F1: 0.97221#####> Valid Avg loss: 4.82629, Acc:0.34095, F1: 0.34095
====> Epoch: 73 Train Avg loss: 0.02278, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 5.55618, Acc:0.31238, F1: 0.31238
===> Epoch: 73: Training loss decreased (0.02605 --> 0.02278), Acc: (0.97511 --> 0.97607), F1: (0.97511 --> 0.97607).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 74 Train Avg loss: 0.02413, Acc: 0.97298, F1: 0.97298#####> Valid Avg loss: 4.94437, Acc:0.34190, F1: 0.34190
====> Epoch: 75 Train Avg loss: 0.02137, Acc: 0.97395, F1: 0.97395#####> Valid Avg loss: 5.15935, Acc:0.32476, F1: 0.32476
===> Epoch: 75: Training loss decreased (0.02278 --> 0.02137), Acc: (0.97607 --> 0.97395), F1: (0.97607 --> 0.97395).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 76 Train Avg loss: 0.02187, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 5.39723, Acc:0.32571, F1: 0.32571
====> Epoch: 77 Train Avg loss: 0.02147, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 5.34917, Acc:0.33524, F1: 0.33524
====> Epoch: 78 Train Avg loss: 0.01920, Acc: 0.97414, F1: 0.97414#####> Valid Avg loss: 5.65571, Acc:0.31333, F1: 0.31333
===> Epoch: 78: Training loss decreased (0.02137 --> 0.01920), Acc: (0.97395 --> 0.97414), F1: (0.97395 --> 0.97414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 79 Train Avg loss: 0.01934, Acc: 0.97993, F1: 0.97993#####> Valid Avg loss: 5.37802, Acc:0.33143, F1: 0.33143
====> Epoch: 80 Train Avg loss: 0.01841, Acc: 0.97781, F1: 0.97781#####> Valid Avg loss: 5.21924, Acc:0.33714, F1: 0.33714
===> Epoch: 80: Training loss decreased (0.01920 --> 0.01841), Acc: (0.97414 --> 0.97781), F1: (0.97414 --> 0.97781).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 81 Train Avg loss: 0.01866, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 5.34501, Acc:0.32286, F1: 0.32286
====> Epoch: 82 Train Avg loss: 0.01835, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 5.14152, Acc:0.32476, F1: 0.32476
===> Epoch: 82: Training loss decreased (0.01841 --> 0.01835), Acc: (0.97781 --> 0.97588), F1: (0.97781 --> 0.97588).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 83 Train Avg loss: 0.01746, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 5.34707, Acc:0.33143, F1: 0.33143
===> Epoch: 83: Training loss decreased (0.01835 --> 0.01746), Acc: (0.97588 --> 0.97646), F1: (0.97588 --> 0.97646).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 84 Train Avg loss: 0.01713, Acc: 0.97549, F1: 0.97549#####> Valid Avg loss: 5.47338, Acc:0.32762, F1: 0.32762
===> Epoch: 84: Training loss decreased (0.01746 --> 0.01713), Acc: (0.97646 --> 0.97549), F1: (0.97646 --> 0.97549).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 85 Train Avg loss: 0.01670, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 5.28355, Acc:0.32857, F1: 0.32857
===> Epoch: 85: Training loss decreased (0.01713 --> 0.01670), Acc: (0.97549 --> 0.97742), F1: (0.97549 --> 0.97742).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 86 Train Avg loss: 0.01658, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 5.65992, Acc:0.34000, F1: 0.34000
===> Epoch: 86: Training loss decreased (0.01670 --> 0.01658), Acc: (0.97742 --> 0.97742), F1: (0.97742 --> 0.97742).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 87 Train Avg loss: 0.01604, Acc: 0.97935, F1: 0.97935#####> Valid Avg loss: 5.65225, Acc:0.33238, F1: 0.33238
===> Epoch: 87: Training loss decreased (0.01658 --> 0.01604), Acc: (0.97742 --> 0.97935), F1: (0.97742 --> 0.97935).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 88 Train Avg loss: 0.01638, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 5.60547, Acc:0.33333, F1: 0.33333
====> Epoch: 89 Train Avg loss: 0.01587, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 5.78151, Acc:0.34476, F1: 0.34476
===> Epoch: 89: Training loss decreased (0.01604 --> 0.01587), Acc: (0.97935 --> 0.97742), F1: (0.97935 --> 0.97742).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 90 Train Avg loss: 0.01572, Acc: 0.97761, F1: 0.97761#####> Valid Avg loss: 5.69738, Acc:0.33143, F1: 0.33143
===> Epoch: 90: Training loss decreased (0.01587 --> 0.01572), Acc: (0.97742 --> 0.97761), F1: (0.97742 --> 0.97761).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 91 Train Avg loss: 0.01544, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 5.74027, Acc:0.33524, F1: 0.33524
===> Epoch: 91: Training loss decreased (0.01572 --> 0.01544), Acc: (0.97761 --> 0.97800), F1: (0.97761 --> 0.97800).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 92 Train Avg loss: 0.01541, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 5.58764, Acc:0.33429, F1: 0.33429
===> Epoch: 92: Training loss decreased (0.01544 --> 0.01541), Acc: (0.97800 --> 0.97684), F1: (0.97800 --> 0.97684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 93 Train Avg loss: 0.01523, Acc: 0.97935, F1: 0.97935#####> Valid Avg loss: 5.58478, Acc:0.33143, F1: 0.33143
===> Epoch: 93: Training loss decreased (0.01541 --> 0.01523), Acc: (0.97684 --> 0.97935), F1: (0.97684 --> 0.97935).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 94 Train Avg loss: 0.01520, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 5.65063, Acc:0.33333, F1: 0.33333
===> Epoch: 94: Training loss decreased (0.01523 --> 0.01520), Acc: (0.97935 --> 0.97665), F1: (0.97935 --> 0.97665).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 95 Train Avg loss: 0.01496, Acc: 0.97877, F1: 0.97877#####> Valid Avg loss: 5.75789, Acc:0.32857, F1: 0.32857
===> Epoch: 95: Training loss decreased (0.01520 --> 0.01496), Acc: (0.97665 --> 0.97877), F1: (0.97665 --> 0.97877).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 96 Train Avg loss: 0.01488, Acc: 0.97858, F1: 0.97858#####> Valid Avg loss: 5.70529, Acc:0.33143, F1: 0.33143
===> Epoch: 96: Training loss decreased (0.01496 --> 0.01488), Acc: (0.97877 --> 0.97858), F1: (0.97877 --> 0.97858).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 97 Train Avg loss: 0.01488, Acc: 0.98070, F1: 0.98070#####> Valid Avg loss: 5.58209, Acc:0.33238, F1: 0.33238
====> Epoch: 98 Train Avg loss: 0.01477, Acc: 0.98051, F1: 0.98051#####> Valid Avg loss: 5.63404, Acc:0.33238, F1: 0.33238
===> Epoch: 98: Training loss decreased (0.01488 --> 0.01477), Acc: (0.97858 --> 0.98051), F1: (0.97858 --> 0.98051).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 99 Train Avg loss: 0.01487, Acc: 0.97897, F1: 0.97897#####> Valid Avg loss: 5.54776, Acc:0.33143, F1: 0.33143
====> Epoch: 100 Train Avg loss: 0.53789, Acc: 0.64454, F1: 0.64454#####> Valid Avg loss: 1.34938, Acc:0.31333, F1: 0.31333
====> Epoch: 101 Train Avg loss: 0.45912, Acc: 0.67889, F1: 0.67889#####> Valid Avg loss: 1.35729, Acc:0.33905, F1: 0.33905
====> Epoch: 102 Train Avg loss: 0.41590, Acc: 0.70108, F1: 0.70108#####> Valid Avg loss: 1.34802, Acc:0.38381, F1: 0.38381
====> Epoch: 103 Train Avg loss: 0.40193, Acc: 0.71189, F1: 0.71189#####> Valid Avg loss: 1.75465, Acc:0.25810, F1: 0.25810
====> Epoch: 104 Train Avg loss: 0.38346, Acc: 0.72231, F1: 0.72231#####> Valid Avg loss: 1.84702, Acc:0.27143, F1: 0.27143
====> Epoch: 105 Train Avg loss: 0.35800, Acc: 0.73755, F1: 0.73755#####> Valid Avg loss: 1.81775, Acc:0.29714, F1: 0.29714
====> Epoch: 106 Train Avg loss: 0.34987, Acc: 0.74373, F1: 0.74373#####> Valid Avg loss: 1.99842, Acc:0.25333, F1: 0.25333
====> Epoch: 107 Train Avg loss: 0.33421, Acc: 0.74797, F1: 0.74797#####> Valid Avg loss: 1.79803, Acc:0.34190, F1: 0.34190
====> Epoch: 108 Train Avg loss: 0.32456, Acc: 0.75917, F1: 0.75917#####> Valid Avg loss: 1.79809, Acc:0.33048, F1: 0.33048
====> Epoch: 109 Train Avg loss: 0.31535, Acc: 0.76283, F1: 0.76283#####> Valid Avg loss: 1.87465, Acc:0.32571, F1: 0.32571
====> Epoch: 110 Train Avg loss: 0.30438, Acc: 0.76939, F1: 0.76939#####> Valid Avg loss: 2.33002, Acc:0.23048, F1: 0.23048
====> Epoch: 111 Train Avg loss: 0.30511, Acc: 0.76997, F1: 0.76997#####> Valid Avg loss: 2.05437, Acc:0.28857, F1: 0.28857
====> Epoch: 112 Train Avg loss: 0.28438, Acc: 0.78850, F1: 0.78850#####> Valid Avg loss: 1.83877, Acc:0.30000, F1: 0.30000
====> Epoch: 113 Train Avg loss: 0.29224, Acc: 0.77403, F1: 0.77403#####> Valid Avg loss: 1.73688, Acc:0.29048, F1: 0.29048
====> Epoch: 114 Train Avg loss: 0.27584, Acc: 0.79564, F1: 0.79564#####> Valid Avg loss: 2.57315, Acc:0.27619, F1: 0.27619
====> Epoch: 115 Train Avg loss: 0.25710, Acc: 0.80432, F1: 0.80432#####> Valid Avg loss: 2.58526, Acc:0.27810, F1: 0.27810
====> Epoch: 116 Train Avg loss: 0.27069, Acc: 0.78850, F1: 0.78850#####> Valid Avg loss: 2.37648, Acc:0.33429, F1: 0.33429
====> Epoch: 117 Train Avg loss: 0.26377, Acc: 0.80181, F1: 0.80181#####> Valid Avg loss: 2.20791, Acc:0.28095, F1: 0.28095
====> Epoch: 118 Train Avg loss: 0.25160, Acc: 0.80780, F1: 0.80780#####> Valid Avg loss: 2.37740, Acc:0.28190, F1: 0.28190
====> Epoch: 119 Train Avg loss: 0.25101, Acc: 0.81030, F1: 0.81030#####> Valid Avg loss: 1.95629, Acc:0.28095, F1: 0.28095
====> Epoch: 120 Train Avg loss: 0.25097, Acc: 0.80722, F1: 0.80722#####> Valid Avg loss: 1.99353, Acc:0.32286, F1: 0.32286
====> Epoch: 121 Train Avg loss: 0.23387, Acc: 0.81744, F1: 0.81745#####> Valid Avg loss: 1.84572, Acc:0.30000, F1: 0.30000
====> Epoch: 122 Train Avg loss: 0.22009, Acc: 0.83404, F1: 0.83404#####> Valid Avg loss: 2.64968, Acc:0.27524, F1: 0.27524
====> Epoch: 123 Train Avg loss: 0.22766, Acc: 0.82150, F1: 0.82150#####> Valid Avg loss: 2.54748, Acc:0.24381, F1: 0.24381
====> Epoch: 124 Train Avg loss: 0.20741, Acc: 0.83983, F1: 0.83983#####> Valid Avg loss: 2.22302, Acc:0.27905, F1: 0.27905
====> Epoch: 125 Train Avg loss: 0.22656, Acc: 0.82266, F1: 0.82266#####> Valid Avg loss: 2.14775, Acc:0.32571, F1: 0.32571
====> Epoch: 126 Train Avg loss: 0.21234, Acc: 0.83732, F1: 0.83732#####> Valid Avg loss: 2.07049, Acc:0.25524, F1: 0.25524
====> Epoch: 127 Train Avg loss: 0.20473, Acc: 0.84022, F1: 0.84022#####> Valid Avg loss: 2.37885, Acc:0.23810, F1: 0.23810
====> Epoch: 128 Train Avg loss: 0.21688, Acc: 0.83153, F1: 0.83153#####> Valid Avg loss: 3.25803, Acc:0.24571, F1: 0.24571
====> Epoch: 129 Train Avg loss: 0.19927, Acc: 0.84311, F1: 0.84311#####> Valid Avg loss: 2.56083, Acc:0.24190, F1: 0.24190
====> Epoch: 130 Train Avg loss: 0.18980, Acc: 0.85546, F1: 0.85546#####> Valid Avg loss: 2.60910, Acc:0.28286, F1: 0.28286
====> Epoch: 131 Train Avg loss: 0.19497, Acc: 0.84736, F1: 0.84736#####> Valid Avg loss: 2.15003, Acc:0.31429, F1: 0.31429
====> Epoch: 132 Train Avg loss: 0.19315, Acc: 0.85372, F1: 0.85372#####> Valid Avg loss: 1.51900, Acc:0.40667, F1: 0.40667
====> Epoch: 133 Train Avg loss: 0.18138, Acc: 0.86029, F1: 0.86029#####> Valid Avg loss: 1.57310, Acc:0.41238, F1: 0.41238
====> Epoch: 134 Train Avg loss: 0.17763, Acc: 0.86743, F1: 0.86743#####> Valid Avg loss: 2.27050, Acc:0.35143, F1: 0.35143
====> Epoch: 135 Train Avg loss: 0.17621, Acc: 0.86415, F1: 0.86415#####> Valid Avg loss: 2.75909, Acc:0.22000, F1: 0.22000
====> Epoch: 136 Train Avg loss: 0.17941, Acc: 0.86125, F1: 0.86125#####> Valid Avg loss: 2.28886, Acc:0.33524, F1: 0.33524
====> Epoch: 137 Train Avg loss: 0.16702, Acc: 0.86916, F1: 0.86916#####> Valid Avg loss: 2.17337, Acc:0.37810, F1: 0.37810
====> Epoch: 138 Train Avg loss: 0.16138, Acc: 0.86974, F1: 0.86974#####> Valid Avg loss: 2.21863, Acc:0.32286, F1: 0.32286
====> Epoch: 139 Train Avg loss: 0.15838, Acc: 0.87630, F1: 0.87630#####> Valid Avg loss: 2.44618, Acc:0.30000, F1: 0.30000
====> Epoch: 140 Train Avg loss: 0.15551, Acc: 0.87843, F1: 0.87843#####> Valid Avg loss: 2.58842, Acc:0.27810, F1: 0.27810
====> Epoch: 141 Train Avg loss: 0.15880, Acc: 0.87765, F1: 0.87765#####> Valid Avg loss: 2.78429, Acc:0.30095, F1: 0.30095
====> Epoch: 142 Train Avg loss: 0.16088, Acc: 0.86646, F1: 0.86646#####> Valid Avg loss: 2.50614, Acc:0.26667, F1: 0.26667
====> Epoch: 143 Train Avg loss: 0.14876, Acc: 0.88364, F1: 0.88364#####> Valid Avg loss: 3.01098, Acc:0.24000, F1: 0.24000
====> Epoch: 144 Train Avg loss: 0.15072, Acc: 0.88306, F1: 0.88306#####> Valid Avg loss: 2.25909, Acc:0.25619, F1: 0.25619
====> Epoch: 145 Train Avg loss: 0.14054, Acc: 0.88885, F1: 0.88885#####> Valid Avg loss: 2.16585, Acc:0.30952, F1: 0.30952
====> Epoch: 146 Train Avg loss: 0.13737, Acc: 0.88769, F1: 0.88769#####> Valid Avg loss: 2.66646, Acc:0.26381, F1: 0.26381
====> Epoch: 147 Train Avg loss: 0.13947, Acc: 0.88923, F1: 0.88923#####> Valid Avg loss: 2.25713, Acc:0.32762, F1: 0.32762
====> Epoch: 148 Train Avg loss: 0.13038, Acc: 0.89444, F1: 0.89444#####> Valid Avg loss: 2.75407, Acc:0.28190, F1: 0.28190
====> Epoch: 149 Train Avg loss: 0.12715, Acc: 0.89772, F1: 0.89772#####> Valid Avg loss: 2.97112, Acc:0.22857, F1: 0.22857
====> Epoch: 150 Train Avg loss: 0.12405, Acc: 0.89695, F1: 0.89695#####> Valid Avg loss: 2.75573, Acc:0.26381, F1: 0.26381
====> Epoch: 151 Train Avg loss: 0.11398, Acc: 0.90988, F1: 0.90988#####> Valid Avg loss: 3.06211, Acc:0.26667, F1: 0.26667
====> Epoch: 152 Train Avg loss: 0.11687, Acc: 0.90621, F1: 0.90621#####> Valid Avg loss: 2.54819, Acc:0.26000, F1: 0.26000
====> Epoch: 153 Train Avg loss: 0.11814, Acc: 0.90621, F1: 0.90621#####> Valid Avg loss: 2.75372, Acc:0.25905, F1: 0.25905
====> Epoch: 154 Train Avg loss: 0.11462, Acc: 0.90428, F1: 0.90428#####> Valid Avg loss: 3.04873, Acc:0.27143, F1: 0.27143
====> Epoch: 155 Train Avg loss: 0.10797, Acc: 0.91085, F1: 0.91085#####> Valid Avg loss: 3.22579, Acc:0.27619, F1: 0.27619
====> Epoch: 156 Train Avg loss: 0.10664, Acc: 0.91104, F1: 0.91104#####> Valid Avg loss: 2.67215, Acc:0.31714, F1: 0.31714
====> Epoch: 157 Train Avg loss: 0.11482, Acc: 0.90235, F1: 0.90235#####> Valid Avg loss: 2.84151, Acc:0.28381, F1: 0.28381
====> Epoch: 158 Train Avg loss: 0.10437, Acc: 0.91818, F1: 0.91818#####> Valid Avg loss: 3.75944, Acc:0.22857, F1: 0.22857
====> Epoch: 159 Train Avg loss: 0.11379, Acc: 0.90988, F1: 0.90988#####> Valid Avg loss: 2.98116, Acc:0.25143, F1: 0.25143
====> Epoch: 160 Train Avg loss: 0.09042, Acc: 0.92532, F1: 0.92532#####> Valid Avg loss: 2.88882, Acc:0.31905, F1: 0.31905
====> Epoch: 161 Train Avg loss: 0.10511, Acc: 0.91606, F1: 0.91606#####> Valid Avg loss: 2.59047, Acc:0.29810, F1: 0.29810
====> Epoch: 162 Train Avg loss: 0.11037, Acc: 0.91142, F1: 0.91142#####> Valid Avg loss: 3.48044, Acc:0.25905, F1: 0.25905
====> Epoch: 163 Train Avg loss: 0.08855, Acc: 0.92744, F1: 0.92744#####> Valid Avg loss: 2.76769, Acc:0.30286, F1: 0.30286
====> Epoch: 164 Train Avg loss: 0.09581, Acc: 0.92320, F1: 0.92320#####> Valid Avg loss: 2.75398, Acc:0.22476, F1: 0.22476
====> Epoch: 165 Train Avg loss: 0.09093, Acc: 0.92551, F1: 0.92551#####> Valid Avg loss: 2.86344, Acc:0.24000, F1: 0.24000
====> Epoch: 166 Train Avg loss: 0.08134, Acc: 0.93188, F1: 0.93188#####> Valid Avg loss: 2.82234, Acc:0.26095, F1: 0.26095
====> Epoch: 167 Train Avg loss: 0.08665, Acc: 0.92918, F1: 0.92918#####> Valid Avg loss: 3.56401, Acc:0.25810, F1: 0.25810
====> Epoch: 168 Train Avg loss: 0.08138, Acc: 0.93169, F1: 0.93169#####> Valid Avg loss: 2.50234, Acc:0.28476, F1: 0.28476
====> Epoch: 169 Train Avg loss: 0.08762, Acc: 0.92918, F1: 0.92918#####> Valid Avg loss: 2.76155, Acc:0.32000, F1: 0.32000
====> Epoch: 170 Train Avg loss: 0.07519, Acc: 0.93863, F1: 0.93863#####> Valid Avg loss: 3.76734, Acc:0.23905, F1: 0.23905
====> Epoch: 171 Train Avg loss: 0.07493, Acc: 0.93728, F1: 0.93728#####> Valid Avg loss: 3.94265, Acc:0.23905, F1: 0.23905
====> Epoch: 172 Train Avg loss: 0.07866, Acc: 0.93709, F1: 0.93709#####> Valid Avg loss: 3.44605, Acc:0.26190, F1: 0.26190
====> Epoch: 173 Train Avg loss: 0.07930, Acc: 0.93651, F1: 0.93651#####> Valid Avg loss: 3.70163, Acc:0.22381, F1: 0.22381
====> Epoch: 174 Train Avg loss: 0.06955, Acc: 0.94577, F1: 0.94577#####> Valid Avg loss: 3.66655, Acc:0.26000, F1: 0.26000
====> Epoch: 175 Train Avg loss: 0.06969, Acc: 0.94346, F1: 0.94346#####> Valid Avg loss: 3.58356, Acc:0.23714, F1: 0.23714
====> Epoch: 176 Train Avg loss: 0.07836, Acc: 0.93670, F1: 0.93670#####> Valid Avg loss: 3.59210, Acc:0.22381, F1: 0.22381
====> Epoch: 177 Train Avg loss: 0.06957, Acc: 0.94134, F1: 0.94134#####> Valid Avg loss: 4.40792, Acc:0.23810, F1: 0.23810
====> Epoch: 178 Train Avg loss: 0.06664, Acc: 0.94269, F1: 0.94269#####> Valid Avg loss: 3.49091, Acc:0.24762, F1: 0.24762
====> Epoch: 179 Train Avg loss: 0.06471, Acc: 0.94442, F1: 0.94442#####> Valid Avg loss: 3.05956, Acc:0.28571, F1: 0.28571
====> Epoch: 180 Train Avg loss: 0.06519, Acc: 0.94539, F1: 0.94539#####> Valid Avg loss: 2.81257, Acc:0.29143, F1: 0.29143
====> Epoch: 181 Train Avg loss: 0.05394, Acc: 0.95504, F1: 0.95504#####> Valid Avg loss: 3.59253, Acc:0.24381, F1: 0.24381
====> Epoch: 182 Train Avg loss: 0.06429, Acc: 0.94462, F1: 0.94462#####> Valid Avg loss: 3.39645, Acc:0.22667, F1: 0.22667
====> Epoch: 183 Train Avg loss: 0.05954, Acc: 0.95195, F1: 0.95195#####> Valid Avg loss: 3.81446, Acc:0.25810, F1: 0.25810
====> Epoch: 184 Train Avg loss: 0.05568, Acc: 0.95060, F1: 0.95060#####> Valid Avg loss: 3.53787, Acc:0.23619, F1: 0.23619
====> Epoch: 185 Train Avg loss: 0.06076, Acc: 0.94693, F1: 0.94693#####> Valid Avg loss: 3.67377, Acc:0.26095, F1: 0.26095
====> Epoch: 186 Train Avg loss: 0.05138, Acc: 0.95562, F1: 0.95562#####> Valid Avg loss: 3.90733, Acc:0.24381, F1: 0.24381
====> Epoch: 187 Train Avg loss: 0.05667, Acc: 0.95311, F1: 0.95311#####> Valid Avg loss: 3.65951, Acc:0.28000, F1: 0.28000
====> Epoch: 188 Train Avg loss: 0.05528, Acc: 0.94674, F1: 0.94674#####> Valid Avg loss: 4.41387, Acc:0.23333, F1: 0.23333
====> Epoch: 189 Train Avg loss: 0.05419, Acc: 0.94963, F1: 0.94963#####> Valid Avg loss: 3.56215, Acc:0.28190, F1: 0.28190
====> Epoch: 190 Train Avg loss: 0.05696, Acc: 0.95234, F1: 0.95234#####> Valid Avg loss: 2.32260, Acc:0.39333, F1: 0.39333
====> Epoch: 191 Train Avg loss: 0.04490, Acc: 0.95812, F1: 0.95812#####> Valid Avg loss: 3.28616, Acc:0.29619, F1: 0.29619
====> Epoch: 192 Train Avg loss: 0.05090, Acc: 0.95388, F1: 0.95388#####> Valid Avg loss: 3.38970, Acc:0.28000, F1: 0.28000
====> Epoch: 193 Train Avg loss: 0.05372, Acc: 0.95369, F1: 0.95369#####> Valid Avg loss: 2.85466, Acc:0.31048, F1: 0.31048
====> Epoch: 194 Train Avg loss: 0.03732, Acc: 0.96449, F1: 0.96449#####> Valid Avg loss: 4.37194, Acc:0.23429, F1: 0.23429
====> Epoch: 195 Train Avg loss: 0.05619, Acc: 0.95465, F1: 0.95465#####> Valid Avg loss: 3.25535, Acc:0.29905, F1: 0.29905
====> Epoch: 196 Train Avg loss: 0.04478, Acc: 0.95928, F1: 0.95928#####> Valid Avg loss: 3.47759, Acc:0.24000, F1: 0.24000
====> Epoch: 197 Train Avg loss: 0.04679, Acc: 0.95870, F1: 0.95870#####> Valid Avg loss: 3.34084, Acc:0.29429, F1: 0.29429
====> Epoch: 198 Train Avg loss: 0.04053, Acc: 0.96160, F1: 0.96160#####> Valid Avg loss: 4.08300, Acc:0.24762, F1: 0.24762
====> Epoch: 199 Train Avg loss: 0.04384, Acc: 0.96044, F1: 0.96044#####> Valid Avg loss: 2.95882, Acc:0.32762, F1: 0.32762
====> Epoch: 200 Train Avg loss: 0.04028, Acc: 0.96025, F1: 0.96025#####> Valid Avg loss: 3.39720, Acc:0.26095, F1: 0.26095
====> Epoch: 201 Train Avg loss: 0.04150, Acc: 0.96179, F1: 0.96179#####> Valid Avg loss: 3.10257, Acc:0.28476, F1: 0.28476
====> Epoch: 202 Train Avg loss: 0.03631, Acc: 0.96700, F1: 0.96700#####> Valid Avg loss: 3.99698, Acc:0.25143, F1: 0.25143
====> Epoch: 203 Train Avg loss: 0.04222, Acc: 0.96295, F1: 0.96295#####> Valid Avg loss: 3.68392, Acc:0.29238, F1: 0.29238
====> Epoch: 204 Train Avg loss: 0.03402, Acc: 0.96777, F1: 0.96777#####> Valid Avg loss: 3.22639, Acc:0.31238, F1: 0.31238
====> Epoch: 205 Train Avg loss: 0.03652, Acc: 0.96758, F1: 0.96758#####> Valid Avg loss: 3.22813, Acc:0.34286, F1: 0.34286
====> Epoch: 206 Train Avg loss: 0.03644, Acc: 0.96333, F1: 0.96333#####> Valid Avg loss: 3.31928, Acc:0.25810, F1: 0.25810
====> Epoch: 207 Train Avg loss: 0.03081, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 3.68487, Acc:0.25810, F1: 0.25810
====> Epoch: 208 Train Avg loss: 0.03800, Acc: 0.96372, F1: 0.96372#####> Valid Avg loss: 3.46506, Acc:0.25524, F1: 0.25524
====> Epoch: 209 Train Avg loss: 0.03165, Acc: 0.96739, F1: 0.96739#####> Valid Avg loss: 4.52741, Acc:0.30476, F1: 0.30476
====> Epoch: 210 Train Avg loss: 0.03391, Acc: 0.96816, F1: 0.96816#####> Valid Avg loss: 3.25268, Acc:0.25714, F1: 0.25714
====> Epoch: 211 Train Avg loss: 0.03138, Acc: 0.96893, F1: 0.96893#####> Valid Avg loss: 4.20441, Acc:0.23810, F1: 0.23810
====> Epoch: 212 Train Avg loss: 0.02960, Acc: 0.96990, F1: 0.96990#####> Valid Avg loss: 3.62758, Acc:0.26286, F1: 0.26286
====> Epoch: 213 Train Avg loss: 0.02521, Acc: 0.97356, F1: 0.97356#####> Valid Avg loss: 3.51890, Acc:0.28000, F1: 0.28000
====> Epoch: 214 Train Avg loss: 0.03143, Acc: 0.96507, F1: 0.96507#####> Valid Avg loss: 3.58372, Acc:0.26571, F1: 0.26571
====> Epoch: 215 Train Avg loss: 0.02445, Acc: 0.97453, F1: 0.97453#####> Valid Avg loss: 3.74733, Acc:0.26762, F1: 0.26762
====> Epoch: 216 Train Avg loss: 0.03138, Acc: 0.96835, F1: 0.96835#####> Valid Avg loss: 3.89938, Acc:0.25714, F1: 0.25714
====> Epoch: 217 Train Avg loss: 0.02749, Acc: 0.97105, F1: 0.97105#####> Valid Avg loss: 3.60098, Acc:0.27238, F1: 0.27238
====> Epoch: 218 Train Avg loss: 0.02592, Acc: 0.97125, F1: 0.97125#####> Valid Avg loss: 3.75686, Acc:0.26667, F1: 0.26667
====> Epoch: 219 Train Avg loss: 0.02589, Acc: 0.97086, F1: 0.97086#####> Valid Avg loss: 4.36725, Acc:0.26000, F1: 0.26000
====> Epoch: 220 Train Avg loss: 0.02561, Acc: 0.97163, F1: 0.97163#####> Valid Avg loss: 3.84522, Acc:0.30476, F1: 0.30476
====> Epoch: 221 Train Avg loss: 0.02841, Acc: 0.96874, F1: 0.96874#####> Valid Avg loss: 3.51985, Acc:0.26762, F1: 0.26762
====> Epoch: 222 Train Avg loss: 0.02621, Acc: 0.97395, F1: 0.97395#####> Valid Avg loss: 3.81455, Acc:0.25143, F1: 0.25143
====> Epoch: 223 Train Avg loss: 0.02305, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 3.98751, Acc:0.26952, F1: 0.26952
====> Epoch: 224 Train Avg loss: 0.02506, Acc: 0.97298, F1: 0.97298#####> Valid Avg loss: 3.68459, Acc:0.27429, F1: 0.27429
====> Epoch: 225 Train Avg loss: 0.02146, Acc: 0.97125, F1: 0.97125#####> Valid Avg loss: 4.06144, Acc:0.27905, F1: 0.27905
====> Epoch: 226 Train Avg loss: 0.02067, Acc: 0.97491, F1: 0.97491#####> Valid Avg loss: 4.15028, Acc:0.28000, F1: 0.28000
====> Epoch: 227 Train Avg loss: 0.02257, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 3.86779, Acc:0.27333, F1: 0.27333
====> Epoch: 228 Train Avg loss: 0.02290, Acc: 0.97279, F1: 0.97279#####> Valid Avg loss: 4.77532, Acc:0.25238, F1: 0.25238
====> Epoch: 229 Train Avg loss: 0.02034, Acc: 0.97569, F1: 0.97569#####> Valid Avg loss: 4.27397, Acc:0.26286, F1: 0.26286
====> Epoch: 230 Train Avg loss: 0.02122, Acc: 0.97279, F1: 0.97279#####> Valid Avg loss: 3.74656, Acc:0.27524, F1: 0.27524
====> Epoch: 231 Train Avg loss: 0.01885, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 4.62713, Acc:0.24857, F1: 0.24857
====> Epoch: 232 Train Avg loss: 0.02112, Acc: 0.97337, F1: 0.97337#####> Valid Avg loss: 4.09633, Acc:0.28762, F1: 0.28762
====> Epoch: 233 Train Avg loss: 0.02511, Acc: 0.97240, F1: 0.97240#####> Valid Avg loss: 4.35259, Acc:0.24286, F1: 0.24286
====> Epoch: 234 Train Avg loss: 0.01823, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 4.37638, Acc:0.25619, F1: 0.25619
====> Epoch: 235 Train Avg loss: 0.02083, Acc: 0.97472, F1: 0.97472#####> Valid Avg loss: 4.03863, Acc:0.25619, F1: 0.25619
====> Epoch: 236 Train Avg loss: 0.01890, Acc: 0.97569, F1: 0.97569#####> Valid Avg loss: 4.51397, Acc:0.24952, F1: 0.24952
====> Epoch: 237 Train Avg loss: 0.02018, Acc: 0.97530, F1: 0.97530#####> Valid Avg loss: 4.50068, Acc:0.25429, F1: 0.25429
====> Epoch: 238 Train Avg loss: 0.01844, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 4.66668, Acc:0.25905, F1: 0.25905
====> Epoch: 239 Train Avg loss: 0.01813, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 3.67541, Acc:0.28095, F1: 0.28095
====> Epoch: 240 Train Avg loss: 0.02034, Acc: 0.97298, F1: 0.97298#####> Valid Avg loss: 3.76184, Acc:0.27810, F1: 0.27810
====> Epoch: 241 Train Avg loss: 0.01790, Acc: 0.97318, F1: 0.97318#####> Valid Avg loss: 3.75295, Acc:0.28667, F1: 0.28667
====> Epoch: 242 Train Avg loss: 0.01862, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 4.08433, Acc:0.27048, F1: 0.27048
====> Epoch: 243 Train Avg loss: 0.01788, Acc: 0.97433, F1: 0.97433#####> Valid Avg loss: 4.19679, Acc:0.27143, F1: 0.27143
====> Epoch: 244 Train Avg loss: 0.01691, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 4.01683, Acc:0.28667, F1: 0.28667
====> Epoch: 245 Train Avg loss: 0.01665, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.10479, Acc:0.26476, F1: 0.26476
====> Epoch: 246 Train Avg loss: 0.01810, Acc: 0.97549, F1: 0.97549#####> Valid Avg loss: 4.48236, Acc:0.23905, F1: 0.23905
====> Epoch: 247 Train Avg loss: 0.01765, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 4.40575, Acc:0.26381, F1: 0.26381
====> Epoch: 248 Train Avg loss: 0.01689, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 4.28998, Acc:0.25619, F1: 0.25619
====> Epoch: 249 Train Avg loss: 0.01669, Acc: 0.97858, F1: 0.97858#####> Valid Avg loss: 4.18341, Acc:0.26190, F1: 0.26190
====> Epoch: 250 Train Avg loss: 0.01671, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 4.13517, Acc:0.28000, F1: 0.28000
====> Epoch: 251 Train Avg loss: 0.01623, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 4.33658, Acc:0.25810, F1: 0.25810
====> Epoch: 252 Train Avg loss: 0.01844, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 4.21656, Acc:0.26952, F1: 0.26952
====> Epoch: 253 Train Avg loss: 0.01660, Acc: 0.97761, F1: 0.97761#####> Valid Avg loss: 4.86501, Acc:0.25524, F1: 0.25524
====> Epoch: 254 Train Avg loss: 0.01584, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 4.05016, Acc:0.28571, F1: 0.28571
====> Epoch: 255 Train Avg loss: 0.01606, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 4.48849, Acc:0.26667, F1: 0.26667
====> Epoch: 256 Train Avg loss: 0.01620, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 4.49011, Acc:0.27333, F1: 0.27333
====> Epoch: 257 Train Avg loss: 0.01570, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 4.61986, Acc:0.28095, F1: 0.28095
====> Epoch: 258 Train Avg loss: 0.01625, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 3.92324, Acc:0.27810, F1: 0.27810
====> Epoch: 259 Train Avg loss: 0.01589, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 4.22537, Acc:0.28762, F1: 0.28762
====> Epoch: 260 Train Avg loss: 0.01541, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.66264, Acc:0.25143, F1: 0.25143
====> Epoch: 261 Train Avg loss: 0.01600, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 4.63766, Acc:0.26571, F1: 0.26571
====> Epoch: 262 Train Avg loss: 0.01547, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.62232, Acc:0.27143, F1: 0.27143
====> Epoch: 263 Train Avg loss: 0.01565, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 4.35426, Acc:0.27619, F1: 0.27619
====> Epoch: 264 Train Avg loss: 0.01540, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 4.40811, Acc:0.27143, F1: 0.27143
====> Epoch: 265 Train Avg loss: 0.01545, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.62160, Acc:0.26857, F1: 0.26857
====> Epoch: 266 Train Avg loss: 0.01560, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 4.25127, Acc:0.26571, F1: 0.26571
====> Epoch: 267 Train Avg loss: 0.01525, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 4.52435, Acc:0.27143, F1: 0.27143
====> Epoch: 268 Train Avg loss: 0.01512, Acc: 0.97433, F1: 0.97433#####> Valid Avg loss: 4.63148, Acc:0.26762, F1: 0.26762
====> Epoch: 269 Train Avg loss: 0.01503, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 4.40337, Acc:0.27905, F1: 0.27905
====> Epoch: 270 Train Avg loss: 0.01479, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.55710, Acc:0.26952, F1: 0.26952
====> Epoch: 271 Train Avg loss: 0.01493, Acc: 0.97491, F1: 0.97491#####> Valid Avg loss: 4.44090, Acc:0.27429, F1: 0.27429
====> Epoch: 272 Train Avg loss: 0.01495, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 4.28255, Acc:0.27810, F1: 0.27810
====> Epoch: 273 Train Avg loss: 0.01472, Acc: 0.97781, F1: 0.97781#####> Valid Avg loss: 4.46835, Acc:0.28095, F1: 0.28095
===> Epoch: 273: Training loss decreased (0.01477 --> 0.01472), Acc: (0.98051 --> 0.97781), F1: (0.98051 --> 0.97781).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 274 Train Avg loss: 0.01463, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 4.86780, Acc:0.26762, F1: 0.26762
===> Epoch: 274: Training loss decreased (0.01472 --> 0.01463), Acc: (0.97781 --> 0.97684), F1: (0.97781 --> 0.97684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 275 Train Avg loss: 0.01463, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 4.61092, Acc:0.27429, F1: 0.27429
===> Epoch: 275: Training loss decreased (0.01463 --> 0.01463), Acc: (0.97684 --> 0.97665), F1: (0.97684 --> 0.97665).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 276 Train Avg loss: 0.01468, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 4.40440, Acc:0.27714, F1: 0.27714
====> Epoch: 277 Train Avg loss: 0.01490, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 4.34436, Acc:0.28667, F1: 0.28667
====> Epoch: 278 Train Avg loss: 0.01459, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.57610, Acc:0.27048, F1: 0.27048
===> Epoch: 278: Training loss decreased (0.01463 --> 0.01459), Acc: (0.97665 --> 0.97819), F1: (0.97665 --> 0.97819).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 279 Train Avg loss: 0.01448, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 4.68532, Acc:0.27429, F1: 0.27429
===> Epoch: 279: Training loss decreased (0.01459 --> 0.01448), Acc: (0.97819 --> 0.97684), F1: (0.97819 --> 0.97684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 280 Train Avg loss: 0.01441, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.50297, Acc:0.27238, F1: 0.27238
===> Epoch: 280: Training loss decreased (0.01448 --> 0.01441), Acc: (0.97684 --> 0.97819), F1: (0.97684 --> 0.97819).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 281 Train Avg loss: 0.01448, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 4.56815, Acc:0.27143, F1: 0.27143
====> Epoch: 282 Train Avg loss: 0.01436, Acc: 0.97781, F1: 0.97781#####> Valid Avg loss: 4.59746, Acc:0.27333, F1: 0.27333
===> Epoch: 282: Training loss decreased (0.01441 --> 0.01436), Acc: (0.97819 --> 0.97781), F1: (0.97819 --> 0.97781).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 283 Train Avg loss: 0.01444, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 4.76853, Acc:0.26381, F1: 0.26381
====> Epoch: 284 Train Avg loss: 0.01425, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 4.82791, Acc:0.27238, F1: 0.27238
===> Epoch: 284: Training loss decreased (0.01436 --> 0.01425), Acc: (0.97781 --> 0.97723), F1: (0.97781 --> 0.97723).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 285 Train Avg loss: 0.01426, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 4.52029, Acc:0.27619, F1: 0.27619
====> Epoch: 286 Train Avg loss: 0.01431, Acc: 0.97877, F1: 0.97877#####> Valid Avg loss: 4.76472, Acc:0.27714, F1: 0.27714
====> Epoch: 287 Train Avg loss: 0.01431, Acc: 0.97877, F1: 0.97877#####> Valid Avg loss: 4.64739, Acc:0.27714, F1: 0.27714
====> Epoch: 288 Train Avg loss: 0.01427, Acc: 0.97858, F1: 0.97858#####> Valid Avg loss: 4.74448, Acc:0.27238, F1: 0.27238
====> Epoch: 289 Train Avg loss: 0.01426, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 4.72829, Acc:0.27810, F1: 0.27810
====> Epoch: 290 Train Avg loss: 0.01418, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.77276, Acc:0.27905, F1: 0.27905
===> Epoch: 290: Training loss decreased (0.01425 --> 0.01418), Acc: (0.97723 --> 0.97819), F1: (0.97723 --> 0.97819).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 291 Train Avg loss: 0.01416, Acc: 0.97954, F1: 0.97954#####> Valid Avg loss: 4.63484, Acc:0.27714, F1: 0.27714
===> Epoch: 291: Training loss decreased (0.01418 --> 0.01416), Acc: (0.97819 --> 0.97954), F1: (0.97819 --> 0.97954).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 292 Train Avg loss: 0.01418, Acc: 0.97935, F1: 0.97935#####> Valid Avg loss: 4.82219, Acc:0.27714, F1: 0.27714
====> Epoch: 293 Train Avg loss: 0.01412, Acc: 0.97916, F1: 0.97916#####> Valid Avg loss: 4.73580, Acc:0.27810, F1: 0.27810
===> Epoch: 293: Training loss decreased (0.01416 --> 0.01412), Acc: (0.97954 --> 0.97916), F1: (0.97954 --> 0.97916).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 294 Train Avg loss: 0.01414, Acc: 0.97974, F1: 0.97974#####> Valid Avg loss: 4.86428, Acc:0.27810, F1: 0.27810
====> Epoch: 295 Train Avg loss: 0.01417, Acc: 0.97819, F1: 0.97819#####> Valid Avg loss: 4.68211, Acc:0.27810, F1: 0.27810
====> Epoch: 296 Train Avg loss: 0.01411, Acc: 0.97897, F1: 0.97897#####> Valid Avg loss: 4.70985, Acc:0.27810, F1: 0.27810
===> Epoch: 296: Training loss decreased (0.01412 --> 0.01411), Acc: (0.97916 --> 0.97897), F1: (0.97916 --> 0.97897).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 297 Train Avg loss: 0.01409, Acc: 0.98051, F1: 0.98051#####> Valid Avg loss: 4.81005, Acc:0.27714, F1: 0.27714
===> Epoch: 297: Training loss decreased (0.01411 --> 0.01409), Acc: (0.97897 --> 0.98051), F1: (0.97897 --> 0.98051).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 298 Train Avg loss: 0.01412, Acc: 0.98051, F1: 0.98051#####> Valid Avg loss: 4.73504, Acc:0.27714, F1: 0.27714
====> Epoch: 299 Train Avg loss: 0.01409, Acc: 0.98070, F1: 0.98070#####> Valid Avg loss: 4.69937, Acc:0.27524, F1: 0.27524
====> Epoch: 300 Train Avg loss: 0.54995, Acc: 0.62852, F1: 0.62852#####> Valid Avg loss: 0.81659, Acc:0.44762, F1: 0.44762

####> Epoch: 300: validation loss decreased (0.84687 --> 0.81659), Acc: (0.47810 --> 0.44762), F1: (0.47810 --> 0.44762).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1595988675.151555.pth_2
====> Epoch: 301 Train Avg loss: 0.47299, Acc: 0.67233, F1: 0.67233#####> Valid Avg loss: 1.01502, Acc:0.43524, F1: 0.43524
====> Epoch: 302 Train Avg loss: 0.45117, Acc: 0.68294, F1: 0.68294#####> Valid Avg loss: 1.13249, Acc:0.34762, F1: 0.34762
====> Epoch: 303 Train Avg loss: 0.43490, Acc: 0.68757, F1: 0.68757#####> Valid Avg loss: 1.69939, Acc:0.29048, F1: 0.29048
====> Epoch: 304 Train Avg loss: 0.42404, Acc: 0.70031, F1: 0.70031#####> Valid Avg loss: 1.69741, Acc:0.25714, F1: 0.25714
====> Epoch: 305 Train Avg loss: 0.39410, Acc: 0.72327, F1: 0.72327#####> Valid Avg loss: 1.63664, Acc:0.29524, F1: 0.29524
====> Epoch: 306 Train Avg loss: 0.37099, Acc: 0.73292, F1: 0.73292#####> Valid Avg loss: 1.68307, Acc:0.29048, F1: 0.29048
====> Epoch: 307 Train Avg loss: 0.35934, Acc: 0.73832, F1: 0.73832#####> Valid Avg loss: 1.61248, Acc:0.31429, F1: 0.31429
====> Epoch: 308 Train Avg loss: 0.33866, Acc: 0.74624, F1: 0.74624#####> Valid Avg loss: 1.93461, Acc:0.24571, F1: 0.24571
====> Epoch: 309 Train Avg loss: 0.29961, Acc: 0.77827, F1: 0.77827#####> Valid Avg loss: 1.75815, Acc:0.30000, F1: 0.30000
====> Epoch: 310 Train Avg loss: 0.26347, Acc: 0.80278, F1: 0.80278#####> Valid Avg loss: 2.31931, Acc:0.26476, F1: 0.26476
====> Epoch: 311 Train Avg loss: 0.24825, Acc: 0.81320, F1: 0.81320#####> Valid Avg loss: 2.27301, Acc:0.28095, F1: 0.28095
====> Epoch: 312 Train Avg loss: 0.22754, Acc: 0.82362, F1: 0.82362#####> Valid Avg loss: 1.70749, Acc:0.28857, F1: 0.28857
====> Epoch: 313 Train Avg loss: 0.19966, Acc: 0.84929, F1: 0.84929#####> Valid Avg loss: 2.36671, Acc:0.30000, F1: 0.30000
====> Epoch: 314 Train Avg loss: 0.18983, Acc: 0.85276, F1: 0.85276#####> Valid Avg loss: 1.99234, Acc:0.28000, F1: 0.28000
====> Epoch: 315 Train Avg loss: 0.17549, Acc: 0.86009, F1: 0.86009#####> Valid Avg loss: 2.49406, Acc:0.21524, F1: 0.21524
====> Epoch: 316 Train Avg loss: 0.17737, Acc: 0.86337, F1: 0.86337#####> Valid Avg loss: 2.07889, Acc:0.24762, F1: 0.24762
====> Epoch: 317 Train Avg loss: 0.16255, Acc: 0.87206, F1: 0.87206#####> Valid Avg loss: 2.74912, Acc:0.27048, F1: 0.27048
====> Epoch: 318 Train Avg loss: 0.15833, Acc: 0.87437, F1: 0.87437#####> Valid Avg loss: 2.81193, Acc:0.22190, F1: 0.22190
====> Epoch: 319 Train Avg loss: 0.15241, Acc: 0.88325, F1: 0.88325#####> Valid Avg loss: 2.82895, Acc:0.22286, F1: 0.22286
====> Epoch: 320 Train Avg loss: 0.16562, Acc: 0.86685, F1: 0.86685#####> Valid Avg loss: 2.28877, Acc:0.27524, F1: 0.27524
====> Epoch: 321 Train Avg loss: 0.14422, Acc: 0.88113, F1: 0.88113#####> Valid Avg loss: 2.96586, Acc:0.23524, F1: 0.23524
====> Epoch: 322 Train Avg loss: 0.14226, Acc: 0.88846, F1: 0.88846#####> Valid Avg loss: 2.99471, Acc:0.26381, F1: 0.26381
====> Epoch: 323 Train Avg loss: 0.13924, Acc: 0.88981, F1: 0.88981#####> Valid Avg loss: 2.37296, Acc:0.31048, F1: 0.31048
====> Epoch: 324 Train Avg loss: 0.14842, Acc: 0.87765, F1: 0.87765#####> Valid Avg loss: 2.34898, Acc:0.33810, F1: 0.33810
====> Epoch: 325 Train Avg loss: 0.13271, Acc: 0.89039, F1: 0.89039#####> Valid Avg loss: 2.55968, Acc:0.27524, F1: 0.27524
====> Epoch: 326 Train Avg loss: 0.12711, Acc: 0.89830, F1: 0.89830#####> Valid Avg loss: 2.86457, Acc:0.32190, F1: 0.32190
====> Epoch: 327 Train Avg loss: 0.13566, Acc: 0.89213, F1: 0.89213#####> Valid Avg loss: 2.43488, Acc:0.30571, F1: 0.30571
====> Epoch: 328 Train Avg loss: 0.13048, Acc: 0.88981, F1: 0.88981#####> Valid Avg loss: 2.65379, Acc:0.25238, F1: 0.25238
====> Epoch: 329 Train Avg loss: 0.13799, Acc: 0.88672, F1: 0.88672#####> Valid Avg loss: 2.79931, Acc:0.25143, F1: 0.25143
====> Epoch: 330 Train Avg loss: 0.12532, Acc: 0.90023, F1: 0.90023#####> Valid Avg loss: 2.32772, Acc:0.23238, F1: 0.23238
====> Epoch: 331 Train Avg loss: 0.11723, Acc: 0.90544, F1: 0.90544#####> Valid Avg loss: 2.55397, Acc:0.33524, F1: 0.33524
====> Epoch: 332 Train Avg loss: 0.14320, Acc: 0.89039, F1: 0.89039#####> Valid Avg loss: 2.40783, Acc:0.29524, F1: 0.29524
====> Epoch: 333 Train Avg loss: 0.12058, Acc: 0.90583, F1: 0.90583#####> Valid Avg loss: 3.04742, Acc:0.25810, F1: 0.25810
====> Epoch: 334 Train Avg loss: 0.11942, Acc: 0.90834, F1: 0.90834#####> Valid Avg loss: 2.68867, Acc:0.30762, F1: 0.30762
====> Epoch: 335 Train Avg loss: 0.12185, Acc: 0.90178, F1: 0.90178#####> Valid Avg loss: 2.00471, Acc:0.26571, F1: 0.26571
====> Epoch: 336 Train Avg loss: 0.11143, Acc: 0.91085, F1: 0.91085#####> Valid Avg loss: 3.05412, Acc:0.22476, F1: 0.22476
====> Epoch: 337 Train Avg loss: 0.11679, Acc: 0.90679, F1: 0.90679#####> Valid Avg loss: 2.97708, Acc:0.31905, F1: 0.31905
====> Epoch: 338 Train Avg loss: 0.12065, Acc: 0.90506, F1: 0.90506#####> Valid Avg loss: 2.91930, Acc:0.29714, F1: 0.29714
====> Epoch: 339 Train Avg loss: 0.10668, Acc: 0.91876, F1: 0.91876#####> Valid Avg loss: 2.53424, Acc:0.28095, F1: 0.28095
====> Epoch: 340 Train Avg loss: 0.11729, Acc: 0.91413, F1: 0.91413#####> Valid Avg loss: 2.23198, Acc:0.33905, F1: 0.33905
====> Epoch: 341 Train Avg loss: 0.12896, Acc: 0.90062, F1: 0.90062#####> Valid Avg loss: 2.96380, Acc:0.24571, F1: 0.24571
====> Epoch: 342 Train Avg loss: 0.10477, Acc: 0.91528, F1: 0.91528#####> Valid Avg loss: 3.54135, Acc:0.24476, F1: 0.24476
====> Epoch: 343 Train Avg loss: 0.11907, Acc: 0.90100, F1: 0.90100#####> Valid Avg loss: 2.66301, Acc:0.28381, F1: 0.28381
====> Epoch: 344 Train Avg loss: 0.12210, Acc: 0.90371, F1: 0.90371#####> Valid Avg loss: 2.10882, Acc:0.33905, F1: 0.33905
====> Epoch: 345 Train Avg loss: 0.11141, Acc: 0.91162, F1: 0.91162#####> Valid Avg loss: 2.06318, Acc:0.34381, F1: 0.34381
====> Epoch: 346 Train Avg loss: 0.12108, Acc: 0.90197, F1: 0.90197#####> Valid Avg loss: 2.18197, Acc:0.33238, F1: 0.33238
====> Epoch: 347 Train Avg loss: 0.10879, Acc: 0.91760, F1: 0.91760#####> Valid Avg loss: 2.45227, Acc:0.27714, F1: 0.27714
====> Epoch: 348 Train Avg loss: 0.10884, Acc: 0.91644, F1: 0.91644#####> Valid Avg loss: 2.41342, Acc:0.30476, F1: 0.30476
====> Epoch: 349 Train Avg loss: 0.10610, Acc: 0.92049, F1: 0.92049#####> Valid Avg loss: 2.78045, Acc:0.29143, F1: 0.29143
====> Epoch: 350 Train Avg loss: 0.11917, Acc: 0.90544, F1: 0.90544#####> Valid Avg loss: 2.80141, Acc:0.29333, F1: 0.29333
====> Epoch: 351 Train Avg loss: 0.10035, Acc: 0.91644, F1: 0.91644#####> Valid Avg loss: 2.44680, Acc:0.27048, F1: 0.27048
====> Epoch: 352 Train Avg loss: 0.10750, Acc: 0.91528, F1: 0.91528#####> Valid Avg loss: 3.00648, Acc:0.29048, F1: 0.29048
====> Epoch: 353 Train Avg loss: 0.09542, Acc: 0.92223, F1: 0.92223#####> Valid Avg loss: 3.00903, Acc:0.29429, F1: 0.29429
====> Epoch: 354 Train Avg loss: 0.09983, Acc: 0.91953, F1: 0.91953#####> Valid Avg loss: 2.33450, Acc:0.32952, F1: 0.32952
====> Epoch: 355 Train Avg loss: 0.11447, Acc: 0.91123, F1: 0.91123#####> Valid Avg loss: 2.72255, Acc:0.23238, F1: 0.23238
====> Epoch: 356 Train Avg loss: 0.10305, Acc: 0.91606, F1: 0.91606#####> Valid Avg loss: 2.81720, Acc:0.30190, F1: 0.30190
====> Epoch: 357 Train Avg loss: 0.10936, Acc: 0.91432, F1: 0.91432#####> Valid Avg loss: 2.40922, Acc:0.29810, F1: 0.29810
====> Epoch: 358 Train Avg loss: 0.10233, Acc: 0.92377, F1: 0.92377#####> Valid Avg loss: 1.91020, Acc:0.37429, F1: 0.37429
====> Epoch: 359 Train Avg loss: 0.10359, Acc: 0.91567, F1: 0.91567#####> Valid Avg loss: 2.59480, Acc:0.28857, F1: 0.28857
====> Epoch: 360 Train Avg loss: 0.09619, Acc: 0.92223, F1: 0.92223#####> Valid Avg loss: 2.49654, Acc:0.24190, F1: 0.24190
====> Epoch: 361 Train Avg loss: 0.09480, Acc: 0.92493, F1: 0.92493#####> Valid Avg loss: 2.75763, Acc:0.31714, F1: 0.31714
====> Epoch: 362 Train Avg loss: 0.08904, Acc: 0.93149, F1: 0.93149#####> Valid Avg loss: 2.46681, Acc:0.31333, F1: 0.31333
====> Epoch: 363 Train Avg loss: 0.10257, Acc: 0.91818, F1: 0.91818#####> Valid Avg loss: 2.07961, Acc:0.36571, F1: 0.36571
====> Epoch: 364 Train Avg loss: 0.10216, Acc: 0.92030, F1: 0.92030#####> Valid Avg loss: 2.29680, Acc:0.30476, F1: 0.30476
====> Epoch: 365 Train Avg loss: 0.09273, Acc: 0.92821, F1: 0.92821#####> Valid Avg loss: 2.61414, Acc:0.31143, F1: 0.31143
====> Epoch: 366 Train Avg loss: 0.10579, Acc: 0.91856, F1: 0.91856#####> Valid Avg loss: 2.97746, Acc:0.22667, F1: 0.22667
====> Epoch: 367 Train Avg loss: 0.09057, Acc: 0.92628, F1: 0.92628#####> Valid Avg loss: 2.76444, Acc:0.25810, F1: 0.25810
====> Epoch: 368 Train Avg loss: 0.08705, Acc: 0.92802, F1: 0.92802#####> Valid Avg loss: 2.59347, Acc:0.27238, F1: 0.27238
====> Epoch: 369 Train Avg loss: 0.08632, Acc: 0.92590, F1: 0.92590#####> Valid Avg loss: 2.50297, Acc:0.32286, F1: 0.32286
====> Epoch: 370 Train Avg loss: 0.09542, Acc: 0.92165, F1: 0.92165#####> Valid Avg loss: 2.83238, Acc:0.27143, F1: 0.27143
====> Epoch: 371 Train Avg loss: 0.10490, Acc: 0.91509, F1: 0.91509#####> Valid Avg loss: 2.52242, Acc:0.32857, F1: 0.32857
====> Epoch: 372 Train Avg loss: 0.08972, Acc: 0.92725, F1: 0.92725#####> Valid Avg loss: 2.65497, Acc:0.32095, F1: 0.32095
====> Epoch: 373 Train Avg loss: 0.09763, Acc: 0.92223, F1: 0.92223#####> Valid Avg loss: 2.40892, Acc:0.29143, F1: 0.29143
====> Epoch: 374 Train Avg loss: 0.09857, Acc: 0.92165, F1: 0.92165#####> Valid Avg loss: 2.23898, Acc:0.33524, F1: 0.33524
====> Epoch: 375 Train Avg loss: 0.08504, Acc: 0.93111, F1: 0.93111#####> Valid Avg loss: 2.70433, Acc:0.29714, F1: 0.29714
====> Epoch: 376 Train Avg loss: 0.08472, Acc: 0.93053, F1: 0.93053#####> Valid Avg loss: 2.57029, Acc:0.30286, F1: 0.30286
====> Epoch: 377 Train Avg loss: 0.09119, Acc: 0.92165, F1: 0.92165#####> Valid Avg loss: 2.55024, Acc:0.29143, F1: 0.29143
====> Epoch: 378 Train Avg loss: 0.08901, Acc: 0.92686, F1: 0.92686#####> Valid Avg loss: 2.77359, Acc:0.25333, F1: 0.25333
====> Epoch: 379 Train Avg loss: 0.08265, Acc: 0.93034, F1: 0.93034#####> Valid Avg loss: 2.62306, Acc:0.30667, F1: 0.30667
====> Epoch: 380 Train Avg loss: 0.08119, Acc: 0.93574, F1: 0.93574#####> Valid Avg loss: 2.06097, Acc:0.32381, F1: 0.32381
====> Epoch: 381 Train Avg loss: 0.08975, Acc: 0.92686, F1: 0.92686#####> Valid Avg loss: 2.31223, Acc:0.29238, F1: 0.29238
====> Epoch: 382 Train Avg loss: 0.09343, Acc: 0.92628, F1: 0.92628#####> Valid Avg loss: 2.23663, Acc:0.32095, F1: 0.32095
====> Epoch: 383 Train Avg loss: 0.08903, Acc: 0.93034, F1: 0.93034#####> Valid Avg loss: 3.48342, Acc:0.23714, F1: 0.23714
====> Epoch: 384 Train Avg loss: 0.07708, Acc: 0.93670, F1: 0.93670#####> Valid Avg loss: 2.85644, Acc:0.33333, F1: 0.33333
====> Epoch: 385 Train Avg loss: 0.08609, Acc: 0.93497, F1: 0.93497#####> Valid Avg loss: 2.57339, Acc:0.30762, F1: 0.30762
====> Epoch: 386 Train Avg loss: 0.08823, Acc: 0.93304, F1: 0.93304#####> Valid Avg loss: 3.34420, Acc:0.25810, F1: 0.25810
====> Epoch: 387 Train Avg loss: 0.07610, Acc: 0.93960, F1: 0.93960#####> Valid Avg loss: 2.32285, Acc:0.28000, F1: 0.28000
====> Epoch: 388 Train Avg loss: 0.07564, Acc: 0.93960, F1: 0.93960#####> Valid Avg loss: 3.27885, Acc:0.27810, F1: 0.27810
====> Epoch: 389 Train Avg loss: 0.09623, Acc: 0.92339, F1: 0.92339#####> Valid Avg loss: 2.46294, Acc:0.35905, F1: 0.35905
====> Epoch: 390 Train Avg loss: 0.07968, Acc: 0.93805, F1: 0.93805#####> Valid Avg loss: 3.46718, Acc:0.23524, F1: 0.23524
====> Epoch: 391 Train Avg loss: 0.08441, Acc: 0.93400, F1: 0.93400#####> Valid Avg loss: 2.62263, Acc:0.30381, F1: 0.30381
====> Epoch: 392 Train Avg loss: 0.07448, Acc: 0.94095, F1: 0.94095#####> Valid Avg loss: 2.83609, Acc:0.31524, F1: 0.31524
====> Epoch: 393 Train Avg loss: 0.07632, Acc: 0.94076, F1: 0.94076#####> Valid Avg loss: 2.56441, Acc:0.32190, F1: 0.32190
====> Epoch: 394 Train Avg loss: 0.08268, Acc: 0.93400, F1: 0.93400#####> Valid Avg loss: 3.64515, Acc:0.24476, F1: 0.24476
====> Epoch: 395 Train Avg loss: 0.08702, Acc: 0.93207, F1: 0.93207#####> Valid Avg loss: 2.87173, Acc:0.24095, F1: 0.24095
====> Epoch: 396 Train Avg loss: 0.08366, Acc: 0.93362, F1: 0.93362#####> Valid Avg loss: 2.54084, Acc:0.27905, F1: 0.27905
====> Epoch: 397 Train Avg loss: 0.06920, Acc: 0.94172, F1: 0.94172#####> Valid Avg loss: 2.49801, Acc:0.27333, F1: 0.27333
====> Epoch: 398 Train Avg loss: 0.07314, Acc: 0.93709, F1: 0.93709#####> Valid Avg loss: 2.75657, Acc:0.31714, F1: 0.31714
====> Epoch: 399 Train Avg loss: 0.08215, Acc: 0.93690, F1: 0.93690#####> Valid Avg loss: 3.22044, Acc:0.23143, F1: 0.23143
====> Epoch: 400 Train Avg loss: 0.07878, Acc: 0.93574, F1: 0.93574#####> Valid Avg loss: 3.29334, Acc:0.23048, F1: 0.23048
====> Epoch: 401 Train Avg loss: 0.05783, Acc: 0.94867, F1: 0.94867#####> Valid Avg loss: 2.89918, Acc:0.25333, F1: 0.25333
====> Epoch: 402 Train Avg loss: 0.08919, Acc: 0.92918, F1: 0.92918#####> Valid Avg loss: 3.16192, Acc:0.30952, F1: 0.30952
====> Epoch: 403 Train Avg loss: 0.07602, Acc: 0.93786, F1: 0.93786#####> Valid Avg loss: 3.47917, Acc:0.28476, F1: 0.28476
====> Epoch: 404 Train Avg loss: 0.07467, Acc: 0.93767, F1: 0.93767#####> Valid Avg loss: 2.84923, Acc:0.28190, F1: 0.28190
====> Epoch: 405 Train Avg loss: 0.06723, Acc: 0.94249, F1: 0.94249#####> Valid Avg loss: 2.61842, Acc:0.28857, F1: 0.28857
====> Epoch: 406 Train Avg loss: 0.07237, Acc: 0.93863, F1: 0.93863#####> Valid Avg loss: 3.45463, Acc:0.22095, F1: 0.22095
====> Epoch: 407 Train Avg loss: 0.07494, Acc: 0.94037, F1: 0.94037#####> Valid Avg loss: 2.39043, Acc:0.35048, F1: 0.35048
====> Epoch: 408 Train Avg loss: 0.06120, Acc: 0.94693, F1: 0.94693#####> Valid Avg loss: 2.74897, Acc:0.25524, F1: 0.25524
====> Epoch: 409 Train Avg loss: 0.07252, Acc: 0.94037, F1: 0.94037#####> Valid Avg loss: 2.24720, Acc:0.34286, F1: 0.34286
====> Epoch: 410 Train Avg loss: 0.07883, Acc: 0.93786, F1: 0.93786#####> Valid Avg loss: 2.86290, Acc:0.25524, F1: 0.25524
====> Epoch: 411 Train Avg loss: 0.06012, Acc: 0.94905, F1: 0.94905#####> Valid Avg loss: 3.02908, Acc:0.31524, F1: 0.31524
====> Epoch: 412 Train Avg loss: 0.06223, Acc: 0.94597, F1: 0.94597#####> Valid Avg loss: 3.45849, Acc:0.30952, F1: 0.30952
====> Epoch: 413 Train Avg loss: 0.06653, Acc: 0.94404, F1: 0.94404#####> Valid Avg loss: 2.60910, Acc:0.28571, F1: 0.28571
====> Epoch: 414 Train Avg loss: 0.06473, Acc: 0.94558, F1: 0.94558#####> Valid Avg loss: 3.27467, Acc:0.22952, F1: 0.22952
====> Epoch: 415 Train Avg loss: 0.07042, Acc: 0.94307, F1: 0.94307#####> Valid Avg loss: 3.02898, Acc:0.32571, F1: 0.32571
====> Epoch: 416 Train Avg loss: 0.05838, Acc: 0.94828, F1: 0.94828#####> Valid Avg loss: 3.46309, Acc:0.23619, F1: 0.23619
====> Epoch: 417 Train Avg loss: 0.07365, Acc: 0.93477, F1: 0.93477#####> Valid Avg loss: 3.04137, Acc:0.25619, F1: 0.25619
====> Epoch: 418 Train Avg loss: 0.06556, Acc: 0.94983, F1: 0.94983#####> Valid Avg loss: 3.14440, Acc:0.26000, F1: 0.26000
====> Epoch: 419 Train Avg loss: 0.05590, Acc: 0.95041, F1: 0.95041#####> Valid Avg loss: 3.22936, Acc:0.26000, F1: 0.26000
====> Epoch: 420 Train Avg loss: 0.06797, Acc: 0.94462, F1: 0.94462#####> Valid Avg loss: 3.02417, Acc:0.23524, F1: 0.23524
====> Epoch: 421 Train Avg loss: 0.05243, Acc: 0.95542, F1: 0.95542#####> Valid Avg loss: 4.12226, Acc:0.25524, F1: 0.25524
====> Epoch: 422 Train Avg loss: 0.06882, Acc: 0.94597, F1: 0.94597#####> Valid Avg loss: 2.84478, Acc:0.26000, F1: 0.26000
====> Epoch: 423 Train Avg loss: 0.06225, Acc: 0.94732, F1: 0.94732#####> Valid Avg loss: 3.23333, Acc:0.24476, F1: 0.24476
====> Epoch: 424 Train Avg loss: 0.05803, Acc: 0.94886, F1: 0.94886#####> Valid Avg loss: 3.27206, Acc:0.25333, F1: 0.25333
====> Epoch: 425 Train Avg loss: 0.06303, Acc: 0.94732, F1: 0.94732#####> Valid Avg loss: 3.13282, Acc:0.25810, F1: 0.25810
====> Epoch: 426 Train Avg loss: 0.06000, Acc: 0.95195, F1: 0.95195#####> Valid Avg loss: 2.51787, Acc:0.26571, F1: 0.26571
====> Epoch: 427 Train Avg loss: 0.05636, Acc: 0.94925, F1: 0.94925#####> Valid Avg loss: 2.64339, Acc:0.28762, F1: 0.28762
====> Epoch: 428 Train Avg loss: 0.06194, Acc: 0.94423, F1: 0.94423#####> Valid Avg loss: 2.77891, Acc:0.27333, F1: 0.27333
====> Epoch: 429 Train Avg loss: 0.05865, Acc: 0.94848, F1: 0.94848#####> Valid Avg loss: 2.70025, Acc:0.24190, F1: 0.24190
====> Epoch: 430 Train Avg loss: 0.06019, Acc: 0.94848, F1: 0.94848#####> Valid Avg loss: 2.43440, Acc:0.35905, F1: 0.35905
====> Epoch: 431 Train Avg loss: 0.06099, Acc: 0.94732, F1: 0.94732#####> Valid Avg loss: 2.62122, Acc:0.31619, F1: 0.31619
====> Epoch: 432 Train Avg loss: 0.05825, Acc: 0.94963, F1: 0.94963#####> Valid Avg loss: 3.04085, Acc:0.24571, F1: 0.24571
====> Epoch: 433 Train Avg loss: 0.06068, Acc: 0.94712, F1: 0.94712#####> Valid Avg loss: 2.28962, Acc:0.37238, F1: 0.37238
====> Epoch: 434 Train Avg loss: 0.05582, Acc: 0.94963, F1: 0.94963#####> Valid Avg loss: 2.54021, Acc:0.27524, F1: 0.27524
====> Epoch: 435 Train Avg loss: 0.05848, Acc: 0.94983, F1: 0.94983#####> Valid Avg loss: 3.26409, Acc:0.29429, F1: 0.29429
====> Epoch: 436 Train Avg loss: 0.05607, Acc: 0.94905, F1: 0.94905#####> Valid Avg loss: 2.43640, Acc:0.33619, F1: 0.33619
====> Epoch: 437 Train Avg loss: 0.05099, Acc: 0.95253, F1: 0.95253#####> Valid Avg loss: 3.03385, Acc:0.30762, F1: 0.30762
====> Epoch: 438 Train Avg loss: 0.06229, Acc: 0.94597, F1: 0.94597#####> Valid Avg loss: 2.45194, Acc:0.31619, F1: 0.31619
====> Epoch: 439 Train Avg loss: 0.05931, Acc: 0.94867, F1: 0.94867#####> Valid Avg loss: 3.02813, Acc:0.28000, F1: 0.28000
====> Epoch: 440 Train Avg loss: 0.05785, Acc: 0.95041, F1: 0.95041#####> Valid Avg loss: 2.91454, Acc:0.28095, F1: 0.28095
====> Epoch: 441 Train Avg loss: 0.05263, Acc: 0.95562, F1: 0.95562#####> Valid Avg loss: 3.44563, Acc:0.24190, F1: 0.24190
====> Epoch: 442 Train Avg loss: 0.05670, Acc: 0.95291, F1: 0.95291#####> Valid Avg loss: 2.80834, Acc:0.27524, F1: 0.27524
====> Epoch: 443 Train Avg loss: 0.06004, Acc: 0.94848, F1: 0.94848#####> Valid Avg loss: 2.70395, Acc:0.29429, F1: 0.29429
====> Epoch: 444 Train Avg loss: 0.04541, Acc: 0.95639, F1: 0.95639#####> Valid Avg loss: 2.98133, Acc:0.26190, F1: 0.26190
====> Epoch: 445 Train Avg loss: 0.05889, Acc: 0.94828, F1: 0.94828#####> Valid Avg loss: 2.67960, Acc:0.33524, F1: 0.33524
====> Epoch: 446 Train Avg loss: 0.05122, Acc: 0.95426, F1: 0.95426#####> Valid Avg loss: 2.64537, Acc:0.34286, F1: 0.34286
====> Epoch: 447 Train Avg loss: 0.04719, Acc: 0.96005, F1: 0.96005#####> Valid Avg loss: 3.16719, Acc:0.26571, F1: 0.26571
====> Epoch: 448 Train Avg loss: 0.04820, Acc: 0.95581, F1: 0.95581#####> Valid Avg loss: 3.16847, Acc:0.32762, F1: 0.32762
====> Epoch: 449 Train Avg loss: 0.05183, Acc: 0.95755, F1: 0.95755#####> Valid Avg loss: 2.75936, Acc:0.29714, F1: 0.29714
====> Epoch: 450 Train Avg loss: 0.05466, Acc: 0.95195, F1: 0.95195#####> Valid Avg loss: 3.07271, Acc:0.29333, F1: 0.29333
====> Epoch: 451 Train Avg loss: 0.04304, Acc: 0.96276, F1: 0.96276#####> Valid Avg loss: 2.95065, Acc:0.32095, F1: 0.32095
====> Epoch: 452 Train Avg loss: 0.04788, Acc: 0.95677, F1: 0.95677#####> Valid Avg loss: 2.86565, Acc:0.32190, F1: 0.32190
====> Epoch: 453 Train Avg loss: 0.05464, Acc: 0.95079, F1: 0.95079#####> Valid Avg loss: 3.48720, Acc:0.22381, F1: 0.22381
====> Epoch: 454 Train Avg loss: 0.04378, Acc: 0.95851, F1: 0.95851#####> Valid Avg loss: 2.89670, Acc:0.26381, F1: 0.26381
====> Epoch: 455 Train Avg loss: 0.04874, Acc: 0.95735, F1: 0.95735#####> Valid Avg loss: 3.66008, Acc:0.24000, F1: 0.24000
====> Epoch: 456 Train Avg loss: 0.05035, Acc: 0.95658, F1: 0.95658#####> Valid Avg loss: 2.93113, Acc:0.24571, F1: 0.24571
====> Epoch: 457 Train Avg loss: 0.04248, Acc: 0.95909, F1: 0.95909#####> Valid Avg loss: 3.02273, Acc:0.25333, F1: 0.25333
====> Epoch: 458 Train Avg loss: 0.04583, Acc: 0.96005, F1: 0.96005#####> Valid Avg loss: 3.26455, Acc:0.23333, F1: 0.23333
====> Epoch: 459 Train Avg loss: 0.04117, Acc: 0.96391, F1: 0.96391#####> Valid Avg loss: 2.50307, Acc:0.29524, F1: 0.29524
====> Epoch: 460 Train Avg loss: 0.04663, Acc: 0.95716, F1: 0.95716#####> Valid Avg loss: 2.60822, Acc:0.35619, F1: 0.35619
====> Epoch: 461 Train Avg loss: 0.03869, Acc: 0.96372, F1: 0.96372#####> Valid Avg loss: 3.72185, Acc:0.22952, F1: 0.22952
====> Epoch: 462 Train Avg loss: 0.05411, Acc: 0.95311, F1: 0.95311#####> Valid Avg loss: 2.77202, Acc:0.32857, F1: 0.32857
====> Epoch: 463 Train Avg loss: 0.04099, Acc: 0.96179, F1: 0.96179#####> Valid Avg loss: 2.31232, Acc:0.30952, F1: 0.30952
====> Epoch: 464 Train Avg loss: 0.04355, Acc: 0.95812, F1: 0.95812#####> Valid Avg loss: 3.28331, Acc:0.24190, F1: 0.24190
====> Epoch: 465 Train Avg loss: 0.04380, Acc: 0.96160, F1: 0.96160#####> Valid Avg loss: 3.37324, Acc:0.23524, F1: 0.23524
====> Epoch: 466 Train Avg loss: 0.04242, Acc: 0.96083, F1: 0.96083#####> Valid Avg loss: 3.66302, Acc:0.23810, F1: 0.23810
====> Epoch: 467 Train Avg loss: 0.04125, Acc: 0.96256, F1: 0.96256#####> Valid Avg loss: 3.85497, Acc:0.25714, F1: 0.25714
====> Epoch: 468 Train Avg loss: 0.04000, Acc: 0.96121, F1: 0.96121#####> Valid Avg loss: 3.70925, Acc:0.24095, F1: 0.24095
====> Epoch: 469 Train Avg loss: 0.04337, Acc: 0.96005, F1: 0.96005#####> Valid Avg loss: 2.94751, Acc:0.31143, F1: 0.31143
====> Epoch: 470 Train Avg loss: 0.03789, Acc: 0.96237, F1: 0.96237#####> Valid Avg loss: 3.73519, Acc:0.31810, F1: 0.31810
====> Epoch: 471 Train Avg loss: 0.04425, Acc: 0.95909, F1: 0.95909#####> Valid Avg loss: 2.94314, Acc:0.32571, F1: 0.32571
====> Epoch: 472 Train Avg loss: 0.04461, Acc: 0.96179, F1: 0.96179#####> Valid Avg loss: 3.44062, Acc:0.30952, F1: 0.30952
====> Epoch: 473 Train Avg loss: 0.04015, Acc: 0.95928, F1: 0.95928#####> Valid Avg loss: 3.36964, Acc:0.32190, F1: 0.32190
====> Epoch: 474 Train Avg loss: 0.04123, Acc: 0.96237, F1: 0.96237#####> Valid Avg loss: 3.02664, Acc:0.33619, F1: 0.33619
====> Epoch: 475 Train Avg loss: 0.03905, Acc: 0.96198, F1: 0.96198#####> Valid Avg loss: 3.12360, Acc:0.29619, F1: 0.29619
====> Epoch: 476 Train Avg loss: 0.03755, Acc: 0.96893, F1: 0.96893#####> Valid Avg loss: 2.92724, Acc:0.33429, F1: 0.33429
====> Epoch: 477 Train Avg loss: 0.04086, Acc: 0.95928, F1: 0.95928#####> Valid Avg loss: 3.16121, Acc:0.27429, F1: 0.27429
====> Epoch: 478 Train Avg loss: 0.03737, Acc: 0.96507, F1: 0.96507#####> Valid Avg loss: 3.21210, Acc:0.29238, F1: 0.29238
====> Epoch: 479 Train Avg loss: 0.03780, Acc: 0.96469, F1: 0.96469#####> Valid Avg loss: 2.63185, Acc:0.37143, F1: 0.37143
====> Epoch: 480 Train Avg loss: 0.03716, Acc: 0.96584, F1: 0.96584#####> Valid Avg loss: 3.04211, Acc:0.28190, F1: 0.28190
====> Epoch: 481 Train Avg loss: 0.03617, Acc: 0.96256, F1: 0.96256#####> Valid Avg loss: 2.87218, Acc:0.32190, F1: 0.32190
====> Epoch: 482 Train Avg loss: 0.04394, Acc: 0.96140, F1: 0.96140#####> Valid Avg loss: 2.63747, Acc:0.35333, F1: 0.35333
====> Epoch: 483 Train Avg loss: 0.03317, Acc: 0.96758, F1: 0.96758#####> Valid Avg loss: 2.91807, Acc:0.29238, F1: 0.29238
====> Epoch: 484 Train Avg loss: 0.03714, Acc: 0.96507, F1: 0.96507#####> Valid Avg loss: 3.09336, Acc:0.30667, F1: 0.30667
====> Epoch: 485 Train Avg loss: 0.03567, Acc: 0.96411, F1: 0.96411#####> Valid Avg loss: 2.90953, Acc:0.34476, F1: 0.34476
====> Epoch: 486 Train Avg loss: 0.03496, Acc: 0.96623, F1: 0.96623#####> Valid Avg loss: 2.94327, Acc:0.31905, F1: 0.31905
====> Epoch: 487 Train Avg loss: 0.03653, Acc: 0.96719, F1: 0.96719#####> Valid Avg loss: 2.93767, Acc:0.32762, F1: 0.32762
====> Epoch: 488 Train Avg loss: 0.03363, Acc: 0.96507, F1: 0.96507#####> Valid Avg loss: 3.04027, Acc:0.31238, F1: 0.31238
====> Epoch: 489 Train Avg loss: 0.02947, Acc: 0.97009, F1: 0.97009#####> Valid Avg loss: 3.49401, Acc:0.31714, F1: 0.31714
====> Epoch: 490 Train Avg loss: 0.03619, Acc: 0.96507, F1: 0.96507#####> Valid Avg loss: 3.01669, Acc:0.32095, F1: 0.32095
====> Epoch: 491 Train Avg loss: 0.03748, Acc: 0.96469, F1: 0.96469#####> Valid Avg loss: 2.70921, Acc:0.38286, F1: 0.38286
====> Epoch: 492 Train Avg loss: 0.03130, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 3.64986, Acc:0.27524, F1: 0.27524
====> Epoch: 493 Train Avg loss: 0.03135, Acc: 0.96874, F1: 0.96874#####> Valid Avg loss: 2.48916, Acc:0.35238, F1: 0.35238
====> Epoch: 494 Train Avg loss: 0.03857, Acc: 0.96198, F1: 0.96198#####> Valid Avg loss: 3.21384, Acc:0.29905, F1: 0.29905
====> Epoch: 495 Train Avg loss: 0.02698, Acc: 0.97240, F1: 0.97240#####> Valid Avg loss: 3.36384, Acc:0.32000, F1: 0.32000
====> Epoch: 496 Train Avg loss: 0.03030, Acc: 0.96893, F1: 0.96893#####> Valid Avg loss: 3.65804, Acc:0.29524, F1: 0.29524
====> Epoch: 497 Train Avg loss: 0.03378, Acc: 0.96739, F1: 0.96739#####> Valid Avg loss: 2.65912, Acc:0.32381, F1: 0.32381
====> Epoch: 498 Train Avg loss: 0.03082, Acc: 0.96816, F1: 0.96816#####> Valid Avg loss: 3.43228, Acc:0.26190, F1: 0.26190
validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 2591
valid_dataloader len: 561
test_dataloader len: 525
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 2591
valid dataset len: 1121, valid dataloader len: 561
valid dataset len: 1050, test dataloader len: 561
====> Epoch: 1 Train Avg loss: 0.71338, Acc: 0.51370, F1: 0.51370#####> Valid Avg loss: 0.85720, Acc:0.40410, F1: 0.40374
===> Epoch: 1: Training loss decreased (inf --> 0.71338), Acc: (0.00000 --> 0.51370), F1: (0.00000 --> 0.51370).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.85720), Acc: (0.00000 --> 0.40410), F1: (0.00000 --> 0.40374).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.85720), Acc: (0.00000 --> 0.40410), F1: (0.00000 --> 0.40374).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 2 Train Avg loss: 0.58517, Acc: 0.60961, F1: 0.60961#####> Valid Avg loss: 0.86936, Acc:0.40500, F1: 0.40463
===> Epoch: 2: Training loss decreased (0.71338 --> 0.58517), Acc: (0.51370 --> 0.60961), F1: (0.51370 --> 0.60961).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1

####> Epoch: 2: validation acc increase (0.85720 --> 0.86936), Acc: (0.40410 --> 0.40500), F1: (0.40374 --> 0.40463).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 3 Train Avg loss: 0.54455, Acc: 0.63161, F1: 0.63161#####> Valid Avg loss: 1.09879, Acc:0.40678, F1: 0.40642
===> Epoch: 3: Training loss decreased (0.58517 --> 0.54455), Acc: (0.60961 --> 0.63161), F1: (0.60961 --> 0.63161).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1

####> Epoch: 3: validation acc increase (0.86936 --> 1.09879), Acc: (0.40500 --> 0.40678), F1: (0.40463 --> 0.40642).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 4 Train Avg loss: 0.51958, Acc: 0.64396, F1: 0.64396#####> Valid Avg loss: 0.92693, Acc:0.40054, F1: 0.40018
===> Epoch: 4: Training loss decreased (0.54455 --> 0.51958), Acc: (0.63161 --> 0.64396), F1: (0.63161 --> 0.64396).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 5 Train Avg loss: 0.50155, Acc: 0.65129, F1: 0.65129#####> Valid Avg loss: 1.00803, Acc:0.40500, F1: 0.40463
===> Epoch: 5: Training loss decreased (0.51958 --> 0.50155), Acc: (0.64396 --> 0.65129), F1: (0.64396 --> 0.65129).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 6 Train Avg loss: 0.48572, Acc: 0.66789, F1: 0.66789#####> Valid Avg loss: 1.15603, Acc:0.40678, F1: 0.40642
===> Epoch: 6: Training loss decreased (0.50155 --> 0.48572), Acc: (0.65129 --> 0.66789), F1: (0.65129 --> 0.66789).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 7 Train Avg loss: 0.47616, Acc: 0.67020, F1: 0.67020#####> Valid Avg loss: 1.13842, Acc:0.40767, F1: 0.40731
===> Epoch: 7: Training loss decreased (0.48572 --> 0.47616), Acc: (0.66789 --> 0.67020), F1: (0.66789 --> 0.67020).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1

####> Epoch: 7: validation acc increase (1.09879 --> 1.13842), Acc: (0.40678 --> 0.40767), F1: (0.40642 --> 0.40731).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 8 Train Avg loss: 0.46609, Acc: 0.66943, F1: 0.66943#####> Valid Avg loss: 1.09883, Acc:0.40589, F1: 0.40553
===> Epoch: 8: Training loss decreased (0.47616 --> 0.46609), Acc: (0.67020 --> 0.66943), F1: (0.67020 --> 0.66943).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 9 Train Avg loss: 0.45683, Acc: 0.68101, F1: 0.68101#####> Valid Avg loss: 1.08213, Acc:0.40500, F1: 0.40463
===> Epoch: 9: Training loss decreased (0.46609 --> 0.45683), Acc: (0.66943 --> 0.68101), F1: (0.66943 --> 0.68101).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 10 Train Avg loss: 0.44834, Acc: 0.67889, F1: 0.67889#####> Valid Avg loss: 1.09324, Acc:0.39607, F1: 0.39572
===> Epoch: 10: Training loss decreased (0.45683 --> 0.44834), Acc: (0.68101 --> 0.67889), F1: (0.68101 --> 0.67889).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 11 Train Avg loss: 0.44173, Acc: 0.68757, F1: 0.68757#####> Valid Avg loss: 0.91703, Acc:0.39964, F1: 0.39929
===> Epoch: 11: Training loss decreased (0.44834 --> 0.44173), Acc: (0.67889 --> 0.68757), F1: (0.67889 --> 0.68757).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596087086.229964.pth_1
====> Epoch: 12 Train Avg loss: 0.43188, Acc: 0.69143, F1: 0.69143validation type: person, valid_person_index:0
window size: 5, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.7, upper_layer_dropout: 0.7
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 2591
valid_dataloader len: 561
test_dataloader len: 525
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 2591
valid dataset len: 1121, valid dataloader len: 561
valid dataset len: 1050, test dataloader len: 561
====> Epoch: 1 Train Avg loss: 0.72886, Acc: 0.49402, F1: 0.49402#####> Valid Avg loss: 0.98022, Acc:0.39875, F1: 0.39840
===> Epoch: 1: Training loss decreased (inf --> 0.72886), Acc: (0.00000 --> 0.49402), F1: (0.00000 --> 0.49402).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.98022), Acc: (0.00000 --> 0.39875), F1: (0.00000 --> 0.39840).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.98022), Acc: (0.00000 --> 0.39875), F1: (0.00000 --> 0.39840).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
====> Epoch: 2 Train Avg loss: 0.58315, Acc: 0.61096, F1: 0.61096#####> Valid Avg loss: 0.83511, Acc:0.40321, F1: 0.40285
===> Epoch: 2: Training loss decreased (0.72886 --> 0.58315), Acc: (0.49402 --> 0.61096), F1: (0.49402 --> 0.61096).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1

####> Epoch: 2: validation loss decreased (0.98022 --> 0.83511), Acc: (0.39875 --> 0.40321), F1: (0.39840 --> 0.40285).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1

####> Epoch: 2: validation acc increase (0.98022 --> 0.83511), Acc: (0.39875 --> 0.40321), F1: (0.39840 --> 0.40285).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
====> Epoch: 3 Train Avg loss: 0.54400, Acc: 0.63393, F1: 0.63393#####> Valid Avg loss: 0.95066, Acc:0.40589, F1: 0.40553
===> Epoch: 3: Training loss decreased (0.58315 --> 0.54400), Acc: (0.61096 --> 0.63393), F1: (0.61096 --> 0.63393).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1

####> Epoch: 3: validation acc increase (0.83511 --> 0.95066), Acc: (0.40321 --> 0.40589), F1: (0.40285 --> 0.40553).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
====> Epoch: 4 Train Avg loss: 0.51761, Acc: 0.64473, F1: 0.64473#####> Valid Avg loss: 1.03251, Acc:0.40589, F1: 0.40553
===> Epoch: 4: Training loss decreased (0.54400 --> 0.51761), Acc: (0.63393 --> 0.64473), F1: (0.63393 --> 0.64473).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
====> Epoch: 5 Train Avg loss: 0.50785, Acc: 0.65052, F1: 0.65052#####> Valid Avg loss: 1.04538, Acc:0.40678, F1: 0.40642
===> Epoch: 5: Training loss decreased (0.51761 --> 0.50785), Acc: (0.64473 --> 0.65052), F1: (0.64473 --> 0.65052).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1

####> Epoch: 5: validation acc increase (0.95066 --> 1.04538), Acc: (0.40589 --> 0.40678), F1: (0.40553 --> 0.40642).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
====> Epoch: 6 Train Avg loss: 0.48765, Acc: 0.66422, F1: 0.66422#####> Valid Avg loss: 1.06403, Acc:0.40589, F1: 0.40553
===> Epoch: 6: Training loss decreased (0.50785 --> 0.48765), Acc: (0.65052 --> 0.66422), F1: (0.65052 --> 0.66422).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
====> Epoch: 7 Train Avg loss: 0.47867, Acc: 0.66635, F1: 0.66635#####> Valid Avg loss: 1.09206, Acc:0.40143, F1: 0.40107
===> Epoch: 7: Training loss decreased (0.48765 --> 0.47867), Acc: (0.66422 --> 0.66635), F1: (0.66422 --> 0.66635).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
====> Epoch: 8 Train Avg loss: 0.46847, Acc: 0.66789, F1: 0.66789#####> Valid Avg loss: 1.12302, Acc:0.40589, F1: 0.40553
===> Epoch: 8: Training loss decreased (0.47867 --> 0.46847), Acc: (0.66635 --> 0.66789), F1: (0.66635 --> 0.66789).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
====> Epoch: 9 Train Avg loss: 0.46228, Acc: 0.67252, F1: 0.67252#####> Valid Avg loss: 1.13779, Acc:0.40678, F1: 0.40642
===> Epoch: 9: Training loss decreased (0.46847 --> 0.46228), Acc: (0.66789 --> 0.67252), F1: (0.66789 --> 0.67252).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
====> Epoch: 10 Train Avg loss: 0.44779, Acc: 0.68352, F1: 0.68352#####> Valid Avg loss: 1.14417, Acc:0.40678, F1: 0.40642
===> Epoch: 10: Training loss decreased (0.46228 --> 0.44779), Acc: (0.67252 --> 0.68352), F1: (0.67252 --> 0.68352).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596088664.91471.pth_1
validation type: person, valid_person_index:0
window size: 2, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596091074.35576.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 2, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596091545.035634.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 2591
valid_dataloader len: 561
test_dataloader len: 525
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 2591
valid dataset len: 1121, valid dataloader len: 561
valid dataset len: 1050, test dataloader len: 561
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596186467.39197.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596186981.438827.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 2591
valid_dataloader len: 561
test_dataloader len: 525
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 2591
valid dataset len: 1121, valid dataloader len: 561
valid dataset len: 1050, test dataloader len: 561
====> Epoch: 1 Train Avg loss: 0.71753, Acc: 0.50232, F1: 0.50232#####> Valid Avg loss: 0.93994, Acc:0.40500, F1: 0.40463
===> Epoch: 1: Training loss decreased (inf --> 0.71753), Acc: (0.00000 --> 0.50232), F1: (0.00000 --> 0.50232).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.93994), Acc: (0.00000 --> 0.40500), F1: (0.00000 --> 0.40463).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.93994), Acc: (0.00000 --> 0.40500), F1: (0.00000 --> 0.40463).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 2 Train Avg loss: 0.58328, Acc: 0.61038, F1: 0.61038#####> Valid Avg loss: 0.90764, Acc:0.40678, F1: 0.40642
===> Epoch: 2: Training loss decreased (0.71753 --> 0.58328), Acc: (0.50232 --> 0.61038), F1: (0.50232 --> 0.61038).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1

####> Epoch: 2: validation loss decreased (0.93994 --> 0.90764), Acc: (0.40500 --> 0.40678), F1: (0.40463 --> 0.40642).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1

####> Epoch: 2: validation acc increase (0.93994 --> 0.90764), Acc: (0.40500 --> 0.40678), F1: (0.40463 --> 0.40642).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 3 Train Avg loss: 0.54775, Acc: 0.63489, F1: 0.63489#####> Valid Avg loss: 1.12759, Acc:0.40678, F1: 0.40642
===> Epoch: 3: Training loss decreased (0.58328 --> 0.54775), Acc: (0.61038 --> 0.63489), F1: (0.61038 --> 0.63489).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 4 Train Avg loss: 0.51988, Acc: 0.64222, F1: 0.64222#####> Valid Avg loss: 1.05974, Acc:0.40589, F1: 0.40553
===> Epoch: 4: Training loss decreased (0.54775 --> 0.51988), Acc: (0.63489 --> 0.64222), F1: (0.63489 --> 0.64222).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 5 Train Avg loss: 0.50562, Acc: 0.65110, F1: 0.65110#####> Valid Avg loss: 1.11288, Acc:0.40678, F1: 0.40642
===> Epoch: 5: Training loss decreased (0.51988 --> 0.50562), Acc: (0.64222 --> 0.65110), F1: (0.64222 --> 0.65110).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 6 Train Avg loss: 0.49366, Acc: 0.65650, F1: 0.65650#####> Valid Avg loss: 1.08457, Acc:0.40678, F1: 0.40642
===> Epoch: 6: Training loss decreased (0.50562 --> 0.49366), Acc: (0.65110 --> 0.65650), F1: (0.65110 --> 0.65650).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 7 Train Avg loss: 0.48495, Acc: 0.66017, F1: 0.66017#####> Valid Avg loss: 1.09293, Acc:0.40589, F1: 0.40553
===> Epoch: 7: Training loss decreased (0.49366 --> 0.48495), Acc: (0.65650 --> 0.66017), F1: (0.65650 --> 0.66017).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 8 Train Avg loss: 0.47269, Acc: 0.66422, F1: 0.66422#####> Valid Avg loss: 1.20191, Acc:0.40678, F1: 0.40642
===> Epoch: 8: Training loss decreased (0.48495 --> 0.47269), Acc: (0.66017 --> 0.66422), F1: (0.66017 --> 0.66422).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 9 Train Avg loss: 0.46389, Acc: 0.66789, F1: 0.66789#####> Valid Avg loss: 1.06388, Acc:0.40500, F1: 0.40463
===> Epoch: 9: Training loss decreased (0.47269 --> 0.46389), Acc: (0.66422 --> 0.66789), F1: (0.66422 --> 0.66789).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 10 Train Avg loss: 0.45397, Acc: 0.68178, F1: 0.68178#####> Valid Avg loss: 1.06687, Acc:0.40678, F1: 0.40642
===> Epoch: 10: Training loss decreased (0.46389 --> 0.45397), Acc: (0.66789 --> 0.68178), F1: (0.66789 --> 0.68178).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 11 Train Avg loss: 0.44871, Acc: 0.67908, F1: 0.67908#####> Valid Avg loss: 1.08946, Acc:0.40500, F1: 0.40463
===> Epoch: 11: Training loss decreased (0.45397 --> 0.44871), Acc: (0.68178 --> 0.67908), F1: (0.68178 --> 0.67908).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 12 Train Avg loss: 0.44332, Acc: 0.68468, F1: 0.68468#####> Valid Avg loss: 1.25750, Acc:0.40500, F1: 0.40463
===> Epoch: 12: Training loss decreased (0.44871 --> 0.44332), Acc: (0.67908 --> 0.68468), F1: (0.67908 --> 0.68468).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 13 Train Avg loss: 0.43215, Acc: 0.69587, F1: 0.69587#####> Valid Avg loss: 1.20297, Acc:0.40678, F1: 0.40642
===> Epoch: 13: Training loss decreased (0.44332 --> 0.43215), Acc: (0.68468 --> 0.69587), F1: (0.68468 --> 0.69587).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 14 Train Avg loss: 0.43006, Acc: 0.68777, F1: 0.68777#####> Valid Avg loss: 1.12414, Acc:0.40143, F1: 0.40107
===> Epoch: 14: Training loss decreased (0.43215 --> 0.43006), Acc: (0.69587 --> 0.68777), F1: (0.69587 --> 0.68777).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 15 Train Avg loss: 0.41559, Acc: 0.70398, F1: 0.70398#####> Valid Avg loss: 1.24290, Acc:0.39875, F1: 0.39840
===> Epoch: 15: Training loss decreased (0.43006 --> 0.41559), Acc: (0.68777 --> 0.70398), F1: (0.68777 --> 0.70398).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 16 Train Avg loss: 0.41416, Acc: 0.70185, F1: 0.70185#####> Valid Avg loss: 1.11459, Acc:0.41035, F1: 0.40998
===> Epoch: 16: Training loss decreased (0.41559 --> 0.41416), Acc: (0.70398 --> 0.70185), F1: (0.70398 --> 0.70185).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1

####> Epoch: 16: validation acc increase (0.90764 --> 1.11459), Acc: (0.40678 --> 0.41035), F1: (0.40642 --> 0.40998).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 17 Train Avg loss: 0.40174, Acc: 0.70668, F1: 0.70668#####> Valid Avg loss: 1.20867, Acc:0.40678, F1: 0.40642
===> Epoch: 17: Training loss decreased (0.41416 --> 0.40174), Acc: (0.70185 --> 0.70668), F1: (0.70185 --> 0.70668).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 18 Train Avg loss: 0.40313, Acc: 0.70552, F1: 0.70552#####> Valid Avg loss: 1.19116, Acc:0.40321, F1: 0.40285
====> Epoch: 19 Train Avg loss: 0.39397, Acc: 0.71652, F1: 0.71652#####> Valid Avg loss: 1.37507, Acc:0.40500, F1: 0.40463
===> Epoch: 19: Training loss decreased (0.40174 --> 0.39397), Acc: (0.70668 --> 0.71652), F1: (0.70668 --> 0.71652).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 20 Train Avg loss: 0.38879, Acc: 0.71131, F1: 0.71131#####> Valid Avg loss: 1.20070, Acc:0.39429, F1: 0.39394
===> Epoch: 20: Training loss decreased (0.39397 --> 0.38879), Acc: (0.71652 --> 0.71131), F1: (0.71652 --> 0.71131).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 21 Train Avg loss: 0.38296, Acc: 0.71922, F1: 0.71922#####> Valid Avg loss: 1.22311, Acc:0.40143, F1: 0.40107
===> Epoch: 21: Training loss decreased (0.38879 --> 0.38296), Acc: (0.71131 --> 0.71922), F1: (0.71131 --> 0.71922).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 22 Train Avg loss: 0.37481, Acc: 0.72404, F1: 0.72404#####> Valid Avg loss: 1.30327, Acc:0.40054, F1: 0.40018
===> Epoch: 22: Training loss decreased (0.38296 --> 0.37481), Acc: (0.71922 --> 0.72404), F1: (0.71922 --> 0.72404).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 23 Train Avg loss: 0.36692, Acc: 0.73466, F1: 0.73466#####> Valid Avg loss: 1.44468, Acc:0.40143, F1: 0.40107
===> Epoch: 23: Training loss decreased (0.37481 --> 0.36692), Acc: (0.72404 --> 0.73466), F1: (0.72404 --> 0.73466).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 24 Train Avg loss: 0.36215, Acc: 0.73292, F1: 0.73292#####> Valid Avg loss: 1.51876, Acc:0.40589, F1: 0.40553
===> Epoch: 24: Training loss decreased (0.36692 --> 0.36215), Acc: (0.73466 --> 0.73292), F1: (0.73466 --> 0.73292).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 25 Train Avg loss: 0.35657, Acc: 0.73678, F1: 0.73678#####> Valid Avg loss: 1.40890, Acc:0.40500, F1: 0.40463
===> Epoch: 25: Training loss decreased (0.36215 --> 0.35657), Acc: (0.73292 --> 0.73678), F1: (0.73292 --> 0.73678).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 26 Train Avg loss: 0.34846, Acc: 0.73987, F1: 0.73987#####> Valid Avg loss: 1.34266, Acc:0.40232, F1: 0.40196
===> Epoch: 26: Training loss decreased (0.35657 --> 0.34846), Acc: (0.73678 --> 0.73987), F1: (0.73678 --> 0.73987).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 27 Train Avg loss: 0.34366, Acc: 0.74373, F1: 0.74373#####> Valid Avg loss: 1.51248, Acc:0.40678, F1: 0.40642
===> Epoch: 27: Training loss decreased (0.34846 --> 0.34366), Acc: (0.73987 --> 0.74373), F1: (0.73987 --> 0.74373).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 28 Train Avg loss: 0.33576, Acc: 0.74682, F1: 0.74682#####> Valid Avg loss: 1.18938, Acc:0.39161, F1: 0.39216
===> Epoch: 28: Training loss decreased (0.34366 --> 0.33576), Acc: (0.74373 --> 0.74682), F1: (0.74373 --> 0.74682).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 29 Train Avg loss: 0.32899, Acc: 0.75724, F1: 0.75724#####> Valid Avg loss: 1.34939, Acc:0.39607, F1: 0.39572
===> Epoch: 29: Training loss decreased (0.33576 --> 0.32899), Acc: (0.74682 --> 0.75724), F1: (0.74682 --> 0.75724).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 30 Train Avg loss: 0.31710, Acc: 0.76515, F1: 0.76515#####> Valid Avg loss: 1.51524, Acc:0.40143, F1: 0.40107
===> Epoch: 30: Training loss decreased (0.32899 --> 0.31710), Acc: (0.75724 --> 0.76515), F1: (0.75724 --> 0.76515).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 31 Train Avg loss: 0.31558, Acc: 0.77267, F1: 0.77267#####> Valid Avg loss: 1.68870, Acc:0.40589, F1: 0.40553
===> Epoch: 31: Training loss decreased (0.31710 --> 0.31558), Acc: (0.76515 --> 0.77267), F1: (0.76515 --> 0.77267).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 32 Train Avg loss: 0.30288, Acc: 0.77267, F1: 0.77267#####> Valid Avg loss: 1.58201, Acc:0.39607, F1: 0.39572
===> Epoch: 32: Training loss decreased (0.31558 --> 0.30288), Acc: (0.77267 --> 0.77267), F1: (0.77267 --> 0.77267).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 33 Train Avg loss: 0.29385, Acc: 0.78001, F1: 0.78001#####> Valid Avg loss: 1.39798, Acc:0.39251, F1: 0.39216
===> Epoch: 33: Training loss decreased (0.30288 --> 0.29385), Acc: (0.77267 --> 0.78001), F1: (0.77267 --> 0.78001).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 34 Train Avg loss: 0.29099, Acc: 0.78020, F1: 0.78020#####> Valid Avg loss: 1.46515, Acc:0.40321, F1: 0.40285
===> Epoch: 34: Training loss decreased (0.29385 --> 0.29099), Acc: (0.78001 --> 0.78020), F1: (0.78001 --> 0.78020).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 35 Train Avg loss: 0.28232, Acc: 0.79313, F1: 0.79313#####> Valid Avg loss: 1.48725, Acc:0.38715, F1: 0.38770
===> Epoch: 35: Training loss decreased (0.29099 --> 0.28232), Acc: (0.78020 --> 0.79313), F1: (0.78020 --> 0.79313).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 36 Train Avg loss: 0.27382, Acc: 0.79255, F1: 0.79255#####> Valid Avg loss: 1.56983, Acc:0.39607, F1: 0.39572
===> Epoch: 36: Training loss decreased (0.28232 --> 0.27382), Acc: (0.79313 --> 0.79255), F1: (0.79313 --> 0.79255).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 37 Train Avg loss: 0.25725, Acc: 0.80220, F1: 0.80220#####> Valid Avg loss: 1.72692, Acc:0.40410, F1: 0.40374
===> Epoch: 37: Training loss decreased (0.27382 --> 0.25725), Acc: (0.79255 --> 0.80220), F1: (0.79255 --> 0.80220).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 38 Train Avg loss: 0.25170, Acc: 0.80413, F1: 0.80413#####> Valid Avg loss: 1.79389, Acc:0.38715, F1: 0.38681
===> Epoch: 38: Training loss decreased (0.25725 --> 0.25170), Acc: (0.80220 --> 0.80413), F1: (0.80220 --> 0.80413).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 39 Train Avg loss: 0.24165, Acc: 0.81802, F1: 0.81802#####> Valid Avg loss: 1.71548, Acc:0.39786, F1: 0.39750
===> Epoch: 39: Training loss decreased (0.25170 --> 0.24165), Acc: (0.80413 --> 0.81802), F1: (0.80413 --> 0.81802).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 40 Train Avg loss: 0.23374, Acc: 0.81513, F1: 0.81513#####> Valid Avg loss: 1.74509, Acc:0.39697, F1: 0.39661
===> Epoch: 40: Training loss decreased (0.24165 --> 0.23374), Acc: (0.81802 --> 0.81513), F1: (0.81802 --> 0.81513).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 41 Train Avg loss: 0.22146, Acc: 0.82555, F1: 0.82555#####> Valid Avg loss: 1.64142, Acc:0.38269, F1: 0.38235
===> Epoch: 41: Training loss decreased (0.23374 --> 0.22146), Acc: (0.81513 --> 0.82555), F1: (0.81513 --> 0.82555).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 42 Train Avg loss: 0.21336, Acc: 0.83057, F1: 0.83057#####> Valid Avg loss: 1.91162, Acc:0.38091, F1: 0.38146
===> Epoch: 42: Training loss decreased (0.22146 --> 0.21336), Acc: (0.82555 --> 0.83057), F1: (0.82555 --> 0.83057).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 43 Train Avg loss: 0.19687, Acc: 0.84581, F1: 0.84581#####> Valid Avg loss: 1.83235, Acc:0.37823, F1: 0.37879
===> Epoch: 43: Training loss decreased (0.21336 --> 0.19687), Acc: (0.83057 --> 0.84581), F1: (0.83057 --> 0.84581).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 44 Train Avg loss: 0.19178, Acc: 0.84813, F1: 0.84813#####> Valid Avg loss: 2.25471, Acc:0.39340, F1: 0.39305
===> Epoch: 44: Training loss decreased (0.19687 --> 0.19178), Acc: (0.84581 --> 0.84813), F1: (0.84581 --> 0.84813).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 45 Train Avg loss: 0.17676, Acc: 0.85778, F1: 0.85778#####> Valid Avg loss: 2.13564, Acc:0.38715, F1: 0.38681
===> Epoch: 45: Training loss decreased (0.19178 --> 0.17676), Acc: (0.84813 --> 0.85778), F1: (0.84813 --> 0.85778).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 46 Train Avg loss: 0.16772, Acc: 0.86453, F1: 0.86453#####> Valid Avg loss: 2.08834, Acc:0.33988, F1: 0.33957
===> Epoch: 46: Training loss decreased (0.17676 --> 0.16772), Acc: (0.85778 --> 0.86453), F1: (0.85778 --> 0.86453).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 47 Train Avg loss: 0.16352, Acc: 0.86936, F1: 0.86936#####> Valid Avg loss: 2.09312, Acc:0.37199, F1: 0.37166
===> Epoch: 47: Training loss decreased (0.16772 --> 0.16352), Acc: (0.86453 --> 0.86936), F1: (0.86453 --> 0.86936).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 48 Train Avg loss: 0.15078, Acc: 0.87553, F1: 0.87553#####> Valid Avg loss: 2.37225, Acc:0.37823, F1: 0.37790
===> Epoch: 48: Training loss decreased (0.16352 --> 0.15078), Acc: (0.86936 --> 0.87553), F1: (0.86936 --> 0.87553).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 49 Train Avg loss: 0.13340, Acc: 0.89251, F1: 0.89251#####> Valid Avg loss: 2.57662, Acc:0.34166, F1: 0.34135
===> Epoch: 49: Training loss decreased (0.15078 --> 0.13340), Acc: (0.87553 --> 0.89251), F1: (0.87553 --> 0.89251).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 50 Train Avg loss: 0.12553, Acc: 0.89888, F1: 0.89888#####> Valid Avg loss: 2.56656, Acc:0.37556, F1: 0.37522
===> Epoch: 50: Training loss decreased (0.13340 --> 0.12553), Acc: (0.89251 --> 0.89888), F1: (0.89251 --> 0.89888).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 51 Train Avg loss: 0.11205, Acc: 0.90467, F1: 0.90467#####> Valid Avg loss: 2.66329, Acc:0.38091, F1: 0.38057
===> Epoch: 51: Training loss decreased (0.12553 --> 0.11205), Acc: (0.89888 --> 0.90467), F1: (0.89888 --> 0.90467).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 52 Train Avg loss: 0.11125, Acc: 0.91220, F1: 0.91220#####> Valid Avg loss: 2.48279, Acc:0.35950, F1: 0.35918
===> Epoch: 52: Training loss decreased (0.11205 --> 0.11125), Acc: (0.90467 --> 0.91220), F1: (0.90467 --> 0.91220).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 53 Train Avg loss: 0.10753, Acc: 0.90814, F1: 0.90814#####> Valid Avg loss: 2.74263, Acc:0.34790, F1: 0.34759
===> Epoch: 53: Training loss decreased (0.11125 --> 0.10753), Acc: (0.91220 --> 0.90814), F1: (0.91220 --> 0.90814).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 54 Train Avg loss: 0.09784, Acc: 0.92281, F1: 0.92281#####> Valid Avg loss: 2.65813, Acc:0.36842, F1: 0.36898
===> Epoch: 54: Training loss decreased (0.10753 --> 0.09784), Acc: (0.90814 --> 0.92281), F1: (0.90814 --> 0.92281).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 55 Train Avg loss: 0.08660, Acc: 0.92551, F1: 0.92551#####> Valid Avg loss: 2.58754, Acc:0.36574, F1: 0.36542
===> Epoch: 55: Training loss decreased (0.09784 --> 0.08660), Acc: (0.92281 --> 0.92551), F1: (0.92281 --> 0.92551).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 56 Train Avg loss: 0.08217, Acc: 0.92995, F1: 0.92995#####> Valid Avg loss: 2.90529, Acc:0.37110, F1: 0.37077
===> Epoch: 56: Training loss decreased (0.08660 --> 0.08217), Acc: (0.92551 --> 0.92995), F1: (0.92551 --> 0.92995).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 57 Train Avg loss: 0.07905, Acc: 0.93420, F1: 0.93420#####> Valid Avg loss: 2.85713, Acc:0.34790, F1: 0.34759
===> Epoch: 57: Training loss decreased (0.08217 --> 0.07905), Acc: (0.92995 --> 0.93420), F1: (0.92995 --> 0.93420).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 58 Train Avg loss: 0.06543, Acc: 0.94018, F1: 0.94018#####> Valid Avg loss: 3.21514, Acc:0.36485, F1: 0.36453
===> Epoch: 58: Training loss decreased (0.07905 --> 0.06543), Acc: (0.93420 --> 0.94018), F1: (0.93420 --> 0.94018).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 59 Train Avg loss: 0.06473, Acc: 0.94230, F1: 0.94230#####> Valid Avg loss: 2.94049, Acc:0.36931, F1: 0.36898
===> Epoch: 59: Training loss decreased (0.06543 --> 0.06473), Acc: (0.94018 --> 0.94230), F1: (0.94018 --> 0.94230).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 60 Train Avg loss: 0.05996, Acc: 0.94905, F1: 0.94905#####> Valid Avg loss: 3.18481, Acc:0.37288, F1: 0.37255
===> Epoch: 60: Training loss decreased (0.06473 --> 0.05996), Acc: (0.94230 --> 0.94905), F1: (0.94230 --> 0.94905).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 61 Train Avg loss: 0.05389, Acc: 0.95079, F1: 0.95079#####> Valid Avg loss: 3.27381, Acc:0.33541, F1: 0.33512
===> Epoch: 61: Training loss decreased (0.05996 --> 0.05389), Acc: (0.94905 --> 0.95079), F1: (0.94905 --> 0.95079).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 62 Train Avg loss: 0.04962, Acc: 0.95697, F1: 0.95697#####> Valid Avg loss: 3.37056, Acc:0.36931, F1: 0.36898
===> Epoch: 62: Training loss decreased (0.05389 --> 0.04962), Acc: (0.95079 --> 0.95697), F1: (0.95079 --> 0.95697).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 63 Train Avg loss: 0.04743, Acc: 0.95407, F1: 0.95407#####> Valid Avg loss: 3.27222, Acc:0.36485, F1: 0.36453
===> Epoch: 63: Training loss decreased (0.04962 --> 0.04743), Acc: (0.95697 --> 0.95407), F1: (0.95697 --> 0.95407).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 64 Train Avg loss: 0.04151, Acc: 0.96237, F1: 0.96237#####> Valid Avg loss: 3.69599, Acc:0.37377, F1: 0.37344
===> Epoch: 64: Training loss decreased (0.04743 --> 0.04151), Acc: (0.95407 --> 0.96237), F1: (0.95407 --> 0.96237).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 65 Train Avg loss: 0.03701, Acc: 0.96584, F1: 0.96584#####> Valid Avg loss: 3.68607, Acc:0.37288, F1: 0.37255
===> Epoch: 65: Training loss decreased (0.04151 --> 0.03701), Acc: (0.96237 --> 0.96584), F1: (0.96237 --> 0.96584).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 66 Train Avg loss: 0.03764, Acc: 0.96507, F1: 0.96507#####> Valid Avg loss: 3.80814, Acc:0.35682, F1: 0.35651
====> Epoch: 67 Train Avg loss: 0.03167, Acc: 0.97009, F1: 0.97009#####> Valid Avg loss: 3.91950, Acc:0.33095, F1: 0.33066
===> Epoch: 67: Training loss decreased (0.03701 --> 0.03167), Acc: (0.96584 --> 0.97009), F1: (0.96584 --> 0.97009).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 68 Train Avg loss: 0.03429, Acc: 0.96854, F1: 0.96854#####> Valid Avg loss: 3.69732, Acc:0.36218, F1: 0.36185
====> Epoch: 69 Train Avg loss: 0.02851, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 4.14629, Acc:0.35058, F1: 0.35027
===> Epoch: 69: Training loss decreased (0.03167 --> 0.02851), Acc: (0.97009 --> 0.96912), F1: (0.97009 --> 0.96912).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 70 Train Avg loss: 0.02885, Acc: 0.97337, F1: 0.97337#####> Valid Avg loss: 3.88123, Acc:0.35682, F1: 0.35651
====> Epoch: 71 Train Avg loss: 0.02756, Acc: 0.97125, F1: 0.97125#####> Valid Avg loss: 3.98190, Acc:0.36664, F1: 0.36631
===> Epoch: 71: Training loss decreased (0.02851 --> 0.02756), Acc: (0.96912 --> 0.97125), F1: (0.96912 --> 0.97125).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 72 Train Avg loss: 0.02420, Acc: 0.97221, F1: 0.97221#####> Valid Avg loss: 3.81867, Acc:0.36485, F1: 0.36453
===> Epoch: 72: Training loss decreased (0.02756 --> 0.02420), Acc: (0.97125 --> 0.97221), F1: (0.97125 --> 0.97221).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 73 Train Avg loss: 0.02294, Acc: 0.97318, F1: 0.97318#####> Valid Avg loss: 4.28998, Acc:0.37110, F1: 0.37077
===> Epoch: 73: Training loss decreased (0.02420 --> 0.02294), Acc: (0.97221 --> 0.97318), F1: (0.97221 --> 0.97318).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 74 Train Avg loss: 0.02307, Acc: 0.97298, F1: 0.97298#####> Valid Avg loss: 4.30315, Acc:0.36931, F1: 0.36898
====> Epoch: 75 Train Avg loss: 0.02185, Acc: 0.97453, F1: 0.97453#####> Valid Avg loss: 4.13769, Acc:0.35772, F1: 0.35740
===> Epoch: 75: Training loss decreased (0.02294 --> 0.02185), Acc: (0.97318 --> 0.97453), F1: (0.97318 --> 0.97453).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 76 Train Avg loss: 0.02005, Acc: 0.97530, F1: 0.97530#####> Valid Avg loss: 4.45627, Acc:0.36664, F1: 0.36631
===> Epoch: 76: Training loss decreased (0.02185 --> 0.02005), Acc: (0.97453 --> 0.97530), F1: (0.97453 --> 0.97530).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 77 Train Avg loss: 0.02082, Acc: 0.97376, F1: 0.97376#####> Valid Avg loss: 4.29769, Acc:0.36307, F1: 0.36275
====> Epoch: 78 Train Avg loss: 0.01925, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 4.06252, Acc:0.35415, F1: 0.35383
===> Epoch: 78: Training loss decreased (0.02005 --> 0.01925), Acc: (0.97530 --> 0.97742), F1: (0.97530 --> 0.97742).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 79 Train Avg loss: 0.01956, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 4.24845, Acc:0.36039, F1: 0.36007
====> Epoch: 80 Train Avg loss: 0.01897, Acc: 0.97414, F1: 0.97414#####> Valid Avg loss: 4.40960, Acc:0.36307, F1: 0.36275
===> Epoch: 80: Training loss decreased (0.01925 --> 0.01897), Acc: (0.97742 --> 0.97414), F1: (0.97742 --> 0.97414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 81 Train Avg loss: 0.01823, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 4.34136, Acc:0.36842, F1: 0.36809
===> Epoch: 81: Training loss decreased (0.01897 --> 0.01823), Acc: (0.97414 --> 0.97684), F1: (0.97414 --> 0.97684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 82 Train Avg loss: 0.01705, Acc: 0.97472, F1: 0.97472#####> Valid Avg loss: 4.60832, Acc:0.36485, F1: 0.36453
===> Epoch: 82: Training loss decreased (0.01823 --> 0.01705), Acc: (0.97684 --> 0.97472), F1: (0.97684 --> 0.97472).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 83 Train Avg loss: 0.01716, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 4.36480, Acc:0.35950, F1: 0.35918
====> Epoch: 84 Train Avg loss: 0.01675, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 4.25952, Acc:0.36039, F1: 0.36007
===> Epoch: 84: Training loss decreased (0.01705 --> 0.01675), Acc: (0.97472 --> 0.97723), F1: (0.97472 --> 0.97723).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 85 Train Avg loss: 0.01646, Acc: 0.97569, F1: 0.97569#####> Valid Avg loss: 4.52702, Acc:0.35950, F1: 0.35918
===> Epoch: 85: Training loss decreased (0.01675 --> 0.01646), Acc: (0.97723 --> 0.97569), F1: (0.97723 --> 0.97569).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 86 Train Avg loss: 0.01656, Acc: 0.97376, F1: 0.97376#####> Valid Avg loss: 4.33123, Acc:0.36485, F1: 0.36453
====> Epoch: 87 Train Avg loss: 0.01597, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 4.52633, Acc:0.36753, F1: 0.36720
===> Epoch: 87: Training loss decreased (0.01646 --> 0.01597), Acc: (0.97569 --> 0.97684), F1: (0.97569 --> 0.97684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 88 Train Avg loss: 0.01598, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 4.34981, Acc:0.36039, F1: 0.36007
====> Epoch: 89 Train Avg loss: 0.01562, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 4.46387, Acc:0.36396, F1: 0.36364
===> Epoch: 89: Training loss decreased (0.01597 --> 0.01562), Acc: (0.97684 --> 0.97704), F1: (0.97684 --> 0.97704).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 90 Train Avg loss: 0.01545, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 4.43564, Acc:0.36485, F1: 0.36453
===> Epoch: 90: Training loss decreased (0.01562 --> 0.01545), Acc: (0.97704 --> 0.97665), F1: (0.97704 --> 0.97665).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 91 Train Avg loss: 0.01537, Acc: 0.97569, F1: 0.97569#####> Valid Avg loss: 4.50477, Acc:0.35950, F1: 0.35918
===> Epoch: 91: Training loss decreased (0.01545 --> 0.01537), Acc: (0.97665 --> 0.97569), F1: (0.97665 --> 0.97569).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 92 Train Avg loss: 0.01524, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 4.43447, Acc:0.36485, F1: 0.36453
===> Epoch: 92: Training loss decreased (0.01537 --> 0.01524), Acc: (0.97569 --> 0.97742), F1: (0.97569 --> 0.97742).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 93 Train Avg loss: 0.01498, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 4.55378, Acc:0.36218, F1: 0.36185
===> Epoch: 93: Training loss decreased (0.01524 --> 0.01498), Acc: (0.97742 --> 0.97839), F1: (0.97742 --> 0.97839).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 94 Train Avg loss: 0.01494, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 4.51098, Acc:0.36574, F1: 0.36542
===> Epoch: 94: Training loss decreased (0.01498 --> 0.01494), Acc: (0.97839 --> 0.97800), F1: (0.97839 --> 0.97800).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 95 Train Avg loss: 0.01489, Acc: 0.97993, F1: 0.97993#####> Valid Avg loss: 4.56679, Acc:0.36396, F1: 0.36364
===> Epoch: 95: Training loss decreased (0.01494 --> 0.01489), Acc: (0.97800 --> 0.97993), F1: (0.97800 --> 0.97993).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 96 Train Avg loss: 0.01474, Acc: 0.97897, F1: 0.97897#####> Valid Avg loss: 4.51851, Acc:0.36574, F1: 0.36542
===> Epoch: 96: Training loss decreased (0.01489 --> 0.01474), Acc: (0.97993 --> 0.97897), F1: (0.97993 --> 0.97897).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 97 Train Avg loss: 0.01476, Acc: 0.97781, F1: 0.97781#####> Valid Avg loss: 4.62502, Acc:0.36218, F1: 0.36185
====> Epoch: 98 Train Avg loss: 0.01482, Acc: 0.97993, F1: 0.97993#####> Valid Avg loss: 4.49927, Acc:0.36218, F1: 0.36185
====> Epoch: 99 Train Avg loss: 0.01462, Acc: 0.98070, F1: 0.98070#####> Valid Avg loss: 4.36013, Acc:0.36128, F1: 0.36096
===> Epoch: 99: Training loss decreased (0.01474 --> 0.01462), Acc: (0.97897 --> 0.98070), F1: (0.97897 --> 0.98070).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 100 Train Avg loss: 0.53420, Acc: 0.65361, F1: 0.65361#####> Valid Avg loss: 0.98018, Acc:0.41302, F1: 0.41266

####> Epoch: 100: validation acc increase (1.11459 --> 0.98018), Acc: (0.41035 --> 0.41302), F1: (0.40998 --> 0.41266).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 101 Train Avg loss: 0.44270, Acc: 0.68912, F1: 0.68912#####> Valid Avg loss: 1.25147, Acc:0.40232, F1: 0.40196
====> Epoch: 102 Train Avg loss: 0.40454, Acc: 0.71015, F1: 0.71015#####> Valid Avg loss: 1.08846, Acc:0.40856, F1: 0.40820
====> Epoch: 103 Train Avg loss: 0.38584, Acc: 0.71980, F1: 0.71980#####> Valid Avg loss: 1.50290, Acc:0.39607, F1: 0.39572
====> Epoch: 104 Train Avg loss: 0.35965, Acc: 0.73466, F1: 0.73466#####> Valid Avg loss: 1.40271, Acc:0.37199, F1: 0.37255
====> Epoch: 105 Train Avg loss: 0.33152, Acc: 0.75608, F1: 0.75608#####> Valid Avg loss: 1.34733, Acc:0.39697, F1: 0.39661
====> Epoch: 106 Train Avg loss: 0.31947, Acc: 0.76303, F1: 0.76303#####> Valid Avg loss: 1.37527, Acc:0.38180, F1: 0.38146
====> Epoch: 107 Train Avg loss: 0.29570, Acc: 0.78155, F1: 0.78155#####> Valid Avg loss: 1.42393, Acc:0.39072, F1: 0.39037
====> Epoch: 108 Train Avg loss: 0.29117, Acc: 0.78078, F1: 0.78078#####> Valid Avg loss: 1.27517, Acc:0.37377, F1: 0.37433
====> Epoch: 109 Train Avg loss: 0.28039, Acc: 0.78406, F1: 0.78406#####> Valid Avg loss: 1.47347, Acc:0.39697, F1: 0.39661
====> Epoch: 110 Train Avg loss: 0.26257, Acc: 0.79602, F1: 0.79602#####> Valid Avg loss: 1.76625, Acc:0.40143, F1: 0.40107
====> Epoch: 111 Train Avg loss: 0.25836, Acc: 0.79988, F1: 0.79988#####> Valid Avg loss: 1.42344, Acc:0.38715, F1: 0.38681
====> Epoch: 112 Train Avg loss: 0.23775, Acc: 0.81339, F1: 0.81339#####> Valid Avg loss: 1.69985, Acc:0.33095, F1: 0.33066
====> Epoch: 113 Train Avg loss: 0.23984, Acc: 0.81243, F1: 0.81243#####> Valid Avg loss: 1.32884, Acc:0.39251, F1: 0.39216
====> Epoch: 114 Train Avg loss: 0.23128, Acc: 0.82188, F1: 0.82188#####> Valid Avg loss: 1.72343, Acc:0.36842, F1: 0.36809
====> Epoch: 115 Train Avg loss: 0.22975, Acc: 0.81899, F1: 0.81899#####> Valid Avg loss: 1.75848, Acc:0.38091, F1: 0.38057
====> Epoch: 116 Train Avg loss: 0.22010, Acc: 0.82902, F1: 0.82902#####> Valid Avg loss: 1.48875, Acc:0.38002, F1: 0.38057
====> Epoch: 117 Train Avg loss: 0.21667, Acc: 0.83115, F1: 0.83115#####> Valid Avg loss: 1.82911, Acc:0.32203, F1: 0.32175
====> Epoch: 118 Train Avg loss: 0.20943, Acc: 0.83578, F1: 0.83578#####> Valid Avg loss: 1.91668, Acc:0.34969, F1: 0.34938
====> Epoch: 119 Train Avg loss: 0.20153, Acc: 0.84215, F1: 0.84215#####> Valid Avg loss: 1.89638, Acc:0.35593, F1: 0.35561
====> Epoch: 120 Train Avg loss: 0.19862, Acc: 0.84002, F1: 0.84002#####> Valid Avg loss: 2.02509, Acc:0.38180, F1: 0.38146
====> Epoch: 121 Train Avg loss: 0.19074, Acc: 0.84427, F1: 0.84427#####> Valid Avg loss: 1.84011, Acc:0.35682, F1: 0.35651
====> Epoch: 122 Train Avg loss: 0.18937, Acc: 0.85469, F1: 0.85469#####> Valid Avg loss: 1.79805, Acc:0.35593, F1: 0.35561
====> Epoch: 123 Train Avg loss: 0.19200, Acc: 0.85083, F1: 0.85083#####> Valid Avg loss: 1.72153, Acc:0.34612, F1: 0.34670
====> Epoch: 124 Train Avg loss: 0.18273, Acc: 0.85527, F1: 0.85527#####> Valid Avg loss: 1.85876, Acc:0.35861, F1: 0.35829
====> Epoch: 125 Train Avg loss: 0.17886, Acc: 0.85816, F1: 0.85816#####> Valid Avg loss: 1.83597, Acc:0.34255, F1: 0.34225
====> Epoch: 126 Train Avg loss: 0.17102, Acc: 0.86588, F1: 0.86588#####> Valid Avg loss: 1.84434, Acc:0.29438, F1: 0.29412
====> Epoch: 127 Train Avg loss: 0.16724, Acc: 0.87071, F1: 0.87071#####> Valid Avg loss: 1.98551, Acc:0.37021, F1: 0.36988
====> Epoch: 128 Train Avg loss: 0.17311, Acc: 0.86492, F1: 0.86492#####> Valid Avg loss: 1.95445, Acc:0.33274, F1: 0.33244
====> Epoch: 129 Train Avg loss: 0.17236, Acc: 0.86511, F1: 0.86511#####> Valid Avg loss: 2.00204, Acc:0.36218, F1: 0.36185
====> Epoch: 130 Train Avg loss: 0.15397, Acc: 0.87920, F1: 0.87920#####> Valid Avg loss: 2.11602, Acc:0.38091, F1: 0.38057
====> Epoch: 131 Train Avg loss: 0.16148, Acc: 0.86665, F1: 0.86665#####> Valid Avg loss: 1.86543, Acc:0.35504, F1: 0.35472
====> Epoch: 132 Train Avg loss: 0.14844, Acc: 0.87804, F1: 0.87804#####> Valid Avg loss: 1.96015, Acc:0.36842, F1: 0.36809
====> Epoch: 133 Train Avg loss: 0.15659, Acc: 0.87476, F1: 0.87476#####> Valid Avg loss: 2.11317, Acc:0.36485, F1: 0.36453
====> Epoch: 134 Train Avg loss: 0.14608, Acc: 0.88441, F1: 0.88441#####> Valid Avg loss: 2.13737, Acc:0.34434, F1: 0.34403
====> Epoch: 135 Train Avg loss: 0.13415, Acc: 0.89348, F1: 0.89348#####> Valid Avg loss: 1.96013, Acc:0.33095, F1: 0.33066
====> Epoch: 136 Train Avg loss: 0.14864, Acc: 0.87669, F1: 0.87669#####> Valid Avg loss: 1.93248, Acc:0.36128, F1: 0.36096
====> Epoch: 137 Train Avg loss: 0.13689, Acc: 0.89213, F1: 0.89213#####> Valid Avg loss: 1.89076, Acc:0.32114, F1: 0.32086
====> Epoch: 138 Train Avg loss: 0.15762, Acc: 0.88036, F1: 0.88036#####> Valid Avg loss: 1.86589, Acc:0.38002, F1: 0.37968
====> Epoch: 139 Train Avg loss: 0.13936, Acc: 0.88962, F1: 0.88962#####> Valid Avg loss: 2.06157, Acc:0.35593, F1: 0.35561
====> Epoch: 140 Train Avg loss: 0.14147, Acc: 0.88730, F1: 0.88730#####> Valid Avg loss: 2.04150, Acc:0.36753, F1: 0.36720
====> Epoch: 141 Train Avg loss: 0.12701, Acc: 0.90120, F1: 0.90120#####> Valid Avg loss: 1.90907, Acc:0.30508, F1: 0.30481
====> Epoch: 142 Train Avg loss: 0.12966, Acc: 0.89464, F1: 0.89464#####> Valid Avg loss: 2.05670, Acc:0.34523, F1: 0.34492
====> Epoch: 143 Train Avg loss: 0.11515, Acc: 0.90660, F1: 0.90660#####> Valid Avg loss: 1.88584, Acc:0.35058, F1: 0.35027
====> Epoch: 144 Train Avg loss: 0.11868, Acc: 0.90467, F1: 0.90467#####> Valid Avg loss: 2.26905, Acc:0.32828, F1: 0.32799
====> Epoch: 145 Train Avg loss: 0.12096, Acc: 0.90062, F1: 0.90062#####> Valid Avg loss: 1.97326, Acc:0.30598, F1: 0.30570
====> Epoch: 146 Train Avg loss: 0.12751, Acc: 0.90390, F1: 0.90390#####> Valid Avg loss: 2.09690, Acc:0.36574, F1: 0.36542
====> Epoch: 147 Train Avg loss: 0.11402, Acc: 0.91335, F1: 0.91335#####> Valid Avg loss: 2.29860, Acc:0.36574, F1: 0.36542
====> Epoch: 148 Train Avg loss: 0.10903, Acc: 0.91683, F1: 0.91683#####> Valid Avg loss: 2.40008, Acc:0.38091, F1: 0.38057
====> Epoch: 149 Train Avg loss: 0.10853, Acc: 0.91007, F1: 0.91007#####> Valid Avg loss: 2.43297, Acc:0.36574, F1: 0.36542
====> Epoch: 150 Train Avg loss: 0.11115, Acc: 0.90911, F1: 0.90911#####> Valid Avg loss: 2.15558, Acc:0.33720, F1: 0.33690
====> Epoch: 151 Train Avg loss: 0.09973, Acc: 0.92242, F1: 0.92242#####> Valid Avg loss: 2.68971, Acc:0.38002, F1: 0.37968
====> Epoch: 152 Train Avg loss: 0.10665, Acc: 0.91760, F1: 0.91760#####> Valid Avg loss: 2.14790, Acc:0.32025, F1: 0.31996
====> Epoch: 153 Train Avg loss: 0.09756, Acc: 0.92107, F1: 0.92107#####> Valid Avg loss: 2.38833, Acc:0.35326, F1: 0.35294
====> Epoch: 154 Train Avg loss: 0.10141, Acc: 0.91760, F1: 0.91760#####> Valid Avg loss: 2.27794, Acc:0.36396, F1: 0.36364
====> Epoch: 155 Train Avg loss: 0.09796, Acc: 0.92300, F1: 0.92300#####> Valid Avg loss: 2.39100, Acc:0.35772, F1: 0.35829
====> Epoch: 156 Train Avg loss: 0.09973, Acc: 0.91818, F1: 0.91818#####> Valid Avg loss: 2.34060, Acc:0.33898, F1: 0.33868
====> Epoch: 157 Train Avg loss: 0.08861, Acc: 0.92648, F1: 0.92648#####> Valid Avg loss: 2.27391, Acc:0.35058, F1: 0.35027
====> Epoch: 158 Train Avg loss: 0.08798, Acc: 0.92879, F1: 0.92879#####> Valid Avg loss: 2.37809, Acc:0.34612, F1: 0.34581
====> Epoch: 159 Train Avg loss: 0.09263, Acc: 0.92397, F1: 0.92397#####> Valid Avg loss: 2.42110, Acc:0.36753, F1: 0.36720
====> Epoch: 160 Train Avg loss: 0.08851, Acc: 0.92976, F1: 0.92976#####> Valid Avg loss: 2.44496, Acc:0.33898, F1: 0.33868
====> Epoch: 161 Train Avg loss: 0.09324, Acc: 0.92204, F1: 0.92204#####> Valid Avg loss: 2.45759, Acc:0.36931, F1: 0.36898
====> Epoch: 162 Train Avg loss: 0.08154, Acc: 0.93304, F1: 0.93304#####> Valid Avg loss: 2.36225, Acc:0.37199, F1: 0.37166
====> Epoch: 163 Train Avg loss: 0.08060, Acc: 0.93458, F1: 0.93458#####> Valid Avg loss: 2.38956, Acc:0.32649, F1: 0.32620
====> Epoch: 164 Train Avg loss: 0.07471, Acc: 0.93709, F1: 0.93709#####> Valid Avg loss: 2.60704, Acc:0.34523, F1: 0.34492
====> Epoch: 165 Train Avg loss: 0.07968, Acc: 0.93458, F1: 0.93458#####> Valid Avg loss: 2.61818, Acc:0.36485, F1: 0.36453
====> Epoch: 166 Train Avg loss: 0.08076, Acc: 0.93497, F1: 0.93497#####> Valid Avg loss: 2.50980, Acc:0.36218, F1: 0.36185
====> Epoch: 167 Train Avg loss: 0.07698, Acc: 0.93748, F1: 0.93748#####> Valid Avg loss: 2.26189, Acc:0.35950, F1: 0.35918
====> Epoch: 168 Train Avg loss: 0.07533, Acc: 0.93786, F1: 0.93786#####> Valid Avg loss: 2.43670, Acc:0.33541, F1: 0.33512
====> Epoch: 169 Train Avg loss: 0.07204, Acc: 0.94423, F1: 0.94423#####> Valid Avg loss: 2.36282, Acc:0.35772, F1: 0.35740
====> Epoch: 170 Train Avg loss: 0.06632, Acc: 0.94423, F1: 0.94423#####> Valid Avg loss: 2.45787, Acc:0.33006, F1: 0.32977
====> Epoch: 171 Train Avg loss: 0.07156, Acc: 0.93767, F1: 0.93767#####> Valid Avg loss: 2.73420, Acc:0.35772, F1: 0.35740
====> Epoch: 172 Train Avg loss: 0.06885, Acc: 0.94037, F1: 0.94037#####> Valid Avg loss: 2.37240, Acc:0.34434, F1: 0.34403
====> Epoch: 173 Train Avg loss: 0.06226, Acc: 0.94963, F1: 0.94963#####> Valid Avg loss: 2.87912, Acc:0.33006, F1: 0.32977
====> Epoch: 174 Train Avg loss: 0.06724, Acc: 0.93921, F1: 0.93921#####> Valid Avg loss: 2.70813, Acc:0.29884, F1: 0.29857
====> Epoch: 175 Train Avg loss: 0.06240, Acc: 0.94655, F1: 0.94655#####> Valid Avg loss: 2.83377, Acc:0.35682, F1: 0.35651
====> Epoch: 176 Train Avg loss: 0.05644, Acc: 0.94944, F1: 0.94944#####> Valid Avg loss: 2.69080, Acc:0.32382, F1: 0.32353
====> Epoch: 177 Train Avg loss: 0.06921, Acc: 0.94423, F1: 0.94423#####> Valid Avg loss: 2.71297, Acc:0.34880, F1: 0.34848
====> Epoch: 178 Train Avg loss: 0.05366, Acc: 0.95195, F1: 0.95195#####> Valid Avg loss: 2.58424, Acc:0.35415, F1: 0.35383
====> Epoch: 179 Train Avg loss: 0.06225, Acc: 0.94983, F1: 0.94983#####> Valid Avg loss: 2.53173, Acc:0.34701, F1: 0.34670
====> Epoch: 180 Train Avg loss: 0.04990, Acc: 0.95716, F1: 0.95716#####> Valid Avg loss: 2.63640, Acc:0.31311, F1: 0.31373
====> Epoch: 181 Train Avg loss: 0.05827, Acc: 0.94886, F1: 0.94886#####> Valid Avg loss: 2.67492, Acc:0.36664, F1: 0.36631
====> Epoch: 182 Train Avg loss: 0.05184, Acc: 0.95465, F1: 0.95465#####> Valid Avg loss: 2.61394, Acc:0.34701, F1: 0.34670
====> Epoch: 183 Train Avg loss: 0.05697, Acc: 0.94963, F1: 0.94963#####> Valid Avg loss: 3.03312, Acc:0.36842, F1: 0.36809
====> Epoch: 184 Train Avg loss: 0.05332, Acc: 0.95349, F1: 0.95349#####> Valid Avg loss: 3.04380, Acc:0.29438, F1: 0.29412
====> Epoch: 185 Train Avg loss: 0.05248, Acc: 0.95426, F1: 0.95426#####> Valid Avg loss: 2.95245, Acc:0.31044, F1: 0.31016
====> Epoch: 186 Train Avg loss: 0.05122, Acc: 0.95291, F1: 0.95291#####> Valid Avg loss: 2.65667, Acc:0.35504, F1: 0.35472
====> Epoch: 187 Train Avg loss: 0.04468, Acc: 0.96083, F1: 0.96083#####> Valid Avg loss: 2.77283, Acc:0.36485, F1: 0.36453
====> Epoch: 188 Train Avg loss: 0.04993, Acc: 0.95562, F1: 0.95562#####> Valid Avg loss: 2.66571, Acc:0.35147, F1: 0.35116
====> Epoch: 189 Train Avg loss: 0.04964, Acc: 0.95523, F1: 0.95523#####> Valid Avg loss: 2.62916, Acc:0.34166, F1: 0.34135
====> Epoch: 190 Train Avg loss: 0.04267, Acc: 0.96333, F1: 0.96333#####> Valid Avg loss: 2.80368, Acc:0.35236, F1: 0.35205
====> Epoch: 191 Train Avg loss: 0.04032, Acc: 0.96430, F1: 0.96430#####> Valid Avg loss: 2.79105, Acc:0.31222, F1: 0.31194
====> Epoch: 192 Train Avg loss: 0.05026, Acc: 0.95523, F1: 0.95523#####> Valid Avg loss: 3.02421, Acc:0.37823, F1: 0.37790
====> Epoch: 193 Train Avg loss: 0.03910, Acc: 0.96121, F1: 0.96121#####> Valid Avg loss: 2.97599, Acc:0.34701, F1: 0.34670
====> Epoch: 194 Train Avg loss: 0.04070, Acc: 0.96140, F1: 0.96140#####> Valid Avg loss: 2.98997, Acc:0.32560, F1: 0.32531
====> Epoch: 195 Train Avg loss: 0.04234, Acc: 0.96276, F1: 0.96276#####> Valid Avg loss: 3.20156, Acc:0.33720, F1: 0.33690
====> Epoch: 196 Train Avg loss: 0.03999, Acc: 0.96314, F1: 0.96314#####> Valid Avg loss: 2.99547, Acc:0.34790, F1: 0.34759
====> Epoch: 197 Train Avg loss: 0.04275, Acc: 0.96198, F1: 0.96198#####> Valid Avg loss: 2.76949, Acc:0.32471, F1: 0.32442
====> Epoch: 198 Train Avg loss: 0.03709, Acc: 0.96256, F1: 0.96256#####> Valid Avg loss: 2.86612, Acc:0.37110, F1: 0.37077
====> Epoch: 199 Train Avg loss: 0.03917, Acc: 0.96140, F1: 0.96140#####> Valid Avg loss: 2.76608, Acc:0.33720, F1: 0.33690
====> Epoch: 200 Train Avg loss: 0.04605, Acc: 0.95967, F1: 0.95967#####> Valid Avg loss: 2.80998, Acc:0.36574, F1: 0.36542
====> Epoch: 201 Train Avg loss: 0.02946, Acc: 0.96835, F1: 0.96835#####> Valid Avg loss: 3.04611, Acc:0.35950, F1: 0.35918
====> Epoch: 202 Train Avg loss: 0.03439, Acc: 0.96623, F1: 0.96623#####> Valid Avg loss: 2.94541, Acc:0.33809, F1: 0.33779
====> Epoch: 203 Train Avg loss: 0.03314, Acc: 0.96700, F1: 0.96700#####> Valid Avg loss: 3.27443, Acc:0.34880, F1: 0.34848
====> Epoch: 204 Train Avg loss: 0.03492, Acc: 0.96507, F1: 0.96507#####> Valid Avg loss: 2.91920, Acc:0.33988, F1: 0.33957
====> Epoch: 205 Train Avg loss: 0.03595, Acc: 0.96372, F1: 0.96372#####> Valid Avg loss: 2.89891, Acc:0.35772, F1: 0.35740
====> Epoch: 206 Train Avg loss: 0.03151, Acc: 0.96700, F1: 0.96700#####> Valid Avg loss: 3.01625, Acc:0.34344, F1: 0.34314
====> Epoch: 207 Train Avg loss: 0.03059, Acc: 0.97028, F1: 0.97028#####> Valid Avg loss: 2.99537, Acc:0.35415, F1: 0.35383
====> Epoch: 208 Train Avg loss: 0.03280, Acc: 0.96700, F1: 0.96700#####> Valid Avg loss: 2.89361, Acc:0.35861, F1: 0.35829
====> Epoch: 209 Train Avg loss: 0.03069, Acc: 0.96816, F1: 0.96816#####> Valid Avg loss: 3.28241, Acc:0.37734, F1: 0.37701
====> Epoch: 210 Train Avg loss: 0.02851, Acc: 0.97337, F1: 0.97337#####> Valid Avg loss: 3.05704, Acc:0.34969, F1: 0.34938
====> Epoch: 211 Train Avg loss: 0.03397, Acc: 0.97047, F1: 0.97047#####> Valid Avg loss: 2.77124, Acc:0.32739, F1: 0.32709
====> Epoch: 212 Train Avg loss: 0.02763, Acc: 0.97144, F1: 0.97144#####> Valid Avg loss: 3.00246, Acc:0.35147, F1: 0.35205
====> Epoch: 213 Train Avg loss: 0.02949, Acc: 0.97067, F1: 0.97067#####> Valid Avg loss: 3.20350, Acc:0.33898, F1: 0.33957
====> Epoch: 214 Train Avg loss: 0.02721, Acc: 0.96951, F1: 0.96951#####> Valid Avg loss: 2.96220, Acc:0.33006, F1: 0.32977
====> Epoch: 215 Train Avg loss: 0.02516, Acc: 0.97202, F1: 0.97202#####> Valid Avg loss: 3.16659, Acc:0.33095, F1: 0.33066
====> Epoch: 216 Train Avg loss: 0.02361, Acc: 0.97183, F1: 0.97183#####> Valid Avg loss: 3.11404, Acc:0.36039, F1: 0.36007
====> Epoch: 217 Train Avg loss: 0.02943, Acc: 0.97009, F1: 0.97009#####> Valid Avg loss: 3.44960, Acc:0.36664, F1: 0.36631
====> Epoch: 218 Train Avg loss: 0.02292, Acc: 0.97433, F1: 0.97433#####> Valid Avg loss: 3.17773, Acc:0.35950, F1: 0.35918
====> Epoch: 219 Train Avg loss: 0.02544, Acc: 0.97337, F1: 0.97337#####> Valid Avg loss: 3.32065, Acc:0.36664, F1: 0.36720
====> Epoch: 220 Train Avg loss: 0.02236, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 3.53441, Acc:0.36842, F1: 0.36809
====> Epoch: 221 Train Avg loss: 0.02624, Acc: 0.96854, F1: 0.96854#####> Valid Avg loss: 3.26789, Acc:0.33363, F1: 0.33422
====> Epoch: 222 Train Avg loss: 0.02393, Acc: 0.97318, F1: 0.97318#####> Valid Avg loss: 3.53940, Acc:0.35682, F1: 0.35740
====> Epoch: 223 Train Avg loss: 0.02404, Acc: 0.97279, F1: 0.97279#####> Valid Avg loss: 3.15297, Acc:0.37377, F1: 0.37344
====> Epoch: 224 Train Avg loss: 0.02020, Acc: 0.97260, F1: 0.97260#####> Valid Avg loss: 3.33562, Acc:0.36664, F1: 0.36631
====> Epoch: 225 Train Avg loss: 0.02413, Acc: 0.97163, F1: 0.97163#####> Valid Avg loss: 3.32889, Acc:0.37110, F1: 0.37077
====> Epoch: 226 Train Avg loss: 0.02404, Acc: 0.97491, F1: 0.97491#####> Valid Avg loss: 3.12010, Acc:0.36039, F1: 0.36007
====> Epoch: 227 Train Avg loss: 0.02142, Acc: 0.97414, F1: 0.97414#####> Valid Avg loss: 3.07783, Acc:0.35772, F1: 0.35740
====> Epoch: 228 Train Avg loss: 0.02068, Acc: 0.97530, F1: 0.97530#####> Valid Avg loss: 3.08963, Acc:0.36396, F1: 0.36364
====> Epoch: 229 Train Avg loss: 0.02019, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 3.43453, Acc:0.37110, F1: 0.37077
====> Epoch: 230 Train Avg loss: 0.02254, Acc: 0.97491, F1: 0.97491#####> Valid Avg loss: 3.15765, Acc:0.35415, F1: 0.35383
====> Epoch: 231 Train Avg loss: 0.01925, Acc: 0.97877, F1: 0.97877#####> Valid Avg loss: 3.30946, Acc:0.37021, F1: 0.36988
====> Epoch: 232 Train Avg loss: 0.02019, Acc: 0.97298, F1: 0.97298#####> Valid Avg loss: 2.96808, Acc:0.35415, F1: 0.35383
====> Epoch: 233 Train Avg loss: 0.01967, Acc: 0.97569, F1: 0.97569#####> Valid Avg loss: 3.13664, Acc:0.34434, F1: 0.34403
====> Epoch: 234 Train Avg loss: 0.01962, Acc: 0.97433, F1: 0.97433#####> Valid Avg loss: 3.15484, Acc:0.35504, F1: 0.35472
====> Epoch: 235 Train Avg loss: 0.01838, Acc: 0.97530, F1: 0.97530#####> Valid Avg loss: 3.19231, Acc:0.34255, F1: 0.34225
====> Epoch: 236 Train Avg loss: 0.01817, Acc: 0.97414, F1: 0.97414#####> Valid Avg loss: 3.29294, Acc:0.34612, F1: 0.34581
====> Epoch: 237 Train Avg loss: 0.01886, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 3.37674, Acc:0.36128, F1: 0.36096
====> Epoch: 238 Train Avg loss: 0.01805, Acc: 0.97433, F1: 0.97433#####> Valid Avg loss: 3.41897, Acc:0.35236, F1: 0.35205
====> Epoch: 239 Train Avg loss: 0.01848, Acc: 0.97549, F1: 0.97549#####> Valid Avg loss: 3.34809, Acc:0.36218, F1: 0.36185
====> Epoch: 240 Train Avg loss: 0.02013, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 3.39524, Acc:0.35236, F1: 0.35205
====> Epoch: 241 Train Avg loss: 0.01710, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 3.16574, Acc:0.34701, F1: 0.34670
====> Epoch: 242 Train Avg loss: 0.01897, Acc: 0.97395, F1: 0.97395#####> Valid Avg loss: 3.41186, Acc:0.35236, F1: 0.35205
====> Epoch: 243 Train Avg loss: 0.01829, Acc: 0.97414, F1: 0.97414#####> Valid Avg loss: 3.16981, Acc:0.33006, F1: 0.32977
====> Epoch: 244 Train Avg loss: 0.01720, Acc: 0.97414, F1: 0.97414#####> Valid Avg loss: 3.41008, Acc:0.35950, F1: 0.35918
====> Epoch: 245 Train Avg loss: 0.01636, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 3.06512, Acc:0.34880, F1: 0.34848
====> Epoch: 246 Train Avg loss: 0.01657, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 3.30832, Acc:0.35236, F1: 0.35205
====> Epoch: 247 Train Avg loss: 0.01627, Acc: 0.97858, F1: 0.97858#####> Valid Avg loss: 3.46137, Acc:0.35326, F1: 0.35294
====> Epoch: 248 Train Avg loss: 0.01736, Acc: 0.97665, F1: 0.97665#####> Valid Avg loss: 3.36896, Acc:0.33809, F1: 0.33779
====> Epoch: 249 Train Avg loss: 0.01596, Acc: 0.97453, F1: 0.97453#####> Valid Avg loss: 3.64863, Acc:0.35682, F1: 0.35651
====> Epoch: 250 Train Avg loss: 0.01623, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 3.43727, Acc:0.35682, F1: 0.35651
====> Epoch: 251 Train Avg loss: 0.01589, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 3.72102, Acc:0.34166, F1: 0.34135
====> Epoch: 252 Train Avg loss: 0.01611, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 3.30969, Acc:0.35147, F1: 0.35205
====> Epoch: 253 Train Avg loss: 0.01604, Acc: 0.97858, F1: 0.97858#####> Valid Avg loss: 3.55987, Acc:0.35147, F1: 0.35116
====> Epoch: 254 Train Avg loss: 0.01626, Acc: 0.97549, F1: 0.97549#####> Valid Avg loss: 3.48272, Acc:0.35861, F1: 0.35829
====> Epoch: 255 Train Avg loss: 0.01555, Acc: 0.97530, F1: 0.97530#####> Valid Avg loss: 3.52896, Acc:0.35772, F1: 0.35829
====> Epoch: 256 Train Avg loss: 0.01562, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 3.38642, Acc:0.36128, F1: 0.36096
====> Epoch: 257 Train Avg loss: 0.01541, Acc: 0.97761, F1: 0.97761#####> Valid Avg loss: 3.61379, Acc:0.35147, F1: 0.35205
====> Epoch: 258 Train Avg loss: 0.01590, Acc: 0.97588, F1: 0.97588#####> Valid Avg loss: 3.34564, Acc:0.33988, F1: 0.34046
====> Epoch: 259 Train Avg loss: 0.01585, Acc: 0.97626, F1: 0.97626#####> Valid Avg loss: 3.49033, Acc:0.34523, F1: 0.34492
====> Epoch: 260 Train Avg loss: 0.01559, Acc: 0.97704, F1: 0.97704#####> Valid Avg loss: 3.55477, Acc:0.36218, F1: 0.36185
====> Epoch: 261 Train Avg loss: 0.01525, Acc: 0.97511, F1: 0.97511#####> Valid Avg loss: 3.35036, Acc:0.32917, F1: 0.32888
====> Epoch: 262 Train Avg loss: 0.01505, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 3.65451, Acc:0.35504, F1: 0.35472
====> Epoch: 263 Train Avg loss: 0.01511, Acc: 0.97549, F1: 0.97549#####> Valid Avg loss: 3.34846, Acc:0.34077, F1: 0.34046
====> Epoch: 264 Train Avg loss: 0.01517, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 3.72117, Acc:0.34790, F1: 0.34759
====> Epoch: 265 Train Avg loss: 0.01493, Acc: 0.97877, F1: 0.97877#####> Valid Avg loss: 3.81312, Acc:0.35772, F1: 0.35740
====> Epoch: 266 Train Avg loss: 0.01497, Acc: 0.97646, F1: 0.97646#####> Valid Avg loss: 3.49948, Acc:0.35147, F1: 0.35116
====> Epoch: 267 Train Avg loss: 0.01478, Acc: 0.97761, F1: 0.97761#####> Valid Avg loss: 3.37558, Acc:0.34969, F1: 0.34938
====> Epoch: 268 Train Avg loss: 0.01481, Acc: 0.97781, F1: 0.97781#####> Valid Avg loss: 3.44467, Acc:0.35772, F1: 0.35740
====> Epoch: 269 Train Avg loss: 0.01464, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 3.46915, Acc:0.36574, F1: 0.36542
====> Epoch: 270 Train Avg loss: 0.01466, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 3.56972, Acc:0.36218, F1: 0.36185
====> Epoch: 271 Train Avg loss: 0.01483, Acc: 0.97607, F1: 0.97607#####> Valid Avg loss: 3.48781, Acc:0.36128, F1: 0.36096
====> Epoch: 272 Train Avg loss: 0.01483, Acc: 0.97781, F1: 0.97781#####> Valid Avg loss: 3.57111, Acc:0.34790, F1: 0.34759
====> Epoch: 273 Train Avg loss: 0.01453, Acc: 0.97684, F1: 0.97684#####> Valid Avg loss: 3.55939, Acc:0.33988, F1: 0.33957
===> Epoch: 273: Training loss decreased (0.01462 --> 0.01453), Acc: (0.98070 --> 0.97684), F1: (0.98070 --> 0.97684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 274 Train Avg loss: 0.01449, Acc: 0.97877, F1: 0.97877#####> Valid Avg loss: 3.53181, Acc:0.35861, F1: 0.35829
===> Epoch: 274: Training loss decreased (0.01453 --> 0.01449), Acc: (0.97684 --> 0.97877), F1: (0.97684 --> 0.97877).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 275 Train Avg loss: 0.01446, Acc: 0.97742, F1: 0.97742#####> Valid Avg loss: 3.38154, Acc:0.34701, F1: 0.34670
===> Epoch: 275: Training loss decreased (0.01449 --> 0.01446), Acc: (0.97877 --> 0.97742), F1: (0.97877 --> 0.97742).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 276 Train Avg loss: 0.01455, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 3.71360, Acc:0.35682, F1: 0.35651
====> Epoch: 277 Train Avg loss: 0.01436, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 3.44474, Acc:0.35682, F1: 0.35651
===> Epoch: 277: Training loss decreased (0.01446 --> 0.01436), Acc: (0.97742 --> 0.97723), F1: (0.97742 --> 0.97723).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 278 Train Avg loss: 0.01428, Acc: 0.97993, F1: 0.97993#####> Valid Avg loss: 3.60862, Acc:0.35504, F1: 0.35472
===> Epoch: 278: Training loss decreased (0.01436 --> 0.01428), Acc: (0.97723 --> 0.97993), F1: (0.97723 --> 0.97993).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 279 Train Avg loss: 0.01426, Acc: 0.97800, F1: 0.97800#####> Valid Avg loss: 3.61009, Acc:0.34790, F1: 0.34759
===> Epoch: 279: Training loss decreased (0.01428 --> 0.01426), Acc: (0.97993 --> 0.97800), F1: (0.97993 --> 0.97800).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 280 Train Avg loss: 0.01437, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 3.67141, Acc:0.34790, F1: 0.34759
====> Epoch: 281 Train Avg loss: 0.01425, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 3.64723, Acc:0.35236, F1: 0.35205
===> Epoch: 281: Training loss decreased (0.01426 --> 0.01425), Acc: (0.97800 --> 0.97723), F1: (0.97800 --> 0.97723).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 282 Train Avg loss: 0.01418, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 3.65319, Acc:0.35682, F1: 0.35651
===> Epoch: 282: Training loss decreased (0.01425 --> 0.01418), Acc: (0.97723 --> 0.97839), F1: (0.97723 --> 0.97839).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 283 Train Avg loss: 0.01420, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 3.64973, Acc:0.35593, F1: 0.35561
====> Epoch: 284 Train Avg loss: 0.01410, Acc: 0.97897, F1: 0.97897#####> Valid Avg loss: 3.55905, Acc:0.35415, F1: 0.35383
===> Epoch: 284: Training loss decreased (0.01418 --> 0.01410), Acc: (0.97839 --> 0.97897), F1: (0.97839 --> 0.97897).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 285 Train Avg loss: 0.01414, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 3.79805, Acc:0.35326, F1: 0.35294
====> Epoch: 286 Train Avg loss: 0.01416, Acc: 0.97723, F1: 0.97723#####> Valid Avg loss: 3.59676, Acc:0.35236, F1: 0.35205
====> Epoch: 287 Train Avg loss: 0.01408, Acc: 0.97897, F1: 0.97897#####> Valid Avg loss: 3.63006, Acc:0.35593, F1: 0.35561
===> Epoch: 287: Training loss decreased (0.01410 --> 0.01408), Acc: (0.97897 --> 0.97897), F1: (0.97897 --> 0.97897).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 288 Train Avg loss: 0.01406, Acc: 0.97839, F1: 0.97839#####> Valid Avg loss: 3.58078, Acc:0.35147, F1: 0.35116
===> Epoch: 288: Training loss decreased (0.01408 --> 0.01406), Acc: (0.97897 --> 0.97839), F1: (0.97897 --> 0.97839).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 289 Train Avg loss: 0.01404, Acc: 0.97916, F1: 0.97916#####> Valid Avg loss: 3.49754, Acc:0.35236, F1: 0.35205
===> Epoch: 289: Training loss decreased (0.01406 --> 0.01404), Acc: (0.97839 --> 0.97916), F1: (0.97839 --> 0.97916).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 290 Train Avg loss: 0.01404, Acc: 0.97935, F1: 0.97935#####> Valid Avg loss: 3.67966, Acc:0.35236, F1: 0.35205
===> Epoch: 290: Training loss decreased (0.01404 --> 0.01404), Acc: (0.97916 --> 0.97935), F1: (0.97916 --> 0.97935).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 291 Train Avg loss: 0.01406, Acc: 0.97954, F1: 0.97954#####> Valid Avg loss: 3.63753, Acc:0.35236, F1: 0.35205
====> Epoch: 292 Train Avg loss: 0.01400, Acc: 0.97877, F1: 0.97877#####> Valid Avg loss: 3.60951, Acc:0.35326, F1: 0.35294
===> Epoch: 292: Training loss decreased (0.01404 --> 0.01400), Acc: (0.97935 --> 0.97877), F1: (0.97935 --> 0.97877).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 293 Train Avg loss: 0.01410, Acc: 0.97954, F1: 0.97954#####> Valid Avg loss: 3.64623, Acc:0.35147, F1: 0.35116
====> Epoch: 294 Train Avg loss: 0.01400, Acc: 0.97916, F1: 0.97916#####> Valid Avg loss: 3.67018, Acc:0.35147, F1: 0.35116
====> Epoch: 295 Train Avg loss: 0.01403, Acc: 0.97993, F1: 0.97993#####> Valid Avg loss: 3.59888, Acc:0.35147, F1: 0.35116
====> Epoch: 296 Train Avg loss: 0.01396, Acc: 0.98070, F1: 0.98070#####> Valid Avg loss: 3.54590, Acc:0.35147, F1: 0.35116
===> Epoch: 296: Training loss decreased (0.01400 --> 0.01396), Acc: (0.97877 --> 0.98070), F1: (0.97877 --> 0.98070).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 297 Train Avg loss: 0.01395, Acc: 0.97916, F1: 0.97916#####> Valid Avg loss: 3.61877, Acc:0.35147, F1: 0.35116
===> Epoch: 297: Training loss decreased (0.01396 --> 0.01395), Acc: (0.98070 --> 0.97916), F1: (0.98070 --> 0.97916).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596187176.216853.pth_1
====> Epoch: 298 Train Avg loss: 0.01397, Acc: 0.97974, F1: 0.97974#####> Valid Avg loss: 3.62754, Acc:0.35236, F1: 0.35205
====> Epoch: 299 Train Avg loss: 0.01396, Acc: 0.98012, F1: 0.98012#####> Valid Avg loss: 3.49418, Acc:0.35058, F1: 0.35027
====> Epoch: 300 Train Avg loss: 0.44730, Acc: 0.69857, F1: 0.69857#####> Valid Avg loss: 1.16564, Acc:0.39875, F1: 0.39929
====> Epoch: 301 Train Avg loss: 0.27462, Acc: 0.80104, F1: 0.80104#####> Valid Avg loss: 1.71631, Acc:0.34880, F1: 0.34848
====> Epoch: 302 Train Avg loss: 0.16478, Acc: 0.87379, F1: 0.87379#####> Valid Avg loss: 1.70276, Acc:0.33274, F1: 0.33244
====> Epoch: 303 Train Avg loss: 0.13025, Acc: 0.89965, F1: 0.89965#####> Valid Avg loss: 2.23738, Acc:0.32114, F1: 0.32086
====> Epoch: 304 Train Avg loss: 0.13198, Acc: 0.89927, F1: 0.89927#####> Valid Avg loss: 2.17228, Acc:0.35147, F1: 0.35116
====> Epoch: 305 Train Avg loss: 0.12742, Acc: 0.90506, F1: 0.90506#####> Valid Avg loss: 1.94180, Acc:0.28814, F1: 0.28877
====> Epoch: 306 Train Avg loss: 0.12536, Acc: 0.90467, F1: 0.90467#####> Valid Avg loss: 2.14610, Acc:0.30508, F1: 0.30481
====> Epoch: 307 Train Avg loss: 0.12633, Acc: 0.90506, F1: 0.90506#####> Valid Avg loss: 1.80875, Acc:0.36574, F1: 0.36631
====> Epoch: 308 Train Avg loss: 0.11414, Acc: 0.90621, F1: 0.90621#####> Valid Avg loss: 2.09201, Acc:0.34523, F1: 0.34492
====> Epoch: 309 Train Avg loss: 0.11875, Acc: 0.90525, F1: 0.90525#####> Valid Avg loss: 2.50548, Acc:0.37377, F1: 0.37344
====> Epoch: 310 Train Avg loss: 0.11602, Acc: 0.90930, F1: 0.90930#####> Valid Avg loss: 2.19865, Acc:0.34344, F1: 0.34314
====> Epoch: 311 Train Avg loss: 0.10714, Acc: 0.91509, F1: 0.91509#####> Valid Avg loss: 2.04674, Acc:0.37734, F1: 0.37701
====> Epoch: 312 Train Avg loss: 0.11254, Acc: 0.91085, F1: 0.91085#####> Valid Avg loss: 2.17390, Acc:0.36574, F1: 0.36542
====> Epoch: 313 Train Avg loss: 0.12105, Acc: 0.90486, F1: 0.90486#####> Valid Avg loss: 1.97978, Acc:0.35326, F1: 0.35294
====> Epoch: 314 Train Avg loss: 0.11775, Acc: 0.90583, F1: 0.90583#####> Valid Avg loss: 2.24822, Acc:0.36396, F1: 0.36364
====> Epoch: 315 Train Avg loss: 0.12064, Acc: 0.90660, F1: 0.90660#####> Valid Avg loss: 1.92879, Acc:0.33809, F1: 0.33779
====> Epoch: 316 Train Avg loss: 0.11271, Acc: 0.91393, F1: 0.91393#####> Valid Avg loss: 1.95851, Acc:0.35415, F1: 0.35383
====> Epoch: 317 Train Avg loss: 0.10934, Acc: 0.91606, F1: 0.91606#####> Valid Avg loss: 1.90466, Acc:0.35504, F1: 0.35472
====> Epoch: 318 Train Avg loss: 0.12113, Acc: 0.90428, F1: 0.90428#####> Valid Avg loss: 2.18562, Acc:0.35772, F1: 0.35829
====> Epoch: 319 Train Avg loss: 0.10804, Acc: 0.91393, F1: 0.91393#####> Valid Avg loss: 2.20669, Acc:0.34255, F1: 0.34314
====> Epoch: 320 Train Avg loss: 0.11212, Acc: 0.91374, F1: 0.91374#####> Valid Avg loss: 2.32992, Acc:0.31311, F1: 0.31283
====> Epoch: 321 Train Avg loss: 0.12051, Acc: 0.91007, F1: 0.91007#####> Valid Avg loss: 1.65308, Acc:0.33006, F1: 0.33066
====> Epoch: 322 Train Avg loss: 0.11585, Acc: 0.91104, F1: 0.91104#####> Valid Avg loss: 2.01908, Acc:0.36128, F1: 0.36096
====> Epoch: 323 Train Avg loss: 0.10867, Acc: 0.91432, F1: 0.91432#####> Valid Avg loss: 2.17512, Acc:0.34790, F1: 0.34759
====> Epoch: 324 Train Avg loss: 0.11192, Acc: 0.90911, F1: 0.90911#####> Valid Avg loss: 1.98150, Acc:0.34434, F1: 0.34403
====> Epoch: 325 Train Avg loss: 0.11277, Acc: 0.91123, F1: 0.91123#####> Valid Avg loss: 1.93833, Acc:0.36574, F1: 0.36542
====> Epoch: 326 Train Avg loss: 0.10277, Acc: 0.92030, F1: 0.92030#####> Valid Avg loss: 2.52683, Acc:0.34790, F1: 0.34759
====> Epoch: 327 Train Avg loss: 0.10291, Acc: 0.91992, F1: 0.91992#####> Valid Avg loss: 2.07236, Acc:0.35415, F1: 0.35383
====> Epoch: 328 Train Avg loss: 0.12191, Acc: 0.90872, F1: 0.90872#####> Valid Avg loss: 1.97380, Acc:0.34255, F1: 0.34225
====> Epoch: 329 Train Avg loss: 0.09891, Acc: 0.92184, F1: 0.92184#####> Valid Avg loss: 2.16867, Acc:0.37377, F1: 0.37344
====> Epoch: 330 Train Avg loss: 0.10175, Acc: 0.91895, F1: 0.91895#####> Valid Avg loss: 2.06188, Acc:0.35950, F1: 0.35918
====> Epoch: 331 Train Avg loss: 0.10267, Acc: 0.92223, F1: 0.92223#####> Valid Avg loss: 2.08807, Acc:0.34790, F1: 0.34759
====> Epoch: 332 Train Avg loss: 0.11165, Acc: 0.91123, F1: 0.91123#####> Valid Avg loss: 2.14368, Acc:0.36307, F1: 0.36275
====> Epoch: 333 Train Avg loss: 0.09462, Acc: 0.92493, F1: 0.92493#####> Valid Avg loss: 2.29274, Acc:0.34880, F1: 0.34848
====> Epoch: 334 Train Avg loss: 0.10947, Acc: 0.91162, F1: 0.91162#####> Valid Avg loss: 2.18765, Acc:0.37199, F1: 0.37255
====> Epoch: 335 Train Avg loss: 0.10660, Acc: 0.91528, F1: 0.91528#####> Valid Avg loss: 2.07891, Acc:0.35772, F1: 0.35829
====> Epoch: 336 Train Avg loss: 0.09917, Acc: 0.92204, F1: 0.92204#####> Valid Avg loss: 2.52839, Acc:0.37645, F1: 0.37701
====> Epoch: 337 Train Avg loss: 0.11157, Acc: 0.91027, F1: 0.91027#####> Valid Avg loss: 2.35989, Acc:0.36218, F1: 0.36185
====> Epoch: 338 Train Avg loss: 0.10392, Acc: 0.91779, F1: 0.91779#####> Valid Avg loss: 2.48562, Acc:0.33452, F1: 0.33422
====> Epoch: 339 Train Avg loss: 0.10035, Acc: 0.92030, F1: 0.92030#####> Valid Avg loss: 2.00946, Acc:0.35772, F1: 0.35740
====> Epoch: 340 Train Avg loss: 0.10007, Acc: 0.92281, F1: 0.92281#####> Valid Avg loss: 2.24828, Acc:0.33720, F1: 0.33690
====> Epoch: 341 Train Avg loss: 0.09174, Acc: 0.92686, F1: 0.92686#####> Valid Avg loss: 2.35177, Acc:0.35772, F1: 0.35829
====> Epoch: 342 Train Avg loss: 0.09615, Acc: 0.92493, F1: 0.92493#####> Valid Avg loss: 2.09718, Acc:0.36842, F1: 0.36809
====> Epoch: 343 Train Avg loss: 0.09009, Acc: 0.93053, F1: 0.93053#####> Valid Avg loss: 2.35808, Acc:0.36485, F1: 0.36453
====> Epoch: 344 Train Avg loss: 0.09796, Acc: 0.92513, F1: 0.92513#####> Valid Avg loss: 1.99461, Acc:0.32560, F1: 0.32531
====> Epoch: 345 Train Avg loss: 0.10469, Acc: 0.92011, F1: 0.92011#####> Valid Avg loss: 1.98473, Acc:0.32471, F1: 0.32531
====> Epoch: 346 Train Avg loss: 0.09441, Acc: 0.92416, F1: 0.92416#####> Valid Avg loss: 2.42842, Acc:0.34880, F1: 0.34938
====> Epoch: 347 Train Avg loss: 0.10163, Acc: 0.91895, F1: 0.91895#####> Valid Avg loss: 1.95080, Acc:0.31133, F1: 0.31194
====> Epoch: 348 Train Avg loss: 0.09424, Acc: 0.92397, F1: 0.92397#####> Valid Avg loss: 2.11124, Acc:0.31044, F1: 0.31105
====> Epoch: 349 Train Avg loss: 0.10197, Acc: 0.91837, F1: 0.91837#####> Valid Avg loss: 2.30159, Acc:0.32739, F1: 0.32709
====> Epoch: 350 Train Avg loss: 0.09551, Acc: 0.92725, F1: 0.92725#####> Valid Avg loss: 2.10375, Acc:0.33095, F1: 0.33155
====> Epoch: 351 Train Avg loss: 0.09196, Acc: 0.93034, F1: 0.93034#####> Valid Avg loss: 2.31879, Acc:0.33541, F1: 0.33512
====> Epoch: 352 Train Avg loss: 0.09470, Acc: 0.92281, F1: 0.92281#####> Valid Avg loss: 2.36561, Acc:0.35593, F1: 0.35561
====> Epoch: 353 Train Avg loss: 0.08458, Acc: 0.93342, F1: 0.93342#####> Valid Avg loss: 1.78593, Acc:0.34523, F1: 0.34581
====> Epoch: 354 Train Avg loss: 0.09067, Acc: 0.92744, F1: 0.92744#####> Valid Avg loss: 2.46179, Acc:0.37823, F1: 0.37790
====> Epoch: 355 Train Avg loss: 0.08957, Acc: 0.93014, F1: 0.93014#####> Valid Avg loss: 2.52661, Acc:0.36753, F1: 0.36720
====> Epoch: 356 Train Avg loss: 0.09383, Acc: 0.92841, F1: 0.92841#####> Valid Avg loss: 1.99432, Acc:0.33631, F1: 0.33601
====> Epoch: 357 Train Avg loss: 0.09531, Acc: 0.92146, F1: 0.92146#####> Valid Avg loss: 1.95970, Acc:0.35950, F1: 0.36007
====> Epoch: 358 Train Avg loss: 0.08380, Acc: 0.93284, F1: 0.93284#####> Valid Avg loss: 1.94930, Acc:0.34790, F1: 0.34759
====> Epoch: 359 Train Avg loss: 0.08649, Acc: 0.92937, F1: 0.92937#####> Valid Avg loss: 2.24141, Acc:0.34701, F1: 0.34670
====> Epoch: 360 Train Avg loss: 0.09036, Acc: 0.93149, F1: 0.93149#####> Valid Avg loss: 1.87055, Acc:0.34969, F1: 0.34938
====> Epoch: 361 Train Avg loss: 0.09522, Acc: 0.92320, F1: 0.92320#####> Valid Avg loss: 2.12144, Acc:0.36218, F1: 0.36185
====> Epoch: 362 Train Avg loss: 0.09035, Acc: 0.92956, F1: 0.92956#####> Valid Avg loss: 2.22545, Acc:0.33988, F1: 0.33957
====> Epoch: 363 Train Avg loss: 0.08974, Acc: 0.92570, F1: 0.92570#####> Valid Avg loss: 2.46454, Acc:0.33006, F1: 0.33066
====> Epoch: 364 Train Avg loss: 0.08784, Acc: 0.92628, F1: 0.92628#####> Valid Avg loss: 2.30371, Acc:0.33185, F1: 0.33244
====> Epoch: 365 Train Avg loss: 0.07876, Acc: 0.93921, F1: 0.93921#####> Valid Avg loss: 2.54306, Acc:0.38180, F1: 0.38146
====> Epoch: 366 Train Avg loss: 0.08941, Acc: 0.93169, F1: 0.93169#####> Valid Avg loss: 2.41977, Acc:0.39340, F1: 0.39305
====> Epoch: 367 Train Avg loss: 0.08760, Acc: 0.92995, F1: 0.92995#####> Valid Avg loss: 2.25992, Acc:0.34434, F1: 0.34403
====> Epoch: 368 Train Avg loss: 0.08506, Acc: 0.92956, F1: 0.92956#####> Valid Avg loss: 2.39442, Acc:0.37467, F1: 0.37433
====> Epoch: 369 Train Avg loss: 0.08981, Acc: 0.93111, F1: 0.93111#####> Valid Avg loss: 2.09232, Acc:0.36753, F1: 0.36720
====> Epoch: 370 Train Avg loss: 0.07841, Acc: 0.93805, F1: 0.93805#####> Valid Avg loss: 2.32794, Acc:0.36396, F1: 0.36364
====> Epoch: 371 Train Avg loss: 0.07663, Acc: 0.93883, F1: 0.93883#####> Valid Avg loss: 2.27841, Acc:0.35236, F1: 0.35294
====> Epoch: 372 Train Avg loss: 0.08143, Acc: 0.93535, F1: 0.93535#####> Valid Avg loss: 2.43756, Acc:0.33452, F1: 0.33422
====> Epoch: 373 Train Avg loss: 0.08490, Acc: 0.93072, F1: 0.93072#####> Valid Avg loss: 2.06051, Acc:0.35326, F1: 0.35383
====> Epoch: 374 Train Avg loss: 0.07530, Acc: 0.93941, F1: 0.93941#####> Valid Avg loss: 2.47017, Acc:0.34612, F1: 0.34581
====> Epoch: 375 Train Avg loss: 0.08560, Acc: 0.93420, F1: 0.93420#####> Valid Avg loss: 2.28774, Acc:0.33809, F1: 0.33779
====> Epoch: 376 Train Avg loss: 0.09394, Acc: 0.92455, F1: 0.92455#####> Valid Avg loss: 2.13826, Acc:0.34344, F1: 0.34314
====> Epoch: 377 Train Avg loss: 0.06888, Acc: 0.94616, F1: 0.94616#####> Valid Avg loss: 2.29938, Acc:0.35682, F1: 0.35651
====> Epoch: 378 Train Avg loss: 0.07048, Acc: 0.94404, F1: 0.94404#####> Valid Avg loss: 2.35778, Acc:0.33274, F1: 0.33244
====> Epoch: 379 Train Avg loss: 0.08485, Acc: 0.93091, F1: 0.93091#####> Valid Avg loss: 2.30061, Acc:0.32917, F1: 0.32888
====> Epoch: 380 Train Avg loss: 0.07186, Acc: 0.94018, F1: 0.94018#####> Valid Avg loss: 2.28978, Acc:0.36307, F1: 0.36275
====> Epoch: 381 Train Avg loss: 0.07633, Acc: 0.93613, F1: 0.93613#####> Valid Avg loss: 2.44125, Acc:0.33363, F1: 0.33333
====> Epoch: 382 Train Avg loss: 0.08156, Acc: 0.93690, F1: 0.93690#####> Valid Avg loss: 2.09394, Acc:0.35236, F1: 0.35205
====> Epoch: 383 Train Avg loss: 0.07411, Acc: 0.94211, F1: 0.94211#####> Valid Avg loss: 2.55081, Acc:0.33274, F1: 0.33333
====> Epoch: 384 Train Avg loss: 0.07509, Acc: 0.93844, F1: 0.93844#####> Valid Avg loss: 2.07246, Acc:0.32471, F1: 0.32442
====> Epoch: 385 Train Avg loss: 0.06894, Acc: 0.94307, F1: 0.94307#####> Valid Avg loss: 2.39584, Acc:0.29527, F1: 0.29590
====> Epoch: 386 Train Avg loss: 0.07197, Acc: 0.93786, F1: 0.93786#####> Valid Avg loss: 2.28419, Acc:0.32471, F1: 0.32531
====> Epoch: 387 Train Avg loss: 0.07822, Acc: 0.93362, F1: 0.93362#####> Valid Avg loss: 2.31866, Acc:0.31401, F1: 0.31373
====> Epoch: 388 Train Avg loss: 0.06497, Acc: 0.94674, F1: 0.94674#####> Valid Avg loss: 2.80966, Acc:0.35326, F1: 0.35294
====> Epoch: 389 Train Avg loss: 0.07845, Acc: 0.94114, F1: 0.94114#####> Valid Avg loss: 2.69270, Acc:0.32560, F1: 0.32531
====> Epoch: 390 Train Avg loss: 0.07169, Acc: 0.94056, F1: 0.94056#####> Valid Avg loss: 2.46945, Acc:0.34701, F1: 0.34670
====> Epoch: 391 Train Avg loss: 0.07576, Acc: 0.94519, F1: 0.94519#####> Valid Avg loss: 2.18501, Acc:0.34166, F1: 0.34225
====> Epoch: 392 Train Avg loss: 0.07182, Acc: 0.93979, F1: 0.93979#####> Valid Avg loss: 2.53079, Acc:0.32293, F1: 0.32264
====> Epoch: 393 Train Avg loss: 0.06532, Acc: 0.94809, F1: 0.94809#####> Valid Avg loss: 2.55142, Acc:0.36128, F1: 0.36096
====> Epoch: 394 Train Avg loss: 0.07663, Acc: 0.93998, F1: 0.93998#####> Valid Avg loss: 2.18524, Acc:0.34701, F1: 0.34670
====> Epoch: 395 Train Avg loss: 0.06688, Acc: 0.94288, F1: 0.94288#####> Valid Avg loss: 2.14160, Acc:0.34790, F1: 0.34759
====> Epoch: 396 Train Avg loss: 0.07373, Acc: 0.93786, F1: 0.93786#####> Valid Avg loss: 2.25063, Acc:0.35682, F1: 0.35651
====> Epoch: 397 Train Avg loss: 0.06876, Acc: 0.94462, F1: 0.94462#####> Valid Avg loss: 2.54734, Acc:0.32382, F1: 0.32353
====> Epoch: 398 Train Avg loss: 0.07612, Acc: 0.93709, F1: 0.93709#####> Valid Avg loss: 2.47784, Acc:0.34344, F1: 0.34314
====> Epoch: 399 Train Avg loss: 0.06871, Acc: 0.94288, F1: 0.94288#####> Valid Avg loss: 2.39706, Acc:0.35415, F1: 0.35383
====> Epoch: 400 Train Avg loss: 0.07354, Acc: 0.93805, F1: 0.93805#####> Valid Avg loss: 2.13685, Acc:0.32828, F1: 0.32799
====> Epoch: 401 Train Avg loss: 0.06250, Acc: 0.94944, F1: 0.94944#####> Valid Avg loss: 2.07503, Acc:0.35682, F1: 0.35651
====> Epoch: 402 Train Avg loss: 0.07925, Acc: 0.93941, F1: 0.93941#####> Valid Avg loss: 2.03396, Acc:0.36307, F1: 0.36275
====> Epoch: 403 Train Avg loss: 0.06129, Acc: 0.94963, F1: 0.94963#####> Valid Avg loss: 2.33854, Acc:0.34880, F1: 0.34938
====> Epoch: 404 Train Avg loss: 0.06671, Acc: 0.94384, F1: 0.94384#####> Valid Avg loss: 2.35740, Acc:0.36039, F1: 0.36007
====> Epoch: 405 Train Avg loss: 0.06595, Acc: 0.94635, F1: 0.94635#####> Valid Avg loss: 2.27953, Acc:0.33452, F1: 0.33422
====> Epoch: 406 Train Avg loss: 0.06994, Acc: 0.94191, F1: 0.94191#####> Valid Avg loss: 2.18345, Acc:0.33809, F1: 0.33779
====> Epoch: 407 Train Avg loss: 0.07437, Acc: 0.94481, F1: 0.94481#####> Valid Avg loss: 2.42942, Acc:0.37110, F1: 0.37077
====> Epoch: 408 Train Avg loss: 0.06745, Acc: 0.94442, F1: 0.94442#####> Valid Avg loss: 2.48780, Acc:0.34790, F1: 0.34759
====> Epoch: 409 Train Avg loss: 0.06088, Acc: 0.94905, F1: 0.94905#####> Valid Avg loss: 2.72728, Acc:0.34880, F1: 0.34848
====> Epoch: 410 Train Avg loss: 0.06628, Acc: 0.94211, F1: 0.94211#####> Valid Avg loss: 2.36379, Acc:0.33809, F1: 0.33779
====> Epoch: 411 Train Avg loss: 0.06913, Acc: 0.93863, F1: 0.93863#####> Valid Avg loss: 1.92300, Acc:0.35861, F1: 0.35829
====> Epoch: 412 Train Avg loss: 0.06732, Acc: 0.94597, F1: 0.94597#####> Valid Avg loss: 1.96135, Acc:0.30865, F1: 0.30927
====> Epoch: 413 Train Avg loss: 0.06324, Acc: 0.94770, F1: 0.94770#####> Valid Avg loss: 2.07413, Acc:0.36218, F1: 0.36185
====> Epoch: 414 Train Avg loss: 0.06996, Acc: 0.94172, F1: 0.94172#####> Valid Avg loss: 2.18654, Acc:0.32471, F1: 0.32531
====> Epoch: 415 Train Avg loss: 0.06063, Acc: 0.94674, F1: 0.94674#####> Valid Avg loss: 2.31492, Acc:0.34880, F1: 0.34848
====> Epoch: 416 Train Avg loss: 0.05580, Acc: 0.95407, F1: 0.95407#####> Valid Avg loss: 2.68569, Acc:0.35682, F1: 0.35651
====> Epoch: 417 Train Avg loss: 0.06149, Acc: 0.94963, F1: 0.94963#####> Valid Avg loss: 2.35697, Acc:0.38002, F1: 0.37968
====> Epoch: 418 Train Avg loss: 0.05504, Acc: 0.94983, F1: 0.94983#####> Valid Avg loss: 2.34754, Acc:0.32828, F1: 0.32799
====> Epoch: 419 Train Avg loss: 0.05319, Acc: 0.95253, F1: 0.95253#####> Valid Avg loss: 2.36379, Acc:0.36307, F1: 0.36275
====> Epoch: 420 Train Avg loss: 0.06309, Acc: 0.95079, F1: 0.95079#####> Valid Avg loss: 2.21345, Acc:0.34434, F1: 0.34403
====> Epoch: 421 Train Avg loss: 0.06562, Acc: 0.94635, F1: 0.94635#####> Valid Avg loss: 2.27502, Acc:0.32739, F1: 0.32709
====> Epoch: 422 Train Avg loss: 0.05880, Acc: 0.95041, F1: 0.95041#####> Valid Avg loss: 2.50238, Acc:0.35326, F1: 0.35294
====> Epoch: 423 Train Avg loss: 0.05901, Acc: 0.95002, F1: 0.95002#####> Valid Avg loss: 2.31287, Acc:0.35950, F1: 0.35918
====> Epoch: 424 Train Avg loss: 0.05909, Acc: 0.95021, F1: 0.95021#####> Valid Avg loss: 2.29017, Acc:0.34255, F1: 0.34225
====> Epoch: 425 Train Avg loss: 0.05909, Acc: 0.94848, F1: 0.94848#####> Valid Avg loss: 2.81381, Acc:0.37467, F1: 0.37433
====> Epoch: 426 Train Avg loss: 0.06367, Acc: 0.94828, F1: 0.94828#####> Valid Avg loss: 2.05377, Acc:0.33363, F1: 0.33333
====> Epoch: 427 Train Avg loss: 0.05737, Acc: 0.95156, F1: 0.95156#####> Valid Avg loss: 2.36539, Acc:0.36218, F1: 0.36185
====> Epoch: 428 Train Avg loss: 0.05401, Acc: 0.95234, F1: 0.95234#####> Valid Avg loss: 2.60695, Acc:0.33185, F1: 0.33155
====> Epoch: 429 Train Avg loss: 0.05794, Acc: 0.95311, F1: 0.95311#####> Valid Avg loss: 2.51782, Acc:0.35593, F1: 0.35561
====> Epoch: 430 Train Avg loss: 0.06065, Acc: 0.94616, F1: 0.94616#####> Valid Avg loss: 2.50746, Acc:0.34612, F1: 0.34581
====> Epoch: 431 Train Avg loss: 0.05247, Acc: 0.95195, F1: 0.95195#####> Valid Avg loss: 2.52784, Acc:0.33452, F1: 0.33422
====> Epoch: 432 Train Avg loss: 0.06212, Acc: 0.94635, F1: 0.94635#####> Valid Avg loss: 2.34263, Acc:0.34077, F1: 0.34046
====> Epoch: 433 Train Avg loss: 0.04771, Acc: 0.95967, F1: 0.95967#####> Valid Avg loss: 2.52299, Acc:0.34701, F1: 0.34670
====> Epoch: 434 Train Avg loss: 0.05687, Acc: 0.95291, F1: 0.95291#####> Valid Avg loss: 2.51567, Acc:0.34612, F1: 0.34581
====> Epoch: 435 Train Avg loss: 0.05090, Acc: 0.95542, F1: 0.95542#####> Valid Avg loss: 2.62208, Acc:0.35326, F1: 0.35294
====> Epoch: 436 Train Avg loss: 0.04867, Acc: 0.95677, F1: 0.95677#####> Valid Avg loss: 2.46936, Acc:0.33988, F1: 0.33957
====> Epoch: 437 Train Avg loss: 0.05173, Acc: 0.95426, F1: 0.95426#####> Valid Avg loss: 2.74389, Acc:0.34612, F1: 0.34581
====> Epoch: 438 Train Avg loss: 0.05386, Acc: 0.95311, F1: 0.95311#####> Valid Avg loss: 2.47023, Acc:0.36485, F1: 0.36453
====> Epoch: 439 Train Avg loss: 0.05548, Acc: 0.95041, F1: 0.95041#####> Valid Avg loss: 2.28024, Acc:0.32293, F1: 0.32264
====> Epoch: 440 Train Avg loss: 0.04396, Acc: 0.95812, F1: 0.95812#####> Valid Avg loss: 2.49239, Acc:0.32560, F1: 0.32531
====> Epoch: 441 Train Avg loss: 0.05621, Acc: 0.94925, F1: 0.94925#####> Valid Avg loss: 2.33737, Acc:0.34166, F1: 0.34135
====> Epoch: 442 Train Avg loss: 0.04404, Acc: 0.95735, F1: 0.95735#####> Valid Avg loss: 2.62801, Acc:0.38537, F1: 0.38503
====> Epoch: 443 Train Avg loss: 0.05285, Acc: 0.95388, F1: 0.95388#####> Valid Avg loss: 2.20424, Acc:0.34790, F1: 0.34759
====> Epoch: 444 Train Avg loss: 0.04957, Acc: 0.95793, F1: 0.95793#####> Valid Avg loss: 2.32246, Acc:0.32025, F1: 0.31996
====> Epoch: 445 Train Avg loss: 0.05678, Acc: 0.95523, F1: 0.95523#####> Valid Avg loss: 2.68320, Acc:0.34166, F1: 0.34135
====> Epoch: 446 Train Avg loss: 0.04248, Acc: 0.96121, F1: 0.96121#####> Valid Avg loss: 2.70699, Acc:0.35593, F1: 0.35561
====> Epoch: 447 Train Avg loss: 0.05715, Acc: 0.95465, F1: 0.95465#####> Valid Avg loss: 2.16353, Acc:0.33185, F1: 0.33155
====> Epoch: 448 Train Avg loss: 0.05161, Acc: 0.95755, F1: 0.95755#####> Valid Avg loss: 2.35524, Acc:0.33006, F1: 0.32977
====> Epoch: 449 Train Avg loss: 0.05012, Acc: 0.95426, F1: 0.95426#####> Valid Avg loss: 2.46153, Acc:0.35861, F1: 0.35829
====> Epoch: 450 Train Avg loss: 0.05259, Acc: 0.95214, F1: 0.95214#####> Valid Avg loss: 2.57072, Acc:0.36218, F1: 0.36185
====> Epoch: 451 Train Avg loss: 0.03426, Acc: 0.96835, F1: 0.96835#####> Valid Avg loss: 2.78999, Acc:0.34701, F1: 0.34670
====> Epoch: 452 Train Avg loss: 0.05470, Acc: 0.95388, F1: 0.95388#####> Valid Avg loss: 2.61661, Acc:0.36396, F1: 0.36364
====> Epoch: 453 Train Avg loss: 0.04538, Acc: 0.95697, F1: 0.95697#####> Valid Avg loss: 2.71399, Acc:0.36218, F1: 0.36185
====> Epoch: 454 Train Avg loss: 0.05449, Acc: 0.95349, F1: 0.95349#####> Valid Avg loss: 2.39610, Acc:0.36574, F1: 0.36542
====> Epoch: 455 Train Avg loss: 0.04626, Acc: 0.95909, F1: 0.95909#####> Valid Avg loss: 2.73898, Acc:0.36485, F1: 0.36453
====> Epoch: 456 Train Avg loss: 0.04551, Acc: 0.96063, F1: 0.96063#####> Valid Avg loss: 2.70535, Acc:0.34880, F1: 0.34848
====> Epoch: 457 Train Avg loss: 0.05402, Acc: 0.95426, F1: 0.95426#####> Valid Avg loss: 2.37420, Acc:0.30955, F1: 0.30927
====> Epoch: 458 Train Avg loss: 0.04094, Acc: 0.96314, F1: 0.96314#####> Valid Avg loss: 2.60148, Acc:0.36128, F1: 0.36096
====> Epoch: 459 Train Avg loss: 0.04302, Acc: 0.96083, F1: 0.96083#####> Valid Avg loss: 2.89960, Acc:0.34880, F1: 0.34848
====> Epoch: 460 Train Avg loss: 0.04325, Acc: 0.96218, F1: 0.96218#####> Valid Avg loss: 2.39161, Acc:0.34880, F1: 0.34848
====> Epoch: 461 Train Avg loss: 0.04030, Acc: 0.96083, F1: 0.96083#####> Valid Avg loss: 2.76654, Acc:0.36485, F1: 0.36453
====> Epoch: 462 Train Avg loss: 0.04172, Acc: 0.96295, F1: 0.96295#####> Valid Avg loss: 2.68570, Acc:0.36664, F1: 0.36631
====> Epoch: 463 Train Avg loss: 0.04116, Acc: 0.95948, F1: 0.95948#####> Valid Avg loss: 2.44887, Acc:0.29527, F1: 0.29501
====> Epoch: 464 Train Avg loss: 0.04211, Acc: 0.96083, F1: 0.96083#####> Valid Avg loss: 2.52763, Acc:0.34880, F1: 0.34848
====> Epoch: 465 Train Avg loss: 0.04173, Acc: 0.96179, F1: 0.96179#####> Valid Avg loss: 2.55656, Acc:0.36396, F1: 0.36364
====> Epoch: 466 Train Avg loss: 0.03515, Acc: 0.96739, F1: 0.96739#####> Valid Avg loss: 2.74314, Acc:0.33898, F1: 0.33868
====> Epoch: 467 Train Avg loss: 0.04423, Acc: 0.95890, F1: 0.95890#####> Valid Avg loss: 2.51198, Acc:0.34166, F1: 0.34225
====> Epoch: 468 Train Avg loss: 0.03795, Acc: 0.96662, F1: 0.96662#####> Valid Avg loss: 3.13325, Acc:0.36396, F1: 0.36364
====> Epoch: 469 Train Avg loss: 0.04557, Acc: 0.95851, F1: 0.95851#####> Valid Avg loss: 2.59427, Acc:0.37467, F1: 0.37433
====> Epoch: 470 Train Avg loss: 0.03982, Acc: 0.95948, F1: 0.95948#####> Valid Avg loss: 2.90001, Acc:0.32917, F1: 0.32888
====> Epoch: 471 Train Avg loss: 0.04050, Acc: 0.96025, F1: 0.96025#####> Valid Avg loss: 2.74641, Acc:0.35058, F1: 0.35027
====> Epoch: 472 Train Avg loss: 0.04417, Acc: 0.95716, F1: 0.95716#####> Valid Avg loss: 2.44897, Acc:0.37288, F1: 0.37255
====> Epoch: 473 Train Avg loss: 0.03571, Acc: 0.96642, F1: 0.96642#####> Valid Avg loss: 2.65087, Acc:0.35415, F1: 0.35383
====> Epoch: 474 Train Avg loss: 0.03986, Acc: 0.96102, F1: 0.96102#####> Valid Avg loss: 2.57001, Acc:0.33452, F1: 0.33512
====> Epoch: 475 Train Avg loss: 0.03821, Acc: 0.96353, F1: 0.96353#####> Valid Avg loss: 2.54717, Acc:0.33095, F1: 0.33066
====> Epoch: 476 Train Avg loss: 0.03722, Acc: 0.96314, F1: 0.96314#####> Valid Avg loss: 2.91283, Acc:0.37823, F1: 0.37790
====> Epoch: 477 Train Avg loss: 0.04025, Acc: 0.96353, F1: 0.96353#####> Valid Avg loss: 2.66812, Acc:0.36218, F1: 0.36275
====> Epoch: 478 Train Avg loss: 0.03514, Acc: 0.96526, F1: 0.96526#####> Valid Avg loss: 2.97643, Acc:0.37377, F1: 0.37344
====> Epoch: 479 Train Avg loss: 0.03532, Acc: 0.96719, F1: 0.96719#####> Valid Avg loss: 2.67571, Acc:0.37377, F1: 0.37433
====> Epoch: 480 Train Avg loss: 0.03818, Acc: 0.96372, F1: 0.96372#####> Valid Avg loss: 3.10915, Acc:0.37734, F1: 0.37701
====> Epoch: 481 Train Avg loss: 0.03861, Acc: 0.96526, F1: 0.96526#####> Valid Avg loss: 2.49540, Acc:0.38269, F1: 0.38235
====> Epoch: 482 Train Avg loss: 0.03629, Acc: 0.96584, F1: 0.96584#####> Valid Avg loss: 2.70544, Acc:0.35058, F1: 0.35027
====> Epoch: 483 Train Avg loss: 0.02817, Acc: 0.97163, F1: 0.97163#####> Valid Avg loss: 2.89229, Acc:0.35147, F1: 0.35116
====> Epoch: 484 Train Avg loss: 0.04315, Acc: 0.95697, F1: 0.95697#####> Valid Avg loss: 2.51194, Acc:0.35950, F1: 0.35918
====> Epoch: 485 Train Avg loss: 0.03237, Acc: 0.96604, F1: 0.96604#####> Valid Avg loss: 2.93105, Acc:0.35326, F1: 0.35294
====> Epoch: 486 Train Avg loss: 0.04097, Acc: 0.96179, F1: 0.96179#####> Valid Avg loss: 2.55634, Acc:0.33185, F1: 0.33155
====> Epoch: 487 Train Avg loss: 0.02995, Acc: 0.96893, F1: 0.96893#####> Valid Avg loss: 2.30793, Acc:0.36485, F1: 0.36453
====> Epoch: 488 Train Avg loss: 0.03098, Acc: 0.96816, F1: 0.96816#####> Valid Avg loss: 2.91073, Acc:0.36307, F1: 0.36275
====> Epoch: 489 Train Avg loss: 0.03770, Acc: 0.96546, F1: 0.96546#####> Valid Avg loss: 2.51843, Acc:0.36574, F1: 0.36542
====> Epoch: 490 Train Avg loss: 0.03502, Acc: 0.96469, F1: 0.96469#####> Valid Avg loss: 2.60604, Acc:0.35682, F1: 0.35651
====> Epoch: 491 Train Avg loss: 0.03057, Acc: 0.96816, F1: 0.96816#####> Valid Avg loss: 2.65804, Acc:0.35772, F1: 0.35829
====> Epoch: 492 Train Avg loss: 0.03421, Acc: 0.96623, F1: 0.96623#####> Valid Avg loss: 2.51722, Acc:0.36396, F1: 0.36364
====> Epoch: 493 Train Avg loss: 0.02750, Acc: 0.96835, F1: 0.96835#####> Valid Avg loss: 2.84982, Acc:0.35772, F1: 0.35740
====> Epoch: 494 Train Avg loss: 0.03204, Acc: 0.96874, F1: 0.96874#####> Valid Avg loss: 2.99197, Acc:0.36664, F1: 0.36631
====> Epoch: 495 Train Avg loss: 0.03082, Acc: 0.96874, F1: 0.96874#####> Valid Avg loss: 2.92918, Acc:0.35861, F1: 0.35829
====> Epoch: 496 Train Avg loss: 0.03244, Acc: 0.96912, F1: 0.96912#####> Valid Avg loss: 2.95175, Acc:0.36218, F1: 0.36185
====> Epoch: 497 Train Avg loss: 0.02883, Acc: 0.97067, F1: 0.97067#####> Valid Avg loss: 2.86411, Acc:0.33988, F1: 0.33957
====> Epoch: 498 Train Avg loss: 0.02267, Acc: 0.97125, F1: 0.97125#####> Valid Avg loss: 2.95084, Acc:0.35326, F1: 0.35294
====> Epoch: 499 Train Avg loss: 0.03625, Acc: 0.96854, F1: 0.96854#####> Valid Avg loss: 2.44962, Acc:0.31757, F1: 0.31729
====> Epoch: 500 Train Avg loss: 0.02886, Acc: 0.97086, F1: 0.97086#####> Valid Avg loss: 2.59494, Acc:0.36218, F1: 0.36185
#####> Valid Avg loss: 4.39277, Acc:0.25333, F1: 0.25333


$$$$$$> Test it 1: (from train best model) Final Test Avg loss:4.39277, Acc:0.25333, F1:0.25333\n
#####> Valid Avg loss: 1.14319, Acc:0.41429, F1: 0.41429


$$$$$$> Test it 1: (from max acc valid model) Final Test Avg loss:1.14319, Acc:0.41429, F1:0.41429\n
#####> Valid Avg loss: 1.20408, Acc:0.27048, F1: 0.27048


$$$$$$> Test it 1: (from min loss valid model) Final Test Avg loss:1.20408, Acc:0.27048, F1:0.27048\n


	Start execution training validation it 2 

train_dataloader len: 2591
valid_dataloader len: 525
test_dataloader len: 561
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [1]
test performers ids: [2]
train dataset len: 5182, train dataloader len: 2591
valid dataset len: 1050, valid dataloader len: 525
valid dataset len: 1121, test dataloader len: 525
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 2591
valid_dataloader len: 561
test_dataloader len: 525
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 2591
valid dataset len: 1121, valid dataloader len: 561
valid dataset len: 1050, test dataloader len: 561
====> Epoch: 1 Train Avg loss: 0.71423, Acc: 0.51023, F1: 0.51023#####> Valid Avg loss: 0.90957, Acc:0.40589, F1: 0.40553
===> Epoch: 1: Training loss decreased (inf --> 0.71423), Acc: (0.00000 --> 0.51023), F1: (0.00000 --> 0.51023).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.90957), Acc: (0.00000 --> 0.40589), F1: (0.00000 --> 0.40553).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.90957), Acc: (0.00000 --> 0.40589), F1: (0.00000 --> 0.40553).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
====> Epoch: 2 Train Avg loss: 0.58895, Acc: 0.60729, F1: 0.60729#####> Valid Avg loss: 1.03741, Acc:0.36396, F1: 0.36364
===> Epoch: 2: Training loss decreased (0.71423 --> 0.58895), Acc: (0.51023 --> 0.60729), F1: (0.51023 --> 0.60729).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
====> Epoch: 3 Train Avg loss: 0.54809, Acc: 0.62447, F1: 0.62447#####> Valid Avg loss: 0.94666, Acc:0.28635, F1: 0.28699
===> Epoch: 3: Training loss decreased (0.58895 --> 0.54809), Acc: (0.60729 --> 0.62447), F1: (0.60729 --> 0.62447).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
====> Epoch: 4 Train Avg loss: 0.51814, Acc: 0.64107, F1: 0.64107#####> Valid Avg loss: 0.95426, Acc:0.40678, F1: 0.40642
===> Epoch: 4: Training loss decreased (0.54809 --> 0.51814), Acc: (0.62447 --> 0.64107), F1: (0.62447 --> 0.64107).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1

####> Epoch: 4: validation acc increase (0.90957 --> 0.95426), Acc: (0.40589 --> 0.40678), F1: (0.40553 --> 0.40642).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
====> Epoch: 5 Train Avg loss: 0.49247, Acc: 0.65264, F1: 0.65264#####> Valid Avg loss: 1.07759, Acc:0.40678, F1: 0.40642
===> Epoch: 5: Training loss decreased (0.51814 --> 0.49247), Acc: (0.64107 --> 0.65264), F1: (0.64107 --> 0.65264).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
====> Epoch: 6 Train Avg loss: 0.48166, Acc: 0.66075, F1: 0.66075#####> Valid Avg loss: 1.07697, Acc:0.40678, F1: 0.40642
===> Epoch: 6: Training loss decreased (0.49247 --> 0.48166), Acc: (0.65264 --> 0.66075), F1: (0.65264 --> 0.66075).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
====> Epoch: 7 Train Avg loss: 0.47335, Acc: 0.66827, F1: 0.66827#####> Valid Avg loss: 1.07685, Acc:0.40589, F1: 0.40553
===> Epoch: 7: Training loss decreased (0.48166 --> 0.47335), Acc: (0.66075 --> 0.66827), F1: (0.66075 --> 0.66827).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
====> Epoch: 8 Train Avg loss: 0.46196, Acc: 0.67329, F1: 0.67329#####> Valid Avg loss: 0.93461, Acc:0.40410, F1: 0.40374
===> Epoch: 8: Training loss decreased (0.47335 --> 0.46196), Acc: (0.66827 --> 0.67329), F1: (0.66827 --> 0.67329).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
====> Epoch: 9 Train Avg loss: 0.45812, Acc: 0.67522, F1: 0.67522#####> Valid Avg loss: 1.16415, Acc:0.40589, F1: 0.40553
===> Epoch: 9: Training loss decreased (0.46196 --> 0.45812), Acc: (0.67329 --> 0.67522), F1: (0.67329 --> 0.67522).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
====> Epoch: 10 Train Avg loss: 0.44322, Acc: 0.67889, F1: 0.67889#####> Valid Avg loss: 1.05159, Acc:0.40589, F1: 0.40553
===> Epoch: 10: Training loss decreased (0.45812 --> 0.44322), Acc: (0.67522 --> 0.67889), F1: (0.67522 --> 0.67889).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596223721.900615.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596226107.034096.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596226303.67098.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3411
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 3411
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
====> Epoch: 1 Train Avg loss: 0.90586, Acc: 0.43301, F1: 0.43301#####> Valid Avg loss: 1.48604, Acc:0.13601, F1: 0.13590
===> Epoch: 1: Training loss decreased (inf --> 0.90586), Acc: (0.00000 --> 0.43301), F1: (0.00000 --> 0.43301).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.48604), Acc: (0.00000 --> 0.13601), F1: (0.00000 --> 0.13590).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1

####> Epoch: 1: validation acc increase (inf --> 1.48604), Acc: (0.00000 --> 0.13601), F1: (0.00000 --> 0.13590).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 2 Train Avg loss: 0.74316, Acc: 0.56069, F1: 0.56069#####> Valid Avg loss: 1.28475, Acc:0.29940, F1: 0.29915
===> Epoch: 2: Training loss decreased (0.90586 --> 0.74316), Acc: (0.43301 --> 0.56069), F1: (0.43301 --> 0.56069).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1

####> Epoch: 2: validation loss decreased (1.48604 --> 1.28475), Acc: (0.13601 --> 0.29940), F1: (0.13590 --> 0.29915).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1

####> Epoch: 2: validation acc increase (1.48604 --> 1.28475), Acc: (0.13601 --> 0.29940), F1: (0.13590 --> 0.29915).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 3 Train Avg loss: 0.69083, Acc: 0.58912, F1: 0.58912#####> Valid Avg loss: 1.49290, Acc:0.25150, F1: 0.25128
===> Epoch: 3: Training loss decreased (0.74316 --> 0.69083), Acc: (0.56069 --> 0.58912), F1: (0.56069 --> 0.58912).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 4 Train Avg loss: 0.66037, Acc: 0.60818, F1: 0.60818#####> Valid Avg loss: 1.35054, Acc:0.32250, F1: 0.32222
===> Epoch: 4: Training loss decreased (0.69083 --> 0.66037), Acc: (0.58912 --> 0.60818), F1: (0.58912 --> 0.60818).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1

####> Epoch: 4: validation acc increase (1.28475 --> 1.35054), Acc: (0.29940 --> 0.32250), F1: (0.29915 --> 0.32222).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 5 Train Avg loss: 0.63435, Acc: 0.60979, F1: 0.60979#####> Valid Avg loss: 1.39599, Acc:0.27973, F1: 0.27949
===> Epoch: 5: Training loss decreased (0.66037 --> 0.63435), Acc: (0.60818 --> 0.60979), F1: (0.60818 --> 0.60979).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 6 Train Avg loss: 0.61194, Acc: 0.62357, F1: 0.62357#####> Valid Avg loss: 1.36526, Acc:0.34217, F1: 0.34188
===> Epoch: 6: Training loss decreased (0.63435 --> 0.61194), Acc: (0.60979 --> 0.62357), F1: (0.60979 --> 0.62357).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1

####> Epoch: 6: validation acc increase (1.35054 --> 1.36526), Acc: (0.32250 --> 0.34217), F1: (0.32222 --> 0.34188).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 7 Train Avg loss: 0.59988, Acc: 0.63031, F1: 0.63031#####> Valid Avg loss: 1.52805, Acc:0.34388, F1: 0.34359
===> Epoch: 7: Training loss decreased (0.61194 --> 0.59988), Acc: (0.62357 --> 0.63031), F1: (0.62357 --> 0.63031).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1

####> Epoch: 7: validation acc increase (1.36526 --> 1.52805), Acc: (0.34217 --> 0.34388), F1: (0.34188 --> 0.34359).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 8 Train Avg loss: 0.57712, Acc: 0.63794, F1: 0.63794#####> Valid Avg loss: 1.64075, Acc:0.25920, F1: 0.25897
===> Epoch: 8: Training loss decreased (0.59988 --> 0.57712), Acc: (0.63031 --> 0.63794), F1: (0.63031 --> 0.63794).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 9 Train Avg loss: 0.56632, Acc: 0.64468, F1: 0.64468#####> Valid Avg loss: 1.69396, Acc:0.24722, F1: 0.24701
===> Epoch: 9: Training loss decreased (0.57712 --> 0.56632), Acc: (0.63794 --> 0.64468), F1: (0.63794 --> 0.64468).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 10 Train Avg loss: 0.55818, Acc: 0.64732, F1: 0.64732#####> Valid Avg loss: 1.45187, Acc:0.28999, F1: 0.28974
===> Epoch: 10: Training loss decreased (0.56632 --> 0.55818), Acc: (0.64468 --> 0.64732), F1: (0.64468 --> 0.64732).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
====> Epoch: 11 Train Avg loss: 0.55397, Acc: 0.64409, F1: 0.64409#####> Valid Avg loss: 1.45950, Acc:0.35500, F1: 0.35470
===> Epoch: 11: Training loss decreased (0.55818 --> 0.55397), Acc: (0.64732 --> 0.64409), F1: (0.64732 --> 0.64409).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1

####> Epoch: 11: validation acc increase (1.52805 --> 1.45950), Acc: (0.34388 --> 0.35500), F1: (0.34359 --> 0.35470).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596227276.71726.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.75, upper_layer_dropout: 0.75
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596233662.877661.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:20
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 342
valid_dataloader len: 59
test_dataloader len: 59
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 342
valid dataset len: 1169, valid dataloader len: 59
valid dataset len: 1173, test dataloader len: 59
====> Epoch: 1 Train Avg loss: 0.08573, Acc: 0.46936, F1: 0.46944#####> Valid Avg loss: 0.13489, Acc:0.36270, F1: 0.36450
===> Epoch: 1: Training loss decreased (inf --> 0.08573), Acc: (0.00000 --> 0.46936), F1: (0.00000 --> 0.46944).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.13489), Acc: (0.00000 --> 0.36270), F1: (0.00000 --> 0.36450).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.13489), Acc: (0.00000 --> 0.36270), F1: (0.00000 --> 0.36450).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 2 Train Avg loss: 0.06727, Acc: 0.58678, F1: 0.58787#####> Valid Avg loss: 0.15540, Acc:0.27716, F1: 0.27872
===> Epoch: 2: Training loss decreased (0.08573 --> 0.06727), Acc: (0.46936 --> 0.58678), F1: (0.46944 --> 0.58787).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 3 Train Avg loss: 0.06040, Acc: 0.62269, F1: 0.62368#####> Valid Avg loss: 0.15403, Acc:0.28486, F1: 0.28635
===> Epoch: 3: Training loss decreased (0.06727 --> 0.06040), Acc: (0.58678 --> 0.62269), F1: (0.58787 --> 0.62368).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 4 Train Avg loss: 0.05656, Acc: 0.64204, F1: 0.64298#####> Valid Avg loss: 0.16931, Acc:0.30796, F1: 0.30923
===> Epoch: 4: Training loss decreased (0.06040 --> 0.05656), Acc: (0.62269 --> 0.64204), F1: (0.62368 --> 0.64298).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 5 Train Avg loss: 0.05480, Acc: 0.65040, F1: 0.65132#####> Valid Avg loss: 0.18081, Acc:0.20787, F1: 0.20697
===> Epoch: 5: Training loss decreased (0.05656 --> 0.05480), Acc: (0.64204 --> 0.65040), F1: (0.64298 --> 0.65132).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 6 Train Avg loss: 0.05142, Acc: 0.66491, F1: 0.66579#####> Valid Avg loss: 0.14870, Acc:0.33704, F1: 0.33908
===> Epoch: 6: Training loss decreased (0.05480 --> 0.05142), Acc: (0.65040 --> 0.66491), F1: (0.65132 --> 0.66579).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 7 Train Avg loss: 0.05029, Acc: 0.67180, F1: 0.67135#####> Valid Avg loss: 0.16921, Acc:0.39008, F1: 0.39162
===> Epoch: 7: Training loss decreased (0.05142 --> 0.05029), Acc: (0.66491 --> 0.67180), F1: (0.66579 --> 0.67135).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1

####> Epoch: 7: validation acc increase (0.13489 --> 0.16921), Acc: (0.36270 --> 0.39008), F1: (0.36450 --> 0.39162).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 8 Train Avg loss: 0.04794, Acc: 0.68367, F1: 0.68319#####> Valid Avg loss: 0.19085, Acc:0.39008, F1: 0.39162
===> Epoch: 8: Training loss decreased (0.05029 --> 0.04794), Acc: (0.67180 --> 0.68367), F1: (0.67135 --> 0.68319).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 9 Train Avg loss: 0.04650, Acc: 0.69100, F1: 0.68918#####> Valid Avg loss: 0.17301, Acc:0.37468, F1: 0.37637
===> Epoch: 9: Training loss decreased (0.04794 --> 0.04650), Acc: (0.68367 --> 0.69100), F1: (0.68319 --> 0.68918).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 10 Train Avg loss: 0.04512, Acc: 0.70126, F1: 0.70205#####> Valid Avg loss: 0.16440, Acc:0.27203, F1: 0.27053
===> Epoch: 10: Training loss decreased (0.04650 --> 0.04512), Acc: (0.69100 --> 0.70126), F1: (0.68918 --> 0.70205).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 11 Train Avg loss: 0.04406, Acc: 0.70141, F1: 0.70088#####> Valid Avg loss: 0.14855, Acc:0.34474, F1: 0.34567
===> Epoch: 11: Training loss decreased (0.04512 --> 0.04406), Acc: (0.70126 --> 0.70141), F1: (0.70205 --> 0.70088).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 12 Train Avg loss: 0.04382, Acc: 0.70214, F1: 0.70029#####> Valid Avg loss: 0.15436, Acc:0.35415, F1: 0.35499
===> Epoch: 12: Training loss decreased (0.04406 --> 0.04382), Acc: (0.70141 --> 0.70214), F1: (0.70088 --> 0.70029).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 13 Train Avg loss: 0.04135, Acc: 0.71929, F1: 0.71871#####> Valid Avg loss: 0.17230, Acc:0.26861, F1: 0.26714
===> Epoch: 13: Training loss decreased (0.04382 --> 0.04135), Acc: (0.70214 --> 0.71929), F1: (0.70029 --> 0.71871).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 14 Train Avg loss: 0.04194, Acc: 0.71607, F1: 0.71550#####> Valid Avg loss: 0.15965, Acc:0.35586, F1: 0.35669
====> Epoch: 15 Train Avg loss: 0.03971, Acc: 0.72735, F1: 0.72675#####> Valid Avg loss: 0.15337, Acc:0.33875, F1: 0.33974
===> Epoch: 15: Training loss decreased (0.04135 --> 0.03971), Acc: (0.71929 --> 0.72735), F1: (0.71871 --> 0.72675).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 16 Train Avg loss: 0.03879, Acc: 0.73014, F1: 0.72953#####> Valid Avg loss: 0.17083, Acc:0.34046, F1: 0.34143
===> Epoch: 16: Training loss decreased (0.03971 --> 0.03879), Acc: (0.72735 --> 0.73014), F1: (0.72675 --> 0.72953).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 17 Train Avg loss: 0.03725, Acc: 0.73849, F1: 0.73787#####> Valid Avg loss: 0.15838, Acc:0.34645, F1: 0.34633
===> Epoch: 17: Training loss decreased (0.03879 --> 0.03725), Acc: (0.73014 --> 0.73849), F1: (0.72953 --> 0.73787).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 18 Train Avg loss: 0.03607, Acc: 0.75110, F1: 0.75175#####> Valid Avg loss: 0.19026, Acc:0.36270, F1: 0.36347
===> Epoch: 18: Training loss decreased (0.03725 --> 0.03607), Acc: (0.73849 --> 0.75110), F1: (0.73787 --> 0.75175).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 19 Train Avg loss: 0.03526, Acc: 0.75344, F1: 0.75278#####> Valid Avg loss: 0.17407, Acc:0.36955, F1: 0.37024
===> Epoch: 19: Training loss decreased (0.03607 --> 0.03526), Acc: (0.75110 --> 0.75344), F1: (0.75175 --> 0.75278).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 20 Train Avg loss: 0.03382, Acc: 0.75696, F1: 0.75629#####> Valid Avg loss: 0.16451, Acc:0.21300, F1: 0.21412
===> Epoch: 20: Training loss decreased (0.03526 --> 0.03382), Acc: (0.75344 --> 0.75696), F1: (0.75278 --> 0.75629).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 21 Train Avg loss: 0.03323, Acc: 0.76283, F1: 0.76345#####> Valid Avg loss: 0.18353, Acc:0.26176, F1: 0.25932
===> Epoch: 21: Training loss decreased (0.03382 --> 0.03323), Acc: (0.75696 --> 0.76283), F1: (0.75629 --> 0.76345).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 22 Train Avg loss: 0.03139, Acc: 0.77411, F1: 0.77471#####> Valid Avg loss: 0.17820, Acc:0.34731, F1: 0.34821
===> Epoch: 22: Training loss decreased (0.03323 --> 0.03139), Acc: (0.76283 --> 0.77411), F1: (0.76345 --> 0.77471).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 23 Train Avg loss: 0.03047, Acc: 0.78100, F1: 0.78158#####> Valid Avg loss: 0.18370, Acc:0.35500, F1: 0.35584
===> Epoch: 23: Training loss decreased (0.03139 --> 0.03047), Acc: (0.77411 --> 0.78100), F1: (0.77471 --> 0.78158).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 24 Train Avg loss: 0.02902, Acc: 0.79009, F1: 0.79064#####> Valid Avg loss: 0.21326, Acc:0.31394, F1: 0.31309
===> Epoch: 24: Training loss decreased (0.03047 --> 0.02902), Acc: (0.78100 --> 0.79009), F1: (0.78158 --> 0.79064).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 25 Train Avg loss: 0.02864, Acc: 0.78789, F1: 0.78845#####> Valid Avg loss: 0.21635, Acc:0.36784, F1: 0.36855
===> Epoch: 25: Training loss decreased (0.02902 --> 0.02864), Acc: (0.79009 --> 0.78789), F1: (0.79064 --> 0.78845).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 26 Train Avg loss: 0.02723, Acc: 0.80431, F1: 0.80351#####> Valid Avg loss: 0.21159, Acc:0.34474, F1: 0.34567
===> Epoch: 26: Training loss decreased (0.02864 --> 0.02723), Acc: (0.78789 --> 0.80431), F1: (0.78845 --> 0.80351).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 27 Train Avg loss: 0.02752, Acc: 0.79845, F1: 0.79898#####> Valid Avg loss: 0.20947, Acc:0.29940, F1: 0.29972
====> Epoch: 28 Train Avg loss: 0.02512, Acc: 0.81369, F1: 0.81418#####> Valid Avg loss: 0.21139, Acc:0.35158, F1: 0.35245
===> Epoch: 28: Training loss decreased (0.02723 --> 0.02512), Acc: (0.80431 --> 0.81369), F1: (0.80351 --> 0.81418).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 29 Train Avg loss: 0.02404, Acc: 0.82351, F1: 0.82266#####> Valid Avg loss: 0.21870, Acc:0.26518, F1: 0.26478
===> Epoch: 29: Training loss decreased (0.02512 --> 0.02404), Acc: (0.81369 --> 0.82351), F1: (0.81418 --> 0.82266).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 30 Train Avg loss: 0.02342, Acc: 0.82425, F1: 0.82471#####> Valid Avg loss: 0.21544, Acc:0.32849, F1: 0.33060
===> Epoch: 30: Training loss decreased (0.02404 --> 0.02342), Acc: (0.82351 --> 0.82425), F1: (0.82266 --> 0.82471).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 31 Train Avg loss: 0.02083, Acc: 0.84755, F1: 0.84795#####> Valid Avg loss: 0.24372, Acc:0.31565, F1: 0.31478
===> Epoch: 31: Training loss decreased (0.02342 --> 0.02083), Acc: (0.82425 --> 0.84755), F1: (0.82471 --> 0.84795).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 32 Train Avg loss: 0.02039, Acc: 0.84741, F1: 0.84781#####> Valid Avg loss: 0.24384, Acc:0.30453, F1: 0.30687
===> Epoch: 32: Training loss decreased (0.02083 --> 0.02039), Acc: (0.84755 --> 0.84741), F1: (0.84795 --> 0.84781).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
====> Epoch: 33 Train Avg loss: 0.02034, Acc: 0.84667, F1: 0.84576#####> Valid Avg loss: 0.23950, Acc:0.33447, F1: 0.33550
===> Epoch: 33: Training loss decreased (0.02039 --> 0.02034), Acc: (0.84741 --> 0.84667), F1: (0.84781 --> 0.84576).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596233746.11653.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
====> Epoch: 1 Train Avg loss: 0.18038, Acc: 0.43858, F1: 0.43807#####> Valid Avg loss: 0.23678, Acc:0.37211, F1: 0.37227
===> Epoch: 1: Training loss decreased (inf --> 0.18038), Acc: (0.00000 --> 0.43858), F1: (0.00000 --> 0.43807).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.23678), Acc: (0.00000 --> 0.37211), F1: (0.00000 --> 0.37227).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.23678), Acc: (0.00000 --> 0.37211), F1: (0.00000 --> 0.37227).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 2 Train Avg loss: 0.14432, Acc: 0.56919, F1: 0.56852#####> Valid Avg loss: 0.28604, Acc:0.27973, F1: 0.27987
===> Epoch: 2: Training loss decreased (0.18038 --> 0.14432), Acc: (0.43858 --> 0.56919), F1: (0.43807 --> 0.56852).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 3 Train Avg loss: 0.13049, Acc: 0.59850, F1: 0.59898#####> Valid Avg loss: 0.33334, Acc:0.32421, F1: 0.32431
===> Epoch: 3: Training loss decreased (0.14432 --> 0.13049), Acc: (0.56919 --> 0.59850), F1: (0.56852 --> 0.59898).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 4 Train Avg loss: 0.12572, Acc: 0.60921, F1: 0.60849#####> Valid Avg loss: 0.29896, Acc:0.36698, F1: 0.36705
===> Epoch: 4: Training loss decreased (0.13049 --> 0.12572), Acc: (0.59850 --> 0.60921), F1: (0.59898 --> 0.60849).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 5 Train Avg loss: 0.11712, Acc: 0.62929, F1: 0.62972#####> Valid Avg loss: 0.31609, Acc:0.34217, F1: 0.34226
===> Epoch: 5: Training loss decreased (0.12572 --> 0.11712), Acc: (0.60921 --> 0.62929), F1: (0.60849 --> 0.62972).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 6 Train Avg loss: 0.11236, Acc: 0.65084, F1: 0.65124#####> Valid Avg loss: 0.32589, Acc:0.31737, F1: 0.31747
===> Epoch: 6: Training loss decreased (0.11712 --> 0.11236), Acc: (0.62929 --> 0.65084), F1: (0.62972 --> 0.65124).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 7 Train Avg loss: 0.11153, Acc: 0.64277, F1: 0.64261#####> Valid Avg loss: 0.33471, Acc:0.27459, F1: 0.27474
===> Epoch: 7: Training loss decreased (0.11236 --> 0.11153), Acc: (0.65084 --> 0.64277), F1: (0.65124 --> 0.64261).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 8 Train Avg loss: 0.10735, Acc: 0.65523, F1: 0.65564#####> Valid Avg loss: 0.37792, Acc:0.25235, F1: 0.25242
===> Epoch: 8: Training loss decreased (0.11153 --> 0.10735), Acc: (0.64277 --> 0.65523), F1: (0.64261 --> 0.65564).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 9 Train Avg loss: 0.10549, Acc: 0.66139, F1: 0.66061#####> Valid Avg loss: 0.27042, Acc:0.37382, F1: 0.37398
===> Epoch: 9: Training loss decreased (0.10735 --> 0.10549), Acc: (0.65523 --> 0.66139), F1: (0.65564 --> 0.66061).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1

####> Epoch: 9: validation acc increase (0.23678 --> 0.27042), Acc: (0.37211 --> 0.37382), F1: (0.37227 --> 0.37398).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 10 Train Avg loss: 0.10206, Acc: 0.67165, F1: 0.67086#####> Valid Avg loss: 0.31964, Acc:0.34474, F1: 0.34482
===> Epoch: 10: Training loss decreased (0.10549 --> 0.10206), Acc: (0.66139 --> 0.67165), F1: (0.66061 --> 0.67086).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 11 Train Avg loss: 0.09911, Acc: 0.67326, F1: 0.67365#####> Valid Avg loss: 0.33469, Acc:0.31052, F1: 0.31064
===> Epoch: 11: Training loss decreased (0.10206 --> 0.09911), Acc: (0.67165 --> 0.67326), F1: (0.67086 --> 0.67365).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 12 Train Avg loss: 0.09547, Acc: 0.68792, F1: 0.68829#####> Valid Avg loss: 0.30889, Acc:0.31223, F1: 0.31235
===> Epoch: 12: Training loss decreased (0.09911 --> 0.09547), Acc: (0.67326 --> 0.68792), F1: (0.67365 --> 0.68829).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 13 Train Avg loss: 0.09266, Acc: 0.69613, F1: 0.69649#####> Valid Avg loss: 0.28983, Acc:0.36356, F1: 0.36372
===> Epoch: 13: Training loss decreased (0.09547 --> 0.09266), Acc: (0.68792 --> 0.69613), F1: (0.68829 --> 0.69649).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 14 Train Avg loss: 0.09152, Acc: 0.69393, F1: 0.69429#####> Valid Avg loss: 0.32691, Acc:0.38152, F1: 0.38167
===> Epoch: 14: Training loss decreased (0.09266 --> 0.09152), Acc: (0.69613 --> 0.69393), F1: (0.69649 --> 0.69429).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1

####> Epoch: 14: validation acc increase (0.27042 --> 0.32691), Acc: (0.37382 --> 0.38152), F1: (0.37398 --> 0.38167).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 15 Train Avg loss: 0.08957, Acc: 0.70243, F1: 0.70220#####> Valid Avg loss: 0.32885, Acc:0.35500, F1: 0.35518
===> Epoch: 15: Training loss decreased (0.09152 --> 0.08957), Acc: (0.69393 --> 0.70243), F1: (0.69429 --> 0.70220).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 16 Train Avg loss: 0.08666, Acc: 0.71006, F1: 0.70981#####> Valid Avg loss: 0.34983, Acc:0.38409, F1: 0.38424
===> Epoch: 16: Training loss decreased (0.08957 --> 0.08666), Acc: (0.70243 --> 0.71006), F1: (0.70220 --> 0.70981).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1

####> Epoch: 16: validation acc increase (0.32691 --> 0.34983), Acc: (0.38152 --> 0.38409), F1: (0.38167 --> 0.38424).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 17 Train Avg loss: 0.08571, Acc: 0.71680, F1: 0.71713#####> Valid Avg loss: 0.35779, Acc:0.31651, F1: 0.31662
===> Epoch: 17: Training loss decreased (0.08666 --> 0.08571), Acc: (0.71006 --> 0.71680), F1: (0.70981 --> 0.71713).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 18 Train Avg loss: 0.08321, Acc: 0.72090, F1: 0.72123#####> Valid Avg loss: 0.33286, Acc:0.38152, F1: 0.38167
===> Epoch: 18: Training loss decreased (0.08571 --> 0.08321), Acc: (0.71680 --> 0.72090), F1: (0.71713 --> 0.72123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 19 Train Avg loss: 0.08169, Acc: 0.72794, F1: 0.72826#####> Valid Avg loss: 0.36136, Acc:0.24209, F1: 0.24198
===> Epoch: 19: Training loss decreased (0.08321 --> 0.08169), Acc: (0.72090 --> 0.72794), F1: (0.72123 --> 0.72826).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 20 Train Avg loss: 0.07919, Acc: 0.72867, F1: 0.72840#####> Valid Avg loss: 0.35433, Acc:0.36014, F1: 0.36021
===> Epoch: 20: Training loss decreased (0.08169 --> 0.07919), Acc: (0.72794 --> 0.72867), F1: (0.72826 --> 0.72840).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 21 Train Avg loss: 0.07646, Acc: 0.73644, F1: 0.73675#####> Valid Avg loss: 0.37949, Acc:0.35586, F1: 0.35594
===> Epoch: 21: Training loss decreased (0.07919 --> 0.07646), Acc: (0.72867 --> 0.73644), F1: (0.72840 --> 0.73675).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 22 Train Avg loss: 0.07581, Acc: 0.73410, F1: 0.73441#####> Valid Avg loss: 0.34912, Acc:0.29085, F1: 0.29098
===> Epoch: 22: Training loss decreased (0.07646 --> 0.07581), Acc: (0.73644 --> 0.73410), F1: (0.73675 --> 0.73441).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 23 Train Avg loss: 0.07349, Acc: 0.74787, F1: 0.74817#####> Valid Avg loss: 0.37081, Acc:0.29598, F1: 0.29611
===> Epoch: 23: Training loss decreased (0.07581 --> 0.07349), Acc: (0.73410 --> 0.74787), F1: (0.73441 --> 0.74817).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 24 Train Avg loss: 0.07079, Acc: 0.75535, F1: 0.75505#####> Valid Avg loss: 0.41480, Acc:0.30197, F1: 0.30209
===> Epoch: 24: Training loss decreased (0.07349 --> 0.07079), Acc: (0.74787 --> 0.75535), F1: (0.74817 --> 0.75505).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 25 Train Avg loss: 0.07007, Acc: 0.75945, F1: 0.75974#####> Valid Avg loss: 0.39906, Acc:0.31138, F1: 0.31130
===> Epoch: 25: Training loss decreased (0.07079 --> 0.07007), Acc: (0.75535 --> 0.75945), F1: (0.75505 --> 0.75974).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 26 Train Avg loss: 0.06640, Acc: 0.76605, F1: 0.76633#####> Valid Avg loss: 0.39650, Acc:0.34902, F1: 0.34910
===> Epoch: 26: Training loss decreased (0.07007 --> 0.06640), Acc: (0.75945 --> 0.76605), F1: (0.75974 --> 0.76633).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 27 Train Avg loss: 0.06404, Acc: 0.77235, F1: 0.77262#####> Valid Avg loss: 0.42704, Acc:0.30026, F1: 0.30038
===> Epoch: 27: Training loss decreased (0.06640 --> 0.06404), Acc: (0.76605 --> 0.77235), F1: (0.76633 --> 0.77262).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 28 Train Avg loss: 0.06177, Acc: 0.78452, F1: 0.78419#####> Valid Avg loss: 0.38955, Acc:0.31223, F1: 0.31235
===> Epoch: 28: Training loss decreased (0.06404 --> 0.06177), Acc: (0.77235 --> 0.78452), F1: (0.77262 --> 0.78419).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 29 Train Avg loss: 0.06134, Acc: 0.77910, F1: 0.77877#####> Valid Avg loss: 0.41878, Acc:0.36099, F1: 0.36106
===> Epoch: 29: Training loss decreased (0.06177 --> 0.06134), Acc: (0.78452 --> 0.77910), F1: (0.78419 --> 0.77877).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 30 Train Avg loss: 0.05729, Acc: 0.79639, F1: 0.79663#####> Valid Avg loss: 0.42733, Acc:0.30282, F1: 0.30294
===> Epoch: 30: Training loss decreased (0.06134 --> 0.05729), Acc: (0.77910 --> 0.79639), F1: (0.77877 --> 0.79663).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 31 Train Avg loss: 0.05463, Acc: 0.80284, F1: 0.80307#####> Valid Avg loss: 0.42811, Acc:0.25150, F1: 0.25128
===> Epoch: 31: Training loss decreased (0.05729 --> 0.05463), Acc: (0.79639 --> 0.80284), F1: (0.79663 --> 0.80307).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 32 Train Avg loss: 0.05248, Acc: 0.80827, F1: 0.80849#####> Valid Avg loss: 0.44970, Acc:0.27887, F1: 0.27882
===> Epoch: 32: Training loss decreased (0.05463 --> 0.05248), Acc: (0.80284 --> 0.80827), F1: (0.80307 --> 0.80849).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 33 Train Avg loss: 0.04969, Acc: 0.81926, F1: 0.81889#####> Valid Avg loss: 0.41854, Acc:0.34902, F1: 0.34910
===> Epoch: 33: Training loss decreased (0.05248 --> 0.04969), Acc: (0.80827 --> 0.81926), F1: (0.80849 --> 0.81889).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 34 Train Avg loss: 0.04509, Acc: 0.83407, F1: 0.83426#####> Valid Avg loss: 0.49995, Acc:0.30368, F1: 0.30380
===> Epoch: 34: Training loss decreased (0.04969 --> 0.04509), Acc: (0.81926 --> 0.83407), F1: (0.81889 --> 0.83426).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 35 Train Avg loss: 0.04490, Acc: 0.83539, F1: 0.83558#####> Valid Avg loss: 0.45940, Acc:0.33191, F1: 0.33191
===> Epoch: 35: Training loss decreased (0.04509 --> 0.04490), Acc: (0.83407 --> 0.83539), F1: (0.83426 --> 0.83558).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 36 Train Avg loss: 0.04093, Acc: 0.84565, F1: 0.84583#####> Valid Avg loss: 0.45914, Acc:0.24808, F1: 0.24805
===> Epoch: 36: Training loss decreased (0.04490 --> 0.04093), Acc: (0.83539 --> 0.84565), F1: (0.83558 --> 0.84583).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 37 Train Avg loss: 0.03837, Acc: 0.85517, F1: 0.85534#####> Valid Avg loss: 0.49211, Acc:0.24123, F1: 0.24112
===> Epoch: 37: Training loss decreased (0.04093 --> 0.03837), Acc: (0.84565 --> 0.85517), F1: (0.84583 --> 0.85534).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 38 Train Avg loss: 0.03786, Acc: 0.85561, F1: 0.85578#####> Valid Avg loss: 0.48097, Acc:0.28144, F1: 0.28148
===> Epoch: 38: Training loss decreased (0.03837 --> 0.03786), Acc: (0.85517 --> 0.85561), F1: (0.85534 --> 0.85578).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 39 Train Avg loss: 0.03374, Acc: 0.87438, F1: 0.87452#####> Valid Avg loss: 0.50356, Acc:0.28315, F1: 0.28310
===> Epoch: 39: Training loss decreased (0.03786 --> 0.03374), Acc: (0.85561 --> 0.87438), F1: (0.85578 --> 0.87452).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 40 Train Avg loss: 0.03300, Acc: 0.87203, F1: 0.87218#####> Valid Avg loss: 0.49706, Acc:0.26091, F1: 0.26087
===> Epoch: 40: Training loss decreased (0.03374 --> 0.03300), Acc: (0.87438 --> 0.87203), F1: (0.87452 --> 0.87218).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 41 Train Avg loss: 0.03048, Acc: 0.88141, F1: 0.88155#####> Valid Avg loss: 0.49555, Acc:0.30368, F1: 0.30370
===> Epoch: 41: Training loss decreased (0.03300 --> 0.03048), Acc: (0.87203 --> 0.88141), F1: (0.87218 --> 0.88155).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 42 Train Avg loss: 0.02862, Acc: 0.89490, F1: 0.89502#####> Valid Avg loss: 0.53049, Acc:0.26861, F1: 0.26857
===> Epoch: 42: Training loss decreased (0.03048 --> 0.02862), Acc: (0.88141 --> 0.89490), F1: (0.88155 --> 0.89502).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 43 Train Avg loss: 0.02650, Acc: 0.89783, F1: 0.89736#####> Valid Avg loss: 0.57995, Acc:0.29940, F1: 0.29953
===> Epoch: 43: Training loss decreased (0.02862 --> 0.02650), Acc: (0.89490 --> 0.89783), F1: (0.89502 --> 0.89736).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 44 Train Avg loss: 0.02273, Acc: 0.91014, F1: 0.91025#####> Valid Avg loss: 0.64516, Acc:0.33961, F1: 0.33970
===> Epoch: 44: Training loss decreased (0.02650 --> 0.02273), Acc: (0.89783 --> 0.91014), F1: (0.89736 --> 0.91025).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 45 Train Avg loss: 0.02354, Acc: 0.91264, F1: 0.91274#####> Valid Avg loss: 0.57441, Acc:0.29769, F1: 0.29744
====> Epoch: 46 Train Avg loss: 0.01999, Acc: 0.91923, F1: 0.91933#####> Valid Avg loss: 0.65613, Acc:0.31309, F1: 0.31311
===> Epoch: 46: Training loss decreased (0.02273 --> 0.01999), Acc: (0.91014 --> 0.91923), F1: (0.91025 --> 0.91933).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 47 Train Avg loss: 0.02242, Acc: 0.91366, F1: 0.91376#####> Valid Avg loss: 0.65128, Acc:0.30026, F1: 0.30019
====> Epoch: 48 Train Avg loss: 0.01929, Acc: 0.92187, F1: 0.92196#####> Valid Avg loss: 0.68394, Acc:0.30796, F1: 0.30798
===> Epoch: 48: Training loss decreased (0.01999 --> 0.01929), Acc: (0.91923 --> 0.92187), F1: (0.91933 --> 0.92196).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 49 Train Avg loss: 0.01774, Acc: 0.93081, F1: 0.93089#####> Valid Avg loss: 0.64189, Acc:0.28315, F1: 0.28310
===> Epoch: 49: Training loss decreased (0.01929 --> 0.01774), Acc: (0.92187 --> 0.93081), F1: (0.92196 --> 0.93089).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 50 Train Avg loss: 0.01491, Acc: 0.93917, F1: 0.93924#####> Valid Avg loss: 0.70829, Acc:0.29170, F1: 0.29174
===> Epoch: 50: Training loss decreased (0.01774 --> 0.01491), Acc: (0.93081 --> 0.93917), F1: (0.93089 --> 0.93924).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 51 Train Avg loss: 0.01784, Acc: 0.92817, F1: 0.92826#####> Valid Avg loss: 0.61261, Acc:0.28571, F1: 0.28575
====> Epoch: 52 Train Avg loss: 0.01509, Acc: 0.94122, F1: 0.94070#####> Valid Avg loss: 0.65909, Acc:0.28657, F1: 0.28651
====> Epoch: 53 Train Avg loss: 0.01357, Acc: 0.94474, F1: 0.94480#####> Valid Avg loss: 0.74417, Acc:0.30796, F1: 0.30807
===> Epoch: 53: Training loss decreased (0.01491 --> 0.01357), Acc: (0.93917 --> 0.94474), F1: (0.93924 --> 0.94480).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 54 Train Avg loss: 0.01180, Acc: 0.94972, F1: 0.94978#####> Valid Avg loss: 0.71804, Acc:0.28486, F1: 0.28471
===> Epoch: 54: Training loss decreased (0.01357 --> 0.01180), Acc: (0.94474 --> 0.94972), F1: (0.94480 --> 0.94978).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 55 Train Avg loss: 0.01282, Acc: 0.94547, F1: 0.94495#####> Valid Avg loss: 0.71863, Acc:0.33362, F1: 0.33371
====> Epoch: 56 Train Avg loss: 0.01258, Acc: 0.95016, F1: 0.95022#####> Valid Avg loss: 0.71535, Acc:0.31908, F1: 0.31899
====> Epoch: 57 Train Avg loss: 0.01060, Acc: 0.95412, F1: 0.95417#####> Valid Avg loss: 0.80036, Acc:0.26176, F1: 0.26182
===> Epoch: 57: Training loss decreased (0.01180 --> 0.01060), Acc: (0.94972 --> 0.95412), F1: (0.94978 --> 0.95417).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 58 Train Avg loss: 0.01093, Acc: 0.95852, F1: 0.95857#####> Valid Avg loss: 0.79218, Acc:0.32079, F1: 0.32080
====> Epoch: 59 Train Avg loss: 0.00940, Acc: 0.96174, F1: 0.96179#####> Valid Avg loss: 0.73494, Acc:0.29855, F1: 0.29848
===> Epoch: 59: Training loss decreased (0.01060 --> 0.00940), Acc: (0.95412 --> 0.96174), F1: (0.95417 --> 0.96179).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 60 Train Avg loss: 0.00936, Acc: 0.95881, F1: 0.95886#####> Valid Avg loss: 0.84206, Acc:0.29598, F1: 0.29582
===> Epoch: 60: Training loss decreased (0.00940 --> 0.00936), Acc: (0.96174 --> 0.95881), F1: (0.96179 --> 0.95886).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 61 Train Avg loss: 0.00897, Acc: 0.96203, F1: 0.96091#####> Valid Avg loss: 0.86503, Acc:0.30111, F1: 0.30104
===> Epoch: 61: Training loss decreased (0.00936 --> 0.00897), Acc: (0.95881 --> 0.96203), F1: (0.95886 --> 0.96091).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 62 Train Avg loss: 0.00899, Acc: 0.96306, F1: 0.96310#####> Valid Avg loss: 0.81958, Acc:0.32592, F1: 0.32593
====> Epoch: 63 Train Avg loss: 0.00633, Acc: 0.97112, F1: 0.97057#####> Valid Avg loss: 0.91146, Acc:0.30881, F1: 0.30883
===> Epoch: 63: Training loss decreased (0.00897 --> 0.00633), Acc: (0.96203 --> 0.97112), F1: (0.96091 --> 0.97057).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 64 Train Avg loss: 0.00818, Acc: 0.96497, F1: 0.96501#####> Valid Avg loss: 0.88429, Acc:0.30453, F1: 0.30465
====> Epoch: 65 Train Avg loss: 0.00838, Acc: 0.96306, F1: 0.96310#####> Valid Avg loss: 0.82766, Acc:0.27288, F1: 0.27303
====> Epoch: 66 Train Avg loss: 0.00709, Acc: 0.96804, F1: 0.96808#####> Valid Avg loss: 0.79048, Acc:0.30710, F1: 0.30703
====> Epoch: 67 Train Avg loss: 0.00558, Acc: 0.97142, F1: 0.97086#####> Valid Avg loss: 0.85953, Acc:0.31908, F1: 0.31909
===> Epoch: 67: Training loss decreased (0.00633 --> 0.00558), Acc: (0.97112 --> 0.97142), F1: (0.97057 --> 0.97086).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 68 Train Avg loss: 0.00667, Acc: 0.96775, F1: 0.96779#####> Valid Avg loss: 0.83523, Acc:0.32164, F1: 0.32165
====> Epoch: 69 Train Avg loss: 0.00641, Acc: 0.96907, F1: 0.96852#####> Valid Avg loss: 0.76684, Acc:0.31822, F1: 0.31804
====> Epoch: 70 Train Avg loss: 0.00540, Acc: 0.97215, F1: 0.97218#####> Valid Avg loss: 0.81851, Acc:0.34987, F1: 0.34986
===> Epoch: 70: Training loss decreased (0.00558 --> 0.00540), Acc: (0.97142 --> 0.97215), F1: (0.97086 --> 0.97218).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 71 Train Avg loss: 0.00531, Acc: 0.97171, F1: 0.97174#####> Valid Avg loss: 0.84710, Acc:0.31394, F1: 0.31396
===> Epoch: 71: Training loss decreased (0.00540 --> 0.00531), Acc: (0.97215 --> 0.97171), F1: (0.97218 --> 0.97174).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 72 Train Avg loss: 0.00543, Acc: 0.97288, F1: 0.97291#####> Valid Avg loss: 0.83445, Acc:0.29683, F1: 0.29677
====> Epoch: 73 Train Avg loss: 0.00448, Acc: 0.97435, F1: 0.97438#####> Valid Avg loss: 0.84739, Acc:0.33704, F1: 0.33704
===> Epoch: 73: Training loss decreased (0.00531 --> 0.00448), Acc: (0.97171 --> 0.97435), F1: (0.97174 --> 0.97438).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 74 Train Avg loss: 0.00456, Acc: 0.97200, F1: 0.97204#####> Valid Avg loss: 0.86789, Acc:0.31480, F1: 0.31481
====> Epoch: 75 Train Avg loss: 0.00451, Acc: 0.97420, F1: 0.97423#####> Valid Avg loss: 0.82788, Acc:0.28914, F1: 0.28908
====> Epoch: 76 Train Avg loss: 0.00453, Acc: 0.97552, F1: 0.97555#####> Valid Avg loss: 0.87495, Acc:0.32763, F1: 0.32764
====> Epoch: 77 Train Avg loss: 0.00432, Acc: 0.97523, F1: 0.97526#####> Valid Avg loss: 0.93244, Acc:0.33618, F1: 0.33618
===> Epoch: 77: Training loss decreased (0.00448 --> 0.00432), Acc: (0.97435 --> 0.97523), F1: (0.97438 --> 0.97526).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 78 Train Avg loss: 0.00405, Acc: 0.97552, F1: 0.97555#####> Valid Avg loss: 0.92119, Acc:0.29170, F1: 0.29174
===> Epoch: 78: Training loss decreased (0.00432 --> 0.00405), Acc: (0.97523 --> 0.97552), F1: (0.97526 --> 0.97555).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 79 Train Avg loss: 0.00404, Acc: 0.97537, F1: 0.97540#####> Valid Avg loss: 0.88612, Acc:0.32164, F1: 0.32165
===> Epoch: 79: Training loss decreased (0.00405 --> 0.00404), Acc: (0.97552 --> 0.97537), F1: (0.97555 --> 0.97540).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 80 Train Avg loss: 0.00402, Acc: 0.97611, F1: 0.97613#####> Valid Avg loss: 0.93027, Acc:0.28914, F1: 0.28917
===> Epoch: 80: Training loss decreased (0.00404 --> 0.00402), Acc: (0.97537 --> 0.97611), F1: (0.97540 --> 0.97613).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 81 Train Avg loss: 0.00366, Acc: 0.97684, F1: 0.97687#####> Valid Avg loss: 0.92165, Acc:0.30539, F1: 0.30541
===> Epoch: 81: Training loss decreased (0.00402 --> 0.00366), Acc: (0.97611 --> 0.97684), F1: (0.97613 --> 0.97687).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 82 Train Avg loss: 0.00367, Acc: 0.97728, F1: 0.97672#####> Valid Avg loss: 0.91528, Acc:0.28400, F1: 0.28405
====> Epoch: 83 Train Avg loss: 0.00373, Acc: 0.97611, F1: 0.97613#####> Valid Avg loss: 0.93430, Acc:0.28999, F1: 0.29012
====> Epoch: 84 Train Avg loss: 0.00364, Acc: 0.97757, F1: 0.97760#####> Valid Avg loss: 0.90662, Acc:0.31908, F1: 0.31909
===> Epoch: 84: Training loss decreased (0.00366 --> 0.00364), Acc: (0.97684 --> 0.97757), F1: (0.97687 --> 0.97760).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 85 Train Avg loss: 0.00350, Acc: 0.97581, F1: 0.97526#####> Valid Avg loss: 0.97397, Acc:0.31223, F1: 0.31225
===> Epoch: 85: Training loss decreased (0.00364 --> 0.00350), Acc: (0.97757 --> 0.97581), F1: (0.97760 --> 0.97526).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 86 Train Avg loss: 0.00352, Acc: 0.97669, F1: 0.97672#####> Valid Avg loss: 0.91147, Acc:0.30796, F1: 0.30798
====> Epoch: 87 Train Avg loss: 0.00315, Acc: 0.97904, F1: 0.97906#####> Valid Avg loss: 0.95413, Acc:0.29940, F1: 0.29943
===> Epoch: 87: Training loss decreased (0.00350 --> 0.00315), Acc: (0.97581 --> 0.97904), F1: (0.97526 --> 0.97906).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 88 Train Avg loss: 0.00330, Acc: 0.97669, F1: 0.97672#####> Valid Avg loss: 0.91031, Acc:0.30282, F1: 0.30285
====> Epoch: 89 Train Avg loss: 0.00323, Acc: 0.97728, F1: 0.97731#####> Valid Avg loss: 0.96830, Acc:0.30111, F1: 0.30114
====> Epoch: 90 Train Avg loss: 0.00322, Acc: 0.97948, F1: 0.97892#####> Valid Avg loss: 0.94031, Acc:0.30026, F1: 0.30028
====> Epoch: 91 Train Avg loss: 0.00325, Acc: 0.97713, F1: 0.97716#####> Valid Avg loss: 0.88044, Acc:0.29855, F1: 0.29858
====> Epoch: 92 Train Avg loss: 0.00318, Acc: 0.97699, F1: 0.97701#####> Valid Avg loss: 0.92279, Acc:0.30111, F1: 0.30114
====> Epoch: 93 Train Avg loss: 0.00311, Acc: 0.97831, F1: 0.97833#####> Valid Avg loss: 0.92803, Acc:0.30197, F1: 0.30199
===> Epoch: 93: Training loss decreased (0.00315 --> 0.00311), Acc: (0.97904 --> 0.97831), F1: (0.97906 --> 0.97833).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 94 Train Avg loss: 0.00321, Acc: 0.97977, F1: 0.97980#####> Valid Avg loss: 0.87118, Acc:0.30967, F1: 0.30969
====> Epoch: 95 Train Avg loss: 0.00312, Acc: 0.97875, F1: 0.97877#####> Valid Avg loss: 0.95696, Acc:0.31480, F1: 0.31481
====> Epoch: 96 Train Avg loss: 0.00301, Acc: 0.98080, F1: 0.98082#####> Valid Avg loss: 0.90386, Acc:0.30796, F1: 0.30798
===> Epoch: 96: Training loss decreased (0.00311 --> 0.00301), Acc: (0.97831 --> 0.98080), F1: (0.97833 --> 0.98082).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 97 Train Avg loss: 0.00303, Acc: 0.97904, F1: 0.97906#####> Valid Avg loss: 0.95001, Acc:0.30881, F1: 0.30883
====> Epoch: 98 Train Avg loss: 0.00301, Acc: 0.97889, F1: 0.97892#####> Valid Avg loss: 0.91332, Acc:0.31052, F1: 0.31054
===> Epoch: 98: Training loss decreased (0.00301 --> 0.00301), Acc: (0.98080 --> 0.97889), F1: (0.98082 --> 0.97892).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 99 Train Avg loss: 0.00307, Acc: 0.98256, F1: 0.98258#####> Valid Avg loss: 0.92473, Acc:0.30453, F1: 0.30456
====> Epoch: 100 Train Avg loss: 0.13236, Acc: 0.61712, F1: 0.61757#####> Valid Avg loss: 0.28672, Acc:0.34303, F1: 0.34311
====> Epoch: 101 Train Avg loss: 0.09434, Acc: 0.68484, F1: 0.68521#####> Valid Avg loss: 0.35337, Acc:0.31309, F1: 0.31301
====> Epoch: 102 Train Avg loss: 0.06830, Acc: 0.76107, F1: 0.76076#####> Valid Avg loss: 0.40352, Acc:0.29940, F1: 0.29915
====> Epoch: 103 Train Avg loss: 0.05163, Acc: 0.81516, F1: 0.81479#####> Valid Avg loss: 0.52731, Acc:0.34987, F1: 0.35005
====> Epoch: 104 Train Avg loss: 0.04680, Acc: 0.83011, F1: 0.82972#####> Valid Avg loss: 0.45539, Acc:0.30026, F1: 0.30028
====> Epoch: 105 Train Avg loss: 0.04070, Acc: 0.85063, F1: 0.85081#####> Valid Avg loss: 0.49172, Acc:0.24380, F1: 0.24387
====> Epoch: 106 Train Avg loss: 0.03774, Acc: 0.86162, F1: 0.86179#####> Valid Avg loss: 0.52945, Acc:0.28657, F1: 0.28670
====> Epoch: 107 Train Avg loss: 0.03427, Acc: 0.87790, F1: 0.87804#####> Valid Avg loss: 0.50039, Acc:0.28657, F1: 0.28642
====> Epoch: 108 Train Avg loss: 0.03163, Acc: 0.88434, F1: 0.88448#####> Valid Avg loss: 0.60407, Acc:0.30967, F1: 0.30978
====> Epoch: 109 Train Avg loss: 0.03017, Acc: 0.88977, F1: 0.88990#####> Valid Avg loss: 0.57764, Acc:0.33961, F1: 0.33979
====> Epoch: 110 Train Avg loss: 0.03152, Acc: 0.88434, F1: 0.88331#####> Valid Avg loss: 0.59585, Acc:0.24294, F1: 0.24283
====> Epoch: 111 Train Avg loss: 0.03087, Acc: 0.88552, F1: 0.88565#####> Valid Avg loss: 0.59282, Acc:0.23353, F1: 0.23343
====> Epoch: 112 Train Avg loss: 0.02688, Acc: 0.90164, F1: 0.90117#####> Valid Avg loss: 0.54723, Acc:0.29940, F1: 0.29943
====> Epoch: 113 Train Avg loss: 0.02757, Acc: 0.89680, F1: 0.89693#####> Valid Avg loss: 0.62334, Acc:0.31908, F1: 0.31918
====> Epoch: 114 Train Avg loss: 0.02656, Acc: 0.89783, F1: 0.89795#####> Valid Avg loss: 0.53665, Acc:0.31737, F1: 0.31747
====> Epoch: 115 Train Avg loss: 0.02946, Acc: 0.88918, F1: 0.88931#####> Valid Avg loss: 0.55296, Acc:0.34987, F1: 0.34995
====> Epoch: 116 Train Avg loss: 0.02673, Acc: 0.90106, F1: 0.90117#####> Valid Avg loss: 0.55297, Acc:0.30453, F1: 0.30446
====> Epoch: 117 Train Avg loss: 0.02094, Acc: 0.92231, F1: 0.92240#####> Valid Avg loss: 0.63765, Acc:0.32763, F1: 0.32764
====> Epoch: 118 Train Avg loss: 0.02577, Acc: 0.90179, F1: 0.90190#####> Valid Avg loss: 0.62488, Acc:0.32678, F1: 0.32688
====> Epoch: 119 Train Avg loss: 0.02181, Acc: 0.91865, F1: 0.91816#####> Valid Avg loss: 0.59023, Acc:0.26176, F1: 0.26173
====> Epoch: 120 Train Avg loss: 0.02653, Acc: 0.90106, F1: 0.90117#####> Valid Avg loss: 0.54808, Acc:0.26005, F1: 0.26011
====> Epoch: 121 Train Avg loss: 0.02528, Acc: 0.90413, F1: 0.90425#####> Valid Avg loss: 0.65270, Acc:0.32934, F1: 0.32934
====> Epoch: 122 Train Avg loss: 0.02096, Acc: 0.92319, F1: 0.92328#####> Valid Avg loss: 0.55617, Acc:0.27117, F1: 0.27132
====> Epoch: 123 Train Avg loss: 0.02337, Acc: 0.91029, F1: 0.91040#####> Valid Avg loss: 0.67276, Acc:0.31908, F1: 0.31909
====> Epoch: 124 Train Avg loss: 0.02217, Acc: 0.92246, F1: 0.92255#####> Valid Avg loss: 0.58352, Acc:0.30967, F1: 0.30969
====> Epoch: 125 Train Avg loss: 0.02150, Acc: 0.91909, F1: 0.91918#####> Valid Avg loss: 0.52716, Acc:0.27288, F1: 0.27284
====> Epoch: 126 Train Avg loss: 0.02037, Acc: 0.92671, F1: 0.92679#####> Valid Avg loss: 0.53376, Acc:0.30624, F1: 0.30646
====> Epoch: 127 Train Avg loss: 0.02078, Acc: 0.92436, F1: 0.92445#####> Valid Avg loss: 0.60136, Acc:0.27203, F1: 0.27217
====> Epoch: 128 Train Avg loss: 0.01971, Acc: 0.92744, F1: 0.92753#####> Valid Avg loss: 0.60130, Acc:0.30111, F1: 0.30133
====> Epoch: 129 Train Avg loss: 0.02055, Acc: 0.92070, F1: 0.92079#####> Valid Avg loss: 0.62273, Acc:0.29512, F1: 0.29525
====> Epoch: 130 Train Avg loss: 0.01894, Acc: 0.92656, F1: 0.92665#####> Valid Avg loss: 0.61728, Acc:0.26518, F1: 0.26515
====> Epoch: 131 Train Avg loss: 0.01985, Acc: 0.92378, F1: 0.92387#####> Valid Avg loss: 0.60762, Acc:0.35928, F1: 0.35945
====> Epoch: 132 Train Avg loss: 0.02050, Acc: 0.92334, F1: 0.92284#####> Valid Avg loss: 0.58556, Acc:0.30624, F1: 0.30646
====> Epoch: 133 Train Avg loss: 0.01624, Acc: 0.94122, F1: 0.94129#####> Valid Avg loss: 0.65295, Acc:0.31052, F1: 0.31073
====> Epoch: 134 Train Avg loss: 0.01967, Acc: 0.92671, F1: 0.92679#####> Valid Avg loss: 0.60151, Acc:0.28486, F1: 0.28481
====> Epoch: 135 Train Avg loss: 0.01786, Acc: 0.93081, F1: 0.93089#####> Valid Avg loss: 0.59783, Acc:0.31822, F1: 0.31833
====> Epoch: 136 Train Avg loss: 0.01859, Acc: 0.93067, F1: 0.93075#####> Valid Avg loss: 0.58878, Acc:0.34559, F1: 0.34577
====> Epoch: 137 Train Avg loss: 0.02070, Acc: 0.92524, F1: 0.92533#####> Valid Avg loss: 0.58132, Acc:0.32849, F1: 0.32858
====> Epoch: 138 Train Avg loss: 0.01634, Acc: 0.93624, F1: 0.93631#####> Valid Avg loss: 0.64742, Acc:0.31394, F1: 0.31406
====> Epoch: 139 Train Avg loss: 0.01687, Acc: 0.93492, F1: 0.93499#####> Valid Avg loss: 0.59170, Acc:0.29341, F1: 0.29354
====> Epoch: 140 Train Avg loss: 0.01774, Acc: 0.92759, F1: 0.92767#####> Valid Avg loss: 0.61135, Acc:0.34645, F1: 0.34663
====> Epoch: 141 Train Avg loss: 0.01303, Acc: 0.94767, F1: 0.94714#####> Valid Avg loss: 0.66905, Acc:0.31223, F1: 0.31225
====> Epoch: 142 Train Avg loss: 0.01702, Acc: 0.93638, F1: 0.93646#####> Valid Avg loss: 0.62826, Acc:0.24209, F1: 0.24207
====> Epoch: 143 Train Avg loss: 0.01611, Acc: 0.93902, F1: 0.93909#####> Valid Avg loss: 0.65615, Acc:0.33533, F1: 0.33542
====> Epoch: 144 Train Avg loss: 0.01404, Acc: 0.94635, F1: 0.94641#####> Valid Avg loss: 0.60305, Acc:0.31993, F1: 0.31994
====> Epoch: 145 Train Avg loss: 0.01734, Acc: 0.93550, F1: 0.93558#####> Valid Avg loss: 0.64087, Acc:0.28657, F1: 0.28651
====> Epoch: 146 Train Avg loss: 0.01578, Acc: 0.93990, F1: 0.93997#####> Valid Avg loss: 0.52165, Acc:0.30967, F1: 0.30978
====> Epoch: 147 Train Avg loss: 0.01349, Acc: 0.94518, F1: 0.94524#####> Valid Avg loss: 0.64594, Acc:0.31223, F1: 0.31235
====> Epoch: 148 Train Avg loss: 0.01400, Acc: 0.94738, F1: 0.94744#####> Valid Avg loss: 0.55708, Acc:0.27288, F1: 0.27312
====> Epoch: 149 Train Avg loss: 0.01637, Acc: 0.93712, F1: 0.93660#####> Valid Avg loss: 0.56654, Acc:0.32506, F1: 0.32526
====> Epoch: 150 Train Avg loss: 0.01316, Acc: 0.94870, F1: 0.94876#####> Valid Avg loss: 0.63459, Acc:0.26775, F1: 0.26781
====> Epoch: 151 Train Avg loss: 0.01413, Acc: 0.94488, F1: 0.94495#####> Valid Avg loss: 0.58414, Acc:0.31394, F1: 0.31406
====> Epoch: 152 Train Avg loss: 0.01160, Acc: 0.95397, F1: 0.95403#####> Valid Avg loss: 0.66792, Acc:0.29512, F1: 0.29525
====> Epoch: 153 Train Avg loss: 0.01382, Acc: 0.94694, F1: 0.94700#####> Valid Avg loss: 0.67496, Acc:0.30881, F1: 0.30874
====> Epoch: 154 Train Avg loss: 0.01114, Acc: 0.95192, F1: 0.95198#####> Valid Avg loss: 0.65650, Acc:0.28144, F1: 0.28139
====> Epoch: 155 Train Avg loss: 0.01303, Acc: 0.94899, F1: 0.94905#####> Valid Avg loss: 0.64198, Acc:0.32250, F1: 0.32260
====> Epoch: 156 Train Avg loss: 0.01479, Acc: 0.94049, F1: 0.94056#####> Valid Avg loss: 0.70356, Acc:0.32678, F1: 0.32678
====> Epoch: 157 Train Avg loss: 0.01347, Acc: 0.94518, F1: 0.94524#####> Valid Avg loss: 0.66321, Acc:0.34388, F1: 0.34378
====> Epoch: 158 Train Avg loss: 0.01231, Acc: 0.95295, F1: 0.95300#####> Valid Avg loss: 0.63656, Acc:0.31394, F1: 0.31396
====> Epoch: 159 Train Avg loss: 0.01114, Acc: 0.95515, F1: 0.95520#####> Valid Avg loss: 0.66270, Acc:0.30881, F1: 0.30874
====> Epoch: 160 Train Avg loss: 0.01087, Acc: 0.95529, F1: 0.95534#####> Valid Avg loss: 0.69075, Acc:0.33533, F1: 0.33523
====> Epoch: 161 Train Avg loss: 0.01437, Acc: 0.94283, F1: 0.94290#####> Valid Avg loss: 0.70165, Acc:0.30111, F1: 0.30085
====> Epoch: 162 Train Avg loss: 0.00960, Acc: 0.95881, F1: 0.95886#####> Valid Avg loss: 0.72954, Acc:0.27545, F1: 0.27540
====> Epoch: 163 Train Avg loss: 0.01576, Acc: 0.94254, F1: 0.94261#####> Valid Avg loss: 0.62663, Acc:0.32335, F1: 0.32336
====> Epoch: 164 Train Avg loss: 0.01056, Acc: 0.95646, F1: 0.95593#####> Valid Avg loss: 0.67993, Acc:0.29855, F1: 0.29858
====> Epoch: 165 Train Avg loss: 0.00787, Acc: 0.96526, F1: 0.96530#####> Valid Avg loss: 0.72558, Acc:0.31651, F1: 0.31652
====> Epoch: 166 Train Avg loss: 0.01289, Acc: 0.94928, F1: 0.94934#####> Valid Avg loss: 0.65641, Acc:0.30539, F1: 0.30541
====> Epoch: 167 Train Avg loss: 0.00995, Acc: 0.95910, F1: 0.95915#####> Valid Avg loss: 0.69086, Acc:0.31223, F1: 0.31225
====> Epoch: 168 Train Avg loss: 0.01028, Acc: 0.95558, F1: 0.95564#####> Valid Avg loss: 0.66589, Acc:0.33191, F1: 0.33191
====> Epoch: 169 Train Avg loss: 0.00938, Acc: 0.96379, F1: 0.96384#####> Valid Avg loss: 0.70013, Acc:0.33790, F1: 0.33799
====> Epoch: 170 Train Avg loss: 0.01162, Acc: 0.95089, F1: 0.95095#####> Valid Avg loss: 0.65041, Acc:0.24038, F1: 0.24017
====> Epoch: 171 Train Avg loss: 0.00762, Acc: 0.96555, F1: 0.96501#####> Valid Avg loss: 0.77443, Acc:0.29170, F1: 0.29183
====> Epoch: 172 Train Avg loss: 0.01217, Acc: 0.95265, F1: 0.95212#####> Valid Avg loss: 0.65191, Acc:0.34132, F1: 0.34141
====> Epoch: 173 Train Avg loss: 0.01184, Acc: 0.95339, F1: 0.95344#####> Valid Avg loss: 0.73924, Acc:0.34217, F1: 0.34226
====> Epoch: 174 Train Avg loss: 0.00849, Acc: 0.96174, F1: 0.96179#####> Valid Avg loss: 0.71108, Acc:0.31138, F1: 0.31149
====> Epoch: 175 Train Avg loss: 0.00894, Acc: 0.96233, F1: 0.96237#####> Valid Avg loss: 0.66208, Acc:0.30368, F1: 0.30380
====> Epoch: 176 Train Avg loss: 0.00808, Acc: 0.96438, F1: 0.96442#####> Valid Avg loss: 0.71729, Acc:0.31993, F1: 0.32004
====> Epoch: 177 Train Avg loss: 0.00789, Acc: 0.96643, F1: 0.96647#####> Valid Avg loss: 0.78907, Acc:0.27802, F1: 0.27816
====> Epoch: 178 Train Avg loss: 0.00990, Acc: 0.95881, F1: 0.95886#####> Valid Avg loss: 0.68417, Acc:0.27630, F1: 0.27626
====> Epoch: 179 Train Avg loss: 0.00652, Acc: 0.97054, F1: 0.97057#####> Valid Avg loss: 0.70791, Acc:0.31138, F1: 0.31159
====> Epoch: 180 Train Avg loss: 0.00974, Acc: 0.95881, F1: 0.95886#####> Valid Avg loss: 0.70492, Acc:0.29256, F1: 0.29250
====> Epoch: 181 Train Avg loss: 0.00758, Acc: 0.96570, F1: 0.96574#####> Valid Avg loss: 0.69138, Acc:0.25920, F1: 0.25907
====> Epoch: 182 Train Avg loss: 0.00908, Acc: 0.96233, F1: 0.96237#####> Valid Avg loss: 0.66436, Acc:0.27374, F1: 0.27369
====> Epoch: 183 Train Avg loss: 0.00898, Acc: 0.95984, F1: 0.95988#####> Valid Avg loss: 0.76483, Acc:0.29940, F1: 0.29962
====> Epoch: 184 Train Avg loss: 0.00807, Acc: 0.96350, F1: 0.96354#####> Valid Avg loss: 0.70509, Acc:0.27802, F1: 0.27825
====> Epoch: 185 Train Avg loss: 0.00537, Acc: 0.97391, F1: 0.97394#####> Valid Avg loss: 0.75617, Acc:0.29341, F1: 0.29335
====> Epoch: 186 Train Avg loss: 0.01016, Acc: 0.96101, F1: 0.96105#####> Valid Avg loss: 0.66081, Acc:0.30111, F1: 0.30123
====> Epoch: 187 Train Avg loss: 0.00810, Acc: 0.96379, F1: 0.96384#####> Valid Avg loss: 0.75416, Acc:0.31223, F1: 0.31244
====> Epoch: 188 Train Avg loss: 0.00842, Acc: 0.96159, F1: 0.96164#####> Valid Avg loss: 0.69204, Acc:0.32421, F1: 0.32422
====> Epoch: 189 Train Avg loss: 0.00705, Acc: 0.96467, F1: 0.96471#####> Valid Avg loss: 0.66291, Acc:0.29855, F1: 0.29848
====> Epoch: 190 Train Avg loss: 0.00637, Acc: 0.96878, F1: 0.96881#####> Valid Avg loss: 0.68390, Acc:0.28400, F1: 0.28405
====> Epoch: 191 Train Avg loss: 0.00807, Acc: 0.96409, F1: 0.96413#####> Valid Avg loss: 0.70423, Acc:0.29085, F1: 0.29088
====> Epoch: 192 Train Avg loss: 0.00751, Acc: 0.96804, F1: 0.96808#####> Valid Avg loss: 0.63228, Acc:0.31138, F1: 0.31140
====> Epoch: 193 Train Avg loss: 0.00463, Acc: 0.97567, F1: 0.97570#####> Valid Avg loss: 0.74394, Acc:0.30967, F1: 0.30959
====> Epoch: 194 Train Avg loss: 0.00559, Acc: 0.97303, F1: 0.97247#####> Valid Avg loss: 0.74661, Acc:0.29427, F1: 0.29411
====> Epoch: 195 Train Avg loss: 0.00814, Acc: 0.96731, F1: 0.96735#####> Valid Avg loss: 0.73714, Acc:0.32079, F1: 0.32061
====> Epoch: 196 Train Avg loss: 0.00459, Acc: 0.97435, F1: 0.97438#####> Valid Avg loss: 0.69200, Acc:0.27630, F1: 0.27607
====> Epoch: 197 Train Avg loss: 0.00805, Acc: 0.96423, F1: 0.96428#####> Valid Avg loss: 0.72092, Acc:0.27459, F1: 0.27436
====> Epoch: 198 Train Avg loss: 0.00508, Acc: 0.97288, F1: 0.97291#####> Valid Avg loss: 0.71013, Acc:0.27032, F1: 0.27028
====> Epoch: 199 Train Avg loss: 0.00569, Acc: 0.97361, F1: 0.97365#####> Valid Avg loss: 0.75382, Acc:0.32250, F1: 0.32260
====> Epoch: 200 Train Avg loss: 0.00534, Acc: 0.97142, F1: 0.97145#####> Valid Avg loss: 0.72228, Acc:0.32250, F1: 0.32260
====> Epoch: 201 Train Avg loss: 0.00749, Acc: 0.96760, F1: 0.96764#####> Valid Avg loss: 0.73004, Acc:0.31737, F1: 0.31747
====> Epoch: 202 Train Avg loss: 0.00462, Acc: 0.97449, F1: 0.97452#####> Valid Avg loss: 0.80805, Acc:0.27203, F1: 0.27217
====> Epoch: 203 Train Avg loss: 0.00462, Acc: 0.97596, F1: 0.97599#####> Valid Avg loss: 0.85793, Acc:0.32335, F1: 0.32336
====> Epoch: 204 Train Avg loss: 0.00830, Acc: 0.96350, F1: 0.96354#####> Valid Avg loss: 0.75035, Acc:0.31138, F1: 0.31149
====> Epoch: 205 Train Avg loss: 0.00453, Acc: 0.97464, F1: 0.97467#####> Valid Avg loss: 0.74804, Acc:0.33533, F1: 0.33552
====> Epoch: 206 Train Avg loss: 0.00586, Acc: 0.97142, F1: 0.97145#####> Valid Avg loss: 0.77029, Acc:0.30624, F1: 0.30636
====> Epoch: 207 Train Avg loss: 0.00483, Acc: 0.97479, F1: 0.97482#####> Valid Avg loss: 0.76185, Acc:0.29427, F1: 0.29430
====> Epoch: 208 Train Avg loss: 0.00477, Acc: 0.97361, F1: 0.97365#####> Valid Avg loss: 0.79322, Acc:0.30197, F1: 0.30199
====> Epoch: 209 Train Avg loss: 0.00501, Acc: 0.97127, F1: 0.97130#####> Valid Avg loss: 0.84417, Acc:0.30453, F1: 0.30475
====> Epoch: 210 Train Avg loss: 0.00578, Acc: 0.96980, F1: 0.96984#####> Valid Avg loss: 0.76075, Acc:0.29598, F1: 0.29592
====> Epoch: 211 Train Avg loss: 0.00548, Acc: 0.97288, F1: 0.97291#####> Valid Avg loss: 0.69451, Acc:0.29170, F1: 0.29174
====> Epoch: 212 Train Avg loss: 0.00389, Acc: 0.97581, F1: 0.97584#####> Valid Avg loss: 0.75587, Acc:0.28486, F1: 0.28490
====> Epoch: 213 Train Avg loss: 0.00391, Acc: 0.97581, F1: 0.97584#####> Valid Avg loss: 0.83018, Acc:0.26433, F1: 0.26429
====> Epoch: 214 Train Avg loss: 0.00532, Acc: 0.97391, F1: 0.97394#####> Valid Avg loss: 0.78507, Acc:0.30881, F1: 0.30883
====> Epoch: 215 Train Avg loss: 0.00589, Acc: 0.97054, F1: 0.97057#####> Valid Avg loss: 0.76224, Acc:0.31822, F1: 0.31823
====> Epoch: 216 Train Avg loss: 0.00350, Acc: 0.97933, F1: 0.97936#####> Valid Avg loss: 0.74722, Acc:0.30624, F1: 0.30636
====> Epoch: 217 Train Avg loss: 0.00347, Acc: 0.97933, F1: 0.97936#####> Valid Avg loss: 0.80296, Acc:0.29769, F1: 0.29782
====> Epoch: 218 Train Avg loss: 0.00428, Acc: 0.97743, F1: 0.97745#####> Valid Avg loss: 0.78905, Acc:0.27203, F1: 0.27198
====> Epoch: 219 Train Avg loss: 0.00486, Acc: 0.97493, F1: 0.97496#####> Valid Avg loss: 0.80377, Acc:0.30026, F1: 0.30038
====> Epoch: 220 Train Avg loss: 0.00385, Acc: 0.97464, F1: 0.97467#####> Valid Avg loss: 0.85950, Acc:0.27545, F1: 0.27569
====> Epoch: 221 Train Avg loss: 0.00393, Acc: 0.97699, F1: 0.97701#####> Valid Avg loss: 0.78896, Acc:0.28571, F1: 0.28585
====> Epoch: 222 Train Avg loss: 0.00533, Acc: 0.97376, F1: 0.97379#####> Valid Avg loss: 0.80230, Acc:0.26518, F1: 0.26524
====> Epoch: 223 Train Avg loss: 0.00401, Acc: 0.97625, F1: 0.97628#####> Valid Avg loss: 0.86069, Acc:0.30710, F1: 0.30731
====> Epoch: 224 Train Avg loss: 0.00341, Acc: 0.97904, F1: 0.97906#####> Valid Avg loss: 0.86563, Acc:0.28999, F1: 0.29022
====> Epoch: 225 Train Avg loss: 0.00325, Acc: 0.97772, F1: 0.97775#####> Valid Avg loss: 0.76191, Acc:0.30453, F1: 0.30465
====> Epoch: 226 Train Avg loss: 0.00367, Acc: 0.97948, F1: 0.97950#####> Valid Avg loss: 0.75016, Acc:0.32849, F1: 0.32858
====> Epoch: 227 Train Avg loss: 0.00434, Acc: 0.97596, F1: 0.97599#####> Valid Avg loss: 0.87799, Acc:0.29085, F1: 0.29107
====> Epoch: 228 Train Avg loss: 0.00401, Acc: 0.97523, F1: 0.97526#####> Valid Avg loss: 0.89593, Acc:0.28657, F1: 0.28642
====> Epoch: 229 Train Avg loss: 0.00345, Acc: 0.97699, F1: 0.97701#####> Valid Avg loss: 0.87264, Acc:0.29598, F1: 0.29611
====> Epoch: 230 Train Avg loss: 0.00304, Acc: 0.97933, F1: 0.97936#####> Valid Avg loss: 0.89941, Acc:0.29769, F1: 0.29782
====> Epoch: 231 Train Avg loss: 0.00372, Acc: 0.97757, F1: 0.97760#####> Valid Avg loss: 0.84522, Acc:0.28828, F1: 0.28813
====> Epoch: 232 Train Avg loss: 0.00409, Acc: 0.97537, F1: 0.97540#####> Valid Avg loss: 0.83578, Acc:0.29598, F1: 0.29601
====> Epoch: 233 Train Avg loss: 0.00313, Acc: 0.97875, F1: 0.97877#####> Valid Avg loss: 0.91135, Acc:0.28486, F1: 0.28490
====> Epoch: 234 Train Avg loss: 0.00332, Acc: 0.97845, F1: 0.97789#####> Valid Avg loss: 0.87035, Acc:0.29683, F1: 0.29696
====> Epoch: 235 Train Avg loss: 0.00403, Acc: 0.97699, F1: 0.97701#####> Valid Avg loss: 0.81599, Acc:0.29940, F1: 0.29943
====> Epoch: 236 Train Avg loss: 0.00327, Acc: 0.97787, F1: 0.97789#####> Valid Avg loss: 0.86532, Acc:0.30111, F1: 0.30123
====> Epoch: 237 Train Avg loss: 0.00323, Acc: 0.97845, F1: 0.97848#####> Valid Avg loss: 0.90243, Acc:0.28657, F1: 0.28670
====> Epoch: 238 Train Avg loss: 0.00315, Acc: 0.97831, F1: 0.97833#####> Valid Avg loss: 0.86890, Acc:0.30881, F1: 0.30893
====> Epoch: 239 Train Avg loss: 0.00327, Acc: 0.97801, F1: 0.97804#####> Valid Avg loss: 0.96902, Acc:0.31223, F1: 0.31244
====> Epoch: 240 Train Avg loss: 0.00438, Acc: 0.97669, F1: 0.97672#####> Valid Avg loss: 0.87171, Acc:0.30197, F1: 0.30199
====> Epoch: 241 Train Avg loss: 0.00336, Acc: 0.97743, F1: 0.97687#####> Valid Avg loss: 0.83215, Acc:0.30453, F1: 0.30456
====> Epoch: 242 Train Avg loss: 0.00330, Acc: 0.97948, F1: 0.97950#####> Valid Avg loss: 0.86163, Acc:0.31480, F1: 0.31481
====> Epoch: 243 Train Avg loss: 0.00311, Acc: 0.97977, F1: 0.97980#####> Valid Avg loss: 0.96416, Acc:0.32079, F1: 0.32089
====> Epoch: 244 Train Avg loss: 0.00297, Acc: 0.97875, F1: 0.97877#####> Valid Avg loss: 0.84289, Acc:0.30967, F1: 0.30978
===> Epoch: 244: Training loss decreased (0.00301 --> 0.00297), Acc: (0.97889 --> 0.97875), F1: (0.97892 --> 0.97877).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 245 Train Avg loss: 0.00313, Acc: 0.97962, F1: 0.97965#####> Valid Avg loss: 0.89574, Acc:0.29683, F1: 0.29687
====> Epoch: 246 Train Avg loss: 0.00300, Acc: 0.97831, F1: 0.97833#####> Valid Avg loss: 0.93467, Acc:0.29855, F1: 0.29858
====> Epoch: 247 Train Avg loss: 0.00324, Acc: 0.97889, F1: 0.97892#####> Valid Avg loss: 0.91846, Acc:0.30026, F1: 0.30038
====> Epoch: 248 Train Avg loss: 0.00302, Acc: 0.97860, F1: 0.97862#####> Valid Avg loss: 0.86796, Acc:0.30453, F1: 0.30465
====> Epoch: 249 Train Avg loss: 0.00297, Acc: 0.97713, F1: 0.97716#####> Valid Avg loss: 0.90912, Acc:0.31651, F1: 0.31662
====> Epoch: 250 Train Avg loss: 0.00289, Acc: 0.97640, F1: 0.97643#####> Valid Avg loss: 0.88534, Acc:0.31651, F1: 0.31662
===> Epoch: 250: Training loss decreased (0.00297 --> 0.00289), Acc: (0.97875 --> 0.97640), F1: (0.97877 --> 0.97643).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 251 Train Avg loss: 0.00325, Acc: 0.97713, F1: 0.97657#####> Valid Avg loss: 0.88036, Acc:0.29512, F1: 0.29506
====> Epoch: 252 Train Avg loss: 0.00292, Acc: 0.97962, F1: 0.97965#####> Valid Avg loss: 0.93253, Acc:0.31908, F1: 0.31918
====> Epoch: 253 Train Avg loss: 0.00305, Acc: 0.97713, F1: 0.97716#####> Valid Avg loss: 0.90169, Acc:0.30368, F1: 0.30380
====> Epoch: 254 Train Avg loss: 0.00302, Acc: 0.97772, F1: 0.97775#####> Valid Avg loss: 0.86287, Acc:0.28400, F1: 0.28395
====> Epoch: 255 Train Avg loss: 0.00290, Acc: 0.97933, F1: 0.97936#####> Valid Avg loss: 0.91293, Acc:0.30197, F1: 0.30199
====> Epoch: 256 Train Avg loss: 0.00287, Acc: 0.97860, F1: 0.97862#####> Valid Avg loss: 0.88822, Acc:0.29855, F1: 0.29858
===> Epoch: 256: Training loss decreased (0.00289 --> 0.00287), Acc: (0.97640 --> 0.97860), F1: (0.97643 --> 0.97862).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 257 Train Avg loss: 0.00281, Acc: 0.97919, F1: 0.97921#####> Valid Avg loss: 0.91778, Acc:0.28914, F1: 0.28927
===> Epoch: 257: Training loss decreased (0.00287 --> 0.00281), Acc: (0.97860 --> 0.97919), F1: (0.97862 --> 0.97921).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 258 Train Avg loss: 0.00280, Acc: 0.97962, F1: 0.97965#####> Valid Avg loss: 0.93783, Acc:0.30881, F1: 0.30883
===> Epoch: 258: Training loss decreased (0.00281 --> 0.00280), Acc: (0.97919 --> 0.97962), F1: (0.97921 --> 0.97965).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 259 Train Avg loss: 0.00289, Acc: 0.97816, F1: 0.97818#####> Valid Avg loss: 0.89324, Acc:0.31651, F1: 0.31662
====> Epoch: 260 Train Avg loss: 0.00277, Acc: 0.97889, F1: 0.97892#####> Valid Avg loss: 0.92673, Acc:0.29427, F1: 0.29440
===> Epoch: 260: Training loss decreased (0.00280 --> 0.00277), Acc: (0.97962 --> 0.97889), F1: (0.97965 --> 0.97892).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 261 Train Avg loss: 0.00281, Acc: 0.97845, F1: 0.97848#####> Valid Avg loss: 0.93005, Acc:0.30368, F1: 0.30380
====> Epoch: 262 Train Avg loss: 0.00287, Acc: 0.97860, F1: 0.97804#####> Valid Avg loss: 0.99010, Acc:0.27802, F1: 0.27816
====> Epoch: 263 Train Avg loss: 0.00276, Acc: 0.97699, F1: 0.97701#####> Valid Avg loss: 0.91415, Acc:0.29341, F1: 0.29354
===> Epoch: 263: Training loss decreased (0.00277 --> 0.00276), Acc: (0.97889 --> 0.97699), F1: (0.97892 --> 0.97701).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 264 Train Avg loss: 0.00278, Acc: 0.97919, F1: 0.97921#####> Valid Avg loss: 0.94913, Acc:0.28999, F1: 0.29003
====> Epoch: 265 Train Avg loss: 0.00279, Acc: 0.97933, F1: 0.97936#####> Valid Avg loss: 0.94002, Acc:0.30111, F1: 0.30123
====> Epoch: 266 Train Avg loss: 0.00273, Acc: 0.97977, F1: 0.97980#####> Valid Avg loss: 0.93257, Acc:0.30453, F1: 0.30465
===> Epoch: 266: Training loss decreased (0.00276 --> 0.00273), Acc: (0.97699 --> 0.97977), F1: (0.97701 --> 0.97980).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 267 Train Avg loss: 0.00279, Acc: 0.97860, F1: 0.97862#####> Valid Avg loss: 0.92048, Acc:0.30368, F1: 0.30370
====> Epoch: 268 Train Avg loss: 0.00276, Acc: 0.97684, F1: 0.97687#####> Valid Avg loss: 0.93715, Acc:0.29341, F1: 0.29345
====> Epoch: 269 Train Avg loss: 0.00272, Acc: 0.98006, F1: 0.98009#####> Valid Avg loss: 0.93026, Acc:0.29512, F1: 0.29506
===> Epoch: 269: Training loss decreased (0.00273 --> 0.00272), Acc: (0.97977 --> 0.98006), F1: (0.97980 --> 0.98009).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 270 Train Avg loss: 0.00272, Acc: 0.97875, F1: 0.97877#####> Valid Avg loss: 0.92385, Acc:0.30111, F1: 0.30114
===> Epoch: 270: Training loss decreased (0.00272 --> 0.00272), Acc: (0.98006 --> 0.97875), F1: (0.98009 --> 0.97877).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 271 Train Avg loss: 0.00277, Acc: 0.97904, F1: 0.97906#####> Valid Avg loss: 0.93045, Acc:0.29427, F1: 0.29430
====> Epoch: 272 Train Avg loss: 0.00271, Acc: 0.97889, F1: 0.97892#####> Valid Avg loss: 0.90474, Acc:0.30026, F1: 0.30038
===> Epoch: 272: Training loss decreased (0.00272 --> 0.00271), Acc: (0.97875 --> 0.97889), F1: (0.97877 --> 0.97892).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 273 Train Avg loss: 0.00266, Acc: 0.98050, F1: 0.98053#####> Valid Avg loss: 0.92158, Acc:0.30368, F1: 0.30370
===> Epoch: 273: Training loss decreased (0.00271 --> 0.00266), Acc: (0.97889 --> 0.98050), F1: (0.97892 --> 0.98053).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 274 Train Avg loss: 0.00268, Acc: 0.97904, F1: 0.97906#####> Valid Avg loss: 0.97786, Acc:0.30282, F1: 0.30285
====> Epoch: 275 Train Avg loss: 0.00270, Acc: 0.97948, F1: 0.97950#####> Valid Avg loss: 0.95680, Acc:0.29256, F1: 0.29269
====> Epoch: 276 Train Avg loss: 0.00270, Acc: 0.97992, F1: 0.97994#####> Valid Avg loss: 0.97091, Acc:0.29769, F1: 0.29782
====> Epoch: 277 Train Avg loss: 0.00269, Acc: 0.97992, F1: 0.97994#####> Valid Avg loss: 0.90813, Acc:0.29427, F1: 0.29440
====> Epoch: 278 Train Avg loss: 0.00264, Acc: 0.98080, F1: 0.98082#####> Valid Avg loss: 0.96201, Acc:0.28999, F1: 0.29003
===> Epoch: 278: Training loss decreased (0.00266 --> 0.00264), Acc: (0.98050 --> 0.98080), F1: (0.98053 --> 0.98082).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 279 Train Avg loss: 0.00267, Acc: 0.97933, F1: 0.97936#####> Valid Avg loss: 0.95407, Acc:0.28571, F1: 0.28585
====> Epoch: 280 Train Avg loss: 0.00270, Acc: 0.97992, F1: 0.97994#####> Valid Avg loss: 0.98670, Acc:0.29170, F1: 0.29183
====> Epoch: 281 Train Avg loss: 0.00264, Acc: 0.98021, F1: 0.98023#####> Valid Avg loss: 0.94598, Acc:0.30111, F1: 0.30123
====> Epoch: 282 Train Avg loss: 0.00268, Acc: 0.97904, F1: 0.97906#####> Valid Avg loss: 0.95244, Acc:0.30111, F1: 0.30123
====> Epoch: 283 Train Avg loss: 0.00268, Acc: 0.98021, F1: 0.98023#####> Valid Avg loss: 0.94841, Acc:0.29683, F1: 0.29696
====> Epoch: 284 Train Avg loss: 0.00278, Acc: 0.98050, F1: 0.97994#####> Valid Avg loss: 0.93514, Acc:0.29683, F1: 0.29696
====> Epoch: 285 Train Avg loss: 0.00264, Acc: 0.97992, F1: 0.97994#####> Valid Avg loss: 0.98129, Acc:0.29769, F1: 0.29782
====> Epoch: 286 Train Avg loss: 0.00264, Acc: 0.98021, F1: 0.98023#####> Valid Avg loss: 0.93108, Acc:0.29598, F1: 0.29611
===> Epoch: 286: Training loss decreased (0.00264 --> 0.00264), Acc: (0.98080 --> 0.98021), F1: (0.98082 --> 0.98023).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 287 Train Avg loss: 0.00266, Acc: 0.98036, F1: 0.98038#####> Valid Avg loss: 0.90840, Acc:0.29512, F1: 0.29525
====> Epoch: 288 Train Avg loss: 0.00259, Acc: 0.98109, F1: 0.98111#####> Valid Avg loss: 0.93618, Acc:0.29598, F1: 0.29611
===> Epoch: 288: Training loss decreased (0.00264 --> 0.00259), Acc: (0.98021 --> 0.98109), F1: (0.98023 --> 0.98111).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 289 Train Avg loss: 0.00264, Acc: 0.97933, F1: 0.97936#####> Valid Avg loss: 0.90625, Acc:0.29512, F1: 0.29525
====> Epoch: 290 Train Avg loss: 0.00268, Acc: 0.97977, F1: 0.97980#####> Valid Avg loss: 0.94180, Acc:0.29683, F1: 0.29696
====> Epoch: 291 Train Avg loss: 0.00262, Acc: 0.97948, F1: 0.97950#####> Valid Avg loss: 0.92346, Acc:0.29940, F1: 0.29953
====> Epoch: 292 Train Avg loss: 0.00260, Acc: 0.98182, F1: 0.98184#####> Valid Avg loss: 0.99226, Acc:0.29769, F1: 0.29782
====> Epoch: 293 Train Avg loss: 0.00269, Acc: 0.97933, F1: 0.97936#####> Valid Avg loss: 0.98684, Acc:0.29598, F1: 0.29611
====> Epoch: 294 Train Avg loss: 0.00262, Acc: 0.98080, F1: 0.98082#####> Valid Avg loss: 0.98704, Acc:0.29598, F1: 0.29611
====> Epoch: 295 Train Avg loss: 0.00264, Acc: 0.98138, F1: 0.98141#####> Valid Avg loss: 0.91709, Acc:0.29683, F1: 0.29696
====> Epoch: 296 Train Avg loss: 0.00269, Acc: 0.98300, F1: 0.98302#####> Valid Avg loss: 0.96344, Acc:0.29683, F1: 0.29696
====> Epoch: 297 Train Avg loss: 0.00259, Acc: 0.98226, F1: 0.98228#####> Valid Avg loss: 0.92319, Acc:0.29683, F1: 0.29696
===> Epoch: 297: Training loss decreased (0.00259 --> 0.00259), Acc: (0.98109 --> 0.98226), F1: (0.98111 --> 0.98228).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 298 Train Avg loss: 0.00260, Acc: 0.98373, F1: 0.98375#####> Valid Avg loss: 0.94733, Acc:0.29683, F1: 0.29696
====> Epoch: 299 Train Avg loss: 0.00258, Acc: 0.98285, F1: 0.98287#####> Valid Avg loss: 0.95881, Acc:0.29769, F1: 0.29782
===> Epoch: 299: Training loss decreased (0.00259 --> 0.00258), Acc: (0.98226 --> 0.98285), F1: (0.98228 --> 0.98287).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_1
====> Epoch: 300 Train Avg loss: 0.11773, Acc: 0.65553, F1: 0.65534#####> Valid Avg loss: 0.32056, Acc:0.24123, F1: 0.24122
====> Epoch: 301 Train Avg loss: 0.08588, Acc: 0.71064, F1: 0.71098#####> Valid Avg loss: 0.31641, Acc:0.26861, F1: 0.26866
====> Epoch: 302 Train Avg loss: 0.06918, Acc: 0.75799, F1: 0.75769#####> Valid Avg loss: 0.38561, Acc:0.30881, F1: 0.30893
====> Epoch: 303 Train Avg loss: 0.02975, Acc: 0.89167, F1: 0.89180#####> Valid Avg loss: 0.53543, Acc:0.25235, F1: 0.25223
====> Epoch: 304 Train Avg loss: 0.01926, Acc: 0.92700, F1: 0.92709#####> Valid Avg loss: 0.53094, Acc:0.27459, F1: 0.27455
====> Epoch: 305 Train Avg loss: 0.01400, Acc: 0.94356, F1: 0.94363#####> Valid Avg loss: 0.59327, Acc:0.30453, F1: 0.30465
====> Epoch: 306 Train Avg loss: 0.01693, Acc: 0.93272, F1: 0.93280#####> Valid Avg loss: 0.57810, Acc:0.31565, F1: 0.31576
====> Epoch: 307 Train Avg loss: 0.01503, Acc: 0.94269, F1: 0.94275#####> Valid Avg loss: 0.62329, Acc:0.21044, F1: 0.21073
====> Epoch: 308 Train Avg loss: 0.01619, Acc: 0.93975, F1: 0.93982#####> Valid Avg loss: 0.58681, Acc:0.27288, F1: 0.27293
====> Epoch: 309 Train Avg loss: 0.01561, Acc: 0.94122, F1: 0.94129#####> Valid Avg loss: 0.65548, Acc:0.32592, F1: 0.32612
====> Epoch: 310 Train Avg loss: 0.01410, Acc: 0.94239, F1: 0.94246#####> Valid Avg loss: 0.50759, Acc:0.29341, F1: 0.29354
====> Epoch: 311 Train Avg loss: 0.01653, Acc: 0.94166, F1: 0.94173#####> Valid Avg loss: 0.53552, Acc:0.29170, F1: 0.29174
====> Epoch: 312 Train Avg loss: 0.01425, Acc: 0.94356, F1: 0.94363#####> Valid Avg loss: 0.54491, Acc:0.29170, F1: 0.29174
====> Epoch: 313 Train Avg loss: 0.01156, Acc: 0.95104, F1: 0.95110#####> Valid Avg loss: 0.60959, Acc:0.24380, F1: 0.24378
====> Epoch: 314 Train Avg loss: 0.01951, Acc: 0.92905, F1: 0.92914#####> Valid Avg loss: 0.50357, Acc:0.29427, F1: 0.29430
====> Epoch: 315 Train Avg loss: 0.01062, Acc: 0.95720, F1: 0.95725#####> Valid Avg loss: 0.62235, Acc:0.24123, F1: 0.24122
====> Epoch: 316 Train Avg loss: 0.01626, Acc: 0.94093, F1: 0.94100#####> Valid Avg loss: 0.54417, Acc:0.30967, F1: 0.30969
====> Epoch: 317 Train Avg loss: 0.01351, Acc: 0.94782, F1: 0.94788#####> Valid Avg loss: 0.58286, Acc:0.29170, F1: 0.29183
====> Epoch: 318 Train Avg loss: 0.01404, Acc: 0.94503, F1: 0.94510#####> Valid Avg loss: 0.63392, Acc:0.29256, F1: 0.29278
====> Epoch: 319 Train Avg loss: 0.01410, Acc: 0.94225, F1: 0.94173#####> Valid Avg loss: 0.64129, Acc:0.23695, F1: 0.23685
====> Epoch: 320 Train Avg loss: 0.01371, Acc: 0.94547, F1: 0.94553#####> Valid Avg loss: 0.64668, Acc:0.25749, F1: 0.25736
====> Epoch: 321 Train Avg loss: 0.01682, Acc: 0.93770, F1: 0.93660#####> Valid Avg loss: 0.50516, Acc:0.30710, F1: 0.30741
====> Epoch: 322 Train Avg loss: 0.01372, Acc: 0.94576, F1: 0.94583#####> Valid Avg loss: 0.60942, Acc:0.29427, F1: 0.29430
====> Epoch: 323 Train Avg loss: 0.01380, Acc: 0.94855, F1: 0.94861#####> Valid Avg loss: 0.63774, Acc:0.30881, F1: 0.30893
====> Epoch: 324 Train Avg loss: 0.01305, Acc: 0.94767, F1: 0.94773#####> Valid Avg loss: 0.67724, Acc:0.29341, F1: 0.29335
====> Epoch: 325 Train Avg loss: 0.01465, Acc: 0.94694, F1: 0.94700#####> Valid Avg loss: 0.57689, Acc:0.26347, F1: 0.26363
====> Epoch: 326 Train Avg loss: 0.01242, Acc: 0.95001, F1: 0.94949#####> Valid Avg loss: 0.63849, Acc:0.28657, F1: 0.28680
====> Epoch: 327 Train Avg loss: 0.01229, Acc: 0.94855, F1: 0.94861#####> Valid Avg loss: 0.59404, Acc:0.31651, F1: 0.31671
====> Epoch: 328 Train Avg loss: 0.01489, Acc: 0.94430, F1: 0.94378#####> Valid Avg loss: 0.58209, Acc:0.26176, F1: 0.26173
====> Epoch: 329 Train Avg loss: 0.01048, Acc: 0.95764, F1: 0.95769#####> Valid Avg loss: 0.69529, Acc:0.32335, F1: 0.32346
====> Epoch: 330 Train Avg loss: 0.01175, Acc: 0.95163, F1: 0.95168#####> Valid Avg loss: 0.59719, Acc:0.33020, F1: 0.33029
====> Epoch: 331 Train Avg loss: 0.01527, Acc: 0.93917, F1: 0.93924#####> Valid Avg loss: 0.70786, Acc:0.28058, F1: 0.28072
====> Epoch: 332 Train Avg loss: 0.01120, Acc: 0.95515, F1: 0.95520#####> Valid Avg loss: 0.68884, Acc:0.30453, F1: 0.30465
====> Epoch: 333 Train Avg loss: 0.01276, Acc: 0.95368, F1: 0.95373#####> Valid Avg loss: 0.57539, Acc:0.30111, F1: 0.30104
====> Epoch: 334 Train Avg loss: 0.01178, Acc: 0.95397, F1: 0.95403#####> Valid Avg loss: 0.56184, Acc:0.27203, F1: 0.27198
====> Epoch: 335 Train Avg loss: 0.01524, Acc: 0.94269, F1: 0.94275#####> Valid Avg loss: 0.63627, Acc:0.30967, F1: 0.30950
====> Epoch: 336 Train Avg loss: 0.01088, Acc: 0.95265, F1: 0.95271#####> Valid Avg loss: 0.70046, Acc:0.25834, F1: 0.25812
====> Epoch: 337 Train Avg loss: 0.01268, Acc: 0.95133, F1: 0.95139#####> Valid Avg loss: 0.69880, Acc:0.29085, F1: 0.29098
====> Epoch: 338 Train Avg loss: 0.01277, Acc: 0.94620, F1: 0.94627#####> Valid Avg loss: 0.62363, Acc:0.29598, F1: 0.29601
====> Epoch: 339 Train Avg loss: 0.01078, Acc: 0.95236, F1: 0.95242#####> Valid Avg loss: 0.64289, Acc:0.31052, F1: 0.31073
====> Epoch: 340 Train Avg loss: 0.01516, Acc: 0.94034, F1: 0.94041#####> Valid Avg loss: 0.60467, Acc:0.24380, F1: 0.24368
====> Epoch: 341 Train Avg loss: 0.00990, Acc: 0.96028, F1: 0.95974#####> Valid Avg loss: 0.67458, Acc:0.25749, F1: 0.25736
====> Epoch: 342 Train Avg loss: 0.01418, Acc: 0.94576, F1: 0.94583#####> Valid Avg loss: 0.54704, Acc:0.31908, F1: 0.31909
====> Epoch: 343 Train Avg loss: 0.01295, Acc: 0.94708, F1: 0.94714#####> Valid Avg loss: 0.63432, Acc:0.34474, F1: 0.34482
====> Epoch: 344 Train Avg loss: 0.01163, Acc: 0.95529, F1: 0.95534#####> Valid Avg loss: 0.67343, Acc:0.25406, F1: 0.25394
====> Epoch: 345 Train Avg loss: 0.01644, Acc: 0.94034, F1: 0.94041#####> Valid Avg loss: 0.55842, Acc:0.32934, F1: 0.32934
====> Epoch: 346 Train Avg loss: 0.00858, Acc: 0.96453, F1: 0.96457#####> Valid Avg loss: 0.60200, Acc:0.27459, F1: 0.27455
====> Epoch: 347 Train Avg loss: 0.01419, Acc: 0.94957, F1: 0.94963#####> Valid Avg loss: 0.57469, Acc:0.29683, F1: 0.29696
====> Epoch: 348 Train Avg loss: 0.01229, Acc: 0.94914, F1: 0.94919#####> Valid Avg loss: 0.64088, Acc:0.31394, F1: 0.31387
====> Epoch: 349 Train Avg loss: 0.00987, Acc: 0.95866, F1: 0.95871#####> Valid Avg loss: 0.64400, Acc:0.30796, F1: 0.30807
====> Epoch: 350 Train Avg loss: 0.00975, Acc: 0.96042, F1: 0.96047#####> Valid Avg loss: 0.64991, Acc:0.31565, F1: 0.31586
====> Epoch: 351 Train Avg loss: 0.01266, Acc: 0.95148, F1: 0.95154#####> Valid Avg loss: 0.66640, Acc:0.33020, F1: 0.33020
====> Epoch: 352 Train Avg loss: 0.01163, Acc: 0.95573, F1: 0.95578#####> Valid Avg loss: 0.60681, Acc:0.31651, F1: 0.31662
====> Epoch: 353 Train Avg loss: 0.01163, Acc: 0.95529, F1: 0.95534#####> Valid Avg loss: 0.61989, Acc:0.28743, F1: 0.28765
====> Epoch: 354 Train Avg loss: 0.01374, Acc: 0.94664, F1: 0.94671#####> Valid Avg loss: 0.56430, Acc:0.31394, F1: 0.31406
====> Epoch: 355 Train Avg loss: 0.01090, Acc: 0.95676, F1: 0.95622#####> Valid Avg loss: 0.57279, Acc:0.30796, F1: 0.30817
====> Epoch: 356 Train Avg loss: 0.01015, Acc: 0.95793, F1: 0.95798#####> Valid Avg loss: 0.61322, Acc:0.25663, F1: 0.25660
====> Epoch: 357 Train Avg loss: 0.01323, Acc: 0.94664, F1: 0.94671#####> Valid Avg loss: 0.56886, Acc:0.29940, F1: 0.29953
====> Epoch: 358 Train Avg loss: 0.01080, Acc: 0.95441, F1: 0.95447#####> Valid Avg loss: 0.65062, Acc:0.30710, F1: 0.30731
====> Epoch: 359 Train Avg loss: 0.01115, Acc: 0.95485, F1: 0.95490#####> Valid Avg loss: 0.59594, Acc:0.32421, F1: 0.32431
====> Epoch: 360 Train Avg loss: 0.01360, Acc: 0.94576, F1: 0.94583#####> Valid Avg loss: 0.56377, Acc:0.28144, F1: 0.28158
====> Epoch: 361 Train Avg loss: 0.01021, Acc: 0.95778, F1: 0.95783#####> Valid Avg loss: 0.64626, Acc:0.28657, F1: 0.28680
====> Epoch: 362 Train Avg loss: 0.00934, Acc: 0.95866, F1: 0.95871#####> Valid Avg loss: 0.57767, Acc:0.29769, F1: 0.29763
====> Epoch: 363 Train Avg loss: 0.01124, Acc: 0.95295, F1: 0.95300#####> Valid Avg loss: 0.72069, Acc:0.30539, F1: 0.30522
====> Epoch: 364 Train Avg loss: 0.01357, Acc: 0.94782, F1: 0.94788#####> Valid Avg loss: 0.52024, Acc:0.31565, F1: 0.31557
====> Epoch: 365 Train Avg loss: 0.01031, Acc: 0.95778, F1: 0.95783#####> Valid Avg loss: 0.55667, Acc:0.31223, F1: 0.31225
====> Epoch: 366 Train Avg loss: 0.00662, Acc: 0.97010, F1: 0.97013#####> Valid Avg loss: 0.68373, Acc:0.31052, F1: 0.31064
====> Epoch: 367 Train Avg loss: 0.01227, Acc: 0.95001, F1: 0.95007#####> Valid Avg loss: 0.57335, Acc:0.29855, F1: 0.29858
====> Epoch: 368 Train Avg loss: 0.01595, Acc: 0.94474, F1: 0.94480#####> Valid Avg loss: 0.57451, Acc:0.27459, F1: 0.27455
====> Epoch: 369 Train Avg loss: 0.01131, Acc: 0.95515, F1: 0.95520#####> Valid Avg loss: 0.57734, Acc:0.27288, F1: 0.27284
====> Epoch: 370 Train Avg loss: 0.00905, Acc: 0.96306, F1: 0.96310#####> Valid Avg loss: 0.58183, Acc:0.29512, F1: 0.29525
====> Epoch: 371 Train Avg loss: 0.00677, Acc: 0.96834, F1: 0.96837#####> Valid Avg loss: 0.71132, Acc:0.29683, F1: 0.29687
====> Epoch: 372 Train Avg loss: 0.01443, Acc: 0.94723, F1: 0.94729#####> Valid Avg loss: 0.57411, Acc:0.26262, F1: 0.26258
====> Epoch: 373 Train Avg loss: 0.00948, Acc: 0.95969, F1: 0.95974#####> Valid Avg loss: 0.64545, Acc:0.30967, F1: 0.30969
====> Epoch: 374 Train Avg loss: 0.01025, Acc: 0.95808, F1: 0.95813#####> Valid Avg loss: 0.56190, Acc:0.31480, F1: 0.31500
====> Epoch: 375 Train Avg loss: 0.01007, Acc: 0.95617, F1: 0.95622#####> Valid Avg loss: 0.61672, Acc:0.29341, F1: 0.29335
====> Epoch: 376 Train Avg loss: 0.01137, Acc: 0.95808, F1: 0.95754#####> Valid Avg loss: 0.49522, Acc:0.29256, F1: 0.29240
====> Epoch: 377 Train Avg loss: 0.00926, Acc: 0.96159, F1: 0.96105#####> Valid Avg loss: 0.58310, Acc:0.29512, F1: 0.29497
====> Epoch: 378 Train Avg loss: 0.01004, Acc: 0.95734, F1: 0.95739#####> Valid Avg loss: 0.58814, Acc:0.30539, F1: 0.30551
====> Epoch: 379 Train Avg loss: 0.01052, Acc: 0.95573, F1: 0.95520#####> Valid Avg loss: 0.53183, Acc:0.31480, F1: 0.31491
====> Epoch: 380 Train Avg loss: 0.01144, Acc: 0.95383, F1: 0.95388#####> Valid Avg loss: 0.57637, Acc:0.29085, F1: 0.29088
====> Epoch: 381 Train Avg loss: 0.01271, Acc: 0.95075, F1: 0.95081#####> Valid Avg loss: 0.56944, Acc:0.26518, F1: 0.26496
====> Epoch: 382 Train Avg loss: 0.00588, Acc: 0.97098, F1: 0.97101#####> Valid Avg loss: 0.65518, Acc:0.30368, F1: 0.30351
====> Epoch: 383 Train Avg loss: 0.01276, Acc: 0.94957, F1: 0.94905#####> Valid Avg loss: 0.48399, Acc:0.31993, F1: 0.32013
====> Epoch: 384 Train Avg loss: 0.00947, Acc: 0.96116, F1: 0.96120#####> Valid Avg loss: 0.64013, Acc:0.29085, F1: 0.29079
====> Epoch: 385 Train Avg loss: 0.01121, Acc: 0.95515, F1: 0.95520#####> Valid Avg loss: 0.60172, Acc:0.32079, F1: 0.32070
====> Epoch: 386 Train Avg loss: 0.00835, Acc: 0.96467, F1: 0.96471#####> Valid Avg loss: 0.65852, Acc:0.30624, F1: 0.30617
====> Epoch: 387 Train Avg loss: 0.00893, Acc: 0.96321, F1: 0.96325#####> Valid Avg loss: 0.69105, Acc:0.32421, F1: 0.32441
====> Epoch: 388 Train Avg loss: 0.01295, Acc: 0.95075, F1: 0.95081#####> Valid Avg loss: 0.58389, Acc:0.31309, F1: 0.31311
====> Epoch: 389 Train Avg loss: 0.00863, Acc: 0.96101, F1: 0.96105#####> Valid Avg loss: 0.68256, Acc:0.31138, F1: 0.31130
====> Epoch: 390 Train Avg loss: 0.00692, Acc: 0.96878, F1: 0.96881#####> Valid Avg loss: 0.66479, Acc:0.29683, F1: 0.29677
====> Epoch: 391 Train Avg loss: 0.00838, Acc: 0.96365, F1: 0.96369#####> Valid Avg loss: 0.67113, Acc:0.34217, F1: 0.34226
====> Epoch: 392 Train Avg loss: 0.00720, Acc: 0.96819, F1: 0.96823#####> Valid Avg loss: 0.72594, Acc:0.33533, F1: 0.33542
====> Epoch: 393 Train Avg loss: 0.01222, Acc: 0.95163, F1: 0.95168#####> Valid Avg loss: 0.63415, Acc:0.32079, F1: 0.32080
====> Epoch: 394 Train Avg loss: 0.01014, Acc: 0.95705, F1: 0.95710#####> Valid Avg loss: 0.65760, Acc:0.31651, F1: 0.31662
====> Epoch: 395 Train Avg loss: 0.00662, Acc: 0.96922, F1: 0.96925#####> Valid Avg loss: 0.74405, Acc:0.28743, F1: 0.28727
====> Epoch: 396 Train Avg loss: 0.01134, Acc: 0.95529, F1: 0.95534#####> Valid Avg loss: 0.70425, Acc:0.31309, F1: 0.31311
====> Epoch: 397 Train Avg loss: 0.00864, Acc: 0.96174, F1: 0.96179#####> Valid Avg loss: 0.68423, Acc:0.32592, F1: 0.32593
====> Epoch: 398 Train Avg loss: 0.01111, Acc: 0.95646, F1: 0.95652#####> Valid Avg loss: 0.62109, Acc:0.32592, F1: 0.32602
====> Epoch: 399 Train Avg loss: 0.00679, Acc: 0.96804, F1: 0.96808#####> Valid Avg loss: 0.67059, Acc:0.32335, F1: 0.32346
====> Epoch: 400 Train Avg loss: 0.00820, Acc: 0.96541, F1: 0.96545#####> Valid Avg loss: 0.64698, Acc:0.33533, F1: 0.33552
====> Epoch: 401 Train Avg loss: 0.00839, Acc: 0.96511, F1: 0.96515#####> Valid Avg loss: 0.65624, Acc:0.28743, F1: 0.28746
====> Epoch: 402 Train Avg loss: 0.00607, Acc: 0.97039, F1: 0.97042#####> Valid Avg loss: 0.71174, Acc:0.25663, F1: 0.25641
====> Epoch: 403 Train Avg loss: 0.01350, Acc: 0.95133, F1: 0.95139#####> Valid Avg loss: 0.54935, Acc:0.27288, F1: 0.27284
====> Epoch: 404 Train Avg loss: 0.00740, Acc: 0.96599, F1: 0.96603#####> Valid Avg loss: 0.66735, Acc:0.24636, F1: 0.24625
====> Epoch: 405 Train Avg loss: 0.01090, Acc: 0.95778, F1: 0.95783#####> Valid Avg loss: 0.61934, Acc:0.30967, F1: 0.30969
====> Epoch: 406 Train Avg loss: 0.00760, Acc: 0.96614, F1: 0.96618#####> Valid Avg loss: 0.67268, Acc:0.28400, F1: 0.28414
====> Epoch: 407 Train Avg loss: 0.00883, Acc: 0.96086, F1: 0.96091#####> Valid Avg loss: 0.63779, Acc:0.30453, F1: 0.30446
====> Epoch: 408 Train Avg loss: 0.00744, Acc: 0.96995, F1: 0.96999#####> Valid Avg loss: 0.70513, Acc:0.31993, F1: 0.32013
====> Epoch: 409 Train Avg loss: 0.00757, Acc: 0.96585, F1: 0.96589#####> Valid Avg loss: 0.62174, Acc:0.31651, F1: 0.31643
====> Epoch: 410 Train Avg loss: 0.01044, Acc: 0.95705, F1: 0.95710#####> Valid Avg loss: 0.65614, Acc:0.29512, F1: 0.29535
====> Epoch: 411 Train Avg loss: 0.00668, Acc: 0.96936, F1: 0.96940#####> Valid Avg loss: 0.68884, Acc:0.27545, F1: 0.27550
====> Epoch: 412 Train Avg loss: 0.00690, Acc: 0.96834, F1: 0.96837#####> Valid Avg loss: 0.76701, Acc:0.27203, F1: 0.27198
====> Epoch: 413 Train Avg loss: 0.01001, Acc: 0.95822, F1: 0.95827#####> Valid Avg loss: 0.65461, Acc:0.30881, F1: 0.30902
====> Epoch: 414 Train Avg loss: 0.00758, Acc: 0.96760, F1: 0.96764#####> Valid Avg loss: 0.65576, Acc:0.30967, F1: 0.30969
====> Epoch: 415 Train Avg loss: 0.00712, Acc: 0.96570, F1: 0.96574#####> Valid Avg loss: 0.65202, Acc:0.27459, F1: 0.27455
====> Epoch: 416 Train Avg loss: 0.00709, Acc: 0.96687, F1: 0.96691#####> Valid Avg loss: 0.71548, Acc:0.30197, F1: 0.30199
====> Epoch: 417 Train Avg loss: 0.00814, Acc: 0.96394, F1: 0.96398#####> Valid Avg loss: 0.64431, Acc:0.26946, F1: 0.26942
====> Epoch: 418 Train Avg loss: 0.00890, Acc: 0.96116, F1: 0.96120#####> Valid Avg loss: 0.57139, Acc:0.27887, F1: 0.27863
====> Epoch: 419 Train Avg loss: 0.00832, Acc: 0.96482, F1: 0.96486#####> Valid Avg loss: 0.65761, Acc:0.31394, F1: 0.31406
====> Epoch: 420 Train Avg loss: 0.00678, Acc: 0.96878, F1: 0.96881#####> Valid Avg loss: 0.63502, Acc:0.29085, F1: 0.29079
====> Epoch: 421 Train Avg loss: 0.00732, Acc: 0.96907, F1: 0.96911#####> Valid Avg loss: 0.60128, Acc:0.32763, F1: 0.32754
====> Epoch: 422 Train Avg loss: 0.00903, Acc: 0.95925, F1: 0.95930#####> Valid Avg loss: 0.66021, Acc:0.27545, F1: 0.27531
====> Epoch: 423 Train Avg loss: 0.00733, Acc: 0.96717, F1: 0.96720#####> Valid Avg loss: 0.62009, Acc:0.30796, F1: 0.30798
====> Epoch: 424 Train Avg loss: 0.00713, Acc: 0.96497, F1: 0.96501#####> Valid Avg loss: 0.62832, Acc:0.31651, F1: 0.31643
====> Epoch: 425 Train Avg loss: 0.00916, Acc: 0.96203, F1: 0.96208#####> Valid Avg loss: 0.61933, Acc:0.33875, F1: 0.33884
====> Epoch: 426 Train Avg loss: 0.00728, Acc: 0.96731, F1: 0.96676#####> Valid Avg loss: 0.67327, Acc:0.28400, F1: 0.28424
====> Epoch: 427 Train Avg loss: 0.00779, Acc: 0.96702, F1: 0.96706#####> Valid Avg loss: 0.66187, Acc:0.30026, F1: 0.30009
====> Epoch: 428 Train Avg loss: 0.00905, Acc: 0.96438, F1: 0.96442#####> Valid Avg loss: 0.64727, Acc:0.31480, F1: 0.31491
====> Epoch: 429 Train Avg loss: 0.00754, Acc: 0.96599, F1: 0.96545#####> Valid Avg loss: 0.67717, Acc:0.31737, F1: 0.31738
====> Epoch: 430 Train Avg loss: 0.00625, Acc: 0.96878, F1: 0.96881#####> Valid Avg loss: 0.68526, Acc:0.32250, F1: 0.32251
====> Epoch: 431 Train Avg loss: 0.00432, Acc: 0.97567, F1: 0.97511#####> Valid Avg loss: 0.72562, Acc:0.32079, F1: 0.32080
====> Epoch: 432 Train Avg loss: 0.00914, Acc: 0.95881, F1: 0.95886#####> Valid Avg loss: 0.65505, Acc:0.31993, F1: 0.32013
====> Epoch: 433 Train Avg loss: 0.00692, Acc: 0.96819, F1: 0.96823#####> Valid Avg loss: 0.66532, Acc:0.33704, F1: 0.33704
====> Epoch: 434 Train Avg loss: 0.00792, Acc: 0.96629, F1: 0.96633#####> Valid Avg loss: 0.69437, Acc:0.29598, F1: 0.29582
====> Epoch: 435 Train Avg loss: 0.00565, Acc: 0.97435, F1: 0.97438#####> Valid Avg loss: 0.70180, Acc:0.30710, F1: 0.30703
====> Epoch: 436 Train Avg loss: 0.00555, Acc: 0.97420, F1: 0.97423#####> Valid Avg loss: 0.70034, Acc:0.32592, F1: 0.32574
====> Epoch: 437 Train Avg loss: 0.00460, Acc: 0.97332, F1: 0.97335#####> Valid Avg loss: 0.85071, Acc:0.32335, F1: 0.32336
====> Epoch: 438 Train Avg loss: 0.01173, Acc: 0.95353, F1: 0.95359#####> Valid Avg loss: 0.65898, Acc:0.31908, F1: 0.31899
====> Epoch: 439 Train Avg loss: 0.00856, Acc: 0.96555, F1: 0.96559#####> Valid Avg loss: 0.59893, Acc:0.30967, F1: 0.30950
====> Epoch: 440 Train Avg loss: 0.00502, Acc: 0.97567, F1: 0.97570#####> Valid Avg loss: 0.71476, Acc:0.26433, F1: 0.26420
====> Epoch: 441 Train Avg loss: 0.00650, Acc: 0.96746, F1: 0.96750#####> Valid Avg loss: 0.62247, Acc:0.28657, F1: 0.28661
====> Epoch: 442 Train Avg loss: 0.00831, Acc: 0.96072, F1: 0.96076#####> Valid Avg loss: 0.66273, Acc:0.28486, F1: 0.28471
====> Epoch: 443 Train Avg loss: 0.00709, Acc: 0.96746, F1: 0.96750#####> Valid Avg loss: 0.63339, Acc:0.32421, F1: 0.32412
====> Epoch: 444 Train Avg loss: 0.00535, Acc: 0.97376, F1: 0.97379#####> Valid Avg loss: 0.65595, Acc:0.28400, F1: 0.28414
====> Epoch: 445 Train Avg loss: 0.00670, Acc: 0.96819, F1: 0.96823#####> Valid Avg loss: 0.66650, Acc:0.30197, F1: 0.30199
====> Epoch: 446 Train Avg loss: 0.00698, Acc: 0.96746, F1: 0.96750#####> Valid Avg loss: 0.63903, Acc:0.27459, F1: 0.27436
====> Epoch: 447 Train Avg loss: 0.00841, Acc: 0.96218, F1: 0.96223#####> Valid Avg loss: 0.63112, Acc:0.28914, F1: 0.28927
====> Epoch: 448 Train Avg loss: 0.00529, Acc: 0.97274, F1: 0.97277#####> Valid Avg loss: 0.68978, Acc:0.32849, F1: 0.32840
====> Epoch: 449 Train Avg loss: 0.00651, Acc: 0.96951, F1: 0.96955#####> Valid Avg loss: 0.72582, Acc:0.30796, F1: 0.30798
====> Epoch: 450 Train Avg loss: 0.00623, Acc: 0.96848, F1: 0.96852#####> Valid Avg loss: 0.67499, Acc:0.33276, F1: 0.33276
====> Epoch: 451 Train Avg loss: 0.00481, Acc: 0.97449, F1: 0.97452#####> Valid Avg loss: 0.67343, Acc:0.29769, F1: 0.29753
====> Epoch: 452 Train Avg loss: 0.00474, Acc: 0.97303, F1: 0.97306#####> Valid Avg loss: 0.74689, Acc:0.32164, F1: 0.32165
====> Epoch: 453 Train Avg loss: 0.00584, Acc: 0.97054, F1: 0.97057#####> Valid Avg loss: 0.74522, Acc:0.33447, F1: 0.33457
====> Epoch: 454 Train Avg loss: 0.00590, Acc: 0.97083, F1: 0.97086#####> Valid Avg loss: 0.66657, Acc:0.31908, F1: 0.31918
====> Epoch: 455 Train Avg loss: 0.00694, Acc: 0.96980, F1: 0.96984#####> Valid Avg loss: 0.70400, Acc:0.32421, F1: 0.32431
====> Epoch: 456 Train Avg loss: 0.00562, Acc: 0.97171, F1: 0.97174#####> Valid Avg loss: 0.67555, Acc:0.33704, F1: 0.33704
====> Epoch: 457 Train Avg loss: 0.00432, Acc: 0.97611, F1: 0.97613#####> Valid Avg loss: 0.69639, Acc:0.31309, F1: 0.31320
====> Epoch: 458 Train Avg loss: 0.00682, Acc: 0.96790, F1: 0.96794#####> Valid Avg loss: 0.70934, Acc:0.28999, F1: 0.28993
====> Epoch: 459 Train Avg loss: 0.00618, Acc: 0.97024, F1: 0.97028#####> Valid Avg loss: 0.76300, Acc:0.33020, F1: 0.33039
====> Epoch: 460 Train Avg loss: 0.00797, Acc: 0.96453, F1: 0.96457#####> Valid Avg loss: 0.70762, Acc:0.29769, F1: 0.29763
====> Epoch: 461 Train Avg loss: 0.00506, Acc: 0.97318, F1: 0.97321#####> Valid Avg loss: 0.66969, Acc:0.29598, F1: 0.29582
====> Epoch: 462 Train Avg loss: 0.00507, Acc: 0.97259, F1: 0.97262#####> Valid Avg loss: 0.65682, Acc:0.31480, F1: 0.31472
====> Epoch: 463 Train Avg loss: 0.00335, Acc: 0.97816, F1: 0.97818#####> Valid Avg loss: 0.69765, Acc:0.32678, F1: 0.32678
====> Epoch: 464 Train Avg loss: 0.00734, Acc: 0.96599, F1: 0.96603#####> Valid Avg loss: 0.70397, Acc:0.33020, F1: 0.33029
====> Epoch: 465 Train Avg loss: 0.00805, Acc: 0.96629, F1: 0.96633#####> Valid Avg loss: 0.62624, Acc:0.34303, F1: 0.34321
====> Epoch: 466 Train Avg loss: 0.00534, Acc: 0.97244, F1: 0.97247#####> Valid Avg loss: 0.66674, Acc:0.29598, F1: 0.29601
====> Epoch: 467 Train Avg loss: 0.00394, Acc: 0.97787, F1: 0.97789#####> Valid Avg loss: 0.68264, Acc:0.31138, F1: 0.31130
====> Epoch: 468 Train Avg loss: 0.00582, Acc: 0.96980, F1: 0.96984#####> Valid Avg loss: 0.79892, Acc:0.33704, F1: 0.33704
====> Epoch: 469 Train Avg loss: 0.00582, Acc: 0.97230, F1: 0.97233#####> Valid Avg loss: 0.70989, Acc:0.33276, F1: 0.33295
====> Epoch: 470 Train Avg loss: 0.00530, Acc: 0.97405, F1: 0.97408#####> Valid Avg loss: 0.68999, Acc:0.32250, F1: 0.32232
====> Epoch: 471 Train Avg loss: 0.00465, Acc: 0.97112, F1: 0.97116#####> Valid Avg loss: 0.77620, Acc:0.34217, F1: 0.34226
====> Epoch: 472 Train Avg loss: 0.00590, Acc: 0.97332, F1: 0.97335#####> Valid Avg loss: 0.68405, Acc:0.31223, F1: 0.31244
====> Epoch: 473 Train Avg loss: 0.00421, Acc: 0.97537, F1: 0.97540#####> Valid Avg loss: 0.76508, Acc:0.31822, F1: 0.31823
====> Epoch: 474 Train Avg loss: 0.00743, Acc: 0.96878, F1: 0.96881#####> Valid Avg loss: 0.69287, Acc:0.32592, F1: 0.32583
====> Epoch: 475 Train Avg loss: 0.00527, Acc: 0.97391, F1: 0.97394#####> Valid Avg loss: 0.73673, Acc:0.30111, F1: 0.30114
====> Epoch: 476 Train Avg loss: 0.00475, Acc: 0.97171, F1: 0.97174#####> Valid Avg loss: 0.76845, Acc:0.29940, F1: 0.29953
====> Epoch: 477 Train Avg loss: 0.00502, Acc: 0.97259, F1: 0.97262#####> Valid Avg loss: 0.76761, Acc:0.27630, F1: 0.27626
====> Epoch: 478 Train Avg loss: 0.00525, Acc: 0.97391, F1: 0.97394#####> Valid Avg loss: 0.76176, Acc:0.32079, F1: 0.32089
====> Epoch: 479 Train Avg loss: 0.00382, Acc: 0.97699, F1: 0.97701#####> Valid Avg loss: 0.78686, Acc:0.28999, F1: 0.29003
====> Epoch: 480 Train Avg loss: 0.00539, Acc: 0.97186, F1: 0.97189#####> Valid Avg loss: 0.72923, Acc:0.30368, F1: 0.30351
====> Epoch: 481 Train Avg loss: 0.00443, Acc: 0.97699, F1: 0.97701#####> Valid Avg loss: 0.74299, Acc:0.29683, F1: 0.29668
====> Epoch: 482 Train Avg loss: 0.00601, Acc: 0.96951, F1: 0.96896#####> Valid Avg loss: 0.82179, Acc:0.27117, F1: 0.27142
====> Epoch: 483 Train Avg loss: 0.00712, Acc: 0.96585, F1: 0.96589#####> Valid Avg loss: 0.70213, Acc:0.28914, F1: 0.28898
====> Epoch: 484 Train Avg loss: 0.00373, Acc: 0.97581, F1: 0.97584#####> Valid Avg loss: 0.77826, Acc:0.28657, F1: 0.28642
====> Epoch: 485 Train Avg loss: 0.00591, Acc: 0.97200, F1: 0.97204#####> Valid Avg loss: 0.69625, Acc:0.28315, F1: 0.28300
====> Epoch: 486 Train Avg loss: 0.00481, Acc: 0.97479, F1: 0.97482#####> Valid Avg loss: 0.73879, Acc:0.26861, F1: 0.26857
====> Epoch: 487 Train Avg loss: 0.00376, Acc: 0.97537, F1: 0.97540#####> Valid Avg loss: 0.74416, Acc:0.27887, F1: 0.27873
====> Epoch: 488 Train Avg loss: 0.00455, Acc: 0.97361, F1: 0.97365#####> Valid Avg loss: 0.82847, Acc:0.27545, F1: 0.27550
====> Epoch: 489 Train Avg loss: 0.00362, Acc: 0.97933, F1: 0.97877#####> Valid Avg loss: 0.69506, Acc:0.29855, F1: 0.29858
====> Epoch: 490 Train Avg loss: 0.00702, Acc: 0.96673, F1: 0.96676#####> Valid Avg loss: 0.72789, Acc:0.31394, F1: 0.31396
====> Epoch: 491 Train Avg loss: 0.00478, Acc: 0.97464, F1: 0.97467#####> Valid Avg loss: 0.71356, Acc:0.31993, F1: 0.31985
====> Epoch: 492 Train Avg loss: 0.00337, Acc: 0.97713, F1: 0.97716#####> Valid Avg loss: 0.78329, Acc:0.29256, F1: 0.29250
====> Epoch: 493 Train Avg loss: 0.00559, Acc: 0.96966, F1: 0.96911#####> Valid Avg loss: 0.78831, Acc:0.33020, F1: 0.33020
====> Epoch: 494 Train Avg loss: 0.00570, Acc: 0.97024, F1: 0.97028#####> Valid Avg loss: 0.68897, Acc:0.31480, F1: 0.31481
====> Epoch: 495 Train Avg loss: 0.00395, Acc: 0.97743, F1: 0.97745#####> Valid Avg loss: 0.72692, Acc:0.28999, F1: 0.29003
====> Epoch: 496 Train Avg loss: 0.00452, Acc: 0.97523, F1: 0.97526#####> Valid Avg loss: 0.71076, Acc:0.31394, F1: 0.31415
====> Epoch: 497 Train Avg loss: 0.00332, Acc: 0.97787, F1: 0.97789#####> Valid Avg loss: 0.77241, Acc:0.32763, F1: 0.32773
====> Epoch: 498 Train Avg loss: 0.00506, Acc: 0.97200, F1: 0.97204#####> Valid Avg loss: 0.75589, Acc:0.32849, F1: 0.32849
====> Epoch: 499 Train Avg loss: 0.00407, Acc: 0.97713, F1: 0.97716#####> Valid Avg loss: 0.80816, Acc:0.28400, F1: 0.28395
====> Epoch: 500 Train Avg loss: 0.00563, Acc: 0.96819, F1: 0.96823#####> Valid Avg loss: 0.72425, Acc:0.29170, F1: 0.29183
#####> Valid Avg loss: 1.48431, Acc:0.22933, F1: 0.22994


$$$$$$> Test it 1: (from train best model) Final Test Avg loss:1.48431, Acc:0.22933, F1:0.22994\n
#####> Valid Avg loss: 0.49305, Acc:0.26598, F1: 0.26836


$$$$$$> Test it 1: (from max acc valid model) Final Test Avg loss:0.49305, Acc:0.26598, F1:0.26836\n
#####> Valid Avg loss: 0.29593, Acc:0.29838, F1: 0.30056


$$$$$$> Test it 1: (from min loss valid model) Final Test Avg loss:0.29593, Acc:0.29838, F1:0.30056\n


	Start execution training validation it 2 

train_dataloader len: 683
valid_dataloader len: 118
test_dataloader len: 117
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [1]
test performers ids: [2]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1173, valid dataloader len: 118
valid dataset len: 1169, test dataloader len: 118
====> Epoch: 1 Train Avg loss: 0.18488, Acc: 0.41146, F1: 0.41157#####> Valid Avg loss: 0.39437, Acc:0.19608, F1: 0.19887
===> Epoch: 1: Training loss decreased (inf --> 0.18488), Acc: (0.00000 --> 0.41146), F1: (0.00000 --> 0.41157).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2

####> Epoch: 1: validation loss decreased (inf --> 0.39437), Acc: (0.00000 --> 0.19608), F1: (0.00000 --> 0.19887).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2

####> Epoch: 1: validation acc increase (inf --> 0.39437), Acc: (0.00000 --> 0.19608), F1: (0.00000 --> 0.19887).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 2 Train Avg loss: 0.14323, Acc: 0.57095, F1: 0.57145#####> Valid Avg loss: 0.38478, Acc:0.15345, F1: 0.15452
===> Epoch: 2: Training loss decreased (0.18488 --> 0.14323), Acc: (0.41146 --> 0.57095), F1: (0.41157 --> 0.57145).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2

####> Epoch: 2: validation loss decreased (0.39437 --> 0.38478), Acc: (0.19608 --> 0.15345), F1: (0.19887 --> 0.15452).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 3 Train Avg loss: 0.13163, Acc: 0.60070, F1: 0.60117#####> Valid Avg loss: 0.38572, Acc:0.20205, F1: 0.20282
===> Epoch: 3: Training loss decreased (0.14323 --> 0.13163), Acc: (0.57095 --> 0.60070), F1: (0.57145 --> 0.60117).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2

####> Epoch: 3: validation acc increase (0.39437 --> 0.38572), Acc: (0.19608 --> 0.20205), F1: (0.19887 --> 0.20282).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 4 Train Avg loss: 0.12322, Acc: 0.61947, F1: 0.61933#####> Valid Avg loss: 0.38034, Acc:0.26598, F1: 0.26836
===> Epoch: 4: Training loss decreased (0.13163 --> 0.12322), Acc: (0.60070 --> 0.61947), F1: (0.60117 --> 0.61933).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2

####> Epoch: 4: validation loss decreased (0.38478 --> 0.38034), Acc: (0.15345 --> 0.26598), F1: (0.15452 --> 0.26836).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2

####> Epoch: 4: validation acc increase (0.38572 --> 0.38034), Acc: (0.20205 --> 0.26598), F1: (0.20282 --> 0.26836).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 5 Train Avg loss: 0.11829, Acc: 0.62504, F1: 0.62548#####> Valid Avg loss: 0.39938, Acc:0.28986, F1: 0.29209
===> Epoch: 5: Training loss decreased (0.12322 --> 0.11829), Acc: (0.61947 --> 0.62504), F1: (0.61933 --> 0.62548).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2

####> Epoch: 5: validation acc increase (0.38034 --> 0.39938), Acc: (0.26598 --> 0.28986), F1: (0.26836 --> 0.29209).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 6 Train Avg loss: 0.11349, Acc: 0.63896, F1: 0.63821#####> Valid Avg loss: 0.37241, Acc:0.25490, F1: 0.25734
===> Epoch: 6: Training loss decreased (0.11829 --> 0.11349), Acc: (0.62504 --> 0.63896), F1: (0.62548 --> 0.63821).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2

####> Epoch: 6: validation loss decreased (0.38034 --> 0.37241), Acc: (0.26598 --> 0.25490), F1: (0.26836 --> 0.25734).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 7 Train Avg loss: 0.11158, Acc: 0.64527, F1: 0.64510#####> Valid Avg loss: 0.41854, Acc:0.28218, F1: 0.28446
===> Epoch: 7: Training loss decreased (0.11349 --> 0.11158), Acc: (0.63896 --> 0.64527), F1: (0.63821 --> 0.64510).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 8 Train Avg loss: 0.10619, Acc: 0.65904, F1: 0.65944#####> Valid Avg loss: 0.45408, Acc:0.29668, F1: 0.29887
===> Epoch: 8: Training loss decreased (0.11158 --> 0.10619), Acc: (0.64527 --> 0.65904), F1: (0.64510 --> 0.65944).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2

####> Epoch: 8: validation acc increase (0.39938 --> 0.45408), Acc: (0.28986 --> 0.29668), F1: (0.29209 --> 0.29887).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 9 Train Avg loss: 0.10440, Acc: 0.66330, F1: 0.66369#####> Valid Avg loss: 0.44340, Acc:0.27621, F1: 0.27853
===> Epoch: 9: Training loss decreased (0.10619 --> 0.10440), Acc: (0.65904 --> 0.66330), F1: (0.65944 --> 0.66369).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 10 Train Avg loss: 0.09998, Acc: 0.67106, F1: 0.67145#####> Valid Avg loss: 0.43938, Acc:0.27792, F1: 0.28023
===> Epoch: 10: Training loss decreased (0.10440 --> 0.09998), Acc: (0.66330 --> 0.67106), F1: (0.66369 --> 0.67145).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 11 Train Avg loss: 0.09844, Acc: 0.67971, F1: 0.67892#####> Valid Avg loss: 0.48258, Acc:0.20887, F1: 0.21158
===> Epoch: 11: Training loss decreased (0.09998 --> 0.09844), Acc: (0.67106 --> 0.67971), F1: (0.67145 --> 0.67892).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 12 Train Avg loss: 0.09673, Acc: 0.68001, F1: 0.68038#####> Valid Avg loss: 0.48532, Acc:0.27366, F1: 0.27599
===> Epoch: 12: Training loss decreased (0.09844 --> 0.09673), Acc: (0.67971 --> 0.68001), F1: (0.67892 --> 0.68038).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 13 Train Avg loss: 0.09386, Acc: 0.69217, F1: 0.69136#####> Valid Avg loss: 0.44632, Acc:0.27110, F1: 0.27345
===> Epoch: 13: Training loss decreased (0.09673 --> 0.09386), Acc: (0.68001 --> 0.69217), F1: (0.68038 --> 0.69136).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 14 Train Avg loss: 0.09037, Acc: 0.70009, F1: 0.70044#####> Valid Avg loss: 0.39659, Acc:0.27536, F1: 0.27768
===> Epoch: 14: Training loss decreased (0.09386 --> 0.09037), Acc: (0.69217 --> 0.70009), F1: (0.69136 --> 0.70044).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 15 Train Avg loss: 0.09027, Acc: 0.70141, F1: 0.70176#####> Valid Avg loss: 0.44083, Acc:0.24552, F1: 0.24802
===> Epoch: 15: Training loss decreased (0.09037 --> 0.09027), Acc: (0.70009 --> 0.70141), F1: (0.70044 --> 0.70176).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 16 Train Avg loss: 0.08886, Acc: 0.70419, F1: 0.70454#####> Valid Avg loss: 0.41565, Acc:0.24552, F1: 0.24802
===> Epoch: 16: Training loss decreased (0.09027 --> 0.08886), Acc: (0.70141 --> 0.70419), F1: (0.70176 --> 0.70454).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 17 Train Avg loss: 0.08501, Acc: 0.71695, F1: 0.71728#####> Valid Avg loss: 0.46626, Acc:0.27280, F1: 0.27514
===> Epoch: 17: Training loss decreased (0.08886 --> 0.08501), Acc: (0.70419 --> 0.71695), F1: (0.70454 --> 0.71728).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 18 Train Avg loss: 0.08270, Acc: 0.72017, F1: 0.71933#####> Valid Avg loss: 0.47037, Acc:0.25916, F1: 0.26158
===> Epoch: 18: Training loss decreased (0.08501 --> 0.08270), Acc: (0.71695 --> 0.72017), F1: (0.71728 --> 0.71933).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 19 Train Avg loss: 0.08139, Acc: 0.72662, F1: 0.72694#####> Valid Avg loss: 0.48034, Acc:0.27621, F1: 0.27853
===> Epoch: 19: Training loss decreased (0.08270 --> 0.08139), Acc: (0.72017 --> 0.72662), F1: (0.71933 --> 0.72694).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 20 Train Avg loss: 0.07913, Acc: 0.72897, F1: 0.72870#####> Valid Avg loss: 0.48316, Acc:0.25405, F1: 0.25650
===> Epoch: 20: Training loss decreased (0.08139 --> 0.07913), Acc: (0.72662 --> 0.72897), F1: (0.72694 --> 0.72870).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 21 Train Avg loss: 0.07728, Acc: 0.73571, F1: 0.73543#####> Valid Avg loss: 0.49811, Acc:0.25490, F1: 0.25734
===> Epoch: 21: Training loss decreased (0.07913 --> 0.07728), Acc: (0.72897 --> 0.73571), F1: (0.72870 --> 0.73543).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 22 Train Avg loss: 0.07623, Acc: 0.73893, F1: 0.73924#####> Valid Avg loss: 0.51263, Acc:0.25661, F1: 0.25904
===> Epoch: 22: Training loss decreased (0.07728 --> 0.07623), Acc: (0.73571 --> 0.73893), F1: (0.73543 --> 0.73924).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 23 Train Avg loss: 0.07399, Acc: 0.73937, F1: 0.73909#####> Valid Avg loss: 0.47454, Acc:0.27110, F1: 0.27345
===> Epoch: 23: Training loss decreased (0.07623 --> 0.07399), Acc: (0.73893 --> 0.73937), F1: (0.73924 --> 0.73909).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 24 Train Avg loss: 0.07062, Acc: 0.74993, F1: 0.74905#####> Valid Avg loss: 0.48045, Acc:0.23870, F1: 0.24124
===> Epoch: 24: Training loss decreased (0.07399 --> 0.07062), Acc: (0.73937 --> 0.74993), F1: (0.73909 --> 0.74905).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 25 Train Avg loss: 0.06981, Acc: 0.75960, F1: 0.75930#####> Valid Avg loss: 0.50296, Acc:0.29241, F1: 0.29463
===> Epoch: 25: Training loss decreased (0.07062 --> 0.06981), Acc: (0.74993 --> 0.75960), F1: (0.74905 --> 0.75930).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 26 Train Avg loss: 0.06879, Acc: 0.76634, F1: 0.76662#####> Valid Avg loss: 0.50989, Acc:0.28133, F1: 0.28362
===> Epoch: 26: Training loss decreased (0.06981 --> 0.06879), Acc: (0.75960 --> 0.76634), F1: (0.75930 --> 0.76662).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 27 Train Avg loss: 0.06578, Acc: 0.76972, F1: 0.76940#####> Valid Avg loss: 0.55535, Acc:0.27792, F1: 0.28023
===> Epoch: 27: Training loss decreased (0.06879 --> 0.06578), Acc: (0.76634 --> 0.76972), F1: (0.76662 --> 0.76940).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 28 Train Avg loss: 0.06374, Acc: 0.77045, F1: 0.77072#####> Valid Avg loss: 0.51477, Acc:0.27877, F1: 0.28107
===> Epoch: 28: Training loss decreased (0.06578 --> 0.06374), Acc: (0.76972 --> 0.77045), F1: (0.76940 --> 0.77072).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 29 Train Avg loss: 0.06031, Acc: 0.78100, F1: 0.78126#####> Valid Avg loss: 0.57740, Acc:0.25661, F1: 0.25904
===> Epoch: 29: Training loss decreased (0.06374 --> 0.06031), Acc: (0.77045 --> 0.78100), F1: (0.77072 --> 0.78126).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 30 Train Avg loss: 0.05863, Acc: 0.78819, F1: 0.78843#####> Valid Avg loss: 0.56479, Acc:0.18755, F1: 0.18842
===> Epoch: 30: Training loss decreased (0.06031 --> 0.05863), Acc: (0.78100 --> 0.78819), F1: (0.78126 --> 0.78843).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 31 Train Avg loss: 0.05594, Acc: 0.79859, F1: 0.79883#####> Valid Avg loss: 0.67102, Acc:0.21057, F1: 0.21328
===> Epoch: 31: Training loss decreased (0.05863 --> 0.05594), Acc: (0.78819 --> 0.79859), F1: (0.78843 --> 0.79883).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 32 Train Avg loss: 0.05228, Acc: 0.80900, F1: 0.80864#####> Valid Avg loss: 0.61607, Acc:0.23956, F1: 0.24209
===> Epoch: 32: Training loss decreased (0.05594 --> 0.05228), Acc: (0.79859 --> 0.80900), F1: (0.79883 --> 0.80864).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 33 Train Avg loss: 0.05004, Acc: 0.82234, F1: 0.82196#####> Valid Avg loss: 0.62941, Acc:0.24552, F1: 0.24802
===> Epoch: 33: Training loss decreased (0.05228 --> 0.05004), Acc: (0.80900 --> 0.82234), F1: (0.80864 --> 0.82196).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 34 Train Avg loss: 0.04742, Acc: 0.83201, F1: 0.83163#####> Valid Avg loss: 0.65068, Acc:0.19096, F1: 0.19379
===> Epoch: 34: Training loss decreased (0.05004 --> 0.04742), Acc: (0.82234 --> 0.83201), F1: (0.82196 --> 0.83163).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 35 Train Avg loss: 0.04487, Acc: 0.83187, F1: 0.83148#####> Valid Avg loss: 0.69716, Acc:0.24382, F1: 0.24633
===> Epoch: 35: Training loss decreased (0.04742 --> 0.04487), Acc: (0.83201 --> 0.83187), F1: (0.83163 --> 0.83148).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 36 Train Avg loss: 0.04200, Acc: 0.84228, F1: 0.84246#####> Valid Avg loss: 0.74953, Acc:0.24638, F1: 0.24887
===> Epoch: 36: Training loss decreased (0.04487 --> 0.04200), Acc: (0.83187 --> 0.84228), F1: (0.83148 --> 0.84246).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 37 Train Avg loss: 0.03988, Acc: 0.85063, F1: 0.85081#####> Valid Avg loss: 0.70528, Acc:0.21910, F1: 0.22175
===> Epoch: 37: Training loss decreased (0.04200 --> 0.03988), Acc: (0.84228 --> 0.85063), F1: (0.84246 --> 0.85081).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
====> Epoch: 38 Train Avg loss: 0.03820, Acc: 0.85825, F1: 0.85725#####> Valid Avg loss: 0.65342, Acc:0.26854, F1: 0.27090
===> Epoch: 38: Training loss decreased (0.03988 --> 0.03820), Acc: (0.85063 --> 0.85825), F1: (0.85081 --> 0.85725).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596245738.978848.pth_2
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596777388.468318.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596777461.914952.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596777828.586134.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6823, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1174, test dataloader len: 117
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596778686.030659.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1174, test dataloader len: 117
====> Epoch: 1 Train Avg loss: 0.17930, Acc: 0.45925, F1: 0.45930#####> Valid Avg loss: 0.35130, Acc:0.33105, F1: 0.33124
===> Epoch: 1: Training loss decreased (inf --> 0.17930), Acc: (0.00000 --> 0.45925), F1: (0.00000 --> 0.45930).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596778686.030659.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.35130), Acc: (0.00000 --> 0.33105), F1: (0.00000 --> 0.33124).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596778686.030659.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.35130), Acc: (0.00000 --> 0.33105), F1: (0.00000 --> 0.33124).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596778686.030659.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596828575.883167.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6823, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1174, test dataloader len: 117
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596836142.217987.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1174, test dataloader len: 117
====> Epoch: 1 Train Avg loss: 0.17403, Acc: 0.49208, F1: 0.49268#####> Valid Avg loss: 0.31901, Acc:0.22669, F1: 0.22659
===> Epoch: 1: Training loss decreased (inf --> 0.17403), Acc: (0.00000 --> 0.49208), F1: (0.00000 --> 0.49268).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.31901), Acc: (0.00000 --> 0.22669), F1: (0.00000 --> 0.22659).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.31901), Acc: (0.00000 --> 0.22669), F1: (0.00000 --> 0.22659).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 2 Train Avg loss: 0.14475, Acc: 0.58619, F1: 0.58668#####> Valid Avg loss: 0.28565, Acc:0.26518, F1: 0.26543
===> Epoch: 2: Training loss decreased (0.17403 --> 0.14475), Acc: (0.49208 --> 0.58619), F1: (0.49268 --> 0.58668).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1

####> Epoch: 2: validation loss decreased (0.31901 --> 0.28565), Acc: (0.22669 --> 0.26518), F1: (0.22659 --> 0.26543).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1

####> Epoch: 2: validation acc increase (0.31901 --> 0.28565), Acc: (0.22669 --> 0.26518), F1: (0.22659 --> 0.26543).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 3 Train Avg loss: 0.13175, Acc: 0.62680, F1: 0.62723#####> Valid Avg loss: 0.32570, Acc:0.23353, F1: 0.23381
===> Epoch: 3: Training loss decreased (0.14475 --> 0.13175), Acc: (0.58619 --> 0.62680), F1: (0.58668 --> 0.62723).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 4 Train Avg loss: 0.12413, Acc: 0.64087, F1: 0.64012#####> Valid Avg loss: 0.26465, Acc:0.34303, F1: 0.34321
===> Epoch: 4: Training loss decreased (0.13175 --> 0.12413), Acc: (0.62680 --> 0.64087), F1: (0.62723 --> 0.64012).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1

####> Epoch: 4: validation loss decreased (0.28565 --> 0.26465), Acc: (0.26518 --> 0.34303), F1: (0.26543 --> 0.34321).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1

####> Epoch: 4: validation acc increase (0.28565 --> 0.26465), Acc: (0.26518 --> 0.34303), F1: (0.26543 --> 0.34321).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 5 Train Avg loss: 0.12267, Acc: 0.64922, F1: 0.64846#####> Valid Avg loss: 0.30855, Acc:0.38837, F1: 0.38851
===> Epoch: 5: Training loss decreased (0.12413 --> 0.12267), Acc: (0.64087 --> 0.64922), F1: (0.64012 --> 0.64846).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1

####> Epoch: 5: validation acc increase (0.26465 --> 0.30855), Acc: (0.34303 --> 0.38837), F1: (0.34321 --> 0.38851).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 6 Train Avg loss: 0.11425, Acc: 0.66080, F1: 0.66120#####> Valid Avg loss: 0.27051, Acc:0.36270, F1: 0.36287
===> Epoch: 6: Training loss decreased (0.12267 --> 0.11425), Acc: (0.64922 --> 0.66080), F1: (0.64846 --> 0.66120).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 7 Train Avg loss: 0.10861, Acc: 0.67575, F1: 0.67555#####> Valid Avg loss: 0.31142, Acc:0.31993, F1: 0.32004
===> Epoch: 7: Training loss decreased (0.11425 --> 0.10861), Acc: (0.66080 --> 0.67575), F1: (0.66120 --> 0.67555).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 8 Train Avg loss: 0.10563, Acc: 0.68206, F1: 0.68243#####> Valid Avg loss: 0.29593, Acc:0.38067, F1: 0.38082
===> Epoch: 8: Training loss decreased (0.10861 --> 0.10563), Acc: (0.67575 --> 0.68206), F1: (0.67555 --> 0.68243).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 9 Train Avg loss: 0.10317, Acc: 0.68719, F1: 0.68697#####> Valid Avg loss: 0.29117, Acc:0.35843, F1: 0.35859
===> Epoch: 9: Training loss decreased (0.10563 --> 0.10317), Acc: (0.68206 --> 0.68719), F1: (0.68243 --> 0.68697).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 10 Train Avg loss: 0.09812, Acc: 0.70126, F1: 0.70161#####> Valid Avg loss: 0.28494, Acc:0.37639, F1: 0.37654
===> Epoch: 10: Training loss decreased (0.10317 --> 0.09812), Acc: (0.68719 --> 0.70126), F1: (0.68697 --> 0.70161).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 11 Train Avg loss: 0.09655, Acc: 0.70537, F1: 0.70512#####> Valid Avg loss: 0.31181, Acc:0.32506, F1: 0.32526
===> Epoch: 11: Training loss decreased (0.09812 --> 0.09655), Acc: (0.70126 --> 0.70537), F1: (0.70161 --> 0.70512).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 12 Train Avg loss: 0.09450, Acc: 0.70361, F1: 0.70337#####> Valid Avg loss: 0.30241, Acc:0.18905, F1: 0.18917
===> Epoch: 12: Training loss decreased (0.09655 --> 0.09450), Acc: (0.70537 --> 0.70361), F1: (0.70512 --> 0.70337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 13 Train Avg loss: 0.08882, Acc: 0.72193, F1: 0.72225#####> Valid Avg loss: 0.29224, Acc:0.24636, F1: 0.24663
===> Epoch: 13: Training loss decreased (0.09450 --> 0.08882), Acc: (0.70361 --> 0.72193), F1: (0.70337 --> 0.72225).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 14 Train Avg loss: 0.08878, Acc: 0.72545, F1: 0.72577#####> Valid Avg loss: 0.27771, Acc:0.35928, F1: 0.35945
===> Epoch: 14: Training loss decreased (0.08882 --> 0.08878), Acc: (0.72193 --> 0.72545), F1: (0.72225 --> 0.72577).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 15 Train Avg loss: 0.08425, Acc: 0.73248, F1: 0.73280#####> Valid Avg loss: 0.31431, Acc:0.22327, F1: 0.22327
===> Epoch: 15: Training loss decreased (0.08878 --> 0.08425), Acc: (0.72545 --> 0.73248), F1: (0.72577 --> 0.73280).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 16 Train Avg loss: 0.08326, Acc: 0.73512, F1: 0.73485#####> Valid Avg loss: 0.29159, Acc:0.29855, F1: 0.29858
===> Epoch: 16: Training loss decreased (0.08425 --> 0.08326), Acc: (0.73248 --> 0.73512), F1: (0.73280 --> 0.73485).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 17 Train Avg loss: 0.08106, Acc: 0.74025, F1: 0.73997#####> Valid Avg loss: 0.30539, Acc:0.28486, F1: 0.28500
===> Epoch: 17: Training loss decreased (0.08326 --> 0.08106), Acc: (0.73512 --> 0.74025), F1: (0.73485 --> 0.73997).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 18 Train Avg loss: 0.07880, Acc: 0.75095, F1: 0.75124#####> Valid Avg loss: 0.28671, Acc:0.28657, F1: 0.28680
===> Epoch: 18: Training loss decreased (0.08106 --> 0.07880), Acc: (0.74025 --> 0.75095), F1: (0.73997 --> 0.75124).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 19 Train Avg loss: 0.07333, Acc: 0.76502, F1: 0.76413#####> Valid Avg loss: 0.31125, Acc:0.26861, F1: 0.26885
===> Epoch: 19: Training loss decreased (0.07880 --> 0.07333), Acc: (0.75095 --> 0.76502), F1: (0.75124 --> 0.76413).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 20 Train Avg loss: 0.07254, Acc: 0.76796, F1: 0.76764#####> Valid Avg loss: 0.30424, Acc:0.31309, F1: 0.31311
===> Epoch: 20: Training loss decreased (0.07333 --> 0.07254), Acc: (0.76502 --> 0.76796), F1: (0.76413 --> 0.76764).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 21 Train Avg loss: 0.06997, Acc: 0.77353, F1: 0.77321#####> Valid Avg loss: 0.31311, Acc:0.37040, F1: 0.37056
===> Epoch: 21: Training loss decreased (0.07254 --> 0.06997), Acc: (0.76796 --> 0.77353), F1: (0.76764 --> 0.77321).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 22 Train Avg loss: 0.06942, Acc: 0.77558, F1: 0.77584#####> Valid Avg loss: 0.31644, Acc:0.32164, F1: 0.32184
===> Epoch: 22: Training loss decreased (0.06997 --> 0.06942), Acc: (0.77353 --> 0.77558), F1: (0.77321 --> 0.77584).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 23 Train Avg loss: 0.06412, Acc: 0.79801, F1: 0.79766#####> Valid Avg loss: 0.34649, Acc:0.30282, F1: 0.30313
===> Epoch: 23: Training loss decreased (0.06942 --> 0.06412), Acc: (0.77558 --> 0.79801), F1: (0.77584 --> 0.79766).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 24 Train Avg loss: 0.06721, Acc: 0.77983, F1: 0.77892#####> Valid Avg loss: 0.35862, Acc:0.21899, F1: 0.21909
====> Epoch: 25 Train Avg loss: 0.06174, Acc: 0.80753, F1: 0.80717#####> Valid Avg loss: 0.32437, Acc:0.24636, F1: 0.24672
===> Epoch: 25: Training loss decreased (0.06412 --> 0.06174), Acc: (0.79801 --> 0.80753), F1: (0.79766 --> 0.80717).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 26 Train Avg loss: 0.05940, Acc: 0.81032, F1: 0.80996#####> Valid Avg loss: 0.33725, Acc:0.24038, F1: 0.24055
===> Epoch: 26: Training loss decreased (0.06174 --> 0.05940), Acc: (0.80753 --> 0.81032), F1: (0.80717 --> 0.80996).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 27 Train Avg loss: 0.05949, Acc: 0.80680, F1: 0.80644#####> Valid Avg loss: 0.34589, Acc:0.27117, F1: 0.27151
====> Epoch: 28 Train Avg loss: 0.05433, Acc: 0.82938, F1: 0.82958#####> Valid Avg loss: 0.37247, Acc:0.21471, F1: 0.21510
===> Epoch: 28: Training loss decreased (0.05940 --> 0.05433), Acc: (0.81032 --> 0.82938), F1: (0.80996 --> 0.82958).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 29 Train Avg loss: 0.05188, Acc: 0.83495, F1: 0.83455#####> Valid Avg loss: 0.39120, Acc:0.23524, F1: 0.23542
===> Epoch: 29: Training loss decreased (0.05433 --> 0.05188), Acc: (0.82938 --> 0.83495), F1: (0.82958 --> 0.83455).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
====> Epoch: 30 Train Avg loss: 0.05131, Acc: 0.83758, F1: 0.83719#####> Valid Avg loss: 0.37930, Acc:0.24722, F1: 0.24758
===> Epoch: 30: Training loss decreased (0.05188 --> 0.05131), Acc: (0.83495 --> 0.83758), F1: (0.83455 --> 0.83719).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1596836220.789386.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597114749.855451.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1174, test dataloader len: 117
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:False,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597117709.013554.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1174, test dataloader len: 117
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597117988.055374.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
====> Epoch: 1 Train Avg loss: 0.29443, Acc: 0.26517, F1: 0.26545#####> Valid Avg loss: 0.30257, Acc:0.37382, F1: 0.37398
===> Epoch: 1: Training loss decreased (inf --> 0.29443), Acc: (0.00000 --> 0.26517), F1: (0.00000 --> 0.26545).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.30257), Acc: (0.00000 --> 0.37382), F1: (0.00000 --> 0.37398).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.30257), Acc: (0.00000 --> 0.37382), F1: (0.00000 --> 0.37398).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 2 Train Avg loss: 0.21429, Acc: 0.44591, F1: 0.44656#####> Valid Avg loss: 0.31080, Acc:0.14970, F1: 0.14976
===> Epoch: 2: Training loss decreased (0.29443 --> 0.21429), Acc: (0.26517 --> 0.44591), F1: (0.26545 --> 0.44656).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 3 Train Avg loss: 0.18250, Acc: 0.52433, F1: 0.52430#####> Valid Avg loss: 0.29472, Acc:0.26604, F1: 0.26619
===> Epoch: 3: Training loss decreased (0.21429 --> 0.18250), Acc: (0.44591 --> 0.52433), F1: (0.44656 --> 0.52430).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1

####> Epoch: 3: validation loss decreased (0.30257 --> 0.29472), Acc: (0.37382 --> 0.26604), F1: (0.37398 --> 0.26619).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 4 Train Avg loss: 0.16926, Acc: 0.55585, F1: 0.55578#####> Valid Avg loss: 0.28581, Acc:0.33875, F1: 0.33894
===> Epoch: 4: Training loss decreased (0.18250 --> 0.16926), Acc: (0.52433 --> 0.55585), F1: (0.52430 --> 0.55578).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1

####> Epoch: 4: validation loss decreased (0.29472 --> 0.28581), Acc: (0.26604 --> 0.33875), F1: (0.26619 --> 0.33894).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 5 Train Avg loss: 0.16018, Acc: 0.56699, F1: 0.56633#####> Valid Avg loss: 0.30016, Acc:0.31651, F1: 0.31662
===> Epoch: 5: Training loss decreased (0.16926 --> 0.16018), Acc: (0.55585 --> 0.56699), F1: (0.55578 --> 0.56633).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 6 Train Avg loss: 0.14860, Acc: 0.60144, F1: 0.60190#####> Valid Avg loss: 0.30351, Acc:0.24380, F1: 0.24387
===> Epoch: 6: Training loss decreased (0.16018 --> 0.14860), Acc: (0.56699 --> 0.60144), F1: (0.56633 --> 0.60190).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 7 Train Avg loss: 0.14429, Acc: 0.59909, F1: 0.59898#####> Valid Avg loss: 0.31700, Acc:0.36784, F1: 0.36800
===> Epoch: 7: Training loss decreased (0.14860 --> 0.14429), Acc: (0.60144 --> 0.59909), F1: (0.60190 --> 0.59898).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 8 Train Avg loss: 0.14052, Acc: 0.60525, F1: 0.60571#####> Valid Avg loss: 0.30850, Acc:0.31822, F1: 0.31833
===> Epoch: 8: Training loss decreased (0.14429 --> 0.14052), Acc: (0.59909 --> 0.60525), F1: (0.59898 --> 0.60571).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 9 Train Avg loss: 0.13612, Acc: 0.62020, F1: 0.62064#####> Valid Avg loss: 0.34140, Acc:0.30368, F1: 0.30380
===> Epoch: 9: Training loss decreased (0.14052 --> 0.13612), Acc: (0.60525 --> 0.62020), F1: (0.60571 --> 0.62064).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 10 Train Avg loss: 0.13280, Acc: 0.62636, F1: 0.62621#####> Valid Avg loss: 0.33357, Acc:0.34987, F1: 0.34995
===> Epoch: 10: Training loss decreased (0.13612 --> 0.13280), Acc: (0.62020 --> 0.62636), F1: (0.62064 --> 0.62621).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 11 Train Avg loss: 0.13012, Acc: 0.63281, F1: 0.63324#####> Valid Avg loss: 0.32210, Acc:0.25150, F1: 0.25166
===> Epoch: 11: Training loss decreased (0.13280 --> 0.13012), Acc: (0.62636 --> 0.63281), F1: (0.62621 --> 0.63324).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 12 Train Avg loss: 0.12972, Acc: 0.63750, F1: 0.63734#####> Valid Avg loss: 0.34479, Acc:0.28229, F1: 0.28243
===> Epoch: 12: Training loss decreased (0.13012 --> 0.12972), Acc: (0.63281 --> 0.63750), F1: (0.63324 --> 0.63734).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 13 Train Avg loss: 0.12568, Acc: 0.64351, F1: 0.64275#####> Valid Avg loss: 0.30900, Acc:0.38238, F1: 0.38253
===> Epoch: 13: Training loss decreased (0.12972 --> 0.12568), Acc: (0.63750 --> 0.64351), F1: (0.63734 --> 0.64275).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1

####> Epoch: 13: validation acc increase (0.30257 --> 0.30900), Acc: (0.37382 --> 0.38238), F1: (0.37398 --> 0.38253).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
====> Epoch: 14 Train Avg loss: 0.12428, Acc: 0.64600, F1: 0.64641#####> Valid Avg loss: 0.33215, Acc:0.30111, F1: 0.30123
===> Epoch: 14: Training loss decreased (0.12568 --> 0.12428), Acc: (0.64351 --> 0.64600), F1: (0.64275 --> 0.64641).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597118500.737835.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597125433.855882.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597125571.48326.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597125723.007954.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597125742.562217.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
====> Epoch: 1 Train Avg loss: 0.29806, Acc: 0.26253, F1: 0.26281#####> Valid Avg loss: 0.32070, Acc:0.18820, F1: 0.18841
===> Epoch: 1: Training loss decreased (inf --> 0.29806), Acc: (0.00000 --> 0.26253), F1: (0.00000 --> 0.26281).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.32070), Acc: (0.00000 --> 0.18820), F1: (0.00000 --> 0.18841).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.32070), Acc: (0.00000 --> 0.18820), F1: (0.00000 --> 0.18841).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 2 Train Avg loss: 0.21906, Acc: 0.43521, F1: 0.43529#####> Valid Avg loss: 0.30605, Acc:0.23097, F1: 0.23096
===> Epoch: 2: Training loss decreased (0.29806 --> 0.21906), Acc: (0.26253 --> 0.43521), F1: (0.26281 --> 0.43529).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1

####> Epoch: 2: validation loss decreased (0.32070 --> 0.30605), Acc: (0.18820 --> 0.23097), F1: (0.18841 --> 0.23096).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1

####> Epoch: 2: validation acc increase (0.32070 --> 0.30605), Acc: (0.18820 --> 0.23097), F1: (0.18841 --> 0.23096).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 3 Train Avg loss: 0.18838, Acc: 0.51026, F1: 0.51025#####> Valid Avg loss: 0.30721, Acc:0.23439, F1: 0.23447
===> Epoch: 3: Training loss decreased (0.21906 --> 0.18838), Acc: (0.43521 --> 0.51026), F1: (0.43529 --> 0.51025).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1

####> Epoch: 3: validation acc increase (0.30605 --> 0.30721), Acc: (0.23097 --> 0.23439), F1: (0.23096 --> 0.23447).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 4 Train Avg loss: 0.17001, Acc: 0.55292, F1: 0.55286#####> Valid Avg loss: 0.29270, Acc:0.34388, F1: 0.34406
===> Epoch: 4: Training loss decreased (0.18838 --> 0.17001), Acc: (0.51026 --> 0.55292), F1: (0.51025 --> 0.55286).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1

####> Epoch: 4: validation loss decreased (0.30605 --> 0.29270), Acc: (0.23097 --> 0.34388), F1: (0.23096 --> 0.34406).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1

####> Epoch: 4: validation acc increase (0.30721 --> 0.29270), Acc: (0.23439 --> 0.34388), F1: (0.23447 --> 0.34406).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 5 Train Avg loss: 0.15959, Acc: 0.57637, F1: 0.57687#####> Valid Avg loss: 0.36712, Acc:0.16595, F1: 0.16591
===> Epoch: 5: Training loss decreased (0.17001 --> 0.15959), Acc: (0.55292 --> 0.57637), F1: (0.55286 --> 0.57687).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 6 Train Avg loss: 0.15200, Acc: 0.59059, F1: 0.59048#####> Valid Avg loss: 0.29834, Acc:0.31394, F1: 0.31415
===> Epoch: 6: Training loss decreased (0.15959 --> 0.15200), Acc: (0.57637 --> 0.59059), F1: (0.57687 --> 0.59048).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 7 Train Avg loss: 0.14372, Acc: 0.60539, F1: 0.60586#####> Valid Avg loss: 0.30741, Acc:0.33533, F1: 0.33552
===> Epoch: 7: Training loss decreased (0.15200 --> 0.14372), Acc: (0.59059 --> 0.60539), F1: (0.59048 --> 0.60586).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 8 Train Avg loss: 0.13944, Acc: 0.61595, F1: 0.61581#####> Valid Avg loss: 0.34305, Acc:0.24636, F1: 0.24644
===> Epoch: 8: Training loss decreased (0.14372 --> 0.13944), Acc: (0.60539 --> 0.61595), F1: (0.60586 --> 0.61581).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 9 Train Avg loss: 0.13810, Acc: 0.61961, F1: 0.61947#####> Valid Avg loss: 0.35429, Acc:0.28999, F1: 0.29012
===> Epoch: 9: Training loss decreased (0.13944 --> 0.13810), Acc: (0.61595 --> 0.61961), F1: (0.61581 --> 0.61947).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 10 Train Avg loss: 0.13170, Acc: 0.62709, F1: 0.62694#####> Valid Avg loss: 0.32480, Acc:0.26946, F1: 0.26961
===> Epoch: 10: Training loss decreased (0.13810 --> 0.13170), Acc: (0.61961 --> 0.62709), F1: (0.61947 --> 0.62694).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 11 Train Avg loss: 0.12821, Acc: 0.63896, F1: 0.63939#####> Valid Avg loss: 0.35384, Acc:0.29855, F1: 0.29867
===> Epoch: 11: Training loss decreased (0.13170 --> 0.12821), Acc: (0.62709 --> 0.63896), F1: (0.62694 --> 0.63939).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597125768.41276.pth_1
====> Epoch: 12 Train Avg loss: 0.12822, Acc: 0.63588, F1: 0.63572#####> Valid Avg loss: 0.35166, Acc:0.18221, F1: 0.18215
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
====> Epoch: 1 Train Avg loss: 0.30217, Acc: 0.24919, F1: 0.24949#####> Valid Avg loss: 0.31459, Acc:0.29769, F1: 0.29791
===> Epoch: 1: Training loss decreased (inf --> 0.30217), Acc: (0.00000 --> 0.24919), F1: (0.00000 --> 0.24949).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.31459), Acc: (0.00000 --> 0.29769), F1: (0.00000 --> 0.29791).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.31459), Acc: (0.00000 --> 0.29769), F1: (0.00000 --> 0.29791).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 2 Train Avg loss: 0.22074, Acc: 0.44796, F1: 0.44861#####> Valid Avg loss: 0.29358, Acc:0.28828, F1: 0.28851
===> Epoch: 2: Training loss decreased (0.30217 --> 0.22074), Acc: (0.24919 --> 0.44796), F1: (0.24949 --> 0.44861).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1

####> Epoch: 2: validation loss decreased (0.31459 --> 0.29358), Acc: (0.29769 --> 0.28828), F1: (0.29791 --> 0.28851).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 3 Train Avg loss: 0.19255, Acc: 0.52683, F1: 0.52621#####> Valid Avg loss: 0.36273, Acc:0.05817, F1: 0.05812
===> Epoch: 3: Training loss decreased (0.22074 --> 0.19255), Acc: (0.44796 --> 0.52683), F1: (0.44861 --> 0.52621).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 4 Train Avg loss: 0.17787, Acc: 0.54559, F1: 0.54553#####> Valid Avg loss: 0.28790, Acc:0.30197, F1: 0.30218
===> Epoch: 4: Training loss decreased (0.19255 --> 0.17787), Acc: (0.52683 --> 0.54559), F1: (0.52621 --> 0.54553).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1

####> Epoch: 4: validation loss decreased (0.29358 --> 0.28790), Acc: (0.28828 --> 0.30197), F1: (0.28851 --> 0.30218).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1

####> Epoch: 4: validation acc increase (0.31459 --> 0.28790), Acc: (0.29769 --> 0.30197), F1: (0.29791 --> 0.30218).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 5 Train Avg loss: 0.16280, Acc: 0.58077, F1: 0.58067#####> Valid Avg loss: 0.33257, Acc:0.18648, F1: 0.18642
===> Epoch: 5: Training loss decreased (0.17787 --> 0.16280), Acc: (0.54559 --> 0.58077), F1: (0.54553 --> 0.58067).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 6 Train Avg loss: 0.15543, Acc: 0.58091, F1: 0.58141#####> Valid Avg loss: 0.29467, Acc:0.34132, F1: 0.34150
===> Epoch: 6: Training loss decreased (0.16280 --> 0.15543), Acc: (0.58077 --> 0.58091), F1: (0.58067 --> 0.58141).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1

####> Epoch: 6: validation acc increase (0.28790 --> 0.29467), Acc: (0.30197 --> 0.34132), F1: (0.30218 --> 0.34150).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 7 Train Avg loss: 0.14595, Acc: 0.60715, F1: 0.60703#####> Valid Avg loss: 0.29971, Acc:0.29341, F1: 0.29354
===> Epoch: 7: Training loss decreased (0.15543 --> 0.14595), Acc: (0.58091 --> 0.60715), F1: (0.58141 --> 0.60703).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 8 Train Avg loss: 0.14178, Acc: 0.61390, F1: 0.61376#####> Valid Avg loss: 0.30304, Acc:0.35586, F1: 0.35603
===> Epoch: 8: Training loss decreased (0.14595 --> 0.14178), Acc: (0.60715 --> 0.61390), F1: (0.60703 --> 0.61376).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1

####> Epoch: 8: validation acc increase (0.29467 --> 0.30304), Acc: (0.34132 --> 0.35586), F1: (0.34150 --> 0.35603).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 9 Train Avg loss: 0.13750, Acc: 0.61478, F1: 0.61523#####> Valid Avg loss: 0.31634, Acc:0.30881, F1: 0.30893
===> Epoch: 9: Training loss decreased (0.14178 --> 0.13750), Acc: (0.61390 --> 0.61478), F1: (0.61376 --> 0.61523).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 10 Train Avg loss: 0.13297, Acc: 0.63251, F1: 0.63294#####> Valid Avg loss: 0.33316, Acc:0.28058, F1: 0.28072
===> Epoch: 10: Training loss decreased (0.13750 --> 0.13297), Acc: (0.61478 --> 0.63251), F1: (0.61523 --> 0.63294).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 11 Train Avg loss: 0.13215, Acc: 0.62738, F1: 0.62782#####> Valid Avg loss: 0.31901, Acc:0.38152, F1: 0.38167
===> Epoch: 11: Training loss decreased (0.13297 --> 0.13215), Acc: (0.63251 --> 0.62738), F1: (0.63294 --> 0.62782).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1

####> Epoch: 11: validation acc increase (0.30304 --> 0.31901), Acc: (0.35586 --> 0.38152), F1: (0.35603 --> 0.38167).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 12 Train Avg loss: 0.12669, Acc: 0.64101, F1: 0.64085#####> Valid Avg loss: 0.32535, Acc:0.30796, F1: 0.30807
===> Epoch: 12: Training loss decreased (0.13215 --> 0.12669), Acc: (0.62738 --> 0.64101), F1: (0.62782 --> 0.64085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 13 Train Avg loss: 0.12508, Acc: 0.64527, F1: 0.64451#####> Valid Avg loss: 0.35823, Acc:0.30197, F1: 0.30209
===> Epoch: 13: Training loss decreased (0.12669 --> 0.12508), Acc: (0.64101 --> 0.64527), F1: (0.64085 --> 0.64451).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 14 Train Avg loss: 0.12139, Acc: 0.64629, F1: 0.64612#####> Valid Avg loss: 0.32863, Acc:0.36612, F1: 0.36629
===> Epoch: 14: Training loss decreased (0.12508 --> 0.12139), Acc: (0.64527 --> 0.64629), F1: (0.64451 --> 0.64612).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 15 Train Avg loss: 0.12019, Acc: 0.65450, F1: 0.65432#####> Valid Avg loss: 0.33107, Acc:0.36955, F1: 0.36971
===> Epoch: 15: Training loss decreased (0.12139 --> 0.12019), Acc: (0.64629 --> 0.65450), F1: (0.64612 --> 0.65432).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 16 Train Avg loss: 0.11899, Acc: 0.65538, F1: 0.65578#####> Valid Avg loss: 0.35754, Acc:0.29855, F1: 0.29867
===> Epoch: 16: Training loss decreased (0.12019 --> 0.11899), Acc: (0.65450 --> 0.65538), F1: (0.65432 --> 0.65578).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 17 Train Avg loss: 0.11495, Acc: 0.66300, F1: 0.66340#####> Valid Avg loss: 0.37266, Acc:0.23952, F1: 0.23951
===> Epoch: 17: Training loss decreased (0.11899 --> 0.11495), Acc: (0.65538 --> 0.66300), F1: (0.65578 --> 0.66340).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 18 Train Avg loss: 0.11492, Acc: 0.66051, F1: 0.66091#####> Valid Avg loss: 0.36787, Acc:0.29085, F1: 0.29098
===> Epoch: 18: Training loss decreased (0.11495 --> 0.11492), Acc: (0.66300 --> 0.66051), F1: (0.66340 --> 0.66091).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 19 Train Avg loss: 0.11128, Acc: 0.67092, F1: 0.67072#####> Valid Avg loss: 0.36052, Acc:0.37126, F1: 0.37142
===> Epoch: 19: Training loss decreased (0.11492 --> 0.11128), Acc: (0.66051 --> 0.67092), F1: (0.66091 --> 0.67072).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 20 Train Avg loss: 0.11188, Acc: 0.66520, F1: 0.66559#####> Valid Avg loss: 0.36715, Acc:0.31223, F1: 0.31235
====> Epoch: 21 Train Avg loss: 0.11173, Acc: 0.67033, F1: 0.67013#####> Valid Avg loss: 0.37738, Acc:0.31138, F1: 0.31149
====> Epoch: 22 Train Avg loss: 0.10927, Acc: 0.67532, F1: 0.67452#####> Valid Avg loss: 0.35430, Acc:0.29940, F1: 0.29953
===> Epoch: 22: Training loss decreased (0.11128 --> 0.10927), Acc: (0.67092 --> 0.67532), F1: (0.67072 --> 0.67452).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 23 Train Avg loss: 0.10660, Acc: 0.67810, F1: 0.67848#####> Valid Avg loss: 0.38621, Acc:0.29256, F1: 0.29269
===> Epoch: 23: Training loss decreased (0.10927 --> 0.10660), Acc: (0.67532 --> 0.67810), F1: (0.67452 --> 0.67848).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 24 Train Avg loss: 0.10695, Acc: 0.67751, F1: 0.67789#####> Valid Avg loss: 0.34677, Acc:0.31480, F1: 0.31491
====> Epoch: 25 Train Avg loss: 0.10231, Acc: 0.68909, F1: 0.68887#####> Valid Avg loss: 0.36187, Acc:0.28400, F1: 0.28405
===> Epoch: 25: Training loss decreased (0.10660 --> 0.10231), Acc: (0.67810 --> 0.68909), F1: (0.67848 --> 0.68887).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 26 Train Avg loss: 0.10380, Acc: 0.68851, F1: 0.68829#####> Valid Avg loss: 0.35516, Acc:0.33447, F1: 0.33457
====> Epoch: 27 Train Avg loss: 0.10273, Acc: 0.69203, F1: 0.69122#####> Valid Avg loss: 0.37597, Acc:0.34731, F1: 0.34748
====> Epoch: 28 Train Avg loss: 0.09971, Acc: 0.69510, F1: 0.69546#####> Valid Avg loss: 0.37942, Acc:0.29170, F1: 0.29183
===> Epoch: 28: Training loss decreased (0.10231 --> 0.09971), Acc: (0.68909 --> 0.69510), F1: (0.68887 --> 0.69546).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 29 Train Avg loss: 0.09982, Acc: 0.69173, F1: 0.69209#####> Valid Avg loss: 0.37618, Acc:0.27117, F1: 0.27123
====> Epoch: 30 Train Avg loss: 0.09594, Acc: 0.70111, F1: 0.70146#####> Valid Avg loss: 0.35227, Acc:0.35928, F1: 0.35935
===> Epoch: 30: Training loss decreased (0.09971 --> 0.09594), Acc: (0.69510 --> 0.70111), F1: (0.69546 --> 0.70146).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 31 Train Avg loss: 0.09681, Acc: 0.70610, F1: 0.70586#####> Valid Avg loss: 0.37091, Acc:0.36356, F1: 0.36372
====> Epoch: 32 Train Avg loss: 0.09354, Acc: 0.71211, F1: 0.71186#####> Valid Avg loss: 0.38411, Acc:0.32421, F1: 0.32431
===> Epoch: 32: Training loss decreased (0.09594 --> 0.09354), Acc: (0.70111 --> 0.71211), F1: (0.70146 --> 0.71186).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 33 Train Avg loss: 0.09232, Acc: 0.71460, F1: 0.71493#####> Valid Avg loss: 0.39597, Acc:0.28914, F1: 0.28917
===> Epoch: 33: Training loss decreased (0.09354 --> 0.09232), Acc: (0.71211 --> 0.71460), F1: (0.71186 --> 0.71493).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 34 Train Avg loss: 0.09129, Acc: 0.70903, F1: 0.70937#####> Valid Avg loss: 0.35938, Acc:0.31138, F1: 0.31149
===> Epoch: 34: Training loss decreased (0.09232 --> 0.09129), Acc: (0.71460 --> 0.70903), F1: (0.71493 --> 0.70937).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 35 Train Avg loss: 0.09147, Acc: 0.71768, F1: 0.71742#####> Valid Avg loss: 0.36166, Acc:0.37126, F1: 0.37142
====> Epoch: 36 Train Avg loss: 0.08831, Acc: 0.71958, F1: 0.71991#####> Valid Avg loss: 0.37388, Acc:0.30282, F1: 0.30294
===> Epoch: 36: Training loss decreased (0.09129 --> 0.08831), Acc: (0.70903 --> 0.71958), F1: (0.70937 --> 0.71991).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 37 Train Avg loss: 0.08738, Acc: 0.72090, F1: 0.72006#####> Valid Avg loss: 0.39199, Acc:0.33875, F1: 0.33884
===> Epoch: 37: Training loss decreased (0.08831 --> 0.08738), Acc: (0.71958 --> 0.72090), F1: (0.71991 --> 0.72006).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 38 Train Avg loss: 0.08559, Acc: 0.72706, F1: 0.72679#####> Valid Avg loss: 0.38380, Acc:0.29170, F1: 0.29183
===> Epoch: 38: Training loss decreased (0.08738 --> 0.08559), Acc: (0.72090 --> 0.72706), F1: (0.72006 --> 0.72679).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 39 Train Avg loss: 0.08305, Acc: 0.73146, F1: 0.73177#####> Valid Avg loss: 0.39010, Acc:0.34731, F1: 0.34739
===> Epoch: 39: Training loss decreased (0.08559 --> 0.08305), Acc: (0.72706 --> 0.73146), F1: (0.72679 --> 0.73177).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 40 Train Avg loss: 0.08311, Acc: 0.73541, F1: 0.73455#####> Valid Avg loss: 0.41316, Acc:0.31908, F1: 0.31918
====> Epoch: 41 Train Avg loss: 0.08130, Acc: 0.74612, F1: 0.74583#####> Valid Avg loss: 0.43238, Acc:0.34474, F1: 0.34482
===> Epoch: 41: Training loss decreased (0.08305 --> 0.08130), Acc: (0.73146 --> 0.74612), F1: (0.73177 --> 0.74583).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 42 Train Avg loss: 0.07774, Acc: 0.74450, F1: 0.74480#####> Valid Avg loss: 0.39193, Acc:0.34474, F1: 0.34473
===> Epoch: 42: Training loss decreased (0.08130 --> 0.07774), Acc: (0.74612 --> 0.74450), F1: (0.74583 --> 0.74480).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 43 Train Avg loss: 0.07763, Acc: 0.75139, F1: 0.75110#####> Valid Avg loss: 0.40648, Acc:0.36527, F1: 0.36534
===> Epoch: 43: Training loss decreased (0.07774 --> 0.07763), Acc: (0.74450 --> 0.75139), F1: (0.74480 --> 0.75110).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 44 Train Avg loss: 0.07477, Acc: 0.75814, F1: 0.75842#####> Valid Avg loss: 0.42968, Acc:0.27203, F1: 0.27198
===> Epoch: 44: Training loss decreased (0.07763 --> 0.07477), Acc: (0.75139 --> 0.75814), F1: (0.75110 --> 0.75842).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 45 Train Avg loss: 0.07372, Acc: 0.76151, F1: 0.76179#####> Valid Avg loss: 0.41815, Acc:0.28828, F1: 0.28832
===> Epoch: 45: Training loss decreased (0.07477 --> 0.07372), Acc: (0.75814 --> 0.76151), F1: (0.75842 --> 0.76179).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 46 Train Avg loss: 0.07251, Acc: 0.76048, F1: 0.76076#####> Valid Avg loss: 0.39146, Acc:0.36527, F1: 0.36524
===> Epoch: 46: Training loss decreased (0.07372 --> 0.07251), Acc: (0.76151 --> 0.76048), F1: (0.76179 --> 0.76076).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 47 Train Avg loss: 0.06946, Acc: 0.77074, F1: 0.77101#####> Valid Avg loss: 0.39184, Acc:0.30026, F1: 0.30028
===> Epoch: 47: Training loss decreased (0.07251 --> 0.06946), Acc: (0.76048 --> 0.77074), F1: (0.76076 --> 0.77101).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 48 Train Avg loss: 0.06653, Acc: 0.78467, F1: 0.78433#####> Valid Avg loss: 0.41457, Acc:0.28229, F1: 0.28215
===> Epoch: 48: Training loss decreased (0.06946 --> 0.06653), Acc: (0.77074 --> 0.78467), F1: (0.77101 --> 0.78433).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 49 Train Avg loss: 0.06607, Acc: 0.78086, F1: 0.78111#####> Valid Avg loss: 0.38287, Acc:0.28229, F1: 0.28215
===> Epoch: 49: Training loss decreased (0.06653 --> 0.06607), Acc: (0.78467 --> 0.78086), F1: (0.78433 --> 0.78111).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 50 Train Avg loss: 0.06342, Acc: 0.78892, F1: 0.78917#####> Valid Avg loss: 0.42792, Acc:0.34303, F1: 0.34302
===> Epoch: 50: Training loss decreased (0.06607 --> 0.06342), Acc: (0.78086 --> 0.78892), F1: (0.78111 --> 0.78917).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 51 Train Avg loss: 0.06294, Acc: 0.79434, F1: 0.79341#####> Valid Avg loss: 0.42930, Acc:0.34559, F1: 0.34549
===> Epoch: 51: Training loss decreased (0.06342 --> 0.06294), Acc: (0.78892 --> 0.79434), F1: (0.78917 --> 0.79341).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 52 Train Avg loss: 0.06194, Acc: 0.79376, F1: 0.79341#####> Valid Avg loss: 0.42591, Acc:0.32335, F1: 0.32317
===> Epoch: 52: Training loss decreased (0.06294 --> 0.06194), Acc: (0.79434 --> 0.79376), F1: (0.79341 --> 0.79341).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 53 Train Avg loss: 0.05897, Acc: 0.80152, F1: 0.80117#####> Valid Avg loss: 0.41951, Acc:0.30453, F1: 0.30437
===> Epoch: 53: Training loss decreased (0.06194 --> 0.05897), Acc: (0.79376 --> 0.80152), F1: (0.79341 --> 0.80117).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 54 Train Avg loss: 0.05620, Acc: 0.81105, F1: 0.81127#####> Valid Avg loss: 0.41186, Acc:0.31480, F1: 0.31462
===> Epoch: 54: Training loss decreased (0.05897 --> 0.05620), Acc: (0.80152 --> 0.81105), F1: (0.80117 --> 0.81127).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 55 Train Avg loss: 0.05287, Acc: 0.81516, F1: 0.81479#####> Valid Avg loss: 0.41865, Acc:0.30539, F1: 0.30513
===> Epoch: 55: Training loss decreased (0.05620 --> 0.05287), Acc: (0.81105 --> 0.81516), F1: (0.81127 --> 0.81479).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 56 Train Avg loss: 0.05158, Acc: 0.82571, F1: 0.82533#####> Valid Avg loss: 0.45958, Acc:0.28571, F1: 0.28557
===> Epoch: 56: Training loss decreased (0.05287 --> 0.05158), Acc: (0.81516 --> 0.82571), F1: (0.81479 --> 0.82533).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 57 Train Avg loss: 0.04968, Acc: 0.83260, F1: 0.83280#####> Valid Avg loss: 0.47772, Acc:0.34217, F1: 0.34198
===> Epoch: 57: Training loss decreased (0.05158 --> 0.04968), Acc: (0.82571 --> 0.83260), F1: (0.82533 --> 0.83280).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 58 Train Avg loss: 0.04898, Acc: 0.83143, F1: 0.83163#####> Valid Avg loss: 0.49334, Acc:0.34303, F1: 0.34302
===> Epoch: 58: Training loss decreased (0.04968 --> 0.04898), Acc: (0.83260 --> 0.83143), F1: (0.83280 --> 0.83163).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 59 Train Avg loss: 0.04516, Acc: 0.84565, F1: 0.84583#####> Valid Avg loss: 0.46027, Acc:0.27374, F1: 0.27360
===> Epoch: 59: Training loss decreased (0.04898 --> 0.04516), Acc: (0.83143 --> 0.84565), F1: (0.83163 --> 0.84583).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 60 Train Avg loss: 0.04568, Acc: 0.84829, F1: 0.84846#####> Valid Avg loss: 0.48063, Acc:0.30368, F1: 0.30351
====> Epoch: 61 Train Avg loss: 0.04234, Acc: 0.85752, F1: 0.85769#####> Valid Avg loss: 0.47519, Acc:0.32335, F1: 0.32317
===> Epoch: 61: Training loss decreased (0.04516 --> 0.04234), Acc: (0.84565 --> 0.85752), F1: (0.84583 --> 0.85769).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 62 Train Avg loss: 0.03924, Acc: 0.86910, F1: 0.86867#####> Valid Avg loss: 0.50500, Acc:0.33362, F1: 0.33352
===> Epoch: 62: Training loss decreased (0.04234 --> 0.03924), Acc: (0.85752 --> 0.86910), F1: (0.85769 --> 0.86867).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 63 Train Avg loss: 0.03756, Acc: 0.87276, F1: 0.87291#####> Valid Avg loss: 0.50529, Acc:0.29598, F1: 0.29582
===> Epoch: 63: Training loss decreased (0.03924 --> 0.03756), Acc: (0.86910 --> 0.87276), F1: (0.86867 --> 0.87291).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 64 Train Avg loss: 0.03621, Acc: 0.87716, F1: 0.87731#####> Valid Avg loss: 0.51781, Acc:0.29940, F1: 0.29915
===> Epoch: 64: Training loss decreased (0.03756 --> 0.03621), Acc: (0.87276 --> 0.87716), F1: (0.87291 --> 0.87731).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 65 Train Avg loss: 0.03309, Acc: 0.88449, F1: 0.88463#####> Valid Avg loss: 0.54981, Acc:0.32421, F1: 0.32403
===> Epoch: 65: Training loss decreased (0.03621 --> 0.03309), Acc: (0.87716 --> 0.88449), F1: (0.87731 --> 0.88463).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 66 Train Avg loss: 0.03238, Acc: 0.89153, F1: 0.89165#####> Valid Avg loss: 0.52654, Acc:0.29341, F1: 0.29335
===> Epoch: 66: Training loss decreased (0.03309 --> 0.03238), Acc: (0.88449 --> 0.89153), F1: (0.88463 --> 0.89165).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 67 Train Avg loss: 0.03019, Acc: 0.89402, F1: 0.89414#####> Valid Avg loss: 0.55490, Acc:0.30368, F1: 0.30361
===> Epoch: 67: Training loss decreased (0.03238 --> 0.03019), Acc: (0.89153 --> 0.89402), F1: (0.89165 --> 0.89414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 68 Train Avg loss: 0.02753, Acc: 0.90531, F1: 0.90542#####> Valid Avg loss: 0.53785, Acc:0.30710, F1: 0.30693
===> Epoch: 68: Training loss decreased (0.03019 --> 0.02753), Acc: (0.89402 --> 0.90531), F1: (0.89414 --> 0.90542).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 69 Train Avg loss: 0.02857, Acc: 0.90076, F1: 0.90088#####> Valid Avg loss: 0.52939, Acc:0.32335, F1: 0.32308
====> Epoch: 70 Train Avg loss: 0.02539, Acc: 0.91542, F1: 0.91552#####> Valid Avg loss: 0.60454, Acc:0.31565, F1: 0.31548
===> Epoch: 70: Training loss decreased (0.02753 --> 0.02539), Acc: (0.90531 --> 0.91542), F1: (0.90542 --> 0.91552).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 71 Train Avg loss: 0.02344, Acc: 0.92128, F1: 0.92079#####> Valid Avg loss: 0.56701, Acc:0.31138, F1: 0.31130
===> Epoch: 71: Training loss decreased (0.02539 --> 0.02344), Acc: (0.91542 --> 0.92128), F1: (0.91552 --> 0.92079).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 72 Train Avg loss: 0.02304, Acc: 0.92011, F1: 0.92020#####> Valid Avg loss: 0.63852, Acc:0.29769, F1: 0.29753
===> Epoch: 72: Training loss decreased (0.02344 --> 0.02304), Acc: (0.92128 --> 0.92011), F1: (0.92079 --> 0.92020).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 73 Train Avg loss: 0.02140, Acc: 0.93008, F1: 0.92958#####> Valid Avg loss: 0.58448, Acc:0.32849, F1: 0.32830
===> Epoch: 73: Training loss decreased (0.02304 --> 0.02140), Acc: (0.92011 --> 0.93008), F1: (0.92020 --> 0.92958).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 74 Train Avg loss: 0.02118, Acc: 0.93052, F1: 0.93060#####> Valid Avg loss: 0.58433, Acc:0.29855, F1: 0.29839
===> Epoch: 74: Training loss decreased (0.02140 --> 0.02118), Acc: (0.93008 --> 0.93052), F1: (0.92958 --> 0.93060).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 75 Train Avg loss: 0.01980, Acc: 0.93345, F1: 0.93353#####> Valid Avg loss: 0.53293, Acc:0.30967, F1: 0.30950
===> Epoch: 75: Training loss decreased (0.02118 --> 0.01980), Acc: (0.93052 --> 0.93345), F1: (0.93060 --> 0.93353).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 76 Train Avg loss: 0.01886, Acc: 0.93668, F1: 0.93675#####> Valid Avg loss: 0.57911, Acc:0.32335, F1: 0.32327
===> Epoch: 76: Training loss decreased (0.01980 --> 0.01886), Acc: (0.93345 --> 0.93668), F1: (0.93353 --> 0.93675).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 77 Train Avg loss: 0.01836, Acc: 0.93653, F1: 0.93602#####> Valid Avg loss: 0.63888, Acc:0.29683, F1: 0.29658
===> Epoch: 77: Training loss decreased (0.01886 --> 0.01836), Acc: (0.93668 --> 0.93653), F1: (0.93675 --> 0.93602).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 78 Train Avg loss: 0.01654, Acc: 0.94430, F1: 0.94436#####> Valid Avg loss: 0.60454, Acc:0.31737, F1: 0.31719
===> Epoch: 78: Training loss decreased (0.01836 --> 0.01654), Acc: (0.93653 --> 0.94430), F1: (0.93602 --> 0.94436).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 79 Train Avg loss: 0.01719, Acc: 0.94356, F1: 0.94363#####> Valid Avg loss: 0.56730, Acc:0.30710, F1: 0.30684
====> Epoch: 80 Train Avg loss: 0.01551, Acc: 0.95045, F1: 0.95051#####> Valid Avg loss: 0.60462, Acc:0.31480, F1: 0.31453
===> Epoch: 80: Training loss decreased (0.01654 --> 0.01551), Acc: (0.94430 --> 0.95045), F1: (0.94436 --> 0.95051).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 81 Train Avg loss: 0.01517, Acc: 0.94943, F1: 0.94949#####> Valid Avg loss: 0.60859, Acc:0.31651, F1: 0.31633
===> Epoch: 81: Training loss decreased (0.01551 --> 0.01517), Acc: (0.95045 --> 0.94943), F1: (0.95051 --> 0.94949).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 82 Train Avg loss: 0.01421, Acc: 0.95397, F1: 0.95403#####> Valid Avg loss: 0.61336, Acc:0.31737, F1: 0.31719
===> Epoch: 82: Training loss decreased (0.01517 --> 0.01421), Acc: (0.94943 --> 0.95397), F1: (0.94949 --> 0.95403).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 83 Train Avg loss: 0.01420, Acc: 0.95104, F1: 0.95110#####> Valid Avg loss: 0.58827, Acc:0.32164, F1: 0.32156
===> Epoch: 83: Training loss decreased (0.01421 --> 0.01420), Acc: (0.95397 --> 0.95104), F1: (0.95403 --> 0.95110).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 84 Train Avg loss: 0.01368, Acc: 0.95646, F1: 0.95652#####> Valid Avg loss: 0.59744, Acc:0.32079, F1: 0.32080
===> Epoch: 84: Training loss decreased (0.01420 --> 0.01368), Acc: (0.95104 --> 0.95646), F1: (0.95110 --> 0.95652).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 85 Train Avg loss: 0.01292, Acc: 0.95969, F1: 0.95974#####> Valid Avg loss: 0.61930, Acc:0.31223, F1: 0.31206
===> Epoch: 85: Training loss decreased (0.01368 --> 0.01292), Acc: (0.95646 --> 0.95969), F1: (0.95652 --> 0.95974).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 86 Train Avg loss: 0.01332, Acc: 0.95500, F1: 0.95505#####> Valid Avg loss: 0.62641, Acc:0.30453, F1: 0.30437
====> Epoch: 87 Train Avg loss: 0.01263, Acc: 0.95734, F1: 0.95739#####> Valid Avg loss: 0.61410, Acc:0.31908, F1: 0.31890
===> Epoch: 87: Training loss decreased (0.01292 --> 0.01263), Acc: (0.95969 --> 0.95734), F1: (0.95974 --> 0.95739).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 88 Train Avg loss: 0.01242, Acc: 0.95734, F1: 0.95739#####> Valid Avg loss: 0.63801, Acc:0.31908, F1: 0.31899
===> Epoch: 88: Training loss decreased (0.01263 --> 0.01242), Acc: (0.95734 --> 0.95734), F1: (0.95739 --> 0.95739).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 89 Train Avg loss: 0.01228, Acc: 0.96013, F1: 0.95959#####> Valid Avg loss: 0.67202, Acc:0.32335, F1: 0.32317
===> Epoch: 89: Training loss decreased (0.01242 --> 0.01228), Acc: (0.95734 --> 0.96013), F1: (0.95739 --> 0.95959).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 90 Train Avg loss: 0.01210, Acc: 0.95984, F1: 0.95988#####> Valid Avg loss: 0.62712, Acc:0.31737, F1: 0.31719
===> Epoch: 90: Training loss decreased (0.01228 --> 0.01210), Acc: (0.96013 --> 0.95984), F1: (0.95959 --> 0.95988).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 91 Train Avg loss: 0.01166, Acc: 0.96247, F1: 0.96252#####> Valid Avg loss: 0.68173, Acc:0.31651, F1: 0.31633
===> Epoch: 91: Training loss decreased (0.01210 --> 0.01166), Acc: (0.95984 --> 0.96247), F1: (0.95988 --> 0.96252).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 92 Train Avg loss: 0.01216, Acc: 0.96159, F1: 0.96164#####> Valid Avg loss: 0.64698, Acc:0.31480, F1: 0.31462
====> Epoch: 93 Train Avg loss: 0.01107, Acc: 0.96218, F1: 0.96223#####> Valid Avg loss: 0.66372, Acc:0.32250, F1: 0.32232
===> Epoch: 93: Training loss decreased (0.01166 --> 0.01107), Acc: (0.96247 --> 0.96218), F1: (0.96252 --> 0.96223).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 94 Train Avg loss: 0.01129, Acc: 0.96321, F1: 0.96325#####> Valid Avg loss: 0.65741, Acc:0.32079, F1: 0.32061
====> Epoch: 95 Train Avg loss: 0.01163, Acc: 0.96101, F1: 0.96105#####> Valid Avg loss: 0.63708, Acc:0.32079, F1: 0.32061
====> Epoch: 96 Train Avg loss: 0.01143, Acc: 0.96335, F1: 0.96340#####> Valid Avg loss: 0.62792, Acc:0.31822, F1: 0.31804
====> Epoch: 97 Train Avg loss: 0.01095, Acc: 0.96570, F1: 0.96574#####> Valid Avg loss: 0.62205, Acc:0.31651, F1: 0.31633
===> Epoch: 97: Training loss decreased (0.01107 --> 0.01095), Acc: (0.96218 --> 0.96570), F1: (0.96223 --> 0.96574).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 98 Train Avg loss: 0.01115, Acc: 0.96365, F1: 0.96369#####> Valid Avg loss: 0.64624, Acc:0.31908, F1: 0.31890
====> Epoch: 99 Train Avg loss: 0.01090, Acc: 0.96409, F1: 0.96413#####> Valid Avg loss: 0.62560, Acc:0.31908, F1: 0.31890
===> Epoch: 99: Training loss decreased (0.01095 --> 0.01090), Acc: (0.96570 --> 0.96409), F1: (0.96574 --> 0.96413).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597130673.682802.pth_1
====> Epoch: 100 Train Avg loss: 0.13310, Acc: 0.64160, F1: 0.64143#####> Valid Avg loss: 0.36947, Acc:0.37126, F1: 0.37142
====> Epoch: 101 Train Avg loss: 0.09985, Acc: 0.70023, F1: 0.70059#####> Valid Avg loss: 0.42797, Acc:0.30539, F1: 0.30532
====> Epoch: 102 Train Avg loss: 0.08574, Acc: 0.73849, F1: 0.73821#####> Valid Avg loss: 0.38910, Acc:0.28571, F1: 0.28557
====> Epoch: 103 Train Avg loss: 0.08086, Acc: 0.74362, F1: 0.74392#####> Valid Avg loss: 0.41162, Acc:0.33875, F1: 0.33875
====> Epoch: 104 Train Avg loss: 0.07583, Acc: 0.75608, F1: 0.75637#####> Valid Avg loss: 0.38249, Acc:0.24465, F1: 0.24454
====> Epoch: 105 Train Avg loss: 0.07664, Acc: 0.75931, F1: 0.75900#####> Valid Avg loss: 0.41429, Acc:0.32849, F1: 0.32849
====> Epoch: 106 Train Avg loss: 0.07045, Acc: 0.76928, F1: 0.76955#####> Valid Avg loss: 0.40982, Acc:0.30539, F1: 0.30522
====> Epoch: 107 Train Avg loss: 0.07022, Acc: 0.77103, F1: 0.77130#####> Valid Avg loss: 0.44340, Acc:0.32250, F1: 0.32251
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 519
valid_dataloader len: 113
test_dataloader len: 105
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 519
valid dataset len: 1121, valid dataloader len: 113
valid dataset len: 1050, test dataloader len: 113
====> Epoch: 1 Train Avg loss: 0.26228, Acc: 0.31088, F1: 0.31040#####> Valid Avg loss: 0.19818, Acc:0.40589, F1: 0.40265
===> Epoch: 1: Training loss decreased (inf --> 0.26228), Acc: (0.00000 --> 0.31088), F1: (0.00000 --> 0.31040).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.19818), Acc: (0.00000 --> 0.40589), F1: (0.00000 --> 0.40265).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.19818), Acc: (0.00000 --> 0.40589), F1: (0.00000 --> 0.40265).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 2 Train Avg loss: 0.18719, Acc: 0.45021, F1: 0.45029#####> Valid Avg loss: 0.19089, Acc:0.34612, F1: 0.34336
===> Epoch: 2: Training loss decreased (0.26228 --> 0.18719), Acc: (0.31088 --> 0.45021), F1: (0.31040 --> 0.45029).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1

####> Epoch: 2: validation loss decreased (0.19818 --> 0.19089), Acc: (0.40589 --> 0.34612), F1: (0.40265 --> 0.34336).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 3 Train Avg loss: 0.16002, Acc: 0.51409, F1: 0.51329#####> Valid Avg loss: 0.17874, Acc:0.39697, F1: 0.39381
===> Epoch: 3: Training loss decreased (0.18719 --> 0.16002), Acc: (0.45021 --> 0.51409), F1: (0.45029 --> 0.51329).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1

####> Epoch: 3: validation loss decreased (0.19089 --> 0.17874), Acc: (0.34612 --> 0.39697), F1: (0.34336 --> 0.39381).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 4 Train Avg loss: 0.14386, Acc: 0.56735, F1: 0.56647#####> Valid Avg loss: 0.17426, Acc:0.40232, F1: 0.39912
===> Epoch: 4: Training loss decreased (0.16002 --> 0.14386), Acc: (0.51409 --> 0.56735), F1: (0.51329 --> 0.56647).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1

####> Epoch: 4: validation loss decreased (0.17874 --> 0.17426), Acc: (0.39697 --> 0.40232), F1: (0.39381 --> 0.39912).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 5 Train Avg loss: 0.13257, Acc: 0.58858, F1: 0.58844#####> Valid Avg loss: 0.17051, Acc:0.40500, F1: 0.40177
===> Epoch: 5: Training loss decreased (0.14386 --> 0.13257), Acc: (0.56735 --> 0.58858), F1: (0.56647 --> 0.58844).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1

####> Epoch: 5: validation loss decreased (0.17426 --> 0.17051), Acc: (0.40232 --> 0.40500), F1: (0.39912 --> 0.40177).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 6 Train Avg loss: 0.12654, Acc: 0.60459, F1: 0.60520#####> Valid Avg loss: 0.17429, Acc:0.40589, F1: 0.40265
===> Epoch: 6: Training loss decreased (0.13257 --> 0.12654), Acc: (0.58858 --> 0.60459), F1: (0.58844 --> 0.60520).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 7 Train Avg loss: 0.11970, Acc: 0.61887, F1: 0.61946#####> Valid Avg loss: 0.20778, Acc:0.40678, F1: 0.40354
===> Epoch: 7: Training loss decreased (0.12654 --> 0.11970), Acc: (0.60459 --> 0.61887), F1: (0.60520 --> 0.61946).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1

####> Epoch: 7: validation acc increase (0.19818 --> 0.20778), Acc: (0.40589 --> 0.40678), F1: (0.40265 --> 0.40354).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 8 Train Avg loss: 0.11581, Acc: 0.63277, F1: 0.63333#####> Valid Avg loss: 0.18210, Acc:0.39964, F1: 0.39646
===> Epoch: 8: Training loss decreased (0.11970 --> 0.11581), Acc: (0.61887 --> 0.63277), F1: (0.61946 --> 0.63333).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 9 Train Avg loss: 0.11330, Acc: 0.63933, F1: 0.63911#####> Valid Avg loss: 0.19248, Acc:0.37021, F1: 0.36726
===> Epoch: 9: Training loss decreased (0.11581 --> 0.11330), Acc: (0.63277 --> 0.63933), F1: (0.63333 --> 0.63911).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 10 Train Avg loss: 0.10867, Acc: 0.64299, F1: 0.64277#####> Valid Avg loss: 0.19308, Acc:0.39518, F1: 0.39204
===> Epoch: 10: Training loss decreased (0.11330 --> 0.10867), Acc: (0.63933 --> 0.64299), F1: (0.63911 --> 0.64277).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 11 Train Avg loss: 0.10904, Acc: 0.64821, F1: 0.64798#####> Valid Avg loss: 0.22257, Acc:0.38805, F1: 0.38496
====> Epoch: 12 Train Avg loss: 0.10578, Acc: 0.65554, F1: 0.65530#####> Valid Avg loss: 0.18669, Acc:0.40500, F1: 0.40177
===> Epoch: 12: Training loss decreased (0.10867 --> 0.10578), Acc: (0.64299 --> 0.65554), F1: (0.64277 --> 0.65530).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 13 Train Avg loss: 0.10267, Acc: 0.66403, F1: 0.66378#####> Valid Avg loss: 0.20988, Acc:0.38626, F1: 0.38319
===> Epoch: 13: Training loss decreased (0.10578 --> 0.10267), Acc: (0.65554 --> 0.66403), F1: (0.65530 --> 0.66378).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 14 Train Avg loss: 0.10081, Acc: 0.66403, F1: 0.66455#####> Valid Avg loss: 0.25787, Acc:0.39875, F1: 0.39558
===> Epoch: 14: Training loss decreased (0.10267 --> 0.10081), Acc: (0.66403 --> 0.66403), F1: (0.66378 --> 0.66455).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 15 Train Avg loss: 0.10318, Acc: 0.65708, F1: 0.65761#####> Valid Avg loss: 0.22941, Acc:0.39072, F1: 0.38761
====> Epoch: 16 Train Avg loss: 0.09966, Acc: 0.67194, F1: 0.67168#####> Valid Avg loss: 0.19983, Acc:0.40410, F1: 0.40088
===> Epoch: 16: Training loss decreased (0.10081 --> 0.09966), Acc: (0.66403 --> 0.67194), F1: (0.66455 --> 0.67168).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
====> Epoch: 17 Train Avg loss: 0.09656, Acc: 0.67368, F1: 0.67341#####> Valid Avg loss: 0.25416, Acc:0.40410, F1: 0.40088
===> Epoch: 17: Training loss decreased (0.09966 --> 0.09656), Acc: (0.67194 --> 0.67368), F1: (0.67168 --> 0.67341).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597171759.730551.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 519
valid_dataloader len: 113
test_dataloader len: 105
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 519
valid dataset len: 1121, valid dataloader len: 113
valid dataset len: 1050, test dataloader len: 113
====> Epoch: 1 Train Avg loss: 0.25891, Acc: 0.29718, F1: 0.29672#####> Valid Avg loss: 0.20128, Acc:0.38983, F1: 0.38673
===> Epoch: 1: Training loss decreased (inf --> 0.25891), Acc: (0.00000 --> 0.29718), F1: (0.00000 --> 0.29672).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.20128), Acc: (0.00000 --> 0.38983), F1: (0.00000 --> 0.38673).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.20128), Acc: (0.00000 --> 0.38983), F1: (0.00000 --> 0.38673).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 2 Train Avg loss: 0.18424, Acc: 0.45600, F1: 0.45607#####> Valid Avg loss: 0.19452, Acc:0.35593, F1: 0.35310
===> Epoch: 2: Training loss decreased (0.25891 --> 0.18424), Acc: (0.29718 --> 0.45600), F1: (0.29672 --> 0.45607).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1

####> Epoch: 2: validation loss decreased (0.20128 --> 0.19452), Acc: (0.38983 --> 0.35593), F1: (0.38673 --> 0.35310).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 3 Train Avg loss: 0.15370, Acc: 0.53609, F1: 0.53680#####> Valid Avg loss: 0.17743, Acc:0.40678, F1: 0.40354
===> Epoch: 3: Training loss decreased (0.18424 --> 0.15370), Acc: (0.45600 --> 0.53609), F1: (0.45607 --> 0.53680).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1

####> Epoch: 3: validation loss decreased (0.19452 --> 0.17743), Acc: (0.35593 --> 0.40678), F1: (0.35310 --> 0.40354).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1

####> Epoch: 3: validation acc increase (0.20128 --> 0.17743), Acc: (0.38983 --> 0.40678), F1: (0.38673 --> 0.40354).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 4 Train Avg loss: 0.13755, Acc: 0.59205, F1: 0.59191#####> Valid Avg loss: 0.17247, Acc:0.40232, F1: 0.39912
===> Epoch: 4: Training loss decreased (0.15370 --> 0.13755), Acc: (0.53609 --> 0.59205), F1: (0.53680 --> 0.59191).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1

####> Epoch: 4: validation loss decreased (0.17743 --> 0.17247), Acc: (0.40678 --> 0.40232), F1: (0.40354 --> 0.39912).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 5 Train Avg loss: 0.12775, Acc: 0.61096, F1: 0.61079#####> Valid Avg loss: 0.17763, Acc:0.40410, F1: 0.40088
===> Epoch: 5: Training loss decreased (0.13755 --> 0.12775), Acc: (0.59205 --> 0.61096), F1: (0.59191 --> 0.61079).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 6 Train Avg loss: 0.12345, Acc: 0.62254, F1: 0.62312#####> Valid Avg loss: 0.17626, Acc:0.39875, F1: 0.39558
===> Epoch: 6: Training loss decreased (0.12775 --> 0.12345), Acc: (0.61096 --> 0.62254), F1: (0.61079 --> 0.62312).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 7 Train Avg loss: 0.11813, Acc: 0.63393, F1: 0.63449#####> Valid Avg loss: 0.17272, Acc:0.38537, F1: 0.38230
===> Epoch: 7: Training loss decreased (0.12345 --> 0.11813), Acc: (0.62254 --> 0.63393), F1: (0.62312 --> 0.63449).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 8 Train Avg loss: 0.11490, Acc: 0.63875, F1: 0.63931#####> Valid Avg loss: 0.18129, Acc:0.40589, F1: 0.40265
===> Epoch: 8: Training loss decreased (0.11813 --> 0.11490), Acc: (0.63393 --> 0.63875), F1: (0.63449 --> 0.63931).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 9 Train Avg loss: 0.11191, Acc: 0.64608, F1: 0.64663#####> Valid Avg loss: 0.19517, Acc:0.40678, F1: 0.40354
===> Epoch: 9: Training loss decreased (0.11490 --> 0.11191), Acc: (0.63875 --> 0.64608), F1: (0.63931 --> 0.64663).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 10 Train Avg loss: 0.10767, Acc: 0.65766, F1: 0.65742#####> Valid Avg loss: 0.21609, Acc:0.40589, F1: 0.40265
===> Epoch: 10: Training loss decreased (0.11191 --> 0.10767), Acc: (0.64608 --> 0.65766), F1: (0.64663 --> 0.65742).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 11 Train Avg loss: 0.10823, Acc: 0.64280, F1: 0.64258#####> Valid Avg loss: 0.21507, Acc:0.40589, F1: 0.40265
====> Epoch: 12 Train Avg loss: 0.10425, Acc: 0.66268, F1: 0.66320#####> Valid Avg loss: 0.21598, Acc:0.40678, F1: 0.40354
===> Epoch: 12: Training loss decreased (0.10767 --> 0.10425), Acc: (0.65766 --> 0.66268), F1: (0.65742 --> 0.66320).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
====> Epoch: 13 Train Avg loss: 0.10119, Acc: 0.66557, F1: 0.66532#####> Valid Avg loss: 0.19599, Acc:0.40500, F1: 0.40177
===> Epoch: 13: Training loss decreased (0.10425 --> 0.10119), Acc: (0.66268 --> 0.66557), F1: (0.66320 --> 0.66532).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597177182.672922.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 519
valid_dataloader len: 113
test_dataloader len: 105
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 519
valid dataset len: 1121, valid dataloader len: 113
valid dataset len: 1050, test dataloader len: 113
====> Epoch: 1 Train Avg loss: 0.26233, Acc: 0.27094, F1: 0.27206#####> Valid Avg loss: 0.19538, Acc:0.39518, F1: 0.39204
===> Epoch: 1: Training loss decreased (inf --> 0.26233), Acc: (0.00000 --> 0.27094), F1: (0.00000 --> 0.27206).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.19538), Acc: (0.00000 --> 0.39518), F1: (0.00000 --> 0.39204).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.19538), Acc: (0.00000 --> 0.39518), F1: (0.00000 --> 0.39204).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 2 Train Avg loss: 0.18430, Acc: 0.46430, F1: 0.46435#####> Valid Avg loss: 0.17000, Acc:0.39518, F1: 0.39204
===> Epoch: 2: Training loss decreased (0.26233 --> 0.18430), Acc: (0.27094 --> 0.46430), F1: (0.27206 --> 0.46435).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1

####> Epoch: 2: validation loss decreased (0.19538 --> 0.17000), Acc: (0.39518 --> 0.39518), F1: (0.39204 --> 0.39204).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 3 Train Avg loss: 0.15617, Acc: 0.53821, F1: 0.53815#####> Valid Avg loss: 0.17767, Acc:0.40678, F1: 0.40354
===> Epoch: 3: Training loss decreased (0.18430 --> 0.15617), Acc: (0.46430 --> 0.53821), F1: (0.46435 --> 0.53815).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1

####> Epoch: 3: validation acc increase (0.19538 --> 0.17767), Acc: (0.39518 --> 0.40678), F1: (0.39204 --> 0.40354).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 4 Train Avg loss: 0.14104, Acc: 0.58105, F1: 0.58092#####> Valid Avg loss: 0.17847, Acc:0.40678, F1: 0.40354
===> Epoch: 4: Training loss decreased (0.15617 --> 0.14104), Acc: (0.53821 --> 0.58105), F1: (0.53815 --> 0.58092).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 5 Train Avg loss: 0.13017, Acc: 0.59996, F1: 0.60058#####> Valid Avg loss: 0.17024, Acc:0.40678, F1: 0.40354
===> Epoch: 5: Training loss decreased (0.14104 --> 0.13017), Acc: (0.58105 --> 0.59996), F1: (0.58092 --> 0.60058).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 6 Train Avg loss: 0.12438, Acc: 0.61849, F1: 0.61830#####> Valid Avg loss: 0.20744, Acc:0.40678, F1: 0.40354
===> Epoch: 6: Training loss decreased (0.13017 --> 0.12438), Acc: (0.59996 --> 0.61849), F1: (0.60058 --> 0.61830).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 7 Train Avg loss: 0.12010, Acc: 0.62100, F1: 0.62158#####> Valid Avg loss: 0.18973, Acc:0.40678, F1: 0.40354
===> Epoch: 7: Training loss decreased (0.12438 --> 0.12010), Acc: (0.61849 --> 0.62100), F1: (0.61830 --> 0.62158).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 8 Train Avg loss: 0.11419, Acc: 0.62756, F1: 0.62736#####> Valid Avg loss: 0.16538, Acc:0.40767, F1: 0.40442
===> Epoch: 8: Training loss decreased (0.12010 --> 0.11419), Acc: (0.62100 --> 0.62756), F1: (0.62158 --> 0.62736).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1

####> Epoch: 8: validation loss decreased (0.17000 --> 0.16538), Acc: (0.39518 --> 0.40767), F1: (0.39204 --> 0.40442).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1

####> Epoch: 8: validation acc increase (0.17767 --> 0.16538), Acc: (0.40678 --> 0.40767), F1: (0.40354 --> 0.40442).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 9 Train Avg loss: 0.11367, Acc: 0.62679, F1: 0.62659#####> Valid Avg loss: 0.21484, Acc:0.40678, F1: 0.40354
===> Epoch: 9: Training loss decreased (0.11419 --> 0.11367), Acc: (0.62756 --> 0.62679), F1: (0.62736 --> 0.62659).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 10 Train Avg loss: 0.11241, Acc: 0.63836, F1: 0.63892#####> Valid Avg loss: 0.20606, Acc:0.40678, F1: 0.40354
===> Epoch: 10: Training loss decreased (0.11367 --> 0.11241), Acc: (0.62679 --> 0.63836), F1: (0.62659 --> 0.63892).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 11 Train Avg loss: 0.10683, Acc: 0.65650, F1: 0.65626#####> Valid Avg loss: 0.19944, Acc:0.40678, F1: 0.40354
===> Epoch: 11: Training loss decreased (0.11241 --> 0.10683), Acc: (0.63836 --> 0.65650), F1: (0.63892 --> 0.65626).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 12 Train Avg loss: 0.10440, Acc: 0.65264, F1: 0.65318#####> Valid Avg loss: 0.24444, Acc:0.40678, F1: 0.40354
===> Epoch: 12: Training loss decreased (0.10683 --> 0.10440), Acc: (0.65650 --> 0.65264), F1: (0.65626 --> 0.65318).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 13 Train Avg loss: 0.10448, Acc: 0.65457, F1: 0.65434#####> Valid Avg loss: 0.23262, Acc:0.40321, F1: 0.40000
====> Epoch: 14 Train Avg loss: 0.10323, Acc: 0.65920, F1: 0.65973#####> Valid Avg loss: 0.21769, Acc:0.40678, F1: 0.40354
===> Epoch: 14: Training loss decreased (0.10440 --> 0.10323), Acc: (0.65264 --> 0.65920), F1: (0.65318 --> 0.65973).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 15 Train Avg loss: 0.10040, Acc: 0.66499, F1: 0.66474#####> Valid Avg loss: 0.19854, Acc:0.38537, F1: 0.38230
===> Epoch: 15: Training loss decreased (0.10323 --> 0.10040), Acc: (0.65920 --> 0.66499), F1: (0.65973 --> 0.66474).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 16 Train Avg loss: 0.09978, Acc: 0.65920, F1: 0.65896#####> Valid Avg loss: 0.19705, Acc:0.40321, F1: 0.40000
===> Epoch: 16: Training loss decreased (0.10040 --> 0.09978), Acc: (0.66499 --> 0.65920), F1: (0.66474 --> 0.65896).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 17 Train Avg loss: 0.09970, Acc: 0.66557, F1: 0.66609#####> Valid Avg loss: 0.19666, Acc:0.40232, F1: 0.39912
===> Epoch: 17: Training loss decreased (0.09978 --> 0.09970), Acc: (0.65920 --> 0.66557), F1: (0.65896 --> 0.66609).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 18 Train Avg loss: 0.09785, Acc: 0.67136, F1: 0.67110#####> Valid Avg loss: 0.20597, Acc:0.40678, F1: 0.40354
===> Epoch: 18: Training loss decreased (0.09970 --> 0.09785), Acc: (0.66557 --> 0.67136), F1: (0.66609 --> 0.67110).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 19 Train Avg loss: 0.09533, Acc: 0.67754, F1: 0.67726#####> Valid Avg loss: 0.21126, Acc:0.40500, F1: 0.40177
===> Epoch: 19: Training loss decreased (0.09785 --> 0.09533), Acc: (0.67136 --> 0.67754), F1: (0.67110 --> 0.67726).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597181096.729715.pth_1
====> Epoch: 20 Train Avg loss: 0.09662, Acc: 0.68178, F1: 0.68073#####> Valid Avg loss: 0.26413, Acc:0.40589, F1: 0.40265
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597187179.051185.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597187494.65448.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597188088.851773.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597188205.901519.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597188279.71272.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597188402.281618.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597188480.014078.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
====> Epoch: 1 Train Avg loss: 0.29802, Acc: 0.28643, F1: 0.28726#####> Valid Avg loss: 0.34025, Acc:0.11121, F1: 0.11111
===> Epoch: 1: Training loss decreased (inf --> 0.29802), Acc: (0.00000 --> 0.28643), F1: (0.00000 --> 0.28726).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.34025), Acc: (0.00000 --> 0.11121), F1: (0.00000 --> 0.11111).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.34025), Acc: (0.00000 --> 0.11121), F1: (0.00000 --> 0.11111).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 2 Train Avg loss: 0.21769, Acc: 0.44840, F1: 0.44905#####> Valid Avg loss: 0.32834, Acc:0.15997, F1: 0.15992
===> Epoch: 2: Training loss decreased (0.29802 --> 0.21769), Acc: (0.28643 --> 0.44840), F1: (0.28726 --> 0.44905).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 2: validation loss decreased (0.34025 --> 0.32834), Acc: (0.11121 --> 0.15997), F1: (0.11111 --> 0.15992).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 2: validation acc increase (0.34025 --> 0.32834), Acc: (0.11121 --> 0.15997), F1: (0.11111 --> 0.15992).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 3 Train Avg loss: 0.19364, Acc: 0.52961, F1: 0.53016#####> Valid Avg loss: 0.31917, Acc:0.22070, F1: 0.22070
===> Epoch: 3: Training loss decreased (0.21769 --> 0.19364), Acc: (0.44840 --> 0.52961), F1: (0.44905 --> 0.53016).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 3: validation loss decreased (0.32834 --> 0.31917), Acc: (0.15997 --> 0.22070), F1: (0.15992 --> 0.22070).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 3: validation acc increase (0.32834 --> 0.31917), Acc: (0.15997 --> 0.22070), F1: (0.15992 --> 0.22070).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 4 Train Avg loss: 0.17626, Acc: 0.55644, F1: 0.55637#####> Valid Avg loss: 0.30077, Acc:0.33020, F1: 0.33039
===> Epoch: 4: Training loss decreased (0.19364 --> 0.17626), Acc: (0.52961 --> 0.55644), F1: (0.53016 --> 0.55637).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 4: validation loss decreased (0.31917 --> 0.30077), Acc: (0.22070 --> 0.33020), F1: (0.22070 --> 0.33039).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 4: validation acc increase (0.31917 --> 0.30077), Acc: (0.22070 --> 0.33020), F1: (0.22070 --> 0.33039).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 5 Train Avg loss: 0.16420, Acc: 0.57725, F1: 0.57657#####> Valid Avg loss: 0.29173, Acc:0.35244, F1: 0.35261
===> Epoch: 5: Training loss decreased (0.17626 --> 0.16420), Acc: (0.55644 --> 0.57725), F1: (0.55637 --> 0.57657).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 5: validation loss decreased (0.30077 --> 0.29173), Acc: (0.33020 --> 0.35244), F1: (0.33039 --> 0.35261).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 5: validation acc increase (0.30077 --> 0.29173), Acc: (0.33020 --> 0.35244), F1: (0.33039 --> 0.35261).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 6 Train Avg loss: 0.15536, Acc: 0.59220, F1: 0.59209#####> Valid Avg loss: 0.34493, Acc:0.23695, F1: 0.23704
===> Epoch: 6: Training loss decreased (0.16420 --> 0.15536), Acc: (0.57725 --> 0.59220), F1: (0.57657 --> 0.59209).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 7 Train Avg loss: 0.14902, Acc: 0.60202, F1: 0.60249#####> Valid Avg loss: 0.30555, Acc:0.32849, F1: 0.32868
===> Epoch: 7: Training loss decreased (0.15536 --> 0.14902), Acc: (0.59220 --> 0.60202), F1: (0.59209 --> 0.60249).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 8 Train Avg loss: 0.14814, Acc: 0.60671, F1: 0.60717#####> Valid Avg loss: 0.34924, Acc:0.19418, F1: 0.19421
===> Epoch: 8: Training loss decreased (0.14902 --> 0.14814), Acc: (0.60202 --> 0.60671), F1: (0.60249 --> 0.60717).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 9 Train Avg loss: 0.14278, Acc: 0.61478, F1: 0.61464#####> Valid Avg loss: 0.32503, Acc:0.29512, F1: 0.29525
===> Epoch: 9: Training loss decreased (0.14814 --> 0.14278), Acc: (0.60671 --> 0.61478), F1: (0.60717 --> 0.61464).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 10 Train Avg loss: 0.13783, Acc: 0.62518, F1: 0.62504#####> Valid Avg loss: 0.32006, Acc:0.32421, F1: 0.32441
===> Epoch: 10: Training loss decreased (0.14278 --> 0.13783), Acc: (0.61478 --> 0.62518), F1: (0.61464 --> 0.62504).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 11 Train Avg loss: 0.13188, Acc: 0.63500, F1: 0.63485#####> Valid Avg loss: 0.31138, Acc:0.33020, F1: 0.33039
===> Epoch: 11: Training loss decreased (0.13783 --> 0.13188), Acc: (0.62518 --> 0.63500), F1: (0.62504 --> 0.63485).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
====> Epoch: 12 Train Avg loss: 0.13140, Acc: 0.63281, F1: 0.63265#####> Valid Avg loss: 0.33168, Acc:0.35586, F1: 0.35603
===> Epoch: 12: Training loss decreased (0.13188 --> 0.13140), Acc: (0.63500 --> 0.63281), F1: (0.63485 --> 0.63265).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1

####> Epoch: 12: validation acc increase (0.29173 --> 0.33168), Acc: (0.35244 --> 0.35586), F1: (0.35261 --> 0.35603).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597188717.324861.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 4train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 413
valid_dataloader len: 67
test_dataloader len: 89
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 4129, train dataloader len: 413
valid dataset len: 667, valid dataloader len: 67
valid dataset len: 884, test dataloader len: 67
====> Epoch: 1 Train Avg loss: 0.18990, Acc: 0.40712, F1: 0.40713#####> Valid Avg loss: 0.11823, Acc:0.58921, F1: 0.59041
===> Epoch: 1: Training loss decreased (inf --> 0.18990), Acc: (0.00000 --> 0.40712), F1: (0.00000 --> 0.40713).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.11823), Acc: (0.00000 --> 0.58921), F1: (0.00000 --> 0.59041).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.11823), Acc: (0.00000 --> 0.58921), F1: (0.00000 --> 0.59041).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 2 Train Avg loss: 0.12098, Acc: 0.60668, F1: 0.60665#####> Valid Avg loss: 0.11745, Acc:0.57121, F1: 0.57186
===> Epoch: 2: Training loss decreased (0.18990 --> 0.12098), Acc: (0.40712 --> 0.60668), F1: (0.40713 --> 0.60665).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1

####> Epoch: 2: validation loss decreased (0.11823 --> 0.11745), Acc: (0.58921 --> 0.57121), F1: (0.59041 --> 0.57186).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 3 Train Avg loss: 0.09724, Acc: 0.68467, F1: 0.68469#####> Valid Avg loss: 0.12200, Acc:0.60270, F1: 0.60384
===> Epoch: 3: Training loss decreased (0.12098 --> 0.09724), Acc: (0.60668 --> 0.68467), F1: (0.60665 --> 0.68469).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1

####> Epoch: 3: validation acc increase (0.11823 --> 0.12200), Acc: (0.58921 --> 0.60270), F1: (0.59041 --> 0.60384).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 4 Train Avg loss: 0.08574, Acc: 0.72342, F1: 0.72338#####> Valid Avg loss: 0.12752, Acc:0.67466, F1: 0.67612
===> Epoch: 4: Training loss decreased (0.09724 --> 0.08574), Acc: (0.68467 --> 0.72342), F1: (0.68469 --> 0.72338).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1

####> Epoch: 4: validation acc increase (0.12200 --> 0.12752), Acc: (0.60270 --> 0.67466), F1: (0.60384 --> 0.67612).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 5 Train Avg loss: 0.07711, Acc: 0.75345, F1: 0.75346#####> Valid Avg loss: 0.12020, Acc:0.67466, F1: 0.67612
===> Epoch: 5: Training loss decreased (0.08574 --> 0.07711), Acc: (0.72342 --> 0.75345), F1: (0.72338 --> 0.75346).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 6 Train Avg loss: 0.07074, Acc: 0.75829, F1: 0.75827#####> Valid Avg loss: 0.14602, Acc:0.67766, F1: 0.67910
===> Epoch: 6: Training loss decreased (0.07711 --> 0.07074), Acc: (0.75345 --> 0.75829), F1: (0.75346 --> 0.75827).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1

####> Epoch: 6: validation acc increase (0.12752 --> 0.14602), Acc: (0.67466 --> 0.67766), F1: (0.67612 --> 0.67910).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 7 Train Avg loss: 0.06575, Acc: 0.78251, F1: 0.78254#####> Valid Avg loss: 0.18750, Acc:0.68216, F1: 0.68358
===> Epoch: 7: Training loss decreased (0.07074 --> 0.06575), Acc: (0.75829 --> 0.78251), F1: (0.75827 --> 0.78254).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1

####> Epoch: 7: validation acc increase (0.14602 --> 0.18750), Acc: (0.67766 --> 0.68216), F1: (0.67910 --> 0.68358).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 8 Train Avg loss: 0.06307, Acc: 0.78712, F1: 0.78714#####> Valid Avg loss: 0.17074, Acc:0.67466, F1: 0.67612
===> Epoch: 8: Training loss decreased (0.06575 --> 0.06307), Acc: (0.78251 --> 0.78712), F1: (0.78254 --> 0.78714).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 9 Train Avg loss: 0.05892, Acc: 0.79438, F1: 0.79432#####> Valid Avg loss: 0.22707, Acc:0.68366, F1: 0.68507
===> Epoch: 9: Training loss decreased (0.06307 --> 0.05892), Acc: (0.78712 --> 0.79438), F1: (0.78714 --> 0.79432).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1

####> Epoch: 9: validation acc increase (0.18750 --> 0.22707), Acc: (0.68216 --> 0.68366), F1: (0.68358 --> 0.68507).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 10 Train Avg loss: 0.05663, Acc: 0.80358, F1: 0.80363#####> Valid Avg loss: 0.22321, Acc:0.68366, F1: 0.68507
===> Epoch: 10: Training loss decreased (0.05892 --> 0.05663), Acc: (0.79438 --> 0.80358), F1: (0.79432 --> 0.80363).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 11 Train Avg loss: 0.05519, Acc: 0.80625, F1: 0.80624#####> Valid Avg loss: 0.17891, Acc:0.67916, F1: 0.68060
===> Epoch: 11: Training loss decreased (0.05663 --> 0.05519), Acc: (0.80358 --> 0.80625), F1: (0.80363 --> 0.80624).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 12 Train Avg loss: 0.05060, Acc: 0.81836, F1: 0.81835#####> Valid Avg loss: 0.27055, Acc:0.68366, F1: 0.68507
===> Epoch: 12: Training loss decreased (0.05519 --> 0.05060), Acc: (0.80625 --> 0.81836), F1: (0.80624 --> 0.81835).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597193310.018591.pth_1
====> Epoch: 13 Train Avg loss: 0.05215, Acc: 0.81787, F1: 0.81784#####> Valid Avg loss: 0.20050, Acc:0.68216, F1: 0.68358
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 9train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 417
valid_dataloader len: 110
test_dataloader len: 103
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 4163, train dataloader len: 417
valid dataset len: 1099, valid dataloader len: 110
valid dataset len: 1024, test dataloader len: 110
====> Epoch: 1 Train Avg loss: 0.26931, Acc: 0.34014, F1: 0.34013#####> Valid Avg loss: 0.24157, Acc:0.36852, F1: 0.36869
===> Epoch: 1: Training loss decreased (inf --> 0.26931), Acc: (0.00000 --> 0.34014), F1: (0.00000 --> 0.34013).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.24157), Acc: (0.00000 --> 0.36852), F1: (0.00000 --> 0.36869).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.24157), Acc: (0.00000 --> 0.36852), F1: (0.00000 --> 0.36869).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1
====> Epoch: 2 Train Avg loss: 0.20392, Acc: 0.43574, F1: 0.43557#####> Valid Avg loss: 0.21048, Acc:0.38672, F1: 0.38687
===> Epoch: 2: Training loss decreased (0.26931 --> 0.20392), Acc: (0.34014 --> 0.43574), F1: (0.34013 --> 0.43557).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 2: validation loss decreased (0.24157 --> 0.21048), Acc: (0.36852 --> 0.38672), F1: (0.36869 --> 0.38687).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 2: validation acc increase (0.24157 --> 0.21048), Acc: (0.36852 --> 0.38672), F1: (0.36869 --> 0.38687).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1
====> Epoch: 3 Train Avg loss: 0.18114, Acc: 0.48162, F1: 0.48193#####> Valid Avg loss: 0.18951, Acc:0.41310, F1: 0.41323
===> Epoch: 3: Training loss decreased (0.20392 --> 0.18114), Acc: (0.43574 --> 0.48162), F1: (0.43557 --> 0.48193).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 3: validation loss decreased (0.21048 --> 0.18951), Acc: (0.38672 --> 0.41310), F1: (0.38687 --> 0.41323).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 3: validation acc increase (0.21048 --> 0.18951), Acc: (0.38672 --> 0.41310), F1: (0.38687 --> 0.41323).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1
====> Epoch: 4 Train Avg loss: 0.16854, Acc: 0.51742, F1: 0.51823#####> Valid Avg loss: 0.18354, Acc:0.41310, F1: 0.41323
===> Epoch: 4: Training loss decreased (0.18114 --> 0.16854), Acc: (0.48162 --> 0.51742), F1: (0.48193 --> 0.51823).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 4: validation loss decreased (0.18951 --> 0.18354), Acc: (0.41310 --> 0.41310), F1: (0.41323 --> 0.41323).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1
====> Epoch: 5 Train Avg loss: 0.15711, Acc: 0.54120, F1: 0.54085#####> Valid Avg loss: 0.18527, Acc:0.41219, F1: 0.41232
===> Epoch: 5: Training loss decreased (0.16854 --> 0.15711), Acc: (0.51742 --> 0.54120), F1: (0.51823 --> 0.54085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1
====> Epoch: 6 Train Avg loss: 0.15221, Acc: 0.54552, F1: 0.54572#####> Valid Avg loss: 0.17241, Acc:0.41401, F1: 0.41414
===> Epoch: 6: Training loss decreased (0.15711 --> 0.15221), Acc: (0.54120 --> 0.54552), F1: (0.54085 --> 0.54572).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 6: validation loss decreased (0.18354 --> 0.17241), Acc: (0.41310 --> 0.41401), F1: (0.41323 --> 0.41414).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 6: validation acc increase (0.18951 --> 0.17241), Acc: (0.41310 --> 0.41401), F1: (0.41323 --> 0.41414).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1
====> Epoch: 7 Train Avg loss: 0.14489, Acc: 0.55633, F1: 0.55651#####> Valid Avg loss: 0.16704, Acc:0.40673, F1: 0.40687
===> Epoch: 7: Training loss decreased (0.15221 --> 0.14489), Acc: (0.54552 --> 0.55633), F1: (0.54572 --> 0.55651).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 7: validation loss decreased (0.17241 --> 0.16704), Acc: (0.41401 --> 0.40673), F1: (0.41414 --> 0.40687).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1
====> Epoch: 8 Train Avg loss: 0.13869, Acc: 0.57194, F1: 0.57154#####> Valid Avg loss: 0.17533, Acc:0.41492, F1: 0.41505
===> Epoch: 8: Training loss decreased (0.14489 --> 0.13869), Acc: (0.55633 --> 0.57194), F1: (0.55651 --> 0.57154).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1

####> Epoch: 8: validation acc increase (0.17241 --> 0.17533), Acc: (0.41401 --> 0.41492), F1: (0.41414 --> 0.41505).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1
====> Epoch: 9 Train Avg loss: 0.13494, Acc: 0.58900, F1: 0.58913#####> Valid Avg loss: 0.18430, Acc:0.40400, F1: 0.40414
===> Epoch: 9: Training loss decreased (0.13869 --> 0.13494), Acc: (0.57194 --> 0.58900), F1: (0.57154 --> 0.58913).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597196402.810483.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 9train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 417
valid_dataloader len: 110
test_dataloader len: 103
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 4163, train dataloader len: 417
valid dataset len: 1099, valid dataloader len: 110
valid dataset len: 1024, test dataloader len: 110
====> Epoch: 1 Train Avg loss: 0.26302, Acc: 0.35191, F1: 0.35188#####> Valid Avg loss: 0.20952, Acc:0.41037, F1: 0.41051
===> Epoch: 1: Training loss decreased (inf --> 0.26302), Acc: (0.00000 --> 0.35191), F1: (0.00000 --> 0.35188).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.20952), Acc: (0.00000 --> 0.41037), F1: (0.00000 --> 0.41051).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.20952), Acc: (0.00000 --> 0.41037), F1: (0.00000 --> 0.41051).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 2 Train Avg loss: 0.20245, Acc: 0.45616, F1: 0.45596#####> Valid Avg loss: 0.21231, Acc:0.36852, F1: 0.36859
===> Epoch: 2: Training loss decreased (0.26302 --> 0.20245), Acc: (0.35191 --> 0.45616), F1: (0.35188 --> 0.45596).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 3 Train Avg loss: 0.18029, Acc: 0.48499, F1: 0.48529#####> Valid Avg loss: 0.18662, Acc:0.41128, F1: 0.41141
===> Epoch: 3: Training loss decreased (0.20245 --> 0.18029), Acc: (0.45616 --> 0.48499), F1: (0.45596 --> 0.48529).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1

####> Epoch: 3: validation loss decreased (0.20952 --> 0.18662), Acc: (0.41037 --> 0.41128), F1: (0.41051 --> 0.41141).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1

####> Epoch: 3: validation acc increase (0.20952 --> 0.18662), Acc: (0.41037 --> 0.41128), F1: (0.41051 --> 0.41141).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 4 Train Avg loss: 0.16536, Acc: 0.52967, F1: 0.53046#####> Valid Avg loss: 0.17494, Acc:0.40400, F1: 0.40414
===> Epoch: 4: Training loss decreased (0.18029 --> 0.16536), Acc: (0.48499 --> 0.52967), F1: (0.48529 --> 0.53046).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1

####> Epoch: 4: validation loss decreased (0.18662 --> 0.17494), Acc: (0.41128 --> 0.40400), F1: (0.41141 --> 0.40414).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 5 Train Avg loss: 0.15608, Acc: 0.54336, F1: 0.54357#####> Valid Avg loss: 0.17570, Acc:0.40946, F1: 0.40960
===> Epoch: 5: Training loss decreased (0.16536 --> 0.15608), Acc: (0.52967 --> 0.54336), F1: (0.53046 --> 0.54357).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 6 Train Avg loss: 0.15014, Acc: 0.55513, F1: 0.55532#####> Valid Avg loss: 0.17495, Acc:0.39945, F1: 0.39960
===> Epoch: 6: Training loss decreased (0.15608 --> 0.15014), Acc: (0.54336 --> 0.55513), F1: (0.54357 --> 0.55532).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 7 Train Avg loss: 0.14442, Acc: 0.56738, F1: 0.56699#####> Valid Avg loss: 0.17714, Acc:0.41219, F1: 0.41232
===> Epoch: 7: Training loss decreased (0.15014 --> 0.14442), Acc: (0.55513 --> 0.56738), F1: (0.55532 --> 0.56699).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1

####> Epoch: 7: validation acc increase (0.18662 --> 0.17714), Acc: (0.41128 --> 0.41219), F1: (0.41141 --> 0.41232).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 8 Train Avg loss: 0.14034, Acc: 0.57386, F1: 0.57290#####> Valid Avg loss: 0.18580, Acc:0.40491, F1: 0.40505
===> Epoch: 8: Training loss decreased (0.14442 --> 0.14034), Acc: (0.56738 --> 0.57386), F1: (0.56699 --> 0.57290).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 9 Train Avg loss: 0.13424, Acc: 0.58852, F1: 0.58865#####> Valid Avg loss: 0.21605, Acc:0.35032, F1: 0.35051
===> Epoch: 9: Training loss decreased (0.14034 --> 0.13424), Acc: (0.57386 --> 0.58852), F1: (0.57290 --> 0.58865).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 10 Train Avg loss: 0.13127, Acc: 0.59644, F1: 0.59656#####> Valid Avg loss: 0.17085, Acc:0.38217, F1: 0.38232
===> Epoch: 10: Training loss decreased (0.13424 --> 0.13127), Acc: (0.58852 --> 0.59644), F1: (0.58865 --> 0.59656).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1

####> Epoch: 10: validation loss decreased (0.17494 --> 0.17085), Acc: (0.40400 --> 0.38217), F1: (0.40414 --> 0.38232).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 11 Train Avg loss: 0.13147, Acc: 0.59717, F1: 0.59672#####> Valid Avg loss: 0.19228, Acc:0.41401, F1: 0.41414

####> Epoch: 11: validation acc increase (0.17714 --> 0.19228), Acc: (0.41219 --> 0.41401), F1: (0.41232 --> 0.41414).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 12 Train Avg loss: 0.12954, Acc: 0.59332, F1: 0.59233#####> Valid Avg loss: 0.18783, Acc:0.41492, F1: 0.41505
===> Epoch: 12: Training loss decreased (0.13127 --> 0.12954), Acc: (0.59644 --> 0.59332), F1: (0.59656 --> 0.59233).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1

####> Epoch: 12: validation acc increase (0.19228 --> 0.18783), Acc: (0.41401 --> 0.41492), F1: (0.41414 --> 0.41505).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 13 Train Avg loss: 0.12540, Acc: 0.61110, F1: 0.61175#####> Valid Avg loss: 0.19071, Acc:0.41310, F1: 0.41323
===> Epoch: 13: Training loss decreased (0.12954 --> 0.12540), Acc: (0.59332 --> 0.61110), F1: (0.59233 --> 0.61175).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 14 Train Avg loss: 0.12571, Acc: 0.60773, F1: 0.60671#####> Valid Avg loss: 0.22091, Acc:0.41037, F1: 0.41051
====> Epoch: 15 Train Avg loss: 0.12484, Acc: 0.61086, F1: 0.61039#####> Valid Avg loss: 0.20448, Acc:0.40946, F1: 0.40960
===> Epoch: 15: Training loss decreased (0.12540 --> 0.12484), Acc: (0.61110 --> 0.61086), F1: (0.61175 --> 0.61039).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 16 Train Avg loss: 0.12200, Acc: 0.61158, F1: 0.61167#####> Valid Avg loss: 0.23340, Acc:0.41310, F1: 0.41323
===> Epoch: 16: Training loss decreased (0.12484 --> 0.12200), Acc: (0.61086 --> 0.61158), F1: (0.61039 --> 0.61167).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 17 Train Avg loss: 0.12032, Acc: 0.61230, F1: 0.61183#####> Valid Avg loss: 0.20346, Acc:0.41401, F1: 0.41414
===> Epoch: 17: Training loss decreased (0.12200 --> 0.12032), Acc: (0.61158 --> 0.61230), F1: (0.61167 --> 0.61183).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 18 Train Avg loss: 0.12028, Acc: 0.61758, F1: 0.61711#####> Valid Avg loss: 0.21506, Acc:0.41310, F1: 0.41323
===> Epoch: 18: Training loss decreased (0.12032 --> 0.12028), Acc: (0.61230 --> 0.61758), F1: (0.61183 --> 0.61711).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 19 Train Avg loss: 0.11640, Acc: 0.62791, F1: 0.62798#####> Valid Avg loss: 0.19346, Acc:0.40855, F1: 0.40869
===> Epoch: 19: Training loss decreased (0.12028 --> 0.11640), Acc: (0.61758 --> 0.62791), F1: (0.61711 --> 0.62798).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 20 Train Avg loss: 0.11494, Acc: 0.62887, F1: 0.62838#####> Valid Avg loss: 0.21905, Acc:0.41310, F1: 0.41323
===> Epoch: 20: Training loss decreased (0.11640 --> 0.11494), Acc: (0.62791 --> 0.62887), F1: (0.62798 --> 0.62838).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 21 Train Avg loss: 0.11507, Acc: 0.63031, F1: 0.63094#####> Valid Avg loss: 0.22439, Acc:0.40218, F1: 0.40232
====> Epoch: 22 Train Avg loss: 0.11387, Acc: 0.63296, F1: 0.63189#####> Valid Avg loss: 0.22027, Acc:0.41401, F1: 0.41414
===> Epoch: 22: Training loss decreased (0.11494 --> 0.11387), Acc: (0.62887 --> 0.63296), F1: (0.62838 --> 0.63189).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 23 Train Avg loss: 0.11329, Acc: 0.63248, F1: 0.63253#####> Valid Avg loss: 0.20920, Acc:0.41492, F1: 0.41505
===> Epoch: 23: Training loss decreased (0.11387 --> 0.11329), Acc: (0.63296 --> 0.63248), F1: (0.63189 --> 0.63253).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 24 Train Avg loss: 0.11055, Acc: 0.63512, F1: 0.63573#####> Valid Avg loss: 0.19762, Acc:0.41401, F1: 0.41414
===> Epoch: 24: Training loss decreased (0.11329 --> 0.11055), Acc: (0.63248 --> 0.63512), F1: (0.63253 --> 0.63573).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 25 Train Avg loss: 0.11122, Acc: 0.63776, F1: 0.63837#####> Valid Avg loss: 0.19535, Acc:0.41310, F1: 0.41323
====> Epoch: 26 Train Avg loss: 0.10896, Acc: 0.64088, F1: 0.64093#####> Valid Avg loss: 0.24048, Acc:0.40127, F1: 0.40141
===> Epoch: 26: Training loss decreased (0.11055 --> 0.10896), Acc: (0.63512 --> 0.64088), F1: (0.63573 --> 0.64093).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 27 Train Avg loss: 0.10985, Acc: 0.64016, F1: 0.63965#####> Valid Avg loss: 0.20815, Acc:0.41401, F1: 0.41414
====> Epoch: 28 Train Avg loss: 0.10807, Acc: 0.63704, F1: 0.63765#####> Valid Avg loss: 0.23509, Acc:0.41037, F1: 0.41051
===> Epoch: 28: Training loss decreased (0.10896 --> 0.10807), Acc: (0.64088 --> 0.63704), F1: (0.64093 --> 0.63765).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 29 Train Avg loss: 0.10803, Acc: 0.64281, F1: 0.64341#####> Valid Avg loss: 0.23019, Acc:0.41310, F1: 0.41323
===> Epoch: 29: Training loss decreased (0.10807 --> 0.10803), Acc: (0.63704 --> 0.64281), F1: (0.63765 --> 0.64341).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
====> Epoch: 30 Train Avg loss: 0.10408, Acc: 0.64665, F1: 0.64724#####> Valid Avg loss: 0.23230, Acc:0.41310, F1: 0.41323
===> Epoch: 30: Training loss decreased (0.10803 --> 0.10408), Acc: (0.64281 --> 0.64665), F1: (0.64341 --> 0.64724).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597198762.73781.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 281
valid_dataloader len: 91
test_dataloader len: 44
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 281
valid dataset len: 910, valid dataloader len: 91
valid dataset len: 431, test dataloader len: 91
====> Epoch: 1 Train Avg loss: 0.23593, Acc: 0.45756, F1: 0.45872#####> Valid Avg loss: 0.14309, Acc:0.50110, F1: 0.50110
===> Epoch: 1: Training loss decreased (inf --> 0.23593), Acc: (0.00000 --> 0.45756), F1: (0.00000 --> 0.45872).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.14309), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.14309), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1
====> Epoch: 2 Train Avg loss: 0.19188, Acc: 0.48859, F1: 0.48861#####> Valid Avg loss: 0.13292, Acc:0.50110, F1: 0.50110
===> Epoch: 2: Training loss decreased (0.23593 --> 0.19188), Acc: (0.45756 --> 0.48859), F1: (0.45872 --> 0.48861).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1

####> Epoch: 2: validation loss decreased (0.14309 --> 0.13292), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1
====> Epoch: 3 Train Avg loss: 0.17311, Acc: 0.51854, F1: 0.51851#####> Valid Avg loss: 0.13022, Acc:0.50110, F1: 0.50110
===> Epoch: 3: Training loss decreased (0.19188 --> 0.17311), Acc: (0.48859 --> 0.51854), F1: (0.48861 --> 0.51851).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1

####> Epoch: 3: validation loss decreased (0.13292 --> 0.13022), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1
====> Epoch: 4 Train Avg loss: 0.16356, Acc: 0.53424, F1: 0.53416#####> Valid Avg loss: 0.12176, Acc:0.50110, F1: 0.50110
===> Epoch: 4: Training loss decreased (0.17311 --> 0.16356), Acc: (0.51854 --> 0.53424), F1: (0.51851 --> 0.53416).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1

####> Epoch: 4: validation loss decreased (0.13022 --> 0.12176), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1
====> Epoch: 5 Train Avg loss: 0.15434, Acc: 0.54922, F1: 0.54911#####> Valid Avg loss: 0.12233, Acc:0.50110, F1: 0.50110
===> Epoch: 5: Training loss decreased (0.16356 --> 0.15434), Acc: (0.53424 --> 0.54922), F1: (0.53416 --> 0.54911).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1
====> Epoch: 6 Train Avg loss: 0.14774, Acc: 0.54922, F1: 0.54858#####> Valid Avg loss: 0.12013, Acc:0.50110, F1: 0.50110
===> Epoch: 6: Training loss decreased (0.15434 --> 0.14774), Acc: (0.54922 --> 0.54922), F1: (0.54911 --> 0.54858).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1

####> Epoch: 6: validation loss decreased (0.12176 --> 0.12013), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1
====> Epoch: 7 Train Avg loss: 0.14407, Acc: 0.54529, F1: 0.54520#####> Valid Avg loss: 0.11976, Acc:0.50110, F1: 0.50110
===> Epoch: 7: Training loss decreased (0.14774 --> 0.14407), Acc: (0.54922 --> 0.54529), F1: (0.54858 --> 0.54520).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1

####> Epoch: 7: validation loss decreased (0.12013 --> 0.11976), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1
====> Epoch: 8 Train Avg loss: 0.13919, Acc: 0.55385, F1: 0.55427#####> Valid Avg loss: 0.13290, Acc:0.50110, F1: 0.50110
===> Epoch: 8: Training loss decreased (0.14407 --> 0.13919), Acc: (0.54529 --> 0.55385), F1: (0.54520 --> 0.55427).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597205977.211856.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597207471.623176.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 281
valid_dataloader len: 91
test_dataloader len: 44
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 281
valid dataset len: 910, valid dataloader len: 91
valid dataset len: 431, test dataloader len: 91
====> Epoch: 1 Train Avg loss: 0.24798, Acc: 0.46434, F1: 0.46495#####> Valid Avg loss: 0.14868, Acc:0.50110, F1: 0.50110
===> Epoch: 1: Training loss decreased (inf --> 0.24798), Acc: (0.00000 --> 0.46434), F1: (0.00000 --> 0.46495).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597207471.623176.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.14868), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597207471.623176.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.14868), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597207471.623176.pth_1
====> Epoch: 2 Train Avg loss: 0.19642, Acc: 0.47753, F1: 0.47811#####> Valid Avg loss: 0.13565, Acc:0.50110, F1: 0.50110
===> Epoch: 2: Training loss decreased (0.24798 --> 0.19642), Acc: (0.46434 --> 0.47753), F1: (0.46495 --> 0.47811).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597207471.623176.pth_1

####> Epoch: 2: validation loss decreased (0.14868 --> 0.13565), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597207471.623176.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597207890.276483.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 281
valid_dataloader len: 91
test_dataloader len: 44
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 281
valid dataset len: 910, valid dataloader len: 91
valid dataset len: 431, test dataloader len: 91
====> Epoch: 1 Train Avg loss: 0.24440, Acc: 0.45328, F1: 0.45445#####> Valid Avg loss: 0.14683, Acc:0.50110, F1: 0.50110
===> Epoch: 1: Training loss decreased (inf --> 0.24440), Acc: (0.00000 --> 0.45328), F1: (0.00000 --> 0.45445).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597207890.276483.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.14683), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597207890.276483.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.14683), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597207890.276483.pth_1
====> Epoch: 2 Train Avg loss: 0.19069, Acc: 0.48538, F1: 0.48648#####> Valid Avg loss: 0.12856, Acc:0.50110, F1: 0.50110
===> Epoch: 2: Training loss decreased (0.24440 --> 0.19069), Acc: (0.45328 --> 0.48538), F1: (0.45445 --> 0.48648).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597207890.276483.pth_1

####> Epoch: 2: validation loss decreased (0.14683 --> 0.12856), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597207890.276483.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:20
cnn_out_channel: 64, feature_embed_size:64
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597209088.490349.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 141
valid_dataloader len: 46
test_dataloader len: 22
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 141
valid dataset len: 910, valid dataloader len: 46
valid dataset len: 431, test dataloader len: 46
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:20
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597209161.206056.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 141
valid_dataloader len: 46
test_dataloader len: 22
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 141
valid dataset len: 910, valid dataloader len: 46
valid dataset len: 431, test dataloader len: 46
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:20
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597209219.136674.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 141
valid_dataloader len: 46
test_dataloader len: 22
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 141
valid dataset len: 910, valid dataloader len: 46
valid dataset len: 431, test dataloader len: 46
====> Epoch: 1 Train Avg loss: 0.13518, Acc: 0.44437, F1: 0.44610#####> Valid Avg loss: 0.08235, Acc:0.50110, F1: 0.50109
===> Epoch: 1: Training loss decreased (inf --> 0.13518), Acc: (0.00000 --> 0.44437), F1: (0.00000 --> 0.44610).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597209219.136674.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.08235), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50109).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597209219.136674.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.08235), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50109).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597209219.136674.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.003, epoch:500, batch_size:25
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597209349.186092.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 113
valid_dataloader len: 37
test_dataloader len: 18
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 113
valid dataset len: 910, valid dataloader len: 37
valid dataset len: 431, test dataloader len: 37
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.003, epoch:500, batch_size:25
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597209415.71119.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 113
valid_dataloader len: 37
test_dataloader len: 18
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 113
valid dataset len: 910, valid dataloader len: 37
valid dataset len: 431, test dataloader len: 37
====> Epoch: 1 Train Avg loss: 0.09683, Acc: 0.45970, F1: 0.46186#####> Valid Avg loss: 0.04957, Acc:0.50110, F1: 0.50108
===> Epoch: 1: Training loss decreased (inf --> 0.09683), Acc: (0.00000 --> 0.45970), F1: (0.00000 --> 0.46186).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597209415.71119.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.04957), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50108).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597209415.71119.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.04957), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50108).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597209415.71119.pth_1
====> Epoch: 2 Train Avg loss: 0.07372, Acc: 0.51712, F1: 0.51885#####> Valid Avg loss: 0.05177, Acc:0.50110, F1: 0.50108
===> Epoch: 2: Training loss decreased (0.09683 --> 0.07372), Acc: (0.45970 --> 0.51712), F1: (0.46186 --> 0.51885).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597209415.71119.pth_1
====> Epoch: 3 Train Avg loss: 0.06729, Acc: 0.53281, F1: 0.53442#####> Valid Avg loss: 0.05081, Acc:0.50110, F1: 0.50108
===> Epoch: 3: Training loss decreased (0.07372 --> 0.06729), Acc: (0.51712 --> 0.53281), F1: (0.51885 --> 0.53442).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597209415.71119.pth_1
====> Epoch: 4 Train Avg loss: 0.06394, Acc: 0.54208, F1: 0.54177#####> Valid Avg loss: 0.05113, Acc:0.50110, F1: 0.50108
===> Epoch: 4: Training loss decreased (0.06729 --> 0.06394), Acc: (0.53281 --> 0.54208), F1: (0.53442 --> 0.54177).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597209415.71119.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.7, upper_layer_dropout: 0.2
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597209779.059628.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 561
valid_dataloader len: 182
test_dataloader len: 87
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 561
valid dataset len: 910, valid dataloader len: 182
valid dataset len: 431, test dataloader len: 182
====> Epoch: 1 Train Avg loss: 0.40475, Acc: 0.52175, F1: 0.52175#####> Valid Avg loss: 0.26575, Acc:0.50110, F1: 0.50110
===> Epoch: 1: Training loss decreased (inf --> 0.40475), Acc: (0.00000 --> 0.52175), F1: (0.00000 --> 0.52175).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597209779.059628.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.26575), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597209779.059628.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.26575), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597209779.059628.pth_1
====> Epoch: 2 Train Avg loss: 0.31223, Acc: 0.54708, F1: 0.54724#####> Valid Avg loss: 0.26254, Acc:0.50110, F1: 0.50110
===> Epoch: 2: Training loss decreased (0.40475 --> 0.31223), Acc: (0.52175 --> 0.54708), F1: (0.52175 --> 0.54724).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597209779.059628.pth_1

####> Epoch: 2: validation loss decreased (0.26575 --> 0.26254), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597209779.059628.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.005, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.2, upper_layer_dropout: 0.7
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597210405.364657.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.005, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.2, upper_layer_dropout: 0.7
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597210549.093508.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 683
valid_dataloader len: 117
test_dataloader len: 118
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 683
valid dataset len: 1169, valid dataloader len: 117
valid dataset len: 1173, test dataloader len: 117
====> Epoch: 1 Train Avg loss: 0.25898, Acc: 0.20111, F1: 0.20088#####> Valid Avg loss: 0.28014, Acc:0.39008, F1: 0.39022
===> Epoch: 1: Training loss decreased (inf --> 0.25898), Acc: (0.00000 --> 0.20111), F1: (0.00000 --> 0.20088).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597210549.093508.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.28014), Acc: (0.00000 --> 0.39008), F1: (0.00000 --> 0.39022).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597210549.093508.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.28014), Acc: (0.00000 --> 0.39008), F1: (0.00000 --> 0.39022).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597210549.093508.pth_1
====> Epoch: 2 Train Avg loss: 0.23672, Acc: 0.20962, F1: 0.20937#####> Valid Avg loss: 0.27858, Acc:0.39008, F1: 0.39022
===> Epoch: 2: Training loss decreased (0.25898 --> 0.23672), Acc: (0.20111 --> 0.20962), F1: (0.20088 --> 0.20937).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597210549.093508.pth_1

####> Epoch: 2: validation loss decreased (0.28014 --> 0.27858), Acc: (0.39008 --> 0.39008), F1: (0.39022 --> 0.39022).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597210549.093508.pth_1
====> Epoch: 3 Train Avg loss: 0.22699, Acc: 0.21225, F1: 0.21259#####> Valid Avg loss: 0.28747, Acc:0.00000, F1: 0.00000
===> Epoch: 3: Training loss decreased (0.23672 --> 0.22699), Acc: (0.20962 --> 0.21225), F1: (0.20937 --> 0.21259).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597210549.093508.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0007, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.7, upper_layer_dropout: 0.2
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597211873.845508.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 3train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 224
valid_dataloader len: 86
test_dataloader len: 38
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2233, train dataloader len: 224
valid dataset len: 851, valid dataloader len: 86
valid dataset len: 380, test dataloader len: 86
====> Epoch: 1 Train Avg loss: 0.19410, Acc: 0.57949, F1: 0.57872#####> Valid Avg loss: 0.15175, Acc:0.53584, F1: 0.53023
===> Epoch: 1: Training loss decreased (inf --> 0.19410), Acc: (0.00000 --> 0.57949), F1: (0.00000 --> 0.57872).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597211873.845508.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.15175), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53023).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597211873.845508.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.15175), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53023).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597211873.845508.pth_1
====> Epoch: 2 Train Avg loss: 0.14150, Acc: 0.65204, F1: 0.65208#####> Valid Avg loss: 0.12324, Acc:0.53584, F1: 0.53023
===> Epoch: 2: Training loss decreased (0.19410 --> 0.14150), Acc: (0.57949 --> 0.65204), F1: (0.57872 --> 0.65208).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597211873.845508.pth_1

####> Epoch: 2: validation loss decreased (0.15175 --> 0.12324), Acc: (0.53584 --> 0.53584), F1: (0.53023 --> 0.53023).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597211873.845508.pth_1
====> Epoch: 3 Train Avg loss: 0.11992, Acc: 0.66234, F1: 0.66235#####> Valid Avg loss: 0.11083, Acc:0.53584, F1: 0.53023
===> Epoch: 3: Training loss decreased (0.14150 --> 0.11992), Acc: (0.65204 --> 0.66234), F1: (0.65208 --> 0.66235).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597211873.845508.pth_1

####> Epoch: 3: validation loss decreased (0.12324 --> 0.11083), Acc: (0.53584 --> 0.53584), F1: (0.53023 --> 0.53023).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597211873.845508.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0007, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.7, upper_layer_dropout: 0.2
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597212344.766611.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 3train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 224
valid_dataloader len: 86
test_dataloader len: 38
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2233, train dataloader len: 224
valid dataset len: 851, valid dataloader len: 86
valid dataset len: 380, test dataloader len: 86
====> Epoch: 1 Train Avg loss: 0.13182, Acc: 0.64532, F1: 0.64435#####> Valid Avg loss: 0.10749, Acc:0.53584, F1: 0.53023
===> Epoch: 1: Training loss decreased (inf --> 0.13182), Acc: (0.00000 --> 0.64532), F1: (0.00000 --> 0.64435).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597212344.766611.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.10749), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53023).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597212344.766611.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.10749), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53023).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597212344.766611.pth_1
====> Epoch: 2 Train Avg loss: 0.09770, Acc: 0.66547, F1: 0.66652#####> Valid Avg loss: 0.10444, Acc:0.53584, F1: 0.53023
===> Epoch: 2: Training loss decreased (0.13182 --> 0.09770), Acc: (0.64532 --> 0.66547), F1: (0.64435 --> 0.66652).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597212344.766611.pth_1

####> Epoch: 2: validation loss decreased (0.10749 --> 0.10444), Acc: (0.53584 --> 0.53584), F1: (0.53023 --> 0.53023).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597212344.766611.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0007, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.7, upper_layer_dropout: 0.2
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597212716.134134.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 2train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 70
valid_dataloader len: 40
test_dataloader len: 12
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 693, train dataloader len: 70
valid dataset len: 395, valid dataloader len: 40
valid dataset len: 118, test dataloader len: 40
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0007, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597212804.024911.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 2train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 70
valid_dataloader len: 40
test_dataloader len: 12
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 693, train dataloader len: 70
valid dataset len: 395, valid dataloader len: 40
valid dataset len: 118, test dataloader len: 40
====> Epoch: 1 Train Avg loss: 0.12129, Acc: 0.61760, F1: 0.61476#####> Valid Avg loss: 0.06080, Acc:0.77468, F1: 0.77750
===> Epoch: 1: Training loss decreased (inf --> 0.12129), Acc: (0.00000 --> 0.61760), F1: (0.00000 --> 0.61476).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597212804.024911.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.06080), Acc: (0.00000 --> 0.77468), F1: (0.00000 --> 0.77750).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597212804.024911.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.06080), Acc: (0.00000 --> 0.77468), F1: (0.00000 --> 0.77750).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597212804.024911.pth_1
====> Epoch: 2 Train Avg loss: 0.08190, Acc: 0.63781, F1: 0.64143#####> Valid Avg loss: 0.06261, Acc:0.77468, F1: 0.77750
===> Epoch: 2: Training loss decreased (0.12129 --> 0.08190), Acc: (0.61760 --> 0.63781), F1: (0.61476 --> 0.64143).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597212804.024911.pth_1
====> Epoch: 3 Train Avg loss: 0.07353, Acc: 0.66667, F1: 0.66667#####> Valid Avg loss: 0.05820, Acc:0.77468, F1: 0.77750
===> Epoch: 3: Training loss decreased (0.08190 --> 0.07353), Acc: (0.63781 --> 0.66667), F1: (0.64143 --> 0.66667).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597212804.024911.pth_1

####> Epoch: 3: validation loss decreased (0.06080 --> 0.05820), Acc: (0.77468 --> 0.77468), F1: (0.77750 --> 0.77750).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597212804.024911.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0007, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597213000.340553.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 2train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 347
valid_dataloader len: 198
test_dataloader len: 59
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 693, train dataloader len: 347
valid dataset len: 395, valid dataloader len: 198
valid dataset len: 118, test dataloader len: 198
====> Epoch: 1 Train Avg loss: 0.86096, Acc: 0.56277, F1: 0.56340#####> Valid Avg loss: 0.38298, Acc:0.77468, F1: 0.77525
===> Epoch: 1: Training loss decreased (inf --> 0.86096), Acc: (0.00000 --> 0.56277), F1: (0.00000 --> 0.56340).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213000.340553.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.38298), Acc: (0.00000 --> 0.77468), F1: (0.00000 --> 0.77525).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597213000.340553.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.38298), Acc: (0.00000 --> 0.77468), F1: (0.00000 --> 0.77525).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597213000.340553.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.01, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597213179.692362.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 2train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 347
valid_dataloader len: 198
test_dataloader len: 59
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 693, train dataloader len: 347
valid dataset len: 395, valid dataloader len: 198
valid dataset len: 118, test dataloader len: 198
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.01, epoch:500, batch_size:2
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597213246.815911.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 2train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 347
valid_dataloader len: 198
test_dataloader len: 59
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 693, train dataloader len: 347
valid dataset len: 395, valid dataloader len: 198
valid dataset len: 118, test dataloader len: 198
====> Epoch: 1 Train Avg loss: 0.52083, Acc: 0.60606, F1: 0.60663#####> Valid Avg loss: 0.27014, Acc:0.77468, F1: 0.77525
===> Epoch: 1: Training loss decreased (inf --> 0.52083), Acc: (0.00000 --> 0.60606), F1: (0.00000 --> 0.60663).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213246.815911.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.27014), Acc: (0.00000 --> 0.77468), F1: (0.00000 --> 0.77525).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597213246.815911.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.27014), Acc: (0.00000 --> 0.77468), F1: (0.00000 --> 0.77525).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597213246.815911.pth_1
====> Epoch: 2 Train Avg loss: 0.41797, Acc: 0.62338, F1: 0.62392#####> Valid Avg loss: 0.26942, Acc:0.77468, F1: 0.77525
===> Epoch: 2: Training loss decreased (0.52083 --> 0.41797), Acc: (0.60606 --> 0.62338), F1: (0.60663 --> 0.62392).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213246.815911.pth_1

####> Epoch: 2: validation loss decreased (0.27014 --> 0.26942), Acc: (0.77468 --> 0.77468), F1: (0.77525 --> 0.77525).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597213246.815911.pth_1
====> Epoch: 3 Train Avg loss: 0.36673, Acc: 0.64214, F1: 0.64265validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 402
valid_dataloader len: 26
test_dataloader len: 75
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 4018, train dataloader len: 402
valid dataset len: 259, valid dataloader len: 26
valid dataset len: 742, test dataloader len: 26
====> Epoch: 1 Train Avg loss: 0.22629, Acc: 0.40791, F1: 0.40802#####> Valid Avg loss: 0.33093, Acc:0.17375, F1: 0.17650
===> Epoch: 1: Training loss decreased (inf --> 0.22629), Acc: (0.00000 --> 0.40791), F1: (0.00000 --> 0.40802).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.33093), Acc: (0.00000 --> 0.17375), F1: (0.00000 --> 0.17650).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.33093), Acc: (0.00000 --> 0.17375), F1: (0.00000 --> 0.17650).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 2 Train Avg loss: 0.15716, Acc: 0.64385, F1: 0.64384#####> Valid Avg loss: 0.33838, Acc:0.18533, F1: 0.18803
===> Epoch: 2: Training loss decreased (0.22629 --> 0.15716), Acc: (0.40791 --> 0.64385), F1: (0.40802 --> 0.64384).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1

####> Epoch: 2: validation acc increase (0.33093 --> 0.33838), Acc: (0.17375 --> 0.18533), F1: (0.17650 --> 0.18803).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 3 Train Avg loss: 0.13302, Acc: 0.70732, F1: 0.70734#####> Valid Avg loss: 0.33157, Acc:0.22780, F1: 0.23034
===> Epoch: 3: Training loss decreased (0.15716 --> 0.13302), Acc: (0.64385 --> 0.70732), F1: (0.64384 --> 0.70734).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1

####> Epoch: 3: validation acc increase (0.33838 --> 0.33157), Acc: (0.18533 --> 0.22780), F1: (0.18803 --> 0.23034).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 4 Train Avg loss: 0.11770, Acc: 0.74266, F1: 0.74266#####> Valid Avg loss: 0.34132, Acc:0.21236, F1: 0.21496
===> Epoch: 4: Training loss decreased (0.13302 --> 0.11770), Acc: (0.70732 --> 0.74266), F1: (0.70734 --> 0.74266).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 5 Train Avg loss: 0.10891, Acc: 0.75834, F1: 0.75846#####> Valid Avg loss: 0.33606, Acc:0.17761, F1: 0.18034
===> Epoch: 5: Training loss decreased (0.11770 --> 0.10891), Acc: (0.74266 --> 0.75834), F1: (0.74266 --> 0.75846).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 6 Train Avg loss: 0.09797, Acc: 0.77924, F1: 0.77917#####> Valid Avg loss: 0.39811, Acc:0.16988, F1: 0.17265
===> Epoch: 6: Training loss decreased (0.10891 --> 0.09797), Acc: (0.75834 --> 0.77924), F1: (0.75846 --> 0.77917).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 7 Train Avg loss: 0.09070, Acc: 0.78547, F1: 0.78539#####> Valid Avg loss: 0.44606, Acc:0.16988, F1: 0.17265
===> Epoch: 7: Training loss decreased (0.09797 --> 0.09070), Acc: (0.77924 --> 0.78547), F1: (0.77917 --> 0.78539).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 8 Train Avg loss: 0.08491, Acc: 0.79268, F1: 0.79272#####> Valid Avg loss: 0.37223, Acc:0.17375, F1: 0.17650
===> Epoch: 8: Training loss decreased (0.09070 --> 0.08491), Acc: (0.78547 --> 0.79268), F1: (0.78539 --> 0.79272).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 9 Train Avg loss: 0.07941, Acc: 0.80338, F1: 0.80342#####> Valid Avg loss: 0.42447, Acc:0.16988, F1: 0.17265
===> Epoch: 9: Training loss decreased (0.08491 --> 0.07941), Acc: (0.79268 --> 0.80338), F1: (0.79272 --> 0.80342).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 10 Train Avg loss: 0.07671, Acc: 0.80562, F1: 0.80560#####> Valid Avg loss: 0.35883, Acc:0.18533, F1: 0.18803
===> Epoch: 10: Training loss decreased (0.07941 --> 0.07671), Acc: (0.80338 --> 0.80562), F1: (0.80342 --> 0.80560).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 11 Train Avg loss: 0.07297, Acc: 0.80438, F1: 0.80442#####> Valid Avg loss: 0.41601, Acc:0.18147, F1: 0.18419
===> Epoch: 11: Training loss decreased (0.07671 --> 0.07297), Acc: (0.80562 --> 0.80438), F1: (0.80560 --> 0.80442).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
====> Epoch: 12 Train Avg loss: 0.07008, Acc: 0.80836, F1: 0.80821#####> Valid Avg loss: 0.40438, Acc:0.18533, F1: 0.18803
===> Epoch: 12: Training loss decreased (0.07297 --> 0.07008), Acc: (0.80438 --> 0.80836), F1: (0.80442 --> 0.80821).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597213650.337146.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597216284.945459.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 281
valid_dataloader len: 91
test_dataloader len: 44
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 281
valid dataset len: 910, valid dataloader len: 91
valid dataset len: 431, test dataloader len: 91
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 281
valid_dataloader len: 91
test_dataloader len: 44
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2804, train dataloader len: 281
valid dataset len: 910, valid dataloader len: 91
valid dataset len: 431, test dataloader len: 91
====> Epoch: 1 Train Avg loss: 0.23898, Acc: 0.48966, F1: 0.48915#####> Valid Avg loss: 0.15460, Acc:0.50110, F1: 0.50110
===> Epoch: 1: Training loss decreased (inf --> 0.23898), Acc: (0.00000 --> 0.48966), F1: (0.00000 --> 0.48915).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.15460), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.15460), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1
====> Epoch: 2 Train Avg loss: 0.18346, Acc: 0.49608, F1: 0.49609#####> Valid Avg loss: 0.13702, Acc:0.50110, F1: 0.50110
===> Epoch: 2: Training loss decreased (0.23898 --> 0.18346), Acc: (0.48966 --> 0.49608), F1: (0.48915 --> 0.49609).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1

####> Epoch: 2: validation loss decreased (0.15460 --> 0.13702), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1
====> Epoch: 3 Train Avg loss: 0.16810, Acc: 0.50963, F1: 0.51014#####> Valid Avg loss: 0.13019, Acc:0.50110, F1: 0.50110
===> Epoch: 3: Training loss decreased (0.18346 --> 0.16810), Acc: (0.49608 --> 0.50963), F1: (0.49609 --> 0.51014).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1

####> Epoch: 3: validation loss decreased (0.13702 --> 0.13019), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1
====> Epoch: 4 Train Avg loss: 0.15437, Acc: 0.53923, F1: 0.53968#####> Valid Avg loss: 0.12506, Acc:0.50110, F1: 0.50110
===> Epoch: 4: Training loss decreased (0.16810 --> 0.15437), Acc: (0.50963 --> 0.53923), F1: (0.51014 --> 0.53968).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1

####> Epoch: 4: validation loss decreased (0.13019 --> 0.12506), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1
====> Epoch: 5 Train Avg loss: 0.14485, Acc: 0.55920, F1: 0.56014#####> Valid Avg loss: 0.13235, Acc:0.50110, F1: 0.50110
===> Epoch: 5: Training loss decreased (0.15437 --> 0.14485), Acc: (0.53923 --> 0.55920), F1: (0.53968 --> 0.56014).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597216329.400542.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 7train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1037
valid_dataloader len: 225
test_dataloader len: 210
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 5182, train dataloader len: 1037
valid dataset len: 1121, valid dataloader len: 225
valid dataset len: 1050, test dataloader len: 225
====> Epoch: 1 Train Avg loss: 0.46285, Acc: 0.34967, F1: 0.34976#####> Valid Avg loss: 0.38563, Acc:0.39518, F1: 0.39378
===> Epoch: 1: Training loss decreased (inf --> 0.46285), Acc: (0.00000 --> 0.34967), F1: (0.00000 --> 0.34976).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.38563), Acc: (0.00000 --> 0.39518), F1: (0.00000 --> 0.39378).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.38563), Acc: (0.00000 --> 0.39518), F1: (0.00000 --> 0.39378).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 2 Train Avg loss: 0.33193, Acc: 0.50946, F1: 0.50945#####> Valid Avg loss: 0.33196, Acc:0.40232, F1: 0.40089
===> Epoch: 2: Training loss decreased (0.46285 --> 0.33193), Acc: (0.34967 --> 0.50946), F1: (0.34976 --> 0.50945).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1

####> Epoch: 2: validation loss decreased (0.38563 --> 0.33196), Acc: (0.39518 --> 0.40232), F1: (0.39378 --> 0.40089).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1

####> Epoch: 2: validation acc increase (0.38563 --> 0.33196), Acc: (0.39518 --> 0.40232), F1: (0.39378 --> 0.40089).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 3 Train Avg loss: 0.28413, Acc: 0.57603, F1: 0.57599#####> Valid Avg loss: 0.33500, Acc:0.39251, F1: 0.39111
===> Epoch: 3: Training loss decreased (0.33193 --> 0.28413), Acc: (0.50946 --> 0.57603), F1: (0.50945 --> 0.57599).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 4 Train Avg loss: 0.26216, Acc: 0.60652, F1: 0.60675#####> Valid Avg loss: 0.35808, Acc:0.40500, F1: 0.40356
===> Epoch: 4: Training loss decreased (0.28413 --> 0.26216), Acc: (0.57603 --> 0.60652), F1: (0.57599 --> 0.60675).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1

####> Epoch: 4: validation acc increase (0.33196 --> 0.35808), Acc: (0.40232 --> 0.40500), F1: (0.40089 --> 0.40356).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 5 Train Avg loss: 0.24878, Acc: 0.61482, F1: 0.61475#####> Valid Avg loss: 0.35080, Acc:0.40500, F1: 0.40356
===> Epoch: 5: Training loss decreased (0.26216 --> 0.24878), Acc: (0.60652 --> 0.61482), F1: (0.60675 --> 0.61475).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 6 Train Avg loss: 0.23710, Acc: 0.62736, F1: 0.62729#####> Valid Avg loss: 0.37610, Acc:0.40678, F1: 0.40533
===> Epoch: 6: Training loss decreased (0.24878 --> 0.23710), Acc: (0.61482 --> 0.62736), F1: (0.61475 --> 0.62729).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1

####> Epoch: 6: validation acc increase (0.35808 --> 0.37610), Acc: (0.40500 --> 0.40678), F1: (0.40356 --> 0.40533).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 7 Train Avg loss: 0.23384, Acc: 0.63528, F1: 0.63520#####> Valid Avg loss: 0.37893, Acc:0.40678, F1: 0.40533
===> Epoch: 7: Training loss decreased (0.23710 --> 0.23384), Acc: (0.62736 --> 0.63528), F1: (0.62729 --> 0.63520).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 8 Train Avg loss: 0.22070, Acc: 0.63701, F1: 0.63693#####> Valid Avg loss: 0.39426, Acc:0.39786, F1: 0.39644
===> Epoch: 8: Training loss decreased (0.23384 --> 0.22070), Acc: (0.63528 --> 0.63701), F1: (0.63520 --> 0.63693).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 9 Train Avg loss: 0.21498, Acc: 0.65187, F1: 0.65178#####> Valid Avg loss: 0.44117, Acc:0.40678, F1: 0.40533
===> Epoch: 9: Training loss decreased (0.22070 --> 0.21498), Acc: (0.63701 --> 0.65187), F1: (0.63693 --> 0.65178).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 10 Train Avg loss: 0.21618, Acc: 0.65785, F1: 0.65776#####> Valid Avg loss: 0.45813, Acc:0.40589, F1: 0.40444
====> Epoch: 11 Train Avg loss: 0.20736, Acc: 0.65843, F1: 0.65863#####> Valid Avg loss: 0.41361, Acc:0.40678, F1: 0.40533
===> Epoch: 11: Training loss decreased (0.21498 --> 0.20736), Acc: (0.65187 --> 0.65843), F1: (0.65178 --> 0.65863).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 12 Train Avg loss: 0.20105, Acc: 0.67001, F1: 0.66991#####> Valid Avg loss: 0.42799, Acc:0.40410, F1: 0.40267
===> Epoch: 12: Training loss decreased (0.20736 --> 0.20105), Acc: (0.65843 --> 0.67001), F1: (0.65863 --> 0.66991).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 13 Train Avg loss: 0.20130, Acc: 0.66326, F1: 0.66287#####> Valid Avg loss: 0.42379, Acc:0.40410, F1: 0.40267
====> Epoch: 14 Train Avg loss: 0.19771, Acc: 0.67078, F1: 0.67068#####> Valid Avg loss: 0.45445, Acc:0.39340, F1: 0.39200
===> Epoch: 14: Training loss decreased (0.20105 --> 0.19771), Acc: (0.67001 --> 0.67078), F1: (0.66991 --> 0.67068).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 15 Train Avg loss: 0.19682, Acc: 0.66384, F1: 0.66403#####> Valid Avg loss: 0.43077, Acc:0.40589, F1: 0.40444
===> Epoch: 15: Training loss decreased (0.19771 --> 0.19682), Acc: (0.67078 --> 0.66384), F1: (0.67068 --> 0.66403).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 16 Train Avg loss: 0.19528, Acc: 0.67619, F1: 0.67637#####> Valid Avg loss: 0.37890, Acc:0.40232, F1: 0.40089
===> Epoch: 16: Training loss decreased (0.19682 --> 0.19528), Acc: (0.66384 --> 0.67619), F1: (0.66403 --> 0.67637).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 17 Train Avg loss: 0.18869, Acc: 0.68584, F1: 0.68573#####> Valid Avg loss: 0.46726, Acc:0.40678, F1: 0.40533
===> Epoch: 17: Training loss decreased (0.19528 --> 0.18869), Acc: (0.67619 --> 0.68584), F1: (0.67637 --> 0.68573).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 18 Train Avg loss: 0.18990, Acc: 0.67870, F1: 0.67888#####> Valid Avg loss: 0.49177, Acc:0.40410, F1: 0.40267
====> Epoch: 19 Train Avg loss: 0.18270, Acc: 0.68738, F1: 0.68727#####> Valid Avg loss: 0.42134, Acc:0.40589, F1: 0.40444
===> Epoch: 19: Training loss decreased (0.18869 --> 0.18270), Acc: (0.68584 --> 0.68738), F1: (0.68573 --> 0.68727).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 20 Train Avg loss: 0.18119, Acc: 0.68892, F1: 0.68910#####> Valid Avg loss: 0.50167, Acc:0.40500, F1: 0.40356
===> Epoch: 20: Training loss decreased (0.18270 --> 0.18119), Acc: (0.68738 --> 0.68892), F1: (0.68727 --> 0.68910).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 21 Train Avg loss: 0.18353, Acc: 0.68352, F1: 0.68370#####> Valid Avg loss: 0.45486, Acc:0.40678, F1: 0.40533
====> Epoch: 22 Train Avg loss: 0.18155, Acc: 0.69047, F1: 0.69065#####> Valid Avg loss: 0.46426, Acc:0.40500, F1: 0.40356
====> Epoch: 23 Train Avg loss: 0.18334, Acc: 0.69085, F1: 0.69074#####> Valid Avg loss: 0.46772, Acc:0.40500, F1: 0.40356
====> Epoch: 24 Train Avg loss: 0.17356, Acc: 0.69838, F1: 0.69826#####> Valid Avg loss: 0.51138, Acc:0.40589, F1: 0.40444
===> Epoch: 24: Training loss decreased (0.18119 --> 0.17356), Acc: (0.68892 --> 0.69838), F1: (0.68910 --> 0.69826).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 25 Train Avg loss: 0.17605, Acc: 0.69471, F1: 0.69460#####> Valid Avg loss: 0.49839, Acc:0.40500, F1: 0.40356
====> Epoch: 26 Train Avg loss: 0.16905, Acc: 0.70706, F1: 0.70723#####> Valid Avg loss: 0.49694, Acc:0.40678, F1: 0.40533
===> Epoch: 26: Training loss decreased (0.17356 --> 0.16905), Acc: (0.69838 --> 0.70706), F1: (0.69826 --> 0.70723).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 27 Train Avg loss: 0.17141, Acc: 0.69992, F1: 0.70010#####> Valid Avg loss: 0.48097, Acc:0.40500, F1: 0.40356
====> Epoch: 28 Train Avg loss: 0.16786, Acc: 0.70938, F1: 0.70955#####> Valid Avg loss: 0.48710, Acc:0.40321, F1: 0.40178
===> Epoch: 28: Training loss decreased (0.16905 --> 0.16786), Acc: (0.70706 --> 0.70938), F1: (0.70723 --> 0.70955).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 29 Train Avg loss: 0.16674, Acc: 0.70359, F1: 0.70347#####> Valid Avg loss: 0.56601, Acc:0.40321, F1: 0.40178
===> Epoch: 29: Training loss decreased (0.16786 --> 0.16674), Acc: (0.70938 --> 0.70359), F1: (0.70955 --> 0.70347).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 30 Train Avg loss: 0.16302, Acc: 0.70706, F1: 0.70694#####> Valid Avg loss: 0.51967, Acc:0.40143, F1: 0.40000
===> Epoch: 30: Training loss decreased (0.16674 --> 0.16302), Acc: (0.70359 --> 0.70706), F1: (0.70347 --> 0.70694).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 31 Train Avg loss: 0.16205, Acc: 0.71189, F1: 0.71205#####> Valid Avg loss: 0.52324, Acc:0.40232, F1: 0.40089
===> Epoch: 31: Training loss decreased (0.16302 --> 0.16205), Acc: (0.70706 --> 0.71189), F1: (0.70694 --> 0.71205).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 32 Train Avg loss: 0.15977, Acc: 0.71903, F1: 0.71919#####> Valid Avg loss: 0.54906, Acc:0.40589, F1: 0.40444
===> Epoch: 32: Training loss decreased (0.16205 --> 0.15977), Acc: (0.71189 --> 0.71903), F1: (0.71205 --> 0.71919).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 33 Train Avg loss: 0.15946, Acc: 0.71073, F1: 0.71090#####> Valid Avg loss: 0.47772, Acc:0.40410, F1: 0.40267
===> Epoch: 33: Training loss decreased (0.15977 --> 0.15946), Acc: (0.71903 --> 0.71073), F1: (0.71919 --> 0.71090).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 34 Train Avg loss: 0.15346, Acc: 0.72019, F1: 0.72035#####> Valid Avg loss: 0.59328, Acc:0.40589, F1: 0.40444
===> Epoch: 34: Training loss decreased (0.15946 --> 0.15346), Acc: (0.71073 --> 0.72019), F1: (0.71090 --> 0.72035).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 35 Train Avg loss: 0.15324, Acc: 0.71189, F1: 0.71205#####> Valid Avg loss: 0.54999, Acc:0.40500, F1: 0.40356
===> Epoch: 35: Training loss decreased (0.15346 --> 0.15324), Acc: (0.72019 --> 0.71189), F1: (0.72035 --> 0.71205).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 36 Train Avg loss: 0.15138, Acc: 0.72597, F1: 0.72613#####> Valid Avg loss: 0.57337, Acc:0.40232, F1: 0.40089
===> Epoch: 36: Training loss decreased (0.15324 --> 0.15138), Acc: (0.71189 --> 0.72597), F1: (0.71205 --> 0.72613).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 37 Train Avg loss: 0.14891, Acc: 0.73234, F1: 0.73250#####> Valid Avg loss: 0.53034, Acc:0.40589, F1: 0.40444
===> Epoch: 37: Training loss decreased (0.15138 --> 0.14891), Acc: (0.72597 --> 0.73234), F1: (0.72613 --> 0.73250).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 38 Train Avg loss: 0.14760, Acc: 0.72829, F1: 0.72845#####> Valid Avg loss: 0.55430, Acc:0.40143, F1: 0.40000
===> Epoch: 38: Training loss decreased (0.14891 --> 0.14760), Acc: (0.73234 --> 0.72829), F1: (0.73250 --> 0.72845).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 39 Train Avg loss: 0.14280, Acc: 0.73234, F1: 0.73250#####> Valid Avg loss: 0.50785, Acc:0.40232, F1: 0.40089
===> Epoch: 39: Training loss decreased (0.14760 --> 0.14280), Acc: (0.72829 --> 0.73234), F1: (0.72845 --> 0.73250).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 40 Train Avg loss: 0.14040, Acc: 0.73717, F1: 0.73732#####> Valid Avg loss: 0.63691, Acc:0.40321, F1: 0.40178
===> Epoch: 40: Training loss decreased (0.14280 --> 0.14040), Acc: (0.73234 --> 0.73717), F1: (0.73250 --> 0.73732).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 41 Train Avg loss: 0.14012, Acc: 0.73871, F1: 0.73857#####> Valid Avg loss: 0.57055, Acc:0.40232, F1: 0.40089
===> Epoch: 41: Training loss decreased (0.14040 --> 0.14012), Acc: (0.73717 --> 0.73871), F1: (0.73732 --> 0.73857).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 42 Train Avg loss: 0.13918, Acc: 0.74161, F1: 0.74147#####> Valid Avg loss: 0.58067, Acc:0.40232, F1: 0.40089
===> Epoch: 42: Training loss decreased (0.14012 --> 0.13918), Acc: (0.73871 --> 0.74161), F1: (0.73857 --> 0.74147).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 43 Train Avg loss: 0.13140, Acc: 0.75010, F1: 0.74995#####> Valid Avg loss: 0.60644, Acc:0.40143, F1: 0.40000
===> Epoch: 43: Training loss decreased (0.13918 --> 0.13140), Acc: (0.74161 --> 0.75010), F1: (0.74147 --> 0.74995).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 44 Train Avg loss: 0.12935, Acc: 0.75415, F1: 0.75429#####> Valid Avg loss: 0.59207, Acc:0.38894, F1: 0.38756
===> Epoch: 44: Training loss decreased (0.13140 --> 0.12935), Acc: (0.75010 --> 0.75415), F1: (0.74995 --> 0.75429).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 45 Train Avg loss: 0.13048, Acc: 0.75338, F1: 0.75352#####> Valid Avg loss: 0.56686, Acc:0.39964, F1: 0.39822
====> Epoch: 46 Train Avg loss: 0.12668, Acc: 0.75415, F1: 0.75429#####> Valid Avg loss: 0.64490, Acc:0.40232, F1: 0.40089
===> Epoch: 46: Training loss decreased (0.12935 --> 0.12668), Acc: (0.75415 --> 0.75415), F1: (0.75429 --> 0.75429).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 47 Train Avg loss: 0.12255, Acc: 0.76418, F1: 0.76432#####> Valid Avg loss: 0.56888, Acc:0.39875, F1: 0.39733
===> Epoch: 47: Training loss decreased (0.12668 --> 0.12255), Acc: (0.75415 --> 0.76418), F1: (0.75429 --> 0.76432).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 48 Train Avg loss: 0.11639, Acc: 0.77634, F1: 0.77647#####> Valid Avg loss: 0.70885, Acc:0.39875, F1: 0.39733
===> Epoch: 48: Training loss decreased (0.12255 --> 0.11639), Acc: (0.76418 --> 0.77634), F1: (0.76432 --> 0.77647).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 49 Train Avg loss: 0.11549, Acc: 0.77132, F1: 0.77117#####> Valid Avg loss: 0.68631, Acc:0.39429, F1: 0.39289
===> Epoch: 49: Training loss decreased (0.11639 --> 0.11549), Acc: (0.77634 --> 0.77132), F1: (0.77647 --> 0.77117).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 50 Train Avg loss: 0.11309, Acc: 0.78039, F1: 0.78052#####> Valid Avg loss: 0.66216, Acc:0.38983, F1: 0.38844
===> Epoch: 50: Training loss decreased (0.11549 --> 0.11309), Acc: (0.77132 --> 0.78039), F1: (0.77117 --> 0.78052).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 51 Train Avg loss: 0.10951, Acc: 0.78503, F1: 0.78515#####> Valid Avg loss: 0.67359, Acc:0.38626, F1: 0.38489
===> Epoch: 51: Training loss decreased (0.11309 --> 0.10951), Acc: (0.78039 --> 0.78503), F1: (0.78052 --> 0.78515).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 52 Train Avg loss: 0.10343, Acc: 0.79043, F1: 0.79026#####> Valid Avg loss: 0.74483, Acc:0.38180, F1: 0.38044
===> Epoch: 52: Training loss decreased (0.10951 --> 0.10343), Acc: (0.78503 --> 0.79043), F1: (0.78515 --> 0.79026).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 53 Train Avg loss: 0.10353, Acc: 0.79873, F1: 0.79855#####> Valid Avg loss: 0.77466, Acc:0.39161, F1: 0.39022
====> Epoch: 54 Train Avg loss: 0.09903, Acc: 0.80664, F1: 0.80646#####> Valid Avg loss: 0.74910, Acc:0.38537, F1: 0.38400
===> Epoch: 54: Training loss decreased (0.10343 --> 0.09903), Acc: (0.79043 --> 0.80664), F1: (0.79026 --> 0.80646).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 55 Train Avg loss: 0.09766, Acc: 0.80606, F1: 0.80617#####> Valid Avg loss: 0.69822, Acc:0.36218, F1: 0.36089
===> Epoch: 55: Training loss decreased (0.09903 --> 0.09766), Acc: (0.80664 --> 0.80606), F1: (0.80646 --> 0.80617).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 56 Train Avg loss: 0.09262, Acc: 0.81802, F1: 0.81813#####> Valid Avg loss: 0.75648, Acc:0.38537, F1: 0.38400
===> Epoch: 56: Training loss decreased (0.09766 --> 0.09262), Acc: (0.80606 --> 0.81802), F1: (0.80617 --> 0.81813).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 57 Train Avg loss: 0.08975, Acc: 0.82690, F1: 0.82700#####> Valid Avg loss: 0.76602, Acc:0.37645, F1: 0.37511
===> Epoch: 57: Training loss decreased (0.09262 --> 0.08975), Acc: (0.81802 --> 0.82690), F1: (0.81813 --> 0.82700).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 58 Train Avg loss: 0.08681, Acc: 0.83211, F1: 0.83221#####> Valid Avg loss: 0.76416, Acc:0.38002, F1: 0.37867
===> Epoch: 58: Training loss decreased (0.08975 --> 0.08681), Acc: (0.82690 --> 0.83211), F1: (0.82700 --> 0.83221).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 59 Train Avg loss: 0.08244, Acc: 0.83443, F1: 0.83452#####> Valid Avg loss: 0.74881, Acc:0.38894, F1: 0.38756
===> Epoch: 59: Training loss decreased (0.08681 --> 0.08244), Acc: (0.83211 --> 0.83443), F1: (0.83221 --> 0.83452).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 60 Train Avg loss: 0.08010, Acc: 0.84176, F1: 0.84185#####> Valid Avg loss: 0.90995, Acc:0.38894, F1: 0.38756
===> Epoch: 60: Training loss decreased (0.08244 --> 0.08010), Acc: (0.83443 --> 0.84176), F1: (0.83452 --> 0.84185).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 61 Train Avg loss: 0.07527, Acc: 0.85295, F1: 0.85304#####> Valid Avg loss: 0.70431, Acc:0.35861, F1: 0.35733
===> Epoch: 61: Training loss decreased (0.08010 --> 0.07527), Acc: (0.84176 --> 0.85295), F1: (0.84185 --> 0.85304).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 62 Train Avg loss: 0.07494, Acc: 0.84523, F1: 0.84532#####> Valid Avg loss: 0.76304, Acc:0.34434, F1: 0.34667
===> Epoch: 62: Training loss decreased (0.07527 --> 0.07494), Acc: (0.85295 --> 0.84523), F1: (0.85304 --> 0.84532).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 63 Train Avg loss: 0.07026, Acc: 0.85990, F1: 0.85998#####> Valid Avg loss: 0.82521, Acc:0.36039, F1: 0.35911
===> Epoch: 63: Training loss decreased (0.07494 --> 0.07026), Acc: (0.84523 --> 0.85990), F1: (0.84532 --> 0.85998).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 64 Train Avg loss: 0.06531, Acc: 0.86743, F1: 0.86750#####> Valid Avg loss: 0.89386, Acc:0.38180, F1: 0.38044
===> Epoch: 64: Training loss decreased (0.07026 --> 0.06531), Acc: (0.85990 --> 0.86743), F1: (0.85998 --> 0.86750).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 65 Train Avg loss: 0.06698, Acc: 0.86337, F1: 0.86345#####> Valid Avg loss: 0.88128, Acc:0.34434, F1: 0.34311
====> Epoch: 66 Train Avg loss: 0.06310, Acc: 0.87572, F1: 0.87580#####> Valid Avg loss: 0.91651, Acc:0.34969, F1: 0.34844
===> Epoch: 66: Training loss decreased (0.06531 --> 0.06310), Acc: (0.86743 --> 0.87572), F1: (0.86750 --> 0.87580).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 67 Train Avg loss: 0.05923, Acc: 0.87997, F1: 0.88004#####> Valid Avg loss: 0.80514, Acc:0.34880, F1: 0.34756
===> Epoch: 67: Training loss decreased (0.06310 --> 0.05923), Acc: (0.87572 --> 0.87997), F1: (0.87580 --> 0.88004).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 68 Train Avg loss: 0.05805, Acc: 0.88750, F1: 0.88756#####> Valid Avg loss: 1.08362, Acc:0.36039, F1: 0.35911
===> Epoch: 68: Training loss decreased (0.05923 --> 0.05805), Acc: (0.87997 --> 0.88750), F1: (0.88004 --> 0.88756).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 69 Train Avg loss: 0.05379, Acc: 0.89541, F1: 0.89518#####> Valid Avg loss: 0.91948, Acc:0.35504, F1: 0.35378
===> Epoch: 69: Training loss decreased (0.05805 --> 0.05379), Acc: (0.88750 --> 0.89541), F1: (0.88756 --> 0.89518).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 70 Train Avg loss: 0.05137, Acc: 0.90255, F1: 0.90260#####> Valid Avg loss: 0.96928, Acc:0.35415, F1: 0.35289
===> Epoch: 70: Training loss decreased (0.05379 --> 0.05137), Acc: (0.89541 --> 0.90255), F1: (0.89518 --> 0.90260).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 71 Train Avg loss: 0.05240, Acc: 0.89599, F1: 0.89576#####> Valid Avg loss: 0.94685, Acc:0.34969, F1: 0.34844
====> Epoch: 72 Train Avg loss: 0.04827, Acc: 0.90583, F1: 0.90530#####> Valid Avg loss: 1.08459, Acc:0.35861, F1: 0.35733
===> Epoch: 72: Training loss decreased (0.05137 --> 0.04827), Acc: (0.90255 --> 0.90583), F1: (0.90260 --> 0.90530).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 73 Train Avg loss: 0.04543, Acc: 0.91027, F1: 0.91032#####> Valid Avg loss: 1.07132, Acc:0.34166, F1: 0.34044
===> Epoch: 73: Training loss decreased (0.04827 --> 0.04543), Acc: (0.90583 --> 0.91027), F1: (0.90530 --> 0.91032).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 74 Train Avg loss: 0.04386, Acc: 0.91799, F1: 0.91803#####> Valid Avg loss: 1.14454, Acc:0.35593, F1: 0.35467
===> Epoch: 74: Training loss decreased (0.04543 --> 0.04386), Acc: (0.91027 --> 0.91799), F1: (0.91032 --> 0.91803).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 75 Train Avg loss: 0.04131, Acc: 0.91316, F1: 0.91321#####> Valid Avg loss: 1.01603, Acc:0.32293, F1: 0.32178
===> Epoch: 75: Training loss decreased (0.04386 --> 0.04131), Acc: (0.91799 --> 0.91316), F1: (0.91803 --> 0.91321).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 76 Train Avg loss: 0.04009, Acc: 0.91972, F1: 0.91977#####> Valid Avg loss: 1.05799, Acc:0.35147, F1: 0.35022
===> Epoch: 76: Training loss decreased (0.04131 --> 0.04009), Acc: (0.91316 --> 0.91972), F1: (0.91321 --> 0.91977).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 77 Train Avg loss: 0.03980, Acc: 0.91876, F1: 0.91880#####> Valid Avg loss: 1.14981, Acc:0.34344, F1: 0.34222
===> Epoch: 77: Training loss decreased (0.04009 --> 0.03980), Acc: (0.91972 --> 0.91876), F1: (0.91977 --> 0.91880).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 78 Train Avg loss: 0.03691, Acc: 0.92281, F1: 0.92285#####> Valid Avg loss: 0.99968, Acc:0.33452, F1: 0.33333
===> Epoch: 78: Training loss decreased (0.03980 --> 0.03691), Acc: (0.91876 --> 0.92281), F1: (0.91880 --> 0.92285).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 79 Train Avg loss: 0.03705, Acc: 0.92667, F1: 0.92642#####> Valid Avg loss: 1.06026, Acc:0.34790, F1: 0.34667
====> Epoch: 80 Train Avg loss: 0.03507, Acc: 0.92841, F1: 0.92845#####> Valid Avg loss: 1.16198, Acc:0.34790, F1: 0.34667
===> Epoch: 80: Training loss decreased (0.03691 --> 0.03507), Acc: (0.92281 --> 0.92841), F1: (0.92285 --> 0.92845).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 81 Train Avg loss: 0.03437, Acc: 0.93632, F1: 0.93635#####> Valid Avg loss: 1.16779, Acc:0.35147, F1: 0.35022
===> Epoch: 81: Training loss decreased (0.03507 --> 0.03437), Acc: (0.92841 --> 0.93632), F1: (0.92845 --> 0.93635).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 82 Train Avg loss: 0.03259, Acc: 0.93458, F1: 0.93462#####> Valid Avg loss: 1.11131, Acc:0.34880, F1: 0.34756
===> Epoch: 82: Training loss decreased (0.03437 --> 0.03259), Acc: (0.93632 --> 0.93458), F1: (0.93635 --> 0.93462).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 83 Train Avg loss: 0.03130, Acc: 0.93748, F1: 0.93751#####> Valid Avg loss: 1.13843, Acc:0.35682, F1: 0.35556
===> Epoch: 83: Training loss decreased (0.03259 --> 0.03130), Acc: (0.93458 --> 0.93748), F1: (0.93462 --> 0.93751).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 84 Train Avg loss: 0.03114, Acc: 0.93786, F1: 0.93790#####> Valid Avg loss: 1.17556, Acc:0.35950, F1: 0.35822
===> Epoch: 84: Training loss decreased (0.03130 --> 0.03114), Acc: (0.93748 --> 0.93786), F1: (0.93751 --> 0.93790).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 85 Train Avg loss: 0.02878, Acc: 0.94230, F1: 0.94233#####> Valid Avg loss: 1.14024, Acc:0.34790, F1: 0.34667
===> Epoch: 85: Training loss decreased (0.03114 --> 0.02878), Acc: (0.93786 --> 0.94230), F1: (0.93790 --> 0.94233).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 86 Train Avg loss: 0.02889, Acc: 0.94230, F1: 0.94233#####> Valid Avg loss: 1.14472, Acc:0.34969, F1: 0.34844
====> Epoch: 87 Train Avg loss: 0.02861, Acc: 0.94307, F1: 0.94311#####> Valid Avg loss: 1.27444, Acc:0.35326, F1: 0.35200
===> Epoch: 87: Training loss decreased (0.02878 --> 0.02861), Acc: (0.94230 --> 0.94307), F1: (0.94233 --> 0.94311).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 88 Train Avg loss: 0.02785, Acc: 0.94597, F1: 0.94600#####> Valid Avg loss: 1.20439, Acc:0.35147, F1: 0.35022
===> Epoch: 88: Training loss decreased (0.02861 --> 0.02785), Acc: (0.94307 --> 0.94597), F1: (0.94311 --> 0.94600).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 89 Train Avg loss: 0.02882, Acc: 0.94423, F1: 0.94426#####> Valid Avg loss: 1.15762, Acc:0.34790, F1: 0.34667
====> Epoch: 90 Train Avg loss: 0.02672, Acc: 0.95002, F1: 0.95005#####> Valid Avg loss: 1.17479, Acc:0.34790, F1: 0.34667
===> Epoch: 90: Training loss decreased (0.02785 --> 0.02672), Acc: (0.94597 --> 0.95002), F1: (0.94600 --> 0.95005).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 91 Train Avg loss: 0.02714, Acc: 0.94655, F1: 0.94658#####> Valid Avg loss: 1.17982, Acc:0.34790, F1: 0.34667
====> Epoch: 92 Train Avg loss: 0.02534, Acc: 0.94944, F1: 0.94947#####> Valid Avg loss: 1.20427, Acc:0.34790, F1: 0.34667
===> Epoch: 92: Training loss decreased (0.02672 --> 0.02534), Acc: (0.95002 --> 0.94944), F1: (0.95005 --> 0.94947).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 93 Train Avg loss: 0.02583, Acc: 0.94732, F1: 0.94735#####> Valid Avg loss: 1.11580, Acc:0.35147, F1: 0.35022
====> Epoch: 94 Train Avg loss: 0.02592, Acc: 0.94790, F1: 0.94793#####> Valid Avg loss: 1.21510, Acc:0.34969, F1: 0.34844
====> Epoch: 95 Train Avg loss: 0.02516, Acc: 0.94944, F1: 0.94947#####> Valid Avg loss: 1.13519, Acc:0.34880, F1: 0.34756
===> Epoch: 95: Training loss decreased (0.02534 --> 0.02516), Acc: (0.94944 --> 0.94944), F1: (0.94947 --> 0.94947).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 96 Train Avg loss: 0.02402, Acc: 0.95407, F1: 0.95381#####> Valid Avg loss: 1.22666, Acc:0.34790, F1: 0.34667
===> Epoch: 96: Training loss decreased (0.02516 --> 0.02402), Acc: (0.94944 --> 0.95407), F1: (0.94947 --> 0.95381).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597217341.705881.pth_1
====> Epoch: 97 Train Avg loss: 0.02583, Acc: 0.94905, F1: 0.94908#####> Valid Avg loss: 1.16032, Acc:0.34701, F1: 0.34578
====> Epoch: 98 Train Avg loss: 0.02529, Acc: 0.94886, F1: 0.94889#####> Valid Avg loss: 1.17961, Acc:0.34969, F1: 0.34844
====> Epoch: 99 Train Avg loss: 0.02475, Acc: 0.95426, F1: 0.95429#####> Valid Avg loss: 1.23602, Acc:0.34790, F1: 0.34667
====> Epoch: 100 Train Avg loss: 0.17941, Acc: 0.69973, F1: 0.69932#####> Valid Avg loss: 0.57191, Acc:0.38359, F1: 0.38222
====> Epoch: 101 Train Avg loss: 0.12967, Acc: 0.75724, F1: 0.75738#####> Valid Avg loss: 0.71125, Acc:0.40054, F1: 0.39911
====> Epoch: 102 Train Avg loss: 0.12817, Acc: 0.75936, F1: 0.75950#####> Valid Avg loss: 0.67714, Acc:0.39607, F1: 0.39467
====> Epoch: 103 Train Avg loss: 0.12753, Acc: 0.76264, F1: 0.76220#####> Valid Avg loss: 0.62420, Acc:0.38715, F1: 0.38578
====> Epoch: 104 Train Avg loss: 0.11476, Acc: 0.78290, F1: 0.78303#####> Valid Avg loss: 0.64137, Acc:0.38715, F1: 0.38933
====> Epoch: 105 Train Avg loss: 0.12221, Acc: 0.77325, F1: 0.77310#####> Valid Avg loss: 0.75954, Acc:0.39429, F1: 0.39289
====> Epoch: 106 Train Avg loss: 0.11555, Acc: 0.78522, F1: 0.78505#####> Valid Avg loss: 0.65666, Acc:0.34255, F1: 0.34489
====> Epoch: 107 Train Avg loss: 0.11520, Acc: 0.78715, F1: 0.78727#####> Valid Avg loss: 0.72402, Acc:0.38983, F1: 0.38844
====> Epoch: 108 Train Avg loss: 0.11475, Acc: 0.78387, F1: 0.78370#####> Valid Avg loss: 0.67612, Acc:0.39161, F1: 0.39022
====> Epoch: 109 Train Avg loss: 0.11595, Acc: 0.77885, F1: 0.77898#####> Valid Avg loss: 0.67811, Acc:0.36396, F1: 0.36267
====> Epoch: 110 Train Avg loss: 0.11311, Acc: 0.78946, F1: 0.78959#####> Valid Avg loss: 0.79183, Acc:0.38448, F1: 0.38311
====> Epoch: 111 Train Avg loss: 0.11278, Acc: 0.79409, F1: 0.79421#####> Valid Avg loss: 0.72550, Acc:0.37199, F1: 0.37067
====> Epoch: 112 Train Avg loss: 0.11401, Acc: 0.78271, F1: 0.78284#####> Valid Avg loss: 0.71919, Acc:0.39607, F1: 0.39467
====> Epoch: 113 Train Avg loss: 0.10601, Acc: 0.80181, F1: 0.80164#####> Valid Avg loss: 0.73332, Acc:0.37467, F1: 0.37333
====> Epoch: 114 Train Avg loss: 0.10174, Acc: 0.80953, F1: 0.80935#####> Valid Avg loss: 0.65436, Acc:0.35861, F1: 0.36089
====> Epoch: 115 Train Avg loss: 0.12711, Acc: 0.77287, F1: 0.77271#####> Valid Avg loss: 0.69029, Acc:0.38626, F1: 0.38489
====> Epoch: 116 Train Avg loss: 0.10217, Acc: 0.80625, F1: 0.80636#####> Valid Avg loss: 0.77211, Acc:0.37288, F1: 0.37156
====> Epoch: 117 Train Avg loss: 0.09319, Acc: 0.82748, F1: 0.82729#####> Valid Avg loss: 0.66920, Acc:0.35504, F1: 0.35733
====> Epoch: 118 Train Avg loss: 0.10146, Acc: 0.81359, F1: 0.81369#####> Valid Avg loss: 0.69086, Acc:0.33898, F1: 0.33778
====> Epoch: 119 Train Avg loss: 0.10297, Acc: 0.81397, F1: 0.81408#####> Valid Avg loss: 0.70617, Acc:0.37199, F1: 0.37422
====> Epoch: 120 Train Avg loss: 0.09365, Acc: 0.82671, F1: 0.82652#####> Valid Avg loss: 0.75582, Acc:0.29170, F1: 0.29422
====> Epoch: 121 Train Avg loss: 0.08726, Acc: 0.83153, F1: 0.83163#####> Valid Avg loss: 0.74327, Acc:0.36664, F1: 0.36533
====> Epoch: 122 Train Avg loss: 0.09031, Acc: 0.82883, F1: 0.82893#####> Valid Avg loss: 0.81000, Acc:0.35682, F1: 0.35556
====> Epoch: 123 Train Avg loss: 0.09371, Acc: 0.82902, F1: 0.82883#####> Valid Avg loss: 0.77936, Acc:0.34344, F1: 0.34578
====> Epoch: 124 Train Avg loss: 0.09292, Acc: 0.83423, F1: 0.83433#####> Valid Avg loss: 0.70347, Acc:0.34790, F1: 0.34667
====> Epoch: 125 Train Avg loss: 0.08768, Acc: 0.82980, F1: 0.82989#####> Valid Avg loss: 0.71127, Acc:0.38537, F1: 0.38400
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 3train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 447
valid_dataloader len: 171
test_dataloader len: 76
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2233, train dataloader len: 447
valid dataset len: 851, valid dataloader len: 171
valid dataset len: 380, test dataloader len: 171
====> Epoch: 1 Train Avg loss: 0.31464, Acc: 0.63233, F1: 0.63207#####> Valid Avg loss: 0.24253, Acc:0.53584, F1: 0.53333
===> Epoch: 1: Training loss decreased (inf --> 0.31464), Acc: (0.00000 --> 0.63233), F1: (0.00000 --> 0.63207).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.24253), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.24253), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53333).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1
====> Epoch: 2 Train Avg loss: 0.22112, Acc: 0.65383, F1: 0.65414#####> Valid Avg loss: 0.20850, Acc:0.53584, F1: 0.53333
===> Epoch: 2: Training loss decreased (0.31464 --> 0.22112), Acc: (0.63233 --> 0.65383), F1: (0.63207 --> 0.65414).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1

####> Epoch: 2: validation loss decreased (0.24253 --> 0.20850), Acc: (0.53584 --> 0.53584), F1: (0.53333 --> 0.53333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1
====> Epoch: 3 Train Avg loss: 0.19630, Acc: 0.67219, F1: 0.67189#####> Valid Avg loss: 0.20101, Acc:0.53584, F1: 0.53333
===> Epoch: 3: Training loss decreased (0.22112 --> 0.19630), Acc: (0.65383 --> 0.67219), F1: (0.65414 --> 0.67189).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1

####> Epoch: 3: validation loss decreased (0.20850 --> 0.20101), Acc: (0.53584 --> 0.53584), F1: (0.53333 --> 0.53333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1
====> Epoch: 4 Train Avg loss: 0.18592, Acc: 0.68473, F1: 0.68501#####> Valid Avg loss: 0.19881, Acc:0.53584, F1: 0.53333
===> Epoch: 4: Training loss decreased (0.19630 --> 0.18592), Acc: (0.67219 --> 0.68473), F1: (0.67189 --> 0.68501).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1

####> Epoch: 4: validation loss decreased (0.20101 --> 0.19881), Acc: (0.53584 --> 0.53584), F1: (0.53333 --> 0.53333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1
====> Epoch: 5 Train Avg loss: 0.17943, Acc: 0.68786, F1: 0.68814#####> Valid Avg loss: 0.20924, Acc:0.53584, F1: 0.53333
===> Epoch: 5: Training loss decreased (0.18592 --> 0.17943), Acc: (0.68473 --> 0.68786), F1: (0.68501 --> 0.68814).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1
====> Epoch: 6 Train Avg loss: 0.17697, Acc: 0.68876, F1: 0.68874#####> Valid Avg loss: 0.20455, Acc:0.53584, F1: 0.53333
===> Epoch: 6: Training loss decreased (0.17943 --> 0.17697), Acc: (0.68786 --> 0.68876), F1: (0.68814 --> 0.68874).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1
====> Epoch: 7 Train Avg loss: 0.17375, Acc: 0.68966, F1: 0.68963#####> Valid Avg loss: 0.19829, Acc:0.53584, F1: 0.53333
===> Epoch: 7: Training loss decreased (0.17697 --> 0.17375), Acc: (0.68876 --> 0.68966), F1: (0.68874 --> 0.68963).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1

####> Epoch: 7: validation loss decreased (0.19881 --> 0.19829), Acc: (0.53584 --> 0.53584), F1: (0.53333 --> 0.53333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1
====> Epoch: 8 Train Avg loss: 0.17192, Acc: 0.68966, F1: 0.68963#####> Valid Avg loss: 0.19873, Acc:0.53584, F1: 0.53333
===> Epoch: 8: Training loss decreased (0.17375 --> 0.17192), Acc: (0.68966 --> 0.68966), F1: (0.68963 --> 0.68963).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1
====> Epoch: 9 Train Avg loss: 0.17127, Acc: 0.68921, F1: 0.68919#####> Valid Avg loss: 0.19539, Acc:0.53584, F1: 0.53333
===> Epoch: 9: Training loss decreased (0.17192 --> 0.17127), Acc: (0.68966 --> 0.68921), F1: (0.68963 --> 0.68919).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1

####> Epoch: 9: validation loss decreased (0.19829 --> 0.19539), Acc: (0.53584 --> 0.53584), F1: (0.53333 --> 0.53333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597269489.576948.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:16
lstm_hidden_size: 16
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597271446.72426.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 3train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 447
valid_dataloader len: 171
test_dataloader len: 76
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2233, train dataloader len: 447
valid dataset len: 851, valid dataloader len: 171
valid dataset len: 380, test dataloader len: 171
====> Epoch: 1 Train Avg loss: 0.38825, Acc: 0.42365, F1: 0.42386#####> Valid Avg loss: 0.29964, Acc:0.53584, F1: 0.53333
===> Epoch: 1: Training loss decreased (inf --> 0.38825), Acc: (0.00000 --> 0.42365), F1: (0.00000 --> 0.42386).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597271446.72426.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.29964), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597271446.72426.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.29964), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53333).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597271446.72426.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.03, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597271713.577407.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 3train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 447
valid_dataloader len: 171
test_dataloader len: 76
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2233, train dataloader len: 447
valid dataset len: 851, valid dataloader len: 171
valid dataset len: 380, test dataloader len: 171
====> Epoch: 1 Train Avg loss: 0.62387, Acc: 0.67936, F1: 0.67905#####> Valid Avg loss: 0.73402, Acc:0.53584, F1: 0.53333
===> Epoch: 1: Training loss decreased (inf --> 0.62387), Acc: (0.00000 --> 0.67936), F1: (0.00000 --> 0.67905).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597271713.577407.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.73402), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597271713.577407.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.73402), Acc: (0.00000 --> 0.53584), F1: (0.00000 --> 0.53333).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597271713.577407.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597272150.051085.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 5train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 212
valid_dataloader len: 84
test_dataloader len: 30
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 1058, train dataloader len: 212
valid dataset len: 420, valid dataloader len: 84
valid dataset len: 147, test dataloader len: 84
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/scratch/at5cf/ann, modalities:['inside', 'outside']
embed_dir_base: /scratch/at5cf/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 5train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 212
valid_dataloader len: 84
test_dataloader len: 30
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 1058, train dataloader len: 212
valid dataset len: 420, valid dataloader len: 84
valid dataset len: 147, test dataloader len: 84
====> Epoch: 1 Train Avg loss: 0.56123, Acc: 0.21078, F1: 0.21101#####> Valid Avg loss: 0.33347, Acc:0.72857, F1: 0.72857
===> Epoch: 1: Training loss decreased (inf --> 0.56123), Acc: (0.00000 --> 0.21078), F1: (0.00000 --> 0.21101).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.33347), Acc: (0.00000 --> 0.72857), F1: (0.00000 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.33347), Acc: (0.00000 --> 0.72857), F1: (0.00000 --> 0.72857).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 2 Train Avg loss: 0.47110, Acc: 0.33743, F1: 0.33742#####> Valid Avg loss: 0.30303, Acc:0.72857, F1: 0.72857
===> Epoch: 2: Training loss decreased (0.56123 --> 0.47110), Acc: (0.21078 --> 0.33743), F1: (0.21101 --> 0.33742).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 2: validation loss decreased (0.33347 --> 0.30303), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 3 Train Avg loss: 0.42181, Acc: 0.34972, F1: 0.34969#####> Valid Avg loss: 0.29132, Acc:0.72857, F1: 0.72857
===> Epoch: 3: Training loss decreased (0.47110 --> 0.42181), Acc: (0.33743 --> 0.34972), F1: (0.33742 --> 0.34969).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 3: validation loss decreased (0.30303 --> 0.29132), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 4 Train Avg loss: 0.39933, Acc: 0.38658, F1: 0.38711#####> Valid Avg loss: 0.26224, Acc:0.72857, F1: 0.72857
===> Epoch: 4: Training loss decreased (0.42181 --> 0.39933), Acc: (0.34972 --> 0.38658), F1: (0.34969 --> 0.38711).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 4: validation loss decreased (0.29132 --> 0.26224), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 5 Train Avg loss: 0.37803, Acc: 0.37713, F1: 0.37830#####> Valid Avg loss: 0.24755, Acc:0.72857, F1: 0.72857
===> Epoch: 5: Training loss decreased (0.39933 --> 0.37803), Acc: (0.38658 --> 0.37713), F1: (0.38711 --> 0.37830).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 5: validation loss decreased (0.26224 --> 0.24755), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 6 Train Avg loss: 0.36833, Acc: 0.36106, F1: 0.36101#####> Valid Avg loss: 0.24384, Acc:0.72857, F1: 0.72857
===> Epoch: 6: Training loss decreased (0.37803 --> 0.36833), Acc: (0.37713 --> 0.36106), F1: (0.37830 --> 0.36101).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 6: validation loss decreased (0.24755 --> 0.24384), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 7 Train Avg loss: 0.35069, Acc: 0.38941, F1: 0.38868#####> Valid Avg loss: 0.21595, Acc:0.72857, F1: 0.72857
===> Epoch: 7: Training loss decreased (0.36833 --> 0.35069), Acc: (0.36106 --> 0.38941), F1: (0.36101 --> 0.38868).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 7: validation loss decreased (0.24384 --> 0.21595), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 8 Train Avg loss: 0.33574, Acc: 0.41493, F1: 0.41541#####> Valid Avg loss: 0.18937, Acc:0.72857, F1: 0.72857
===> Epoch: 8: Training loss decreased (0.35069 --> 0.33574), Acc: (0.38941 --> 0.41493), F1: (0.38868 --> 0.41541).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 8: validation loss decreased (0.21595 --> 0.18937), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 9 Train Avg loss: 0.33109, Acc: 0.41682, F1: 0.41667#####> Valid Avg loss: 0.21738, Acc:0.72857, F1: 0.72857
===> Epoch: 9: Training loss decreased (0.33574 --> 0.33109), Acc: (0.41493 --> 0.41682), F1: (0.41541 --> 0.41667).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 10 Train Avg loss: 0.31936, Acc: 0.43573, F1: 0.43553#####> Valid Avg loss: 0.22281, Acc:0.72857, F1: 0.72857
===> Epoch: 10: Training loss decreased (0.33109 --> 0.31936), Acc: (0.41682 --> 0.43573), F1: (0.41667 --> 0.43553).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 11 Train Avg loss: 0.31468, Acc: 0.41682, F1: 0.41667#####> Valid Avg loss: 0.19542, Acc:0.72857, F1: 0.72857
===> Epoch: 11: Training loss decreased (0.31936 --> 0.31468), Acc: (0.43573 --> 0.41682), F1: (0.43553 --> 0.41667).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 12 Train Avg loss: 0.30906, Acc: 0.43289, F1: 0.43270#####> Valid Avg loss: 0.18362, Acc:0.72857, F1: 0.72857
===> Epoch: 12: Training loss decreased (0.31468 --> 0.30906), Acc: (0.41682 --> 0.43289), F1: (0.41667 --> 0.43270).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 12: validation loss decreased (0.18937 --> 0.18362), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 13 Train Avg loss: 0.29847, Acc: 0.46125, F1: 0.46164#####> Valid Avg loss: 0.21234, Acc:0.72857, F1: 0.72857
===> Epoch: 13: Training loss decreased (0.30906 --> 0.29847), Acc: (0.43289 --> 0.46125), F1: (0.43270 --> 0.46164).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 14 Train Avg loss: 0.28960, Acc: 0.48393, F1: 0.48428#####> Valid Avg loss: 0.17041, Acc:0.72857, F1: 0.72857
===> Epoch: 14: Training loss decreased (0.29847 --> 0.28960), Acc: (0.46125 --> 0.48393), F1: (0.46164 --> 0.48428).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 14: validation loss decreased (0.18362 --> 0.17041), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 15 Train Avg loss: 0.28519, Acc: 0.45180, F1: 0.45220#####> Valid Avg loss: 0.18633, Acc:0.71905, F1: 0.71905
===> Epoch: 15: Training loss decreased (0.28960 --> 0.28519), Acc: (0.48393 --> 0.45180), F1: (0.48428 --> 0.45220).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 16 Train Avg loss: 0.27091, Acc: 0.50095, F1: 0.50000#####> Valid Avg loss: 0.16586, Acc:0.72857, F1: 0.72857
===> Epoch: 16: Training loss decreased (0.28519 --> 0.27091), Acc: (0.45180 --> 0.50095), F1: (0.45220 --> 0.50000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 16: validation loss decreased (0.17041 --> 0.16586), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 17 Train Avg loss: 0.26444, Acc: 0.49244, F1: 0.49214#####> Valid Avg loss: 0.16498, Acc:0.72857, F1: 0.72857
===> Epoch: 17: Training loss decreased (0.27091 --> 0.26444), Acc: (0.50095 --> 0.49244), F1: (0.50000 --> 0.49214).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 17: validation loss decreased (0.16586 --> 0.16498), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 18 Train Avg loss: 0.26236, Acc: 0.48110, F1: 0.48145#####> Valid Avg loss: 0.18875, Acc:0.72619, F1: 0.72619
===> Epoch: 18: Training loss decreased (0.26444 --> 0.26236), Acc: (0.49244 --> 0.48110), F1: (0.49214 --> 0.48145).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 19 Train Avg loss: 0.25549, Acc: 0.51607, F1: 0.51635#####> Valid Avg loss: 0.19836, Acc:0.64524, F1: 0.64524
===> Epoch: 19: Training loss decreased (0.26236 --> 0.25549), Acc: (0.48110 --> 0.51607), F1: (0.48145 --> 0.51635).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 20 Train Avg loss: 0.26148, Acc: 0.48393, F1: 0.48428#####> Valid Avg loss: 0.16971, Acc:0.72857, F1: 0.72857
====> Epoch: 21 Train Avg loss: 0.24995, Acc: 0.52363, F1: 0.52264#####> Valid Avg loss: 0.17341, Acc:0.72381, F1: 0.72381
===> Epoch: 21: Training loss decreased (0.25549 --> 0.24995), Acc: (0.51607 --> 0.52363), F1: (0.51635 --> 0.52264).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 22 Train Avg loss: 0.24416, Acc: 0.52079, F1: 0.52044#####> Valid Avg loss: 0.16288, Acc:0.71429, F1: 0.71429
===> Epoch: 22: Training loss decreased (0.24995 --> 0.24416), Acc: (0.52363 --> 0.52079), F1: (0.52264 --> 0.52044).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 22: validation loss decreased (0.16498 --> 0.16288), Acc: (0.72857 --> 0.71429), F1: (0.72857 --> 0.71429).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 23 Train Avg loss: 0.23780, Acc: 0.53403, F1: 0.53365#####> Valid Avg loss: 0.17881, Acc:0.71429, F1: 0.71429
===> Epoch: 23: Training loss decreased (0.24416 --> 0.23780), Acc: (0.52079 --> 0.53403), F1: (0.52044 --> 0.53365).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 24 Train Avg loss: 0.23640, Acc: 0.53308, F1: 0.53333#####> Valid Avg loss: 0.16407, Acc:0.72381, F1: 0.72381
===> Epoch: 24: Training loss decreased (0.23780 --> 0.23640), Acc: (0.53403 --> 0.53308), F1: (0.53365 --> 0.53333).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 25 Train Avg loss: 0.23508, Acc: 0.53781, F1: 0.53805#####> Valid Avg loss: 0.16169, Acc:0.72857, F1: 0.72857
===> Epoch: 25: Training loss decreased (0.23640 --> 0.23508), Acc: (0.53308 --> 0.53781), F1: (0.53333 --> 0.53805).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 25: validation loss decreased (0.16288 --> 0.16169), Acc: (0.71429 --> 0.72857), F1: (0.71429 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 26 Train Avg loss: 0.23185, Acc: 0.53875, F1: 0.53962#####> Valid Avg loss: 0.16681, Acc:0.72857, F1: 0.72857
===> Epoch: 26: Training loss decreased (0.23508 --> 0.23185), Acc: (0.53781 --> 0.53875), F1: (0.53805 --> 0.53962).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 27 Train Avg loss: 0.22904, Acc: 0.54537, F1: 0.54560#####> Valid Avg loss: 0.16442, Acc:0.72619, F1: 0.72619
===> Epoch: 27: Training loss decreased (0.23185 --> 0.22904), Acc: (0.53875 --> 0.54537), F1: (0.53962 --> 0.54560).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 28 Train Avg loss: 0.22782, Acc: 0.57089, F1: 0.57107#####> Valid Avg loss: 0.16368, Acc:0.71667, F1: 0.71667
===> Epoch: 28: Training loss decreased (0.22904 --> 0.22782), Acc: (0.54537 --> 0.57089), F1: (0.54560 --> 0.57107).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 29 Train Avg loss: 0.22615, Acc: 0.55671, F1: 0.55692#####> Valid Avg loss: 0.16586, Acc:0.70000, F1: 0.70000
===> Epoch: 29: Training loss decreased (0.22782 --> 0.22615), Acc: (0.57089 --> 0.55671), F1: (0.57107 --> 0.55692).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 30 Train Avg loss: 0.21688, Acc: 0.56900, F1: 0.56792#####> Valid Avg loss: 0.15752, Acc:0.72857, F1: 0.72857
===> Epoch: 30: Training loss decreased (0.22615 --> 0.21688), Acc: (0.55671 --> 0.56900), F1: (0.55692 --> 0.56792).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1

####> Epoch: 30: validation loss decreased (0.16169 --> 0.15752), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 31 Train Avg loss: 0.22267, Acc: 0.56049, F1: 0.56006#####> Valid Avg loss: 0.15951, Acc:0.71667, F1: 0.71667
====> Epoch: 32 Train Avg loss: 0.20796, Acc: 0.60681, F1: 0.60755#####> Valid Avg loss: 0.16819, Acc:0.70238, F1: 0.70238
===> Epoch: 32: Training loss decreased (0.21688 --> 0.20796), Acc: (0.56900 --> 0.60681), F1: (0.56792 --> 0.60755).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 33 Train Avg loss: 0.20597, Acc: 0.60019, F1: 0.59969#####> Valid Avg loss: 0.16513, Acc:0.70238, F1: 0.70238
===> Epoch: 33: Training loss decreased (0.20796 --> 0.20597), Acc: (0.60681 --> 0.60019), F1: (0.60755 --> 0.59969).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 34 Train Avg loss: 0.21383, Acc: 0.58223, F1: 0.58239#####> Valid Avg loss: 0.15778, Acc:0.72857, F1: 0.72857
====> Epoch: 35 Train Avg loss: 0.20818, Acc: 0.59168, F1: 0.59182#####> Valid Avg loss: 0.16149, Acc:0.71190, F1: 0.71190
====> Epoch: 36 Train Avg loss: 0.21503, Acc: 0.58696, F1: 0.58774#####> Valid Avg loss: 0.15850, Acc:0.72619, F1: 0.72619
====> Epoch: 37 Train Avg loss: 0.19756, Acc: 0.60491, F1: 0.60503#####> Valid Avg loss: 0.16704, Acc:0.69762, F1: 0.69762
===> Epoch: 37: Training loss decreased (0.20597 --> 0.19756), Acc: (0.60019 --> 0.60491), F1: (0.59969 --> 0.60503).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 38 Train Avg loss: 0.20406, Acc: 0.61248, F1: 0.61258#####> Valid Avg loss: 0.15945, Acc:0.72619, F1: 0.72619
====> Epoch: 39 Train Avg loss: 0.19248, Acc: 0.62760, F1: 0.62830#####> Valid Avg loss: 0.16066, Acc:0.70952, F1: 0.70952
===> Epoch: 39: Training loss decreased (0.19756 --> 0.19248), Acc: (0.60491 --> 0.62760), F1: (0.60503 --> 0.62830).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 40 Train Avg loss: 0.19795, Acc: 0.62949, F1: 0.63019#####> Valid Avg loss: 0.15605, Acc:0.72857, F1: 0.72857

####> Epoch: 40: validation loss decreased (0.15752 --> 0.15605), Acc: (0.72857 --> 0.72857), F1: (0.72857 --> 0.72857).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 41 Train Avg loss: 0.18521, Acc: 0.63705, F1: 0.63711#####> Valid Avg loss: 0.16109, Acc:0.70714, F1: 0.70714
===> Epoch: 41: Training loss decreased (0.19248 --> 0.18521), Acc: (0.62760 --> 0.63705), F1: (0.62830 --> 0.63711).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 42 Train Avg loss: 0.18974, Acc: 0.62476, F1: 0.62547#####> Valid Avg loss: 0.16921, Acc:0.69524, F1: 0.69524
====> Epoch: 43 Train Avg loss: 0.19219, Acc: 0.63516, F1: 0.63459#####> Valid Avg loss: 0.15967, Acc:0.72381, F1: 0.72381
====> Epoch: 44 Train Avg loss: 0.18282, Acc: 0.63800, F1: 0.63805#####> Valid Avg loss: 0.16084, Acc:0.71667, F1: 0.71667
===> Epoch: 44: Training loss decreased (0.18521 --> 0.18282), Acc: (0.63705 --> 0.63800), F1: (0.63711 --> 0.63805).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 45 Train Avg loss: 0.18350, Acc: 0.64556, F1: 0.64623#####> Valid Avg loss: 0.16115, Acc:0.70714, F1: 0.70714
====> Epoch: 46 Train Avg loss: 0.18008, Acc: 0.65312, F1: 0.65377#####> Valid Avg loss: 0.16353, Acc:0.70238, F1: 0.70238
===> Epoch: 46: Training loss decreased (0.18282 --> 0.18008), Acc: (0.63800 --> 0.65312), F1: (0.63805 --> 0.65377).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 47 Train Avg loss: 0.17837, Acc: 0.65406, F1: 0.65409#####> Valid Avg loss: 0.16681, Acc:0.69762, F1: 0.69762
===> Epoch: 47: Training loss decreased (0.18008 --> 0.17837), Acc: (0.65312 --> 0.65406), F1: (0.65377 --> 0.65409).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 48 Train Avg loss: 0.17801, Acc: 0.66635, F1: 0.66698#####> Valid Avg loss: 0.16395, Acc:0.69762, F1: 0.69762
===> Epoch: 48: Training loss decreased (0.17837 --> 0.17801), Acc: (0.65406 --> 0.66635), F1: (0.65409 --> 0.66698).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 49 Train Avg loss: 0.17564, Acc: 0.66541, F1: 0.66604#####> Valid Avg loss: 0.16477, Acc:0.70476, F1: 0.70476
===> Epoch: 49: Training loss decreased (0.17801 --> 0.17564), Acc: (0.66635 --> 0.66541), F1: (0.66698 --> 0.66604).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 50 Train Avg loss: 0.17806, Acc: 0.64934, F1: 0.64937#####> Valid Avg loss: 0.18061, Acc:0.66667, F1: 0.66667
====> Epoch: 51 Train Avg loss: 0.17843, Acc: 0.64178, F1: 0.64119#####> Valid Avg loss: 0.16435, Acc:0.71667, F1: 0.71667
====> Epoch: 52 Train Avg loss: 0.17017, Acc: 0.65028, F1: 0.65094#####> Valid Avg loss: 0.16757, Acc:0.70238, F1: 0.70238
===> Epoch: 52: Training loss decreased (0.17564 --> 0.17017), Acc: (0.66541 --> 0.65028), F1: (0.66604 --> 0.65094).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 53 Train Avg loss: 0.16512, Acc: 0.66730, F1: 0.66792#####> Valid Avg loss: 0.17128, Acc:0.70238, F1: 0.70238
===> Epoch: 53: Training loss decreased (0.17017 --> 0.16512), Acc: (0.65028 --> 0.66730), F1: (0.65094 --> 0.66792).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 54 Train Avg loss: 0.17615, Acc: 0.65879, F1: 0.65881#####> Valid Avg loss: 0.16694, Acc:0.70952, F1: 0.70952
====> Epoch: 55 Train Avg loss: 0.17527, Acc: 0.65028, F1: 0.65031#####> Valid Avg loss: 0.17310, Acc:0.70238, F1: 0.70238
====> Epoch: 56 Train Avg loss: 0.16502, Acc: 0.67391, F1: 0.67390#####> Valid Avg loss: 0.16994, Acc:0.70476, F1: 0.70476
===> Epoch: 56: Training loss decreased (0.16512 --> 0.16502), Acc: (0.66730 --> 0.67391), F1: (0.66792 --> 0.67390).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 57 Train Avg loss: 0.16349, Acc: 0.67675, F1: 0.67610#####> Valid Avg loss: 0.17503, Acc:0.70238, F1: 0.70238
===> Epoch: 57: Training loss decreased (0.16502 --> 0.16349), Acc: (0.67391 --> 0.67675), F1: (0.67390 --> 0.67610).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 58 Train Avg loss: 0.16300, Acc: 0.66446, F1: 0.66384#####> Valid Avg loss: 0.17438, Acc:0.70238, F1: 0.70238
===> Epoch: 58: Training loss decreased (0.16349 --> 0.16300), Acc: (0.67675 --> 0.66446), F1: (0.67610 --> 0.66384).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 59 Train Avg loss: 0.15791, Acc: 0.67864, F1: 0.67862#####> Valid Avg loss: 0.17647, Acc:0.70952, F1: 0.70952
===> Epoch: 59: Training loss decreased (0.16300 --> 0.15791), Acc: (0.66446 --> 0.67864), F1: (0.66384 --> 0.67862).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 60 Train Avg loss: 0.16027, Acc: 0.68242, F1: 0.68176#####> Valid Avg loss: 0.17241, Acc:0.71190, F1: 0.71190
====> Epoch: 61 Train Avg loss: 0.15604, Acc: 0.68242, F1: 0.68302#####> Valid Avg loss: 0.17257, Acc:0.71190, F1: 0.71190
===> Epoch: 61: Training loss decreased (0.15791 --> 0.15604), Acc: (0.67864 --> 0.68242), F1: (0.67862 --> 0.68302).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 62 Train Avg loss: 0.15991, Acc: 0.67958, F1: 0.68019#####> Valid Avg loss: 0.17055, Acc:0.71667, F1: 0.71667
====> Epoch: 63 Train Avg loss: 0.15614, Acc: 0.67958, F1: 0.68019#####> Valid Avg loss: 0.17337, Acc:0.71667, F1: 0.71667
====> Epoch: 64 Train Avg loss: 0.15277, Acc: 0.68809, F1: 0.68742#####> Valid Avg loss: 0.17024, Acc:0.71667, F1: 0.71667
===> Epoch: 64: Training loss decreased (0.15604 --> 0.15277), Acc: (0.68242 --> 0.68809), F1: (0.68302 --> 0.68742).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 65 Train Avg loss: 0.14703, Acc: 0.70132, F1: 0.70189#####> Valid Avg loss: 0.17725, Acc:0.70476, F1: 0.70476
===> Epoch: 65: Training loss decreased (0.15277 --> 0.14703), Acc: (0.68809 --> 0.70132), F1: (0.68742 --> 0.70189).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 66 Train Avg loss: 0.15482, Acc: 0.68809, F1: 0.68742#####> Valid Avg loss: 0.17542, Acc:0.71667, F1: 0.71667
====> Epoch: 67 Train Avg loss: 0.15543, Acc: 0.69187, F1: 0.69245#####> Valid Avg loss: 0.17570, Acc:0.70714, F1: 0.70714
====> Epoch: 68 Train Avg loss: 0.14768, Acc: 0.69660, F1: 0.69591#####> Valid Avg loss: 0.18235, Acc:0.71429, F1: 0.71429
====> Epoch: 69 Train Avg loss: 0.15534, Acc: 0.67580, F1: 0.67642#####> Valid Avg loss: 0.18053, Acc:0.70714, F1: 0.70714
====> Epoch: 70 Train Avg loss: 0.14420, Acc: 0.70605, F1: 0.70597#####> Valid Avg loss: 0.18106, Acc:0.70238, F1: 0.70238
===> Epoch: 70: Training loss decreased (0.14703 --> 0.14420), Acc: (0.70132 --> 0.70605), F1: (0.70189 --> 0.70597).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 71 Train Avg loss: 0.14849, Acc: 0.69376, F1: 0.69434#####> Valid Avg loss: 0.17309, Acc:0.71429, F1: 0.71429
====> Epoch: 72 Train Avg loss: 0.14154, Acc: 0.70510, F1: 0.70503#####> Valid Avg loss: 0.17548, Acc:0.71190, F1: 0.71190
===> Epoch: 72: Training loss decreased (0.14420 --> 0.14154), Acc: (0.70605 --> 0.70510), F1: (0.70597 --> 0.70503).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 73 Train Avg loss: 0.14209, Acc: 0.70888, F1: 0.70881#####> Valid Avg loss: 0.17729, Acc:0.71190, F1: 0.71190
====> Epoch: 74 Train Avg loss: 0.14491, Acc: 0.70888, F1: 0.70881#####> Valid Avg loss: 0.17366, Acc:0.71667, F1: 0.71667
====> Epoch: 75 Train Avg loss: 0.14334, Acc: 0.69943, F1: 0.70000#####> Valid Avg loss: 0.17794, Acc:0.70952, F1: 0.70952
====> Epoch: 76 Train Avg loss: 0.14474, Acc: 0.70699, F1: 0.70629#####> Valid Avg loss: 0.18097, Acc:0.70476, F1: 0.70476
====> Epoch: 77 Train Avg loss: 0.13665, Acc: 0.70888, F1: 0.70818#####> Valid Avg loss: 0.17926, Acc:0.70952, F1: 0.70952
===> Epoch: 77: Training loss decreased (0.14154 --> 0.13665), Acc: (0.70510 --> 0.70888), F1: (0.70503 --> 0.70818).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 78 Train Avg loss: 0.13711, Acc: 0.70038, F1: 0.70094#####> Valid Avg loss: 0.17274, Acc:0.70952, F1: 0.70952
====> Epoch: 79 Train Avg loss: 0.14120, Acc: 0.71456, F1: 0.71509#####> Valid Avg loss: 0.17224, Acc:0.71190, F1: 0.71190
====> Epoch: 80 Train Avg loss: 0.14133, Acc: 0.70699, F1: 0.70692#####> Valid Avg loss: 0.17553, Acc:0.71667, F1: 0.71667
====> Epoch: 81 Train Avg loss: 0.13717, Acc: 0.71456, F1: 0.71509#####> Valid Avg loss: 0.17970, Acc:0.70714, F1: 0.70714
====> Epoch: 82 Train Avg loss: 0.13578, Acc: 0.71456, F1: 0.71509#####> Valid Avg loss: 0.18128, Acc:0.70714, F1: 0.70714
===> Epoch: 82: Training loss decreased (0.13665 --> 0.13578), Acc: (0.70888 --> 0.71456), F1: (0.70818 --> 0.71509).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 83 Train Avg loss: 0.14216, Acc: 0.70888, F1: 0.70881#####> Valid Avg loss: 0.17672, Acc:0.70952, F1: 0.70952
====> Epoch: 84 Train Avg loss: 0.13929, Acc: 0.70510, F1: 0.70503#####> Valid Avg loss: 0.18074, Acc:0.70952, F1: 0.70952
====> Epoch: 85 Train Avg loss: 0.12878, Acc: 0.72873, F1: 0.72925#####> Valid Avg loss: 0.17899, Acc:0.70714, F1: 0.70714
===> Epoch: 85: Training loss decreased (0.13578 --> 0.12878), Acc: (0.71456 --> 0.72873), F1: (0.71509 --> 0.72925).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597272226.757581.pth_1
====> Epoch: 86 Train Avg loss: 0.13507, Acc: 0.72590, F1: 0.72642#####> Valid Avg loss: 0.17947, Acc:0.70952, F1: 0.70952
====> Epoch: 87 Train Avg loss: 0.13811, Acc: 0.71645, F1: 0.71635#####> Valid Avg loss: 0.17988, Acc:0.70714, F1: 0.70714
====> Epoch: 88 Train Avg loss: 0.13755, Acc: 0.70699, F1: 0.70755#####> Valid Avg loss: 0.18538, Acc:0.70714, F1: 0.70714
====> Epoch: 89 Train Avg loss: 0.13258, Acc: 0.72117, F1: 0.72107#####> Valid Avg loss: 0.18615, Acc:0.70238, F1: 0.70238
====> Epoch: 90 Train Avg loss: 0.13221, Acc: 0.71456, F1: 0.71509#####> Valid Avg loss: 0.17602, Acc:0.71190, F1: 0.71190
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 3train person_ids: [ 1  2  3  5  6  4  8  9 10 11 12 18 16]

	Start execution training validation it 1 

train_dataloader len: 200
valid_dataloader len: 6
test_dataloader len: 12
train performers ids: [3, 4, 5, 6, 8, 9, 10, 11, 12, 16, 18]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 999, train dataloader len: 200
valid dataset len: 28, valid dataloader len: 6
valid dataset len: 57, test dataloader len: 6
====> Epoch: 1 Train Avg loss: 0.44077, Acc: 0.42142, F1: 0.42200#####> Valid Avg loss: 0.35114, Acc:0.60714, F1: 0.63333
===> Epoch: 1: Training loss decreased (inf --> 0.44077), Acc: (0.00000 --> 0.42142), F1: (0.00000 --> 0.42200).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.35114), Acc: (0.00000 --> 0.60714), F1: (0.00000 --> 0.63333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.35114), Acc: (0.00000 --> 0.60714), F1: (0.00000 --> 0.63333).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 2 Train Avg loss: 0.22837, Acc: 0.79580, F1: 0.79600#####> Valid Avg loss: 0.28628, Acc:0.60714, F1: 0.63333
===> Epoch: 2: Training loss decreased (0.44077 --> 0.22837), Acc: (0.42142 --> 0.79580), F1: (0.42200 --> 0.79600).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1

####> Epoch: 2: validation loss decreased (0.35114 --> 0.28628), Acc: (0.60714 --> 0.60714), F1: (0.63333 --> 0.63333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 3 Train Avg loss: 0.16700, Acc: 0.85185, F1: 0.85200#####> Valid Avg loss: 0.25956, Acc:0.60714, F1: 0.63333
===> Epoch: 3: Training loss decreased (0.22837 --> 0.16700), Acc: (0.79580 --> 0.85185), F1: (0.79600 --> 0.85200).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1

####> Epoch: 3: validation loss decreased (0.28628 --> 0.25956), Acc: (0.60714 --> 0.60714), F1: (0.63333 --> 0.63333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 4 Train Avg loss: 0.15263, Acc: 0.86286, F1: 0.86275#####> Valid Avg loss: 0.20274, Acc:0.64286, F1: 0.66667
===> Epoch: 4: Training loss decreased (0.16700 --> 0.15263), Acc: (0.85185 --> 0.86286), F1: (0.85200 --> 0.86275).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1

####> Epoch: 4: validation loss decreased (0.25956 --> 0.20274), Acc: (0.60714 --> 0.64286), F1: (0.63333 --> 0.66667).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1

####> Epoch: 4: validation acc increase (0.35114 --> 0.20274), Acc: (0.60714 --> 0.64286), F1: (0.63333 --> 0.66667).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 5 Train Avg loss: 0.12215, Acc: 0.88589, F1: 0.88600#####> Valid Avg loss: 0.25981, Acc:0.60714, F1: 0.63333
===> Epoch: 5: Training loss decreased (0.15263 --> 0.12215), Acc: (0.86286 --> 0.88589), F1: (0.86275 --> 0.88600).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 6 Train Avg loss: 0.10166, Acc: 0.91692, F1: 0.91700#####> Valid Avg loss: 0.31780, Acc:0.60714, F1: 0.63333
===> Epoch: 6: Training loss decreased (0.12215 --> 0.10166), Acc: (0.88589 --> 0.91692), F1: (0.88600 --> 0.91700).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 7 Train Avg loss: 0.10144, Acc: 0.90390, F1: 0.90400#####> Valid Avg loss: 0.13979, Acc:0.64286, F1: 0.66667
===> Epoch: 7: Training loss decreased (0.10166 --> 0.10144), Acc: (0.91692 --> 0.90390), F1: (0.91700 --> 0.90400).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1

####> Epoch: 7: validation loss decreased (0.20274 --> 0.13979), Acc: (0.64286 --> 0.64286), F1: (0.66667 --> 0.66667).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 8 Train Avg loss: 0.09177, Acc: 0.89890, F1: 0.89900#####> Valid Avg loss: 0.32005, Acc:0.60714, F1: 0.63333
===> Epoch: 8: Training loss decreased (0.10144 --> 0.09177), Acc: (0.90390 --> 0.89890), F1: (0.90400 --> 0.89900).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 9 Train Avg loss: 0.08314, Acc: 0.92593, F1: 0.92600#####> Valid Avg loss: 0.24776, Acc:0.60714, F1: 0.63333
===> Epoch: 9: Training loss decreased (0.09177 --> 0.08314), Acc: (0.89890 --> 0.92593), F1: (0.89900 --> 0.92600).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 10 Train Avg loss: 0.07187, Acc: 0.93193, F1: 0.93200#####> Valid Avg loss: 0.16474, Acc:0.67857, F1: 0.70000
===> Epoch: 10: Training loss decreased (0.08314 --> 0.07187), Acc: (0.92593 --> 0.93193), F1: (0.92600 --> 0.93200).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1

####> Epoch: 10: validation acc increase (0.20274 --> 0.16474), Acc: (0.64286 --> 0.67857), F1: (0.66667 --> 0.70000).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 11 Train Avg loss: 0.06483, Acc: 0.93293, F1: 0.93275#####> Valid Avg loss: 0.16625, Acc:0.75000, F1: 0.76667
===> Epoch: 11: Training loss decreased (0.07187 --> 0.06483), Acc: (0.93193 --> 0.93293), F1: (0.93200 --> 0.93275).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1

####> Epoch: 11: validation acc increase (0.16474 --> 0.16625), Acc: (0.67857 --> 0.75000), F1: (0.70000 --> 0.76667).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 12 Train Avg loss: 0.06038, Acc: 0.94194, F1: 0.94200#####> Valid Avg loss: 0.19972, Acc:0.60714, F1: 0.63333
===> Epoch: 12: Training loss decreased (0.06483 --> 0.06038), Acc: (0.93293 --> 0.94194), F1: (0.93275 --> 0.94200).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 13 Train Avg loss: 0.06439, Acc: 0.93493, F1: 0.93500#####> Valid Avg loss: 0.34790, Acc:0.60714, F1: 0.63333
====> Epoch: 14 Train Avg loss: 0.08439, Acc: 0.89590, F1: 0.89575#####> Valid Avg loss: 0.17537, Acc:0.64286, F1: 0.66667
====> Epoch: 15 Train Avg loss: 0.05719, Acc: 0.93493, F1: 0.93500#####> Valid Avg loss: 0.15575, Acc:0.67857, F1: 0.70000
===> Epoch: 15: Training loss decreased (0.06038 --> 0.05719), Acc: (0.94194 --> 0.93493), F1: (0.94200 --> 0.93500).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 16 Train Avg loss: 0.04043, Acc: 0.95495, F1: 0.95500#####> Valid Avg loss: 0.25798, Acc:0.60714, F1: 0.63333
===> Epoch: 16: Training loss decreased (0.05719 --> 0.04043), Acc: (0.93493 --> 0.95495), F1: (0.93500 --> 0.95500).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 17 Train Avg loss: 0.04387, Acc: 0.94995, F1: 0.95000#####> Valid Avg loss: 0.25530, Acc:0.64286, F1: 0.66667
====> Epoch: 18 Train Avg loss: 0.04665, Acc: 0.94294, F1: 0.94300#####> Valid Avg loss: 0.31878, Acc:0.60714, F1: 0.63333
====> Epoch: 19 Train Avg loss: 0.04529, Acc: 0.94795, F1: 0.94775#####> Valid Avg loss: 0.21909, Acc:0.64286, F1: 0.66667
====> Epoch: 20 Train Avg loss: 0.03408, Acc: 0.96196, F1: 0.96200#####> Valid Avg loss: 0.21878, Acc:0.64286, F1: 0.66667
===> Epoch: 20: Training loss decreased (0.04043 --> 0.03408), Acc: (0.95495 --> 0.96196), F1: (0.95500 --> 0.96200).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597726203.140546.pth_1
====> Epoch: 21 Train Avg loss: 0.04069, Acc: 0.95395, F1: 0.95400#####> Valid Avg loss: 0.15510, Acc:0.64286, F1: 0.66667
====> Epoch: 22 Train Avg loss: 0.04054, Acc: 0.95195, F1: 0.95200#####> Valid Avg loss: 0.27160, Acc:0.67857, F1: 0.70000
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597727934.964086.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 3train person_ids: [ 1  2  3  5  6  4  8  9 10 11 12 18 16]

	Start execution training validation it 1 

train_dataloader len: 200
valid_dataloader len: 6
test_dataloader len: 12
train performers ids: [3, 4, 5, 6, 8, 9, 10, 11, 12, 16, 18]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 999, train dataloader len: 200
valid dataset len: 28, valid dataloader len: 6
valid dataset len: 57, test dataloader len: 6
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 866
valid_dataloader len: 199
test_dataloader len: 143
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 4326, train dataloader len: 866
valid dataset len: 995, valid dataloader len: 199
valid dataset len: 713, test dataloader len: 199
====> Epoch: 1 Train Avg loss: 0.57418, Acc: 0.23024, F1: 0.23002#####> Valid Avg loss: 0.47716, Acc:0.44121, F1: 0.44121
===> Epoch: 1: Training loss decreased (inf --> 0.57418), Acc: (0.00000 --> 0.23024), F1: (0.00000 --> 0.23002).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.47716), Acc: (0.00000 --> 0.44121), F1: (0.00000 --> 0.44121).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.47716), Acc: (0.00000 --> 0.44121), F1: (0.00000 --> 0.44121).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 2 Train Avg loss: 0.50436, Acc: 0.29658, F1: 0.29723#####> Valid Avg loss: 0.46549, Acc:0.44121, F1: 0.44121
===> Epoch: 2: Training loss decreased (0.57418 --> 0.50436), Acc: (0.23024 --> 0.29658), F1: (0.23002 --> 0.29723).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1

####> Epoch: 2: validation loss decreased (0.47716 --> 0.46549), Acc: (0.44121 --> 0.44121), F1: (0.44121 --> 0.44121).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 3 Train Avg loss: 0.46694, Acc: 0.33380, F1: 0.33441#####> Valid Avg loss: 0.42922, Acc:0.42312, F1: 0.42312
===> Epoch: 3: Training loss decreased (0.50436 --> 0.46694), Acc: (0.29658 --> 0.33380), F1: (0.29723 --> 0.33441).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1

####> Epoch: 3: validation loss decreased (0.46549 --> 0.42922), Acc: (0.44121 --> 0.42312), F1: (0.44121 --> 0.42312).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 4 Train Avg loss: 0.44188, Acc: 0.38049, F1: 0.38106#####> Valid Avg loss: 0.48148, Acc:0.18090, F1: 0.18090
===> Epoch: 4: Training loss decreased (0.46694 --> 0.44188), Acc: (0.33380 --> 0.38049), F1: (0.33441 --> 0.38106).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 5 Train Avg loss: 0.42364, Acc: 0.41424, F1: 0.41478#####> Valid Avg loss: 0.44058, Acc:0.31055, F1: 0.31055
===> Epoch: 5: Training loss decreased (0.44188 --> 0.42364), Acc: (0.38049 --> 0.41424), F1: (0.38106 --> 0.41478).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 6 Train Avg loss: 0.40875, Acc: 0.42603, F1: 0.42656#####> Valid Avg loss: 0.40522, Acc:0.40905, F1: 0.40905
===> Epoch: 6: Training loss decreased (0.42364 --> 0.40875), Acc: (0.41424 --> 0.42603), F1: (0.41478 --> 0.42656).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1

####> Epoch: 6: validation loss decreased (0.42922 --> 0.40522), Acc: (0.42312 --> 0.40905), F1: (0.42312 --> 0.40905).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 7 Train Avg loss: 0.39480, Acc: 0.43805, F1: 0.43857#####> Valid Avg loss: 0.40511, Acc:0.43417, F1: 0.43417
===> Epoch: 7: Training loss decreased (0.40875 --> 0.39480), Acc: (0.42603 --> 0.43805), F1: (0.42656 --> 0.43857).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1

####> Epoch: 7: validation loss decreased (0.40522 --> 0.40511), Acc: (0.40905 --> 0.43417), F1: (0.40905 --> 0.43417).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 8 Train Avg loss: 0.38407, Acc: 0.45123, F1: 0.45081#####> Valid Avg loss: 0.41279, Acc:0.38492, F1: 0.38492
===> Epoch: 8: Training loss decreased (0.39480 --> 0.38407), Acc: (0.43805 --> 0.45123), F1: (0.43857 --> 0.45081).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 9 Train Avg loss: 0.37559, Acc: 0.47110, F1: 0.47067#####> Valid Avg loss: 0.39809, Acc:0.42312, F1: 0.42312
===> Epoch: 9: Training loss decreased (0.38407 --> 0.37559), Acc: (0.45123 --> 0.47110), F1: (0.45081 --> 0.47067).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1

####> Epoch: 9: validation loss decreased (0.40511 --> 0.39809), Acc: (0.43417 --> 0.42312), F1: (0.43417 --> 0.42312).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 10 Train Avg loss: 0.37651, Acc: 0.45932, F1: 0.45889#####> Valid Avg loss: 0.39777, Acc:0.41307, F1: 0.41307

####> Epoch: 10: validation loss decreased (0.39809 --> 0.39777), Acc: (0.42312 --> 0.41307), F1: (0.42312 --> 0.41307).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 11 Train Avg loss: 0.36318, Acc: 0.46926, F1: 0.46975#####> Valid Avg loss: 0.40725, Acc:0.40201, F1: 0.40201
===> Epoch: 11: Training loss decreased (0.37559 --> 0.36318), Acc: (0.47110 --> 0.46926), F1: (0.47067 --> 0.46975).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
====> Epoch: 12 Train Avg loss: 0.36935, Acc: 0.45793, F1: 0.45843#####> Valid Avg loss: 0.42227, Acc:0.33367, F1: 0.33367
====> Epoch: 13 Train Avg loss: 0.36214, Acc: 0.47550, F1: 0.47506#####> Valid Avg loss: 0.40848, Acc:0.39598, F1: 0.39598
===> Epoch: 13: Training loss decreased (0.36318 --> 0.36214), Acc: (0.46926 --> 0.47550), F1: (0.46975 --> 0.47506).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597728011.563521.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 12train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 866
valid_dataloader len: 199
test_dataloader len: 143
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 4326, train dataloader len: 866
valid dataset len: 995, valid dataloader len: 199
valid dataset len: 713, test dataloader len: 199
====> Epoch: 1 Train Avg loss: 0.58646, Acc: 0.24364, F1: 0.24434#####> Valid Avg loss: 0.50475, Acc:0.44121, F1: 0.44121
===> Epoch: 1: Training loss decreased (inf --> 0.58646), Acc: (0.00000 --> 0.24364), F1: (0.00000 --> 0.24434).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.50475), Acc: (0.00000 --> 0.44121), F1: (0.00000 --> 0.44121).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.50475), Acc: (0.00000 --> 0.44121), F1: (0.00000 --> 0.44121).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 2 Train Avg loss: 0.52053, Acc: 0.29866, F1: 0.29838#####> Valid Avg loss: 0.43265, Acc:0.44121, F1: 0.44121
===> Epoch: 2: Training loss decreased (0.58646 --> 0.52053), Acc: (0.24364 --> 0.29866), F1: (0.24434 --> 0.29838).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1

####> Epoch: 2: validation loss decreased (0.50475 --> 0.43265), Acc: (0.44121 --> 0.44121), F1: (0.44121 --> 0.44121).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 3 Train Avg loss: 0.48120, Acc: 0.33819, F1: 0.33788#####> Valid Avg loss: 0.42501, Acc:0.44121, F1: 0.44121
===> Epoch: 3: Training loss decreased (0.52053 --> 0.48120), Acc: (0.29866 --> 0.33819), F1: (0.29838 --> 0.33788).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1

####> Epoch: 3: validation loss decreased (0.43265 --> 0.42501), Acc: (0.44121 --> 0.44121), F1: (0.44121 --> 0.44121).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 4 Train Avg loss: 0.43870, Acc: 0.38927, F1: 0.38891#####> Valid Avg loss: 0.42537, Acc:0.39095, F1: 0.39095
===> Epoch: 4: Training loss decreased (0.48120 --> 0.43870), Acc: (0.33819 --> 0.38927), F1: (0.33788 --> 0.38891).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 5 Train Avg loss: 0.41376, Acc: 0.41493, F1: 0.41455#####> Valid Avg loss: 0.39069, Acc:0.44121, F1: 0.44121
===> Epoch: 5: Training loss decreased (0.43870 --> 0.41376), Acc: (0.38927 --> 0.41493), F1: (0.38891 --> 0.41455).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1

####> Epoch: 5: validation loss decreased (0.42501 --> 0.39069), Acc: (0.44121 --> 0.44121), F1: (0.44121 --> 0.44121).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 6 Train Avg loss: 0.39218, Acc: 0.43897, F1: 0.43857#####> Valid Avg loss: 0.39561, Acc:0.43920, F1: 0.43920
===> Epoch: 6: Training loss decreased (0.41376 --> 0.39218), Acc: (0.41493 --> 0.43897), F1: (0.41455 --> 0.43857).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 7 Train Avg loss: 0.38539, Acc: 0.44660, F1: 0.44619#####> Valid Avg loss: 0.39414, Acc:0.43920, F1: 0.43920
===> Epoch: 7: Training loss decreased (0.39218 --> 0.38539), Acc: (0.43897 --> 0.44660), F1: (0.43857 --> 0.44619).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 8 Train Avg loss: 0.37434, Acc: 0.46140, F1: 0.46189#####> Valid Avg loss: 0.39388, Acc:0.43719, F1: 0.43719
===> Epoch: 8: Training loss decreased (0.38539 --> 0.37434), Acc: (0.44660 --> 0.46140), F1: (0.44619 --> 0.46189).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 9 Train Avg loss: 0.36501, Acc: 0.47712, F1: 0.47667#####> Valid Avg loss: 0.40903, Acc:0.44020, F1: 0.44020
===> Epoch: 9: Training loss decreased (0.37434 --> 0.36501), Acc: (0.46140 --> 0.47712), F1: (0.46189 --> 0.47667).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 10 Train Avg loss: 0.35835, Acc: 0.48151, F1: 0.48106#####> Valid Avg loss: 0.39077, Acc:0.43719, F1: 0.43719
===> Epoch: 10: Training loss decreased (0.36501 --> 0.35835), Acc: (0.47712 --> 0.48151), F1: (0.47667 --> 0.48106).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 11 Train Avg loss: 0.34726, Acc: 0.48729, F1: 0.48776#####> Valid Avg loss: 0.38448, Acc:0.44121, F1: 0.44121
===> Epoch: 11: Training loss decreased (0.35835 --> 0.34726), Acc: (0.48151 --> 0.48729), F1: (0.48106 --> 0.48776).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1

####> Epoch: 11: validation loss decreased (0.39069 --> 0.38448), Acc: (0.44121 --> 0.44121), F1: (0.44121 --> 0.44121).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 12 Train Avg loss: 0.34618, Acc: 0.48960, F1: 0.48915#####> Valid Avg loss: 0.38841, Acc:0.44121, F1: 0.44121
===> Epoch: 12: Training loss decreased (0.34726 --> 0.34618), Acc: (0.48729 --> 0.48960), F1: (0.48776 --> 0.48915).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 13 Train Avg loss: 0.34128, Acc: 0.48844, F1: 0.48799#####> Valid Avg loss: 0.39070, Acc:0.44121, F1: 0.44121
===> Epoch: 13: Training loss decreased (0.34618 --> 0.34128), Acc: (0.48960 --> 0.48844), F1: (0.48915 --> 0.48799).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 14 Train Avg loss: 0.33619, Acc: 0.50231, F1: 0.50277#####> Valid Avg loss: 0.38878, Acc:0.43819, F1: 0.43819
===> Epoch: 14: Training loss decreased (0.34128 --> 0.33619), Acc: (0.48844 --> 0.50231), F1: (0.48799 --> 0.50277).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 15 Train Avg loss: 0.33485, Acc: 0.49861, F1: 0.49908#####> Valid Avg loss: 0.42020, Acc:0.39799, F1: 0.39799
===> Epoch: 15: Training loss decreased (0.33619 --> 0.33485), Acc: (0.50231 --> 0.49861), F1: (0.50277 --> 0.49908).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 16 Train Avg loss: 0.32593, Acc: 0.51156, F1: 0.51201#####> Valid Avg loss: 0.39399, Acc:0.44121, F1: 0.44121
===> Epoch: 16: Training loss decreased (0.33485 --> 0.32593), Acc: (0.49861 --> 0.51156), F1: (0.49908 --> 0.51201).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 17 Train Avg loss: 0.32127, Acc: 0.51664, F1: 0.51709#####> Valid Avg loss: 0.40747, Acc:0.43920, F1: 0.43920
===> Epoch: 17: Training loss decreased (0.32593 --> 0.32127), Acc: (0.51156 --> 0.51664), F1: (0.51201 --> 0.51709).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 18 Train Avg loss: 0.31782, Acc: 0.51757, F1: 0.51801#####> Valid Avg loss: 0.39721, Acc:0.44121, F1: 0.44121
===> Epoch: 18: Training loss decreased (0.32127 --> 0.31782), Acc: (0.51664 --> 0.51757), F1: (0.51709 --> 0.51801).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 19 Train Avg loss: 0.31826, Acc: 0.51826, F1: 0.51778#####> Valid Avg loss: 0.41540, Acc:0.44121, F1: 0.44121
====> Epoch: 20 Train Avg loss: 0.31559, Acc: 0.52150, F1: 0.52194#####> Valid Avg loss: 0.41302, Acc:0.42714, F1: 0.42714
===> Epoch: 20: Training loss decreased (0.31782 --> 0.31559), Acc: (0.51757 --> 0.52150), F1: (0.51801 --> 0.52194).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 21 Train Avg loss: 0.30966, Acc: 0.52797, F1: 0.52841#####> Valid Avg loss: 0.39592, Acc:0.44020, F1: 0.44020
===> Epoch: 21: Training loss decreased (0.31559 --> 0.30966), Acc: (0.52150 --> 0.52797), F1: (0.52194 --> 0.52841).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 22 Train Avg loss: 0.31063, Acc: 0.52473, F1: 0.52425#####> Valid Avg loss: 0.40879, Acc:0.41005, F1: 0.41005
====> Epoch: 23 Train Avg loss: 0.30388, Acc: 0.53930, F1: 0.53880#####> Valid Avg loss: 0.43473, Acc:0.39095, F1: 0.39095
===> Epoch: 23: Training loss decreased (0.30966 --> 0.30388), Acc: (0.52797 --> 0.53930), F1: (0.52841 --> 0.53880).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 24 Train Avg loss: 0.30461, Acc: 0.53259, F1: 0.53210#####> Valid Avg loss: 0.42157, Acc:0.43417, F1: 0.43417
====> Epoch: 25 Train Avg loss: 0.29567, Acc: 0.54693, F1: 0.54734#####> Valid Avg loss: 0.42376, Acc:0.43719, F1: 0.43719
===> Epoch: 25: Training loss decreased (0.30388 --> 0.29567), Acc: (0.53930 --> 0.54693), F1: (0.53880 --> 0.54734).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 26 Train Avg loss: 0.29640, Acc: 0.55016, F1: 0.54965#####> Valid Avg loss: 0.43230, Acc:0.43116, F1: 0.43116
====> Epoch: 27 Train Avg loss: 0.29640, Acc: 0.54392, F1: 0.54434#####> Valid Avg loss: 0.42568, Acc:0.43015, F1: 0.43015
====> Epoch: 28 Train Avg loss: 0.29389, Acc: 0.54369, F1: 0.54319#####> Valid Avg loss: 0.42721, Acc:0.42312, F1: 0.42312
===> Epoch: 28: Training loss decreased (0.29567 --> 0.29389), Acc: (0.54693 --> 0.54369), F1: (0.54734 --> 0.54319).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 29 Train Avg loss: 0.29274, Acc: 0.54762, F1: 0.54711#####> Valid Avg loss: 0.41307, Acc:0.43819, F1: 0.43819
===> Epoch: 29: Training loss decreased (0.29389 --> 0.29274), Acc: (0.54369 --> 0.54762), F1: (0.54319 --> 0.54711).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 30 Train Avg loss: 0.29180, Acc: 0.53745, F1: 0.53788#####> Valid Avg loss: 0.44520, Acc:0.39095, F1: 0.39095
===> Epoch: 30: Training loss decreased (0.29274 --> 0.29180), Acc: (0.54762 --> 0.53745), F1: (0.54711 --> 0.53788).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 31 Train Avg loss: 0.28159, Acc: 0.56103, F1: 0.56051#####> Valid Avg loss: 0.41933, Acc:0.44121, F1: 0.44121
===> Epoch: 31: Training loss decreased (0.29180 --> 0.28159), Acc: (0.53745 --> 0.56103), F1: (0.53788 --> 0.56051).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 32 Train Avg loss: 0.28686, Acc: 0.55340, F1: 0.55289#####> Valid Avg loss: 0.41807, Acc:0.44020, F1: 0.44020
====> Epoch: 33 Train Avg loss: 0.28159, Acc: 0.56218, F1: 0.56259#####> Valid Avg loss: 0.42334, Acc:0.44020, F1: 0.44020
====> Epoch: 34 Train Avg loss: 0.28140, Acc: 0.55455, F1: 0.55497#####> Valid Avg loss: 0.43077, Acc:0.44020, F1: 0.44020
===> Epoch: 34: Training loss decreased (0.28159 --> 0.28140), Acc: (0.56103 --> 0.55455), F1: (0.56051 --> 0.55497).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 35 Train Avg loss: 0.28063, Acc: 0.56311, F1: 0.56351#####> Valid Avg loss: 0.44204, Acc:0.44121, F1: 0.44121
===> Epoch: 35: Training loss decreased (0.28140 --> 0.28063), Acc: (0.55455 --> 0.56311), F1: (0.55497 --> 0.56351).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 36 Train Avg loss: 0.28040, Acc: 0.55918, F1: 0.55958#####> Valid Avg loss: 0.43309, Acc:0.44121, F1: 0.44121
===> Epoch: 36: Training loss decreased (0.28063 --> 0.28040), Acc: (0.56311 --> 0.55918), F1: (0.56351 --> 0.55958).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 37 Train Avg loss: 0.27378, Acc: 0.56981, F1: 0.57021#####> Valid Avg loss: 0.43689, Acc:0.44121, F1: 0.44121
===> Epoch: 37: Training loss decreased (0.28040 --> 0.27378), Acc: (0.55918 --> 0.56981), F1: (0.55958 --> 0.57021).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 38 Train Avg loss: 0.26958, Acc: 0.57074, F1: 0.57021#####> Valid Avg loss: 0.41514, Acc:0.44121, F1: 0.44121
===> Epoch: 38: Training loss decreased (0.27378 --> 0.26958), Acc: (0.56981 --> 0.57074), F1: (0.57021 --> 0.57021).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 39 Train Avg loss: 0.27642, Acc: 0.56657, F1: 0.56697#####> Valid Avg loss: 0.44025, Acc:0.39899, F1: 0.39899
====> Epoch: 40 Train Avg loss: 0.27378, Acc: 0.56981, F1: 0.57021#####> Valid Avg loss: 0.42981, Acc:0.44020, F1: 0.44020
====> Epoch: 41 Train Avg loss: 0.26788, Acc: 0.56935, F1: 0.56975#####> Valid Avg loss: 0.43551, Acc:0.44121, F1: 0.44121
===> Epoch: 41: Training loss decreased (0.26958 --> 0.26788), Acc: (0.57074 --> 0.56935), F1: (0.57021 --> 0.56975).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 42 Train Avg loss: 0.26563, Acc: 0.57952, F1: 0.57991#####> Valid Avg loss: 0.42998, Acc:0.44121, F1: 0.44121
===> Epoch: 42: Training loss decreased (0.26788 --> 0.26563), Acc: (0.56935 --> 0.57952), F1: (0.56975 --> 0.57991).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 43 Train Avg loss: 0.26342, Acc: 0.58183, F1: 0.58222#####> Valid Avg loss: 0.42478, Acc:0.43116, F1: 0.43116
===> Epoch: 43: Training loss decreased (0.26563 --> 0.26342), Acc: (0.57952 --> 0.58183), F1: (0.57991 --> 0.58222).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 44 Train Avg loss: 0.26535, Acc: 0.57420, F1: 0.57460#####> Valid Avg loss: 0.43525, Acc:0.43920, F1: 0.43920
====> Epoch: 45 Train Avg loss: 0.26054, Acc: 0.58807, F1: 0.58753#####> Valid Avg loss: 0.43699, Acc:0.43920, F1: 0.43920
===> Epoch: 45: Training loss decreased (0.26342 --> 0.26054), Acc: (0.58183 --> 0.58807), F1: (0.58222 --> 0.58753).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 46 Train Avg loss: 0.26524, Acc: 0.57975, F1: 0.58014#####> Valid Avg loss: 0.44303, Acc:0.43417, F1: 0.43417
====> Epoch: 47 Train Avg loss: 0.25574, Acc: 0.58853, F1: 0.58891#####> Valid Avg loss: 0.42075, Acc:0.44121, F1: 0.44121
===> Epoch: 47: Training loss decreased (0.26054 --> 0.25574), Acc: (0.58807 --> 0.58853), F1: (0.58753 --> 0.58891).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 48 Train Avg loss: 0.26165, Acc: 0.58669, F1: 0.58614#####> Valid Avg loss: 0.43158, Acc:0.44020, F1: 0.44020
====> Epoch: 49 Train Avg loss: 0.25520, Acc: 0.58553, F1: 0.58591#####> Valid Avg loss: 0.43411, Acc:0.44121, F1: 0.44121
===> Epoch: 49: Training loss decreased (0.25574 --> 0.25520), Acc: (0.58853 --> 0.58553), F1: (0.58891 --> 0.58591).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 50 Train Avg loss: 0.25530, Acc: 0.58599, F1: 0.58637#####> Valid Avg loss: 0.42754, Acc:0.43417, F1: 0.43417
====> Epoch: 51 Train Avg loss: 0.25467, Acc: 0.58715, F1: 0.58661#####> Valid Avg loss: 0.43028, Acc:0.43819, F1: 0.43819
===> Epoch: 51: Training loss decreased (0.25520 --> 0.25467), Acc: (0.58553 --> 0.58715), F1: (0.58591 --> 0.58661).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 52 Train Avg loss: 0.25174, Acc: 0.59108, F1: 0.59145#####> Valid Avg loss: 0.44389, Acc:0.44121, F1: 0.44121
===> Epoch: 52: Training loss decreased (0.25467 --> 0.25174), Acc: (0.58715 --> 0.59108), F1: (0.58661 --> 0.59145).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 53 Train Avg loss: 0.25356, Acc: 0.59246, F1: 0.59192#####> Valid Avg loss: 0.43187, Acc:0.44020, F1: 0.44020
====> Epoch: 54 Train Avg loss: 0.25104, Acc: 0.60171, F1: 0.60115#####> Valid Avg loss: 0.43843, Acc:0.43819, F1: 0.43819
===> Epoch: 54: Training loss decreased (0.25174 --> 0.25104), Acc: (0.59108 --> 0.60171), F1: (0.59145 --> 0.60115).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 55 Train Avg loss: 0.24968, Acc: 0.60009, F1: 0.59954#####> Valid Avg loss: 0.42862, Acc:0.43819, F1: 0.43819
===> Epoch: 55: Training loss decreased (0.25104 --> 0.24968), Acc: (0.60171 --> 0.60009), F1: (0.60115 --> 0.59954).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 56 Train Avg loss: 0.24696, Acc: 0.60194, F1: 0.60139#####> Valid Avg loss: 0.44104, Acc:0.43920, F1: 0.43920
===> Epoch: 56: Training loss decreased (0.24968 --> 0.24696), Acc: (0.60009 --> 0.60194), F1: (0.59954 --> 0.60139).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 57 Train Avg loss: 0.24605, Acc: 0.59871, F1: 0.59908#####> Valid Avg loss: 0.43213, Acc:0.43920, F1: 0.43920
===> Epoch: 57: Training loss decreased (0.24696 --> 0.24605), Acc: (0.60194 --> 0.59871), F1: (0.60139 --> 0.59908).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 58 Train Avg loss: 0.24469, Acc: 0.59847, F1: 0.59885#####> Valid Avg loss: 0.42145, Acc:0.43819, F1: 0.43819
===> Epoch: 58: Training loss decreased (0.24605 --> 0.24469), Acc: (0.59871 --> 0.59847), F1: (0.59908 --> 0.59885).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 59 Train Avg loss: 0.24275, Acc: 0.60472, F1: 0.60416#####> Valid Avg loss: 0.42962, Acc:0.43920, F1: 0.43920
===> Epoch: 59: Training loss decreased (0.24469 --> 0.24275), Acc: (0.59847 --> 0.60472), F1: (0.59885 --> 0.60416).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 60 Train Avg loss: 0.23956, Acc: 0.60772, F1: 0.60716#####> Valid Avg loss: 0.40931, Acc:0.43819, F1: 0.43819
===> Epoch: 60: Training loss decreased (0.24275 --> 0.23956), Acc: (0.60472 --> 0.60772), F1: (0.60416 --> 0.60716).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 61 Train Avg loss: 0.23988, Acc: 0.61211, F1: 0.61155#####> Valid Avg loss: 0.43498, Acc:0.44020, F1: 0.44020
====> Epoch: 62 Train Avg loss: 0.23890, Acc: 0.60865, F1: 0.60901#####> Valid Avg loss: 0.44187, Acc:0.43819, F1: 0.43819
===> Epoch: 62: Training loss decreased (0.23956 --> 0.23890), Acc: (0.60772 --> 0.60865), F1: (0.60716 --> 0.60901).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 63 Train Avg loss: 0.24125, Acc: 0.60934, F1: 0.60970#####> Valid Avg loss: 0.43374, Acc:0.44020, F1: 0.44020
====> Epoch: 64 Train Avg loss: 0.23890, Acc: 0.60587, F1: 0.60531#####> Valid Avg loss: 0.44127, Acc:0.44020, F1: 0.44020
===> Epoch: 64: Training loss decreased (0.23890 --> 0.23890), Acc: (0.60865 --> 0.60587), F1: (0.60901 --> 0.60531).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 65 Train Avg loss: 0.23751, Acc: 0.61165, F1: 0.61201#####> Valid Avg loss: 0.43840, Acc:0.44020, F1: 0.44020
===> Epoch: 65: Training loss decreased (0.23890 --> 0.23751), Acc: (0.60587 --> 0.61165), F1: (0.60531 --> 0.61201).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 66 Train Avg loss: 0.23372, Acc: 0.61558, F1: 0.61501#####> Valid Avg loss: 0.42832, Acc:0.43819, F1: 0.43819
===> Epoch: 66: Training loss decreased (0.23751 --> 0.23372), Acc: (0.61165 --> 0.61558), F1: (0.61201 --> 0.61501).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 67 Train Avg loss: 0.23141, Acc: 0.62067, F1: 0.62102#####> Valid Avg loss: 0.44509, Acc:0.43920, F1: 0.43920
===> Epoch: 67: Training loss decreased (0.23372 --> 0.23141), Acc: (0.61558 --> 0.62067), F1: (0.61501 --> 0.62102).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 68 Train Avg loss: 0.23470, Acc: 0.61697, F1: 0.61640#####> Valid Avg loss: 0.44970, Acc:0.43920, F1: 0.43920
====> Epoch: 69 Train Avg loss: 0.22899, Acc: 0.61905, F1: 0.61940#####> Valid Avg loss: 0.45725, Acc:0.43819, F1: 0.43819
===> Epoch: 69: Training loss decreased (0.23141 --> 0.22899), Acc: (0.62067 --> 0.61905), F1: (0.62102 --> 0.61940).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 70 Train Avg loss: 0.23126, Acc: 0.61720, F1: 0.61755#####> Valid Avg loss: 0.42485, Acc:0.44020, F1: 0.44020
====> Epoch: 71 Train Avg loss: 0.23007, Acc: 0.62436, F1: 0.62471#####> Valid Avg loss: 0.44376, Acc:0.44121, F1: 0.44121
====> Epoch: 72 Train Avg loss: 0.22888, Acc: 0.63037, F1: 0.63072#####> Valid Avg loss: 0.43222, Acc:0.43819, F1: 0.43819
===> Epoch: 72: Training loss decreased (0.22899 --> 0.22888), Acc: (0.61905 --> 0.63037), F1: (0.61940 --> 0.63072).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 73 Train Avg loss: 0.22655, Acc: 0.62853, F1: 0.62887#####> Valid Avg loss: 0.43185, Acc:0.43920, F1: 0.43920
===> Epoch: 73: Training loss decreased (0.22888 --> 0.22655), Acc: (0.63037 --> 0.62853), F1: (0.63072 --> 0.62887).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 74 Train Avg loss: 0.22680, Acc: 0.62621, F1: 0.62564#####> Valid Avg loss: 0.45782, Acc:0.44020, F1: 0.44020
====> Epoch: 75 Train Avg loss: 0.22668, Acc: 0.61997, F1: 0.61940#####> Valid Avg loss: 0.45283, Acc:0.43920, F1: 0.43920
====> Epoch: 76 Train Avg loss: 0.22279, Acc: 0.63477, F1: 0.63418#####> Valid Avg loss: 0.43377, Acc:0.44121, F1: 0.44121
===> Epoch: 76: Training loss decreased (0.22655 --> 0.22279), Acc: (0.62853 --> 0.63477), F1: (0.62887 --> 0.63418).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 77 Train Avg loss: 0.22783, Acc: 0.62876, F1: 0.62818#####> Valid Avg loss: 0.42641, Acc:0.43920, F1: 0.43920
====> Epoch: 78 Train Avg loss: 0.22372, Acc: 0.63454, F1: 0.63487#####> Valid Avg loss: 0.44871, Acc:0.43920, F1: 0.43920
====> Epoch: 79 Train Avg loss: 0.22384, Acc: 0.63685, F1: 0.63718#####> Valid Avg loss: 0.44080, Acc:0.43920, F1: 0.43920
====> Epoch: 80 Train Avg loss: 0.22072, Acc: 0.63731, F1: 0.63672#####> Valid Avg loss: 0.43176, Acc:0.43819, F1: 0.43819
===> Epoch: 80: Training loss decreased (0.22279 --> 0.22072), Acc: (0.63477 --> 0.63731), F1: (0.63418 --> 0.63672).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 81 Train Avg loss: 0.22010, Acc: 0.63361, F1: 0.63395#####> Valid Avg loss: 0.44829, Acc:0.43819, F1: 0.43819
===> Epoch: 81: Training loss decreased (0.22072 --> 0.22010), Acc: (0.63731 --> 0.63361), F1: (0.63672 --> 0.63395).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 82 Train Avg loss: 0.22183, Acc: 0.62714, F1: 0.62748#####> Valid Avg loss: 0.42659, Acc:0.43719, F1: 0.43719
====> Epoch: 83 Train Avg loss: 0.21986, Acc: 0.64239, F1: 0.64180#####> Valid Avg loss: 0.43498, Acc:0.43920, F1: 0.43920
===> Epoch: 83: Training loss decreased (0.22010 --> 0.21986), Acc: (0.63361 --> 0.64239), F1: (0.63395 --> 0.64180).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 84 Train Avg loss: 0.21664, Acc: 0.63962, F1: 0.63995#####> Valid Avg loss: 0.45171, Acc:0.43920, F1: 0.43920
===> Epoch: 84: Training loss decreased (0.21986 --> 0.21664), Acc: (0.64239 --> 0.63962), F1: (0.64180 --> 0.63995).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 85 Train Avg loss: 0.21559, Acc: 0.64332, F1: 0.64365#####> Valid Avg loss: 0.47382, Acc:0.43920, F1: 0.43920
===> Epoch: 85: Training loss decreased (0.21664 --> 0.21559), Acc: (0.63962 --> 0.64332), F1: (0.63995 --> 0.64365).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 86 Train Avg loss: 0.21745, Acc: 0.64055, F1: 0.64088#####> Valid Avg loss: 0.44183, Acc:0.43819, F1: 0.43819
====> Epoch: 87 Train Avg loss: 0.21618, Acc: 0.63384, F1: 0.63418#####> Valid Avg loss: 0.43521, Acc:0.43819, F1: 0.43819
====> Epoch: 88 Train Avg loss: 0.21696, Acc: 0.63361, F1: 0.63395#####> Valid Avg loss: 0.43438, Acc:0.43920, F1: 0.43920
====> Epoch: 89 Train Avg loss: 0.21873, Acc: 0.64008, F1: 0.63949#####> Valid Avg loss: 0.46760, Acc:0.43920, F1: 0.43920
====> Epoch: 90 Train Avg loss: 0.21860, Acc: 0.64378, F1: 0.64411#####> Valid Avg loss: 0.43422, Acc:0.43920, F1: 0.43920
====> Epoch: 91 Train Avg loss: 0.21706, Acc: 0.63916, F1: 0.63857#####> Valid Avg loss: 0.44306, Acc:0.43920, F1: 0.43920
====> Epoch: 92 Train Avg loss: 0.21598, Acc: 0.63685, F1: 0.63626#####> Valid Avg loss: 0.43969, Acc:0.43920, F1: 0.43920
====> Epoch: 93 Train Avg loss: 0.21681, Acc: 0.64563, F1: 0.64596#####> Valid Avg loss: 0.42839, Acc:0.43920, F1: 0.43920
====> Epoch: 94 Train Avg loss: 0.21427, Acc: 0.64563, F1: 0.64503#####> Valid Avg loss: 0.44976, Acc:0.43920, F1: 0.43920
===> Epoch: 94: Training loss decreased (0.21559 --> 0.21427), Acc: (0.64332 --> 0.64563), F1: (0.64365 --> 0.64503).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597732701.367708.pth_1
====> Epoch: 95 Train Avg loss: 0.21621, Acc: 0.64286, F1: 0.64319#####> Valid Avg loss: 0.43918, Acc:0.43920, F1: 0.43920
====> Epoch: 96 Train Avg loss: 0.21549, Acc: 0.64147, F1: 0.64180#####> Valid Avg loss: 0.45534, Acc:0.43920, F1: 0.43920
====> Epoch: 97 Train Avg loss: 0.21724, Acc: 0.63823, F1: 0.63857#####> Valid Avg loss: 0.44339, Acc:0.43920, F1: 0.43920
====> Epoch: 98 Train Avg loss: 0.21658, Acc: 0.64794, F1: 0.64827#####> Valid Avg loss: 0.42964, Acc:0.43920, F1: 0.43920
====> Epoch: 99 Train Avg loss: 0.21702, Acc: 0.64609, F1: 0.64642#####> Valid Avg loss: 0.44041, Acc:0.43920, F1: 0.43920
====> Epoch: 100 Train Avg loss: 0.27123, Acc: 0.56126, F1: 0.56166#####> Valid Avg loss: 0.43801, Acc:0.44121, F1: 0.44121
====> Epoch: 101 Train Avg loss: 0.25658, Acc: 0.58853, F1: 0.58799#####> Valid Avg loss: 0.45465, Acc:0.43819, F1: 0.43819
====> Epoch: 102 Train Avg loss: 0.26549, Acc: 0.57998, F1: 0.57945#####> Valid Avg loss: 0.40316, Acc:0.43920, F1: 0.43920
====> Epoch: 103 Train Avg loss: 0.25792, Acc: 0.58692, F1: 0.58730#####> Valid Avg loss: 0.41832, Acc:0.43518, F1: 0.43518
====> Epoch: 104 Train Avg loss: 0.26298, Acc: 0.58183, F1: 0.58129#####> Valid Avg loss: 0.46477, Acc:0.44121, F1: 0.44121
====> Epoch: 105 Train Avg loss: 0.25961, Acc: 0.59547, F1: 0.59584#####> Valid Avg loss: 0.42418, Acc:0.42915, F1: 0.42915
====> Epoch: 106 Train Avg loss: 0.25074, Acc: 0.58877, F1: 0.58915#####> Valid Avg loss: 0.47797, Acc:0.41206, F1: 0.41206
====> Epoch: 107 Train Avg loss: 0.24721, Acc: 0.59663, F1: 0.59700#####> Valid Avg loss: 0.44810, Acc:0.44020, F1: 0.44020
====> Epoch: 108 Train Avg loss: 0.26081, Acc: 0.57651, F1: 0.57598#####> Valid Avg loss: 0.43241, Acc:0.43920, F1: 0.43920
====> Epoch: 109 Train Avg loss: 0.25853, Acc: 0.58669, F1: 0.58707#####> Valid Avg loss: 0.45696, Acc:0.43819, F1: 0.43819
====> Epoch: 110 Train Avg loss: 0.25207, Acc: 0.59501, F1: 0.59538#####> Valid Avg loss: 0.43051, Acc:0.44020, F1: 0.44020
====> Epoch: 111 Train Avg loss: 0.25180, Acc: 0.59131, F1: 0.59076#####> Valid Avg loss: 0.42417, Acc:0.43920, F1: 0.43920
====> Epoch: 112 Train Avg loss: 0.24604, Acc: 0.60171, F1: 0.60208#####> Valid Avg loss: 0.45880, Acc:0.36985, F1: 0.36985
====> Epoch: 113 Train Avg loss: 0.25486, Acc: 0.59061, F1: 0.59099#####> Valid Avg loss: 0.43210, Acc:0.43719, F1: 0.43719
====> Epoch: 114 Train Avg loss: 0.25396, Acc: 0.58784, F1: 0.58730#####> Valid Avg loss: 0.42798, Acc:0.44020, F1: 0.44020
====> Epoch: 115 Train Avg loss: 0.24346, Acc: 0.60772, F1: 0.60716#####> Valid Avg loss: 0.40281, Acc:0.43216, F1: 0.43216
====> Epoch: 116 Train Avg loss: 0.24464, Acc: 0.60240, F1: 0.60277#####> Valid Avg loss: 0.42236, Acc:0.40101, F1: 0.40101
====> Epoch: 117 Train Avg loss: 0.24709, Acc: 0.59755, F1: 0.59792#####> Valid Avg loss: 0.43267, Acc:0.44121, F1: 0.44121
====> Epoch: 118 Train Avg loss: 0.24256, Acc: 0.60333, F1: 0.60370#####> Valid Avg loss: 0.42620, Acc:0.43719, F1: 0.43719
====> Epoch: 119 Train Avg loss: 0.23927, Acc: 0.61119, F1: 0.61062#####> Valid Avg loss: 0.41746, Acc:0.44020, F1: 0.44020
====> Epoch: 120 Train Avg loss: 0.24592, Acc: 0.60125, F1: 0.60162#####> Valid Avg loss: 0.45413, Acc:0.43719, F1: 0.43719
====> Epoch: 121 Train Avg loss: 0.24130, Acc: 0.61281, F1: 0.61316#####> Valid Avg loss: 0.42996, Acc:0.43719, F1: 0.43719
====> Epoch: 122 Train Avg loss: 0.24276, Acc: 0.60333, F1: 0.60370#####> Valid Avg loss: 0.43025, Acc:0.44121, F1: 0.44121
====> Epoch: 123 Train Avg loss: 0.23909, Acc: 0.60518, F1: 0.60462#####> Valid Avg loss: 0.44429, Acc:0.43819, F1: 0.43819
====> Epoch: 124 Train Avg loss: 0.24047, Acc: 0.60865, F1: 0.60901#####> Valid Avg loss: 0.43516, Acc:0.43317, F1: 0.43317
====> Epoch: 125 Train Avg loss: 0.23959, Acc: 0.60333, F1: 0.60277#####> Valid Avg loss: 0.44958, Acc:0.43618, F1: 0.43618
====> Epoch: 126 Train Avg loss: 0.23813, Acc: 0.60633, F1: 0.60577#####> Valid Avg loss: 0.48377, Acc:0.41508, F1: 0.41508
====> Epoch: 127 Train Avg loss: 0.22957, Acc: 0.61928, F1: 0.61963#####> Valid Avg loss: 0.45517, Acc:0.43719, F1: 0.43719
====> Epoch: 128 Train Avg loss: 0.23843, Acc: 0.61073, F1: 0.61109#####> Valid Avg loss: 0.46222, Acc:0.43719, F1: 0.43719
====> Epoch: 129 Train Avg loss: 0.23458, Acc: 0.61003, F1: 0.61039#####> Valid Avg loss: 0.42701, Acc:0.44020, F1: 0.44020
====> Epoch: 130 Train Avg loss: 0.23405, Acc: 0.61073, F1: 0.61016#####> Valid Avg loss: 0.42571, Acc:0.44020, F1: 0.44020
====> Epoch: 131 Train Avg loss: 0.23073, Acc: 0.61535, F1: 0.61570#####> Valid Avg loss: 0.43154, Acc:0.43518, F1: 0.43518
====> Epoch: 132 Train Avg loss: 0.23244, Acc: 0.61442, F1: 0.61478#####> Valid Avg loss: 0.45397, Acc:0.43518, F1: 0.43518
====> Epoch: 133 Train Avg loss: 0.22794, Acc: 0.61396, F1: 0.61432#####> Valid Avg loss: 0.42372, Acc:0.44121, F1: 0.44121
====> Epoch: 134 Train Avg loss: 0.24178, Acc: 0.59570, F1: 0.59607#####> Valid Avg loss: 0.46114, Acc:0.43216, F1: 0.43216
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 10train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 842
valid_dataloader len: 199
test_dataloader len: 143
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 4209, train dataloader len: 842
valid dataset len: 995, valid dataloader len: 199
valid dataset len: 713, test dataloader len: 199
====> Epoch: 1 Train Avg loss: 0.56730, Acc: 0.27798, F1: 0.27815#####> Valid Avg loss: 0.45983, Acc:0.44121, F1: 0.44121
===> Epoch: 1: Training loss decreased (inf --> 0.56730), Acc: (0.00000 --> 0.27798), F1: (0.00000 --> 0.27815).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.45983), Acc: (0.00000 --> 0.44121), F1: (0.00000 --> 0.44121).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.45983), Acc: (0.00000 --> 0.44121), F1: (0.00000 --> 0.44121).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 2 Train Avg loss: 0.43769, Acc: 0.35852, F1: 0.35855#####> Valid Avg loss: 0.38858, Acc:0.42915, F1: 0.42915
===> Epoch: 2: Training loss decreased (0.56730 --> 0.43769), Acc: (0.27798 --> 0.35852), F1: (0.27815 --> 0.35855).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1

####> Epoch: 2: validation loss decreased (0.45983 --> 0.38858), Acc: (0.44121 --> 0.42915), F1: (0.44121 --> 0.42915).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 3 Train Avg loss: 0.39438, Acc: 0.41506, F1: 0.41508#####> Valid Avg loss: 0.38649, Acc:0.26332, F1: 0.26332
===> Epoch: 3: Training loss decreased (0.43769 --> 0.39438), Acc: (0.35852 --> 0.41506), F1: (0.35855 --> 0.41508).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1

####> Epoch: 3: validation loss decreased (0.38858 --> 0.38649), Acc: (0.42915 --> 0.26332), F1: (0.42915 --> 0.26332).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 4 Train Avg loss: 0.36463, Acc: 0.44999, F1: 0.44988#####> Valid Avg loss: 0.35121, Acc:0.42010, F1: 0.42010
===> Epoch: 4: Training loss decreased (0.39438 --> 0.36463), Acc: (0.41506 --> 0.44999), F1: (0.41508 --> 0.44988).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1

####> Epoch: 4: validation loss decreased (0.38649 --> 0.35121), Acc: (0.26332 --> 0.42010), F1: (0.26332 --> 0.42010).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 5 Train Avg loss: 0.34473, Acc: 0.48064, F1: 0.48064#####> Valid Avg loss: 0.38380, Acc:0.31055, F1: 0.31055
===> Epoch: 5: Training loss decreased (0.36463 --> 0.34473), Acc: (0.44999 --> 0.48064), F1: (0.44988 --> 0.48064).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 6 Train Avg loss: 0.33012, Acc: 0.49727, F1: 0.49715#####> Valid Avg loss: 0.38629, Acc:0.27035, F1: 0.27035
===> Epoch: 6: Training loss decreased (0.34473 --> 0.33012), Acc: (0.48064 --> 0.49727), F1: (0.48064 --> 0.49715).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 7 Train Avg loss: 0.31241, Acc: 0.51010, F1: 0.51021#####> Valid Avg loss: 0.37118, Acc:0.36784, F1: 0.36784
===> Epoch: 7: Training loss decreased (0.33012 --> 0.31241), Acc: (0.49727 --> 0.51010), F1: (0.49715 --> 0.51021).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 8 Train Avg loss: 0.30415, Acc: 0.51604, F1: 0.51603#####> Valid Avg loss: 0.36202, Acc:0.41608, F1: 0.41608
===> Epoch: 8: Training loss decreased (0.31241 --> 0.30415), Acc: (0.51010 --> 0.51604), F1: (0.51021 --> 0.51603).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 9 Train Avg loss: 0.29382, Acc: 0.53005, F1: 0.52999#####> Valid Avg loss: 0.35755, Acc:0.39698, F1: 0.39698
===> Epoch: 9: Training loss decreased (0.30415 --> 0.29382), Acc: (0.51604 --> 0.53005), F1: (0.51603 --> 0.52999).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 10 Train Avg loss: 0.28749, Acc: 0.53813, F1: 0.53818#####> Valid Avg loss: 0.38596, Acc:0.34372, F1: 0.34372
===> Epoch: 10: Training loss decreased (0.29382 --> 0.28749), Acc: (0.53005 --> 0.53813), F1: (0.52999 --> 0.53818).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 11 Train Avg loss: 0.28505, Acc: 0.54692, F1: 0.54691#####> Valid Avg loss: 0.36643, Acc:0.35779, F1: 0.35779
===> Epoch: 11: Training loss decreased (0.28749 --> 0.28505), Acc: (0.53813 --> 0.54692), F1: (0.53818 --> 0.54691).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 12 Train Avg loss: 0.27825, Acc: 0.55096, F1: 0.55095#####> Valid Avg loss: 0.35073, Acc:0.38392, F1: 0.38392
===> Epoch: 12: Training loss decreased (0.28505 --> 0.27825), Acc: (0.54692 --> 0.55096), F1: (0.54691 --> 0.55095).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1

####> Epoch: 12: validation loss decreased (0.35121 --> 0.35073), Acc: (0.42010 --> 0.38392), F1: (0.42010 --> 0.38392).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 13 Train Avg loss: 0.27447, Acc: 0.55096, F1: 0.55089#####> Valid Avg loss: 0.36569, Acc:0.36985, F1: 0.36985
===> Epoch: 13: Training loss decreased (0.27825 --> 0.27447), Acc: (0.55096 --> 0.55096), F1: (0.55095 --> 0.55089).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 14 Train Avg loss: 0.26850, Acc: 0.55571, F1: 0.55570#####> Valid Avg loss: 0.38925, Acc:0.43819, F1: 0.43819
===> Epoch: 14: Training loss decreased (0.27447 --> 0.26850), Acc: (0.55096 --> 0.55571), F1: (0.55089 --> 0.55570).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 15 Train Avg loss: 0.26438, Acc: 0.55738, F1: 0.55730#####> Valid Avg loss: 0.43346, Acc:0.29849, F1: 0.29849
===> Epoch: 15: Training loss decreased (0.26850 --> 0.26438), Acc: (0.55571 --> 0.55738), F1: (0.55570 --> 0.55730).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 16 Train Avg loss: 0.26286, Acc: 0.56807, F1: 0.56805#####> Valid Avg loss: 0.36324, Acc:0.42010, F1: 0.42010
===> Epoch: 16: Training loss decreased (0.26438 --> 0.26286), Acc: (0.55738 --> 0.56807), F1: (0.55730 --> 0.56805).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 17 Train Avg loss: 0.25876, Acc: 0.57401, F1: 0.57393#####> Valid Avg loss: 0.38203, Acc:0.29548, F1: 0.29548
===> Epoch: 17: Training loss decreased (0.26286 --> 0.25876), Acc: (0.56807 --> 0.57401), F1: (0.56805 --> 0.57393).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 18 Train Avg loss: 0.25241, Acc: 0.57425, F1: 0.57429#####> Valid Avg loss: 0.38489, Acc:0.25126, F1: 0.25126
===> Epoch: 18: Training loss decreased (0.25876 --> 0.25241), Acc: (0.57401 --> 0.57425), F1: (0.57393 --> 0.57429).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 19 Train Avg loss: 0.24929, Acc: 0.58399, F1: 0.58391#####> Valid Avg loss: 0.37706, Acc:0.24523, F1: 0.24523
===> Epoch: 19: Training loss decreased (0.25241 --> 0.24929), Acc: (0.57425 --> 0.58399), F1: (0.57429 --> 0.58391).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 20 Train Avg loss: 0.25430, Acc: 0.58304, F1: 0.58302#####> Valid Avg loss: 0.37587, Acc:0.41005, F1: 0.41005
====> Epoch: 21 Train Avg loss: 0.24747, Acc: 0.58280, F1: 0.58290#####> Valid Avg loss: 0.38277, Acc:0.36583, F1: 0.36583
===> Epoch: 21: Training loss decreased (0.24929 --> 0.24747), Acc: (0.58399 --> 0.58280), F1: (0.58391 --> 0.58290).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 22 Train Avg loss: 0.24066, Acc: 0.59135, F1: 0.59139#####> Valid Avg loss: 0.37194, Acc:0.41407, F1: 0.41407
===> Epoch: 22: Training loss decreased (0.24747 --> 0.24066), Acc: (0.58280 --> 0.59135), F1: (0.58290 --> 0.59139).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 23 Train Avg loss: 0.23999, Acc: 0.59420, F1: 0.59430#####> Valid Avg loss: 0.39879, Acc:0.39095, F1: 0.39095
===> Epoch: 23: Training loss decreased (0.24066 --> 0.23999), Acc: (0.59135 --> 0.59420), F1: (0.59139 --> 0.59430).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 24 Train Avg loss: 0.23636, Acc: 0.60965, F1: 0.60968#####> Valid Avg loss: 0.36075, Acc:0.43719, F1: 0.43719
===> Epoch: 24: Training loss decreased (0.23999 --> 0.23636), Acc: (0.59420 --> 0.60965), F1: (0.59430 --> 0.60968).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 25 Train Avg loss: 0.23877, Acc: 0.60157, F1: 0.60154#####> Valid Avg loss: 0.38090, Acc:0.42915, F1: 0.42915
====> Epoch: 26 Train Avg loss: 0.23137, Acc: 0.60181, F1: 0.60178#####> Valid Avg loss: 0.35063, Acc:0.43618, F1: 0.43618
===> Epoch: 26: Training loss decreased (0.23636 --> 0.23137), Acc: (0.60965 --> 0.60181), F1: (0.60968 --> 0.60178).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1

####> Epoch: 26: validation loss decreased (0.35073 --> 0.35063), Acc: (0.38392 --> 0.43618), F1: (0.38392 --> 0.43618).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 27 Train Avg loss: 0.23406, Acc: 0.60442, F1: 0.60439#####> Valid Avg loss: 0.37049, Acc:0.41608, F1: 0.41608
====> Epoch: 28 Train Avg loss: 0.22668, Acc: 0.61131, F1: 0.61128#####> Valid Avg loss: 0.37680, Acc:0.44020, F1: 0.44020
===> Epoch: 28: Training loss decreased (0.23137 --> 0.22668), Acc: (0.60181 --> 0.61131), F1: (0.60178 --> 0.61128).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 29 Train Avg loss: 0.22280, Acc: 0.61345, F1: 0.61348#####> Valid Avg loss: 0.35835, Acc:0.39598, F1: 0.39598
===> Epoch: 29: Training loss decreased (0.22668 --> 0.22280), Acc: (0.61131 --> 0.61345), F1: (0.61128 --> 0.61348).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 30 Train Avg loss: 0.22181, Acc: 0.61891, F1: 0.61888#####> Valid Avg loss: 0.39468, Acc:0.33970, F1: 0.33970
===> Epoch: 30: Training loss decreased (0.22280 --> 0.22181), Acc: (0.61345 --> 0.61891), F1: (0.61348 --> 0.61888).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 31 Train Avg loss: 0.22349, Acc: 0.62414, F1: 0.62417#####> Valid Avg loss: 0.35385, Acc:0.41910, F1: 0.41910
====> Epoch: 32 Train Avg loss: 0.22015, Acc: 0.61392, F1: 0.61395#####> Valid Avg loss: 0.34645, Acc:0.41106, F1: 0.41106
===> Epoch: 32: Training loss decreased (0.22181 --> 0.22015), Acc: (0.61891 --> 0.61392), F1: (0.61888 --> 0.61395).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1

####> Epoch: 32: validation loss decreased (0.35063 --> 0.34645), Acc: (0.43618 --> 0.41106), F1: (0.43618 --> 0.41106).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 33 Train Avg loss: 0.21422, Acc: 0.62533, F1: 0.62536#####> Valid Avg loss: 0.36943, Acc:0.43216, F1: 0.43216
===> Epoch: 33: Training loss decreased (0.22015 --> 0.21422), Acc: (0.61392 --> 0.62533), F1: (0.61395 --> 0.62536).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 34 Train Avg loss: 0.21511, Acc: 0.63055, F1: 0.63058#####> Valid Avg loss: 0.38275, Acc:0.40302, F1: 0.40302
====> Epoch: 35 Train Avg loss: 0.21764, Acc: 0.62057, F1: 0.62061#####> Valid Avg loss: 0.40436, Acc:0.37387, F1: 0.37387
====> Epoch: 36 Train Avg loss: 0.21013, Acc: 0.62794, F1: 0.62797#####> Valid Avg loss: 0.38410, Acc:0.43518, F1: 0.43518
===> Epoch: 36: Training loss decreased (0.21422 --> 0.21013), Acc: (0.62533 --> 0.62794), F1: (0.62536 --> 0.62797).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 37 Train Avg loss: 0.20657, Acc: 0.63269, F1: 0.63266#####> Valid Avg loss: 0.35681, Acc:0.42312, F1: 0.42312
===> Epoch: 37: Training loss decreased (0.21013 --> 0.20657), Acc: (0.62794 --> 0.63269), F1: (0.62797 --> 0.63266).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 38 Train Avg loss: 0.20538, Acc: 0.64124, F1: 0.64127#####> Valid Avg loss: 0.40132, Acc:0.43116, F1: 0.43116
===> Epoch: 38: Training loss decreased (0.20657 --> 0.20538), Acc: (0.63269 --> 0.64124), F1: (0.63266 --> 0.64127).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 39 Train Avg loss: 0.20263, Acc: 0.63958, F1: 0.63955#####> Valid Avg loss: 0.37939, Acc:0.42613, F1: 0.42613
===> Epoch: 39: Training loss decreased (0.20538 --> 0.20263), Acc: (0.64124 --> 0.63958), F1: (0.64127 --> 0.63955).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 40 Train Avg loss: 0.20381, Acc: 0.63744, F1: 0.63747#####> Valid Avg loss: 0.40979, Acc:0.44020, F1: 0.44020
====> Epoch: 41 Train Avg loss: 0.19856, Acc: 0.64647, F1: 0.64650#####> Valid Avg loss: 0.39623, Acc:0.43920, F1: 0.43920
===> Epoch: 41: Training loss decreased (0.20263 --> 0.19856), Acc: (0.63958 --> 0.64647), F1: (0.63955 --> 0.64650).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 42 Train Avg loss: 0.19704, Acc: 0.63863, F1: 0.63866#####> Valid Avg loss: 0.39487, Acc:0.38794, F1: 0.38794
===> Epoch: 42: Training loss decreased (0.19856 --> 0.19704), Acc: (0.64647 --> 0.63863), F1: (0.64650 --> 0.63866).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 43 Train Avg loss: 0.19585, Acc: 0.64861, F1: 0.64857#####> Valid Avg loss: 0.37336, Acc:0.43116, F1: 0.43116
===> Epoch: 43: Training loss decreased (0.19704 --> 0.19585), Acc: (0.63863 --> 0.64861), F1: (0.63866 --> 0.64857).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 44 Train Avg loss: 0.19300, Acc: 0.65645, F1: 0.65653#####> Valid Avg loss: 0.41706, Acc:0.39598, F1: 0.39598
===> Epoch: 44: Training loss decreased (0.19585 --> 0.19300), Acc: (0.64861 --> 0.65645), F1: (0.64857 --> 0.65653).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 45 Train Avg loss: 0.19284, Acc: 0.65431, F1: 0.65439#####> Valid Avg loss: 0.38443, Acc:0.42613, F1: 0.42613
===> Epoch: 45: Training loss decreased (0.19300 --> 0.19284), Acc: (0.65645 --> 0.65431), F1: (0.65653 --> 0.65439).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 46 Train Avg loss: 0.18682, Acc: 0.66215, F1: 0.66211#####> Valid Avg loss: 0.42104, Acc:0.40503, F1: 0.40503
===> Epoch: 46: Training loss decreased (0.19284 --> 0.18682), Acc: (0.65431 --> 0.66215), F1: (0.65439 --> 0.66211).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 47 Train Avg loss: 0.18552, Acc: 0.65954, F1: 0.65956#####> Valid Avg loss: 0.45483, Acc:0.34070, F1: 0.34070
===> Epoch: 47: Training loss decreased (0.18682 --> 0.18552), Acc: (0.66215 --> 0.65954), F1: (0.66211 --> 0.65956).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 48 Train Avg loss: 0.18047, Acc: 0.67023, F1: 0.67025#####> Valid Avg loss: 0.42140, Acc:0.42412, F1: 0.42412
===> Epoch: 48: Training loss decreased (0.18552 --> 0.18047), Acc: (0.65954 --> 0.67023), F1: (0.65956 --> 0.67025).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 49 Train Avg loss: 0.18136, Acc: 0.66595, F1: 0.66603#####> Valid Avg loss: 0.39546, Acc:0.41709, F1: 0.41709
====> Epoch: 50 Train Avg loss: 0.17672, Acc: 0.67926, F1: 0.67928#####> Valid Avg loss: 0.42049, Acc:0.41005, F1: 0.41005
===> Epoch: 50: Training loss decreased (0.18047 --> 0.17672), Acc: (0.67023 --> 0.67926), F1: (0.67025 --> 0.67928).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 51 Train Avg loss: 0.17713, Acc: 0.67712, F1: 0.67708#####> Valid Avg loss: 0.39428, Acc:0.38794, F1: 0.38794
====> Epoch: 52 Train Avg loss: 0.17564, Acc: 0.68662, F1: 0.68670#####> Valid Avg loss: 0.41848, Acc:0.41005, F1: 0.41005
===> Epoch: 52: Training loss decreased (0.17672 --> 0.17564), Acc: (0.67926 --> 0.68662), F1: (0.67928 --> 0.68670).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 53 Train Avg loss: 0.16824, Acc: 0.69423, F1: 0.69424#####> Valid Avg loss: 0.45797, Acc:0.38995, F1: 0.38995
===> Epoch: 53: Training loss decreased (0.17564 --> 0.16824), Acc: (0.68662 --> 0.69423), F1: (0.68670 --> 0.69424).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 54 Train Avg loss: 0.16911, Acc: 0.68947, F1: 0.68949#####> Valid Avg loss: 0.42366, Acc:0.40000, F1: 0.40000
====> Epoch: 55 Train Avg loss: 0.15893, Acc: 0.70634, F1: 0.70635#####> Valid Avg loss: 0.44557, Acc:0.41407, F1: 0.41407
===> Epoch: 55: Training loss decreased (0.16824 --> 0.15893), Acc: (0.69423 --> 0.70634), F1: (0.69424 --> 0.70635).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 56 Train Avg loss: 0.16061, Acc: 0.70444, F1: 0.70445#####> Valid Avg loss: 0.47604, Acc:0.41206, F1: 0.41206
====> Epoch: 57 Train Avg loss: 0.15530, Acc: 0.70777, F1: 0.70772#####> Valid Avg loss: 0.42421, Acc:0.41709, F1: 0.41709
===> Epoch: 57: Training loss decreased (0.15893 --> 0.15530), Acc: (0.70634 --> 0.70777), F1: (0.70635 --> 0.70772).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 58 Train Avg loss: 0.15218, Acc: 0.71585, F1: 0.71586#####> Valid Avg loss: 0.48693, Acc:0.40704, F1: 0.40704
===> Epoch: 58: Training loss decreased (0.15530 --> 0.15218), Acc: (0.70777 --> 0.71585), F1: (0.70772 --> 0.71586).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 59 Train Avg loss: 0.15129, Acc: 0.71680, F1: 0.71681#####> Valid Avg loss: 0.44607, Acc:0.40101, F1: 0.40101
===> Epoch: 59: Training loss decreased (0.15218 --> 0.15129), Acc: (0.71585 --> 0.71680), F1: (0.71586 --> 0.71681).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 60 Train Avg loss: 0.14723, Acc: 0.72131, F1: 0.72132#####> Valid Avg loss: 0.46966, Acc:0.41005, F1: 0.41005
===> Epoch: 60: Training loss decreased (0.15129 --> 0.14723), Acc: (0.71680 --> 0.72131), F1: (0.71681 --> 0.72132).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 61 Train Avg loss: 0.14084, Acc: 0.73675, F1: 0.73682#####> Valid Avg loss: 0.48517, Acc:0.37889, F1: 0.37889
===> Epoch: 61: Training loss decreased (0.14723 --> 0.14084), Acc: (0.72131 --> 0.73675), F1: (0.72132 --> 0.73682).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 62 Train Avg loss: 0.14049, Acc: 0.73628, F1: 0.73634#####> Valid Avg loss: 0.45029, Acc:0.41106, F1: 0.41106
===> Epoch: 62: Training loss decreased (0.14084 --> 0.14049), Acc: (0.73675 --> 0.73628), F1: (0.73682 --> 0.73634).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 63 Train Avg loss: 0.13553, Acc: 0.75267, F1: 0.75261#####> Valid Avg loss: 0.48024, Acc:0.37990, F1: 0.37990
===> Epoch: 63: Training loss decreased (0.14049 --> 0.13553), Acc: (0.73628 --> 0.75267), F1: (0.73634 --> 0.75261).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 64 Train Avg loss: 0.13447, Acc: 0.74982, F1: 0.74982#####> Valid Avg loss: 0.51059, Acc:0.41709, F1: 0.41709
===> Epoch: 64: Training loss decreased (0.13553 --> 0.13447), Acc: (0.75267 --> 0.74982), F1: (0.75261 --> 0.74982).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 65 Train Avg loss: 0.13327, Acc: 0.75362, F1: 0.75362#####> Valid Avg loss: 0.50700, Acc:0.42312, F1: 0.42312
===> Epoch: 65: Training loss decreased (0.13447 --> 0.13327), Acc: (0.74982 --> 0.75362), F1: (0.74982 --> 0.75362).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 66 Train Avg loss: 0.12839, Acc: 0.75552, F1: 0.75546#####> Valid Avg loss: 0.52335, Acc:0.41508, F1: 0.41508
===> Epoch: 66: Training loss decreased (0.13327 --> 0.12839), Acc: (0.75362 --> 0.75552), F1: (0.75362 --> 0.75546).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 67 Train Avg loss: 0.12398, Acc: 0.76455, F1: 0.76455#####> Valid Avg loss: 0.50389, Acc:0.40302, F1: 0.40302
===> Epoch: 67: Training loss decreased (0.12839 --> 0.12398), Acc: (0.75552 --> 0.76455), F1: (0.75546 --> 0.76455).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 68 Train Avg loss: 0.12332, Acc: 0.76883, F1: 0.76876#####> Valid Avg loss: 0.55644, Acc:0.39397, F1: 0.39397
===> Epoch: 68: Training loss decreased (0.12398 --> 0.12332), Acc: (0.76455 --> 0.76883), F1: (0.76455 --> 0.76876).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 69 Train Avg loss: 0.11739, Acc: 0.78356, F1: 0.78361#####> Valid Avg loss: 0.54729, Acc:0.40603, F1: 0.40603
===> Epoch: 69: Training loss decreased (0.12332 --> 0.11739), Acc: (0.76883 --> 0.78356), F1: (0.76876 --> 0.78361).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 70 Train Avg loss: 0.11328, Acc: 0.78308, F1: 0.78314#####> Valid Avg loss: 0.52705, Acc:0.39899, F1: 0.39899
===> Epoch: 70: Training loss decreased (0.11739 --> 0.11328), Acc: (0.78356 --> 0.78308), F1: (0.78361 --> 0.78314).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 71 Train Avg loss: 0.11129, Acc: 0.79021, F1: 0.79026#####> Valid Avg loss: 0.57356, Acc:0.39598, F1: 0.39598
===> Epoch: 71: Training loss decreased (0.11328 --> 0.11129), Acc: (0.78308 --> 0.79021), F1: (0.78314 --> 0.79026).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 72 Train Avg loss: 0.10862, Acc: 0.79187, F1: 0.79181#####> Valid Avg loss: 0.58851, Acc:0.40201, F1: 0.40201
===> Epoch: 72: Training loss decreased (0.11129 --> 0.10862), Acc: (0.79021 --> 0.79187), F1: (0.79026 --> 0.79181).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 73 Train Avg loss: 0.10486, Acc: 0.80067, F1: 0.80059#####> Valid Avg loss: 0.57916, Acc:0.38593, F1: 0.38593
===> Epoch: 73: Training loss decreased (0.10862 --> 0.10486), Acc: (0.79187 --> 0.80067), F1: (0.79181 --> 0.80059).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 74 Train Avg loss: 0.10263, Acc: 0.80660, F1: 0.80659#####> Valid Avg loss: 0.59123, Acc:0.38693, F1: 0.38693
===> Epoch: 74: Training loss decreased (0.10486 --> 0.10263), Acc: (0.80067 --> 0.80660), F1: (0.80059 --> 0.80659).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 75 Train Avg loss: 0.09812, Acc: 0.81136, F1: 0.81134#####> Valid Avg loss: 0.58678, Acc:0.38894, F1: 0.38894
===> Epoch: 75: Training loss decreased (0.10263 --> 0.09812), Acc: (0.80660 --> 0.81136), F1: (0.80659 --> 0.81134).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 76 Train Avg loss: 0.09795, Acc: 0.81207, F1: 0.81211#####> Valid Avg loss: 0.59976, Acc:0.40905, F1: 0.40905
===> Epoch: 76: Training loss decreased (0.09812 --> 0.09795), Acc: (0.81136 --> 0.81207), F1: (0.81134 --> 0.81211).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 77 Train Avg loss: 0.09610, Acc: 0.80827, F1: 0.80825#####> Valid Avg loss: 0.58467, Acc:0.38894, F1: 0.38894
===> Epoch: 77: Training loss decreased (0.09795 --> 0.09610), Acc: (0.81207 --> 0.80827), F1: (0.81211 --> 0.80825).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 78 Train Avg loss: 0.09301, Acc: 0.81920, F1: 0.81924#####> Valid Avg loss: 0.62170, Acc:0.36181, F1: 0.36181
===> Epoch: 78: Training loss decreased (0.09610 --> 0.09301), Acc: (0.80827 --> 0.81920), F1: (0.80825 --> 0.81924).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 79 Train Avg loss: 0.09131, Acc: 0.82347, F1: 0.82346#####> Valid Avg loss: 0.65374, Acc:0.39899, F1: 0.39899
===> Epoch: 79: Training loss decreased (0.09301 --> 0.09131), Acc: (0.81920 --> 0.82347), F1: (0.81924 --> 0.82346).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 80 Train Avg loss: 0.08768, Acc: 0.83773, F1: 0.83777#####> Valid Avg loss: 0.61247, Acc:0.39095, F1: 0.39095
===> Epoch: 80: Training loss decreased (0.09131 --> 0.08768), Acc: (0.82347 --> 0.83773), F1: (0.82346 --> 0.83777).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 81 Train Avg loss: 0.08830, Acc: 0.82894, F1: 0.82886#####> Valid Avg loss: 0.66360, Acc:0.38392, F1: 0.38392
====> Epoch: 82 Train Avg loss: 0.08411, Acc: 0.84058, F1: 0.84056#####> Valid Avg loss: 0.65836, Acc:0.38492, F1: 0.38492
===> Epoch: 82: Training loss decreased (0.08768 --> 0.08411), Acc: (0.83773 --> 0.84058), F1: (0.83777 --> 0.84056).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 83 Train Avg loss: 0.08353, Acc: 0.84010, F1: 0.84002#####> Valid Avg loss: 0.65445, Acc:0.38492, F1: 0.38492
===> Epoch: 83: Training loss decreased (0.08411 --> 0.08353), Acc: (0.84058 --> 0.84010), F1: (0.84056 --> 0.84002).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 84 Train Avg loss: 0.08120, Acc: 0.84581, F1: 0.84584#####> Valid Avg loss: 0.72379, Acc:0.38291, F1: 0.38291
===> Epoch: 84: Training loss decreased (0.08353 --> 0.08120), Acc: (0.84010 --> 0.84581), F1: (0.84002 --> 0.84584).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 85 Train Avg loss: 0.08151, Acc: 0.84343, F1: 0.84341#####> Valid Avg loss: 0.65116, Acc:0.37186, F1: 0.37186
====> Epoch: 86 Train Avg loss: 0.07843, Acc: 0.84177, F1: 0.84181#####> Valid Avg loss: 0.61704, Acc:0.38593, F1: 0.38593
===> Epoch: 86: Training loss decreased (0.08120 --> 0.07843), Acc: (0.84581 --> 0.84177), F1: (0.84584 --> 0.84181).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 87 Train Avg loss: 0.07946, Acc: 0.85270, F1: 0.85273#####> Valid Avg loss: 0.65609, Acc:0.38492, F1: 0.38492
====> Epoch: 88 Train Avg loss: 0.07623, Acc: 0.85175, F1: 0.85178#####> Valid Avg loss: 0.70887, Acc:0.38894, F1: 0.38894
===> Epoch: 88: Training loss decreased (0.07843 --> 0.07623), Acc: (0.84177 --> 0.85175), F1: (0.84181 --> 0.85178).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 89 Train Avg loss: 0.07681, Acc: 0.84319, F1: 0.84323#####> Valid Avg loss: 0.68230, Acc:0.37990, F1: 0.37990
====> Epoch: 90 Train Avg loss: 0.07586, Acc: 0.85864, F1: 0.85867#####> Valid Avg loss: 0.70561, Acc:0.38291, F1: 0.38291
===> Epoch: 90: Training loss decreased (0.07623 --> 0.07586), Acc: (0.85175 --> 0.85864), F1: (0.85178 --> 0.85867).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 91 Train Avg loss: 0.07426, Acc: 0.85674, F1: 0.85677#####> Valid Avg loss: 0.70026, Acc:0.38593, F1: 0.38593
===> Epoch: 91: Training loss decreased (0.07586 --> 0.07426), Acc: (0.85864 --> 0.85674), F1: (0.85867 --> 0.85677).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 92 Train Avg loss: 0.07326, Acc: 0.85317, F1: 0.85309#####> Valid Avg loss: 0.67298, Acc:0.38090, F1: 0.38090
===> Epoch: 92: Training loss decreased (0.07426 --> 0.07326), Acc: (0.85674 --> 0.85317), F1: (0.85677 --> 0.85309).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 93 Train Avg loss: 0.07123, Acc: 0.86101, F1: 0.86093#####> Valid Avg loss: 0.70872, Acc:0.38191, F1: 0.38191
===> Epoch: 93: Training loss decreased (0.07326 --> 0.07123), Acc: (0.85317 --> 0.86101), F1: (0.85309 --> 0.86093).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 94 Train Avg loss: 0.07348, Acc: 0.85887, F1: 0.85891#####> Valid Avg loss: 0.75290, Acc:0.38492, F1: 0.38492
====> Epoch: 95 Train Avg loss: 0.07335, Acc: 0.86006, F1: 0.86010#####> Valid Avg loss: 0.71915, Acc:0.38894, F1: 0.38894
====> Epoch: 96 Train Avg loss: 0.07460, Acc: 0.85626, F1: 0.85624#####> Valid Avg loss: 0.73555, Acc:0.38392, F1: 0.38392
====> Epoch: 97 Train Avg loss: 0.07273, Acc: 0.86553, F1: 0.86556#####> Valid Avg loss: 0.68951, Acc:0.38492, F1: 0.38492
====> Epoch: 98 Train Avg loss: 0.07155, Acc: 0.86481, F1: 0.86479#####> Valid Avg loss: 0.73715, Acc:0.38593, F1: 0.38593
====> Epoch: 99 Train Avg loss: 0.07215, Acc: 0.86101, F1: 0.86099#####> Valid Avg loss: 0.71825, Acc:0.38191, F1: 0.38191
====> Epoch: 100 Train Avg loss: 0.22039, Acc: 0.63222, F1: 0.63230#####> Valid Avg loss: 0.45159, Acc:0.42010, F1: 0.42010
====> Epoch: 101 Train Avg loss: 0.18660, Acc: 0.65788, F1: 0.65784#####> Valid Avg loss: 0.46680, Acc:0.40000, F1: 0.40000
====> Epoch: 102 Train Avg loss: 0.18971, Acc: 0.66358, F1: 0.66366#####> Valid Avg loss: 0.52420, Acc:0.43819, F1: 0.43819
====> Epoch: 103 Train Avg loss: 0.19183, Acc: 0.66405, F1: 0.66413#####> Valid Avg loss: 0.49183, Acc:0.37085, F1: 0.37085
====> Epoch: 104 Train Avg loss: 0.18649, Acc: 0.66857, F1: 0.66859#####> Valid Avg loss: 0.44895, Acc:0.37085, F1: 0.37085
====> Epoch: 105 Train Avg loss: 0.18259, Acc: 0.66738, F1: 0.66740#####> Valid Avg loss: 0.43034, Acc:0.40804, F1: 0.40804
====> Epoch: 106 Train Avg loss: 0.18177, Acc: 0.67665, F1: 0.67660#####> Valid Avg loss: 0.43767, Acc:0.39196, F1: 0.39196
====> Epoch: 107 Train Avg loss: 0.17429, Acc: 0.67712, F1: 0.67708#####> Valid Avg loss: 0.44056, Acc:0.37387, F1: 0.37387
====> Epoch: 108 Train Avg loss: 0.18472, Acc: 0.66928, F1: 0.66924#####> Valid Avg loss: 0.41035, Acc:0.39497, F1: 0.39497
====> Epoch: 109 Train Avg loss: 0.18307, Acc: 0.67308, F1: 0.67310#####> Valid Avg loss: 0.44346, Acc:0.43116, F1: 0.43116
====> Epoch: 110 Train Avg loss: 0.18125, Acc: 0.67379, F1: 0.67375#####> Valid Avg loss: 0.41956, Acc:0.40201, F1: 0.40201
====> Epoch: 111 Train Avg loss: 0.17807, Acc: 0.67736, F1: 0.67732#####> Valid Avg loss: 0.41662, Acc:0.41608, F1: 0.41608
====> Epoch: 112 Train Avg loss: 0.16672, Acc: 0.68496, F1: 0.68486#####> Valid Avg loss: 0.49671, Acc:0.41307, F1: 0.41307
====> Epoch: 113 Train Avg loss: 0.16989, Acc: 0.68734, F1: 0.68723#####> Valid Avg loss: 0.48819, Acc:0.41005, F1: 0.41005
====> Epoch: 114 Train Avg loss: 0.17071, Acc: 0.67950, F1: 0.67951#####> Valid Avg loss: 0.46108, Acc:0.40201, F1: 0.40201
====> Epoch: 115 Train Avg loss: 0.17462, Acc: 0.68425, F1: 0.68414#####> Valid Avg loss: 0.43573, Acc:0.36884, F1: 0.36884
====> Epoch: 116 Train Avg loss: 0.16896, Acc: 0.69233, F1: 0.69228#####> Valid Avg loss: 0.46724, Acc:0.37889, F1: 0.37889
====> Epoch: 117 Train Avg loss: 0.16056, Acc: 0.69827, F1: 0.69828#####> Valid Avg loss: 0.41776, Acc:0.37889, F1: 0.37889
====> Epoch: 118 Train Avg loss: 0.16209, Acc: 0.70468, F1: 0.70457#####> Valid Avg loss: 0.45428, Acc:0.36683, F1: 0.36683
====> Epoch: 119 Train Avg loss: 0.15661, Acc: 0.71252, F1: 0.71253#####> Valid Avg loss: 0.53929, Acc:0.32764, F1: 0.32764
====> Epoch: 120 Train Avg loss: 0.15988, Acc: 0.70444, F1: 0.70445#####> Valid Avg loss: 0.48818, Acc:0.37588, F1: 0.37588
====> Epoch: 121 Train Avg loss: 0.15499, Acc: 0.71846, F1: 0.71841#####> Valid Avg loss: 0.44522, Acc:0.37688, F1: 0.37688
====> Epoch: 122 Train Avg loss: 0.15996, Acc: 0.70587, F1: 0.70588#####> Valid Avg loss: 0.49610, Acc:0.39497, F1: 0.39497
====> Epoch: 123 Train Avg loss: 0.14823, Acc: 0.71703, F1: 0.71698#####> Valid Avg loss: 0.51442, Acc:0.42010, F1: 0.42010
====> Epoch: 124 Train Avg loss: 0.15929, Acc: 0.70753, F1: 0.70754#####> Valid Avg loss: 0.44937, Acc:0.35075, F1: 0.35075
====> Epoch: 125 Train Avg loss: 0.14606, Acc: 0.73153, F1: 0.73153#####> Valid Avg loss: 0.52783, Acc:0.41608, F1: 0.41608
====> Epoch: 126 Train Avg loss: 0.16043, Acc: 0.70658, F1: 0.70665#####> Valid Avg loss: 0.43907, Acc:0.41005, F1: 0.41005
====> Epoch: 127 Train Avg loss: 0.14036, Acc: 0.74293, F1: 0.74299#####> Valid Avg loss: 0.48137, Acc:0.39899, F1: 0.39899
====> Epoch: 128 Train Avg loss: 0.13802, Acc: 0.74555, F1: 0.74555#####> Valid Avg loss: 0.51737, Acc:0.39095, F1: 0.39095
====> Epoch: 129 Train Avg loss: 0.14989, Acc: 0.72321, F1: 0.72316#####> Valid Avg loss: 0.52851, Acc:0.35678, F1: 0.35678
====> Epoch: 130 Train Avg loss: 0.14311, Acc: 0.74317, F1: 0.74317#####> Valid Avg loss: 0.55992, Acc:0.39899, F1: 0.39899
====> Epoch: 131 Train Avg loss: 0.13142, Acc: 0.75410, F1: 0.75410#####> Valid Avg loss: 0.52923, Acc:0.41407, F1: 0.41407
====> Epoch: 132 Train Avg loss: 0.14165, Acc: 0.73818, F1: 0.73818#####> Valid Avg loss: 0.57898, Acc:0.34874, F1: 0.34874
====> Epoch: 133 Train Avg loss: 0.12978, Acc: 0.75505, F1: 0.75505#####> Valid Avg loss: 0.52313, Acc:0.41910, F1: 0.41910
====> Epoch: 134 Train Avg loss: 0.13112, Acc: 0.75624, F1: 0.75624#####> Valid Avg loss: 0.46226, Acc:0.40704, F1: 0.40704
====> Epoch: 135 Train Avg loss: 0.14485, Acc: 0.74079, F1: 0.74080#####> Valid Avg loss: 0.63043, Acc:0.35176, F1: 0.35176
====> Epoch: 136 Train Avg loss: 0.12868, Acc: 0.75766, F1: 0.75772#####> Valid Avg loss: 0.57749, Acc:0.32663, F1: 0.32663
====> Epoch: 137 Train Avg loss: 0.12675, Acc: 0.75766, F1: 0.75760#####> Valid Avg loss: 0.55016, Acc:0.39397, F1: 0.39397
====> Epoch: 138 Train Avg loss: 0.12747, Acc: 0.76954, F1: 0.76960#####> Valid Avg loss: 0.51110, Acc:0.38291, F1: 0.38291
====> Epoch: 139 Train Avg loss: 0.12990, Acc: 0.75647, F1: 0.75647#####> Valid Avg loss: 0.57516, Acc:0.36583, F1: 0.36583
====> Epoch: 140 Train Avg loss: 0.12047, Acc: 0.78213, F1: 0.78213#####> Valid Avg loss: 0.56943, Acc:0.34472, F1: 0.34472
====> Epoch: 141 Train Avg loss: 0.12310, Acc: 0.77596, F1: 0.77595#####> Valid Avg loss: 0.55155, Acc:0.40201, F1: 0.40201
====> Epoch: 142 Train Avg loss: 0.11725, Acc: 0.78023, F1: 0.78017#####> Valid Avg loss: 0.57992, Acc:0.36583, F1: 0.36583
====> Epoch: 143 Train Avg loss: 0.12041, Acc: 0.77619, F1: 0.77625#####> Valid Avg loss: 0.56237, Acc:0.37487, F1: 0.37487
====> Epoch: 144 Train Avg loss: 0.12013, Acc: 0.77904, F1: 0.77910#####> Valid Avg loss: 0.52935, Acc:0.37688, F1: 0.37688
====> Epoch: 145 Train Avg loss: 0.11480, Acc: 0.78689, F1: 0.78688#####> Valid Avg loss: 0.57565, Acc:0.38090, F1: 0.38090
====> Epoch: 146 Train Avg loss: 0.11158, Acc: 0.79449, F1: 0.79442#####> Valid Avg loss: 0.65100, Acc:0.35779, F1: 0.35779
====> Epoch: 147 Train Avg loss: 0.11230, Acc: 0.78807, F1: 0.78806#####> Valid Avg loss: 0.65070, Acc:0.35578, F1: 0.35578
====> Epoch: 148 Train Avg loss: 0.10599, Acc: 0.80114, F1: 0.80119#####> Valid Avg loss: 0.58024, Acc:0.38995, F1: 0.38995
====> Epoch: 149 Train Avg loss: 0.10108, Acc: 0.80328, F1: 0.80333#####> Valid Avg loss: 0.55435, Acc:0.37990, F1: 0.37990
====> Epoch: 150 Train Avg loss: 0.11052, Acc: 0.79449, F1: 0.79454#####> Valid Avg loss: 0.54062, Acc:0.37688, F1: 0.37688
====> Epoch: 151 Train Avg loss: 0.10064, Acc: 0.81041, F1: 0.81033#####> Valid Avg loss: 0.62465, Acc:0.36784, F1: 0.36784
====> Epoch: 152 Train Avg loss: 0.10733, Acc: 0.80447, F1: 0.80451#####> Valid Avg loss: 0.58054, Acc:0.38995, F1: 0.38995
====> Epoch: 153 Train Avg loss: 0.09483, Acc: 0.82157, F1: 0.82150#####> Valid Avg loss: 0.58488, Acc:0.36884, F1: 0.36884
====> Epoch: 154 Train Avg loss: 0.09447, Acc: 0.82918, F1: 0.82916#####> Valid Avg loss: 0.58768, Acc:0.35276, F1: 0.35276
====> Epoch: 155 Train Avg loss: 0.09696, Acc: 0.81967, F1: 0.81966#####> Valid Avg loss: 0.67316, Acc:0.36884, F1: 0.36884
====> Epoch: 156 Train Avg loss: 0.08993, Acc: 0.83535, F1: 0.83539#####> Valid Avg loss: 0.63845, Acc:0.38191, F1: 0.38191
====> Epoch: 157 Train Avg loss: 0.09617, Acc: 0.82514, F1: 0.82506#####> Valid Avg loss: 0.58561, Acc:0.37085, F1: 0.37085
====> Epoch: 158 Train Avg loss: 0.08437, Acc: 0.84533, F1: 0.84537#####> Valid Avg loss: 0.82436, Acc:0.36482, F1: 0.36482
====> Epoch: 159 Train Avg loss: 0.08790, Acc: 0.83702, F1: 0.83700#####> Valid Avg loss: 0.59209, Acc:0.31457, F1: 0.31457
====> Epoch: 160 Train Avg loss: 0.08562, Acc: 0.84961, F1: 0.84958#####> Valid Avg loss: 0.64418, Acc:0.33869, F1: 0.33869
====> Epoch: 161 Train Avg loss: 0.07615, Acc: 0.86339, F1: 0.86342#####> Valid Avg loss: 0.71400, Acc:0.37387, F1: 0.37387
====> Epoch: 162 Train Avg loss: 0.08816, Acc: 0.84272, F1: 0.84270#####> Valid Avg loss: 0.70732, Acc:0.36784, F1: 0.36784
====> Epoch: 163 Train Avg loss: 0.07632, Acc: 0.85626, F1: 0.85624#####> Valid Avg loss: 0.78105, Acc:0.34472, F1: 0.34472
====> Epoch: 164 Train Avg loss: 0.07484, Acc: 0.85555, F1: 0.85558#####> Valid Avg loss: 0.73949, Acc:0.36080, F1: 0.36080
====> Epoch: 165 Train Avg loss: 0.07946, Acc: 0.86172, F1: 0.86176#####> Valid Avg loss: 0.71837, Acc:0.38090, F1: 0.38090
====> Epoch: 166 Train Avg loss: 0.07544, Acc: 0.86410, F1: 0.86413#####> Valid Avg loss: 0.76163, Acc:0.39698, F1: 0.39698
====> Epoch: 167 Train Avg loss: 0.07267, Acc: 0.86458, F1: 0.86461#####> Valid Avg loss: 0.71444, Acc:0.35276, F1: 0.35276
====> Epoch: 168 Train Avg loss: 0.06746, Acc: 0.87954, F1: 0.87957#####> Valid Avg loss: 0.84350, Acc:0.41407, F1: 0.41407
===> Epoch: 168: Training loss decreased (0.07123 --> 0.06746), Acc: (0.86101 --> 0.87954), F1: (0.86093 --> 0.87957).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 169 Train Avg loss: 0.07439, Acc: 0.87455, F1: 0.87458#####> Valid Avg loss: 0.79725, Acc:0.37990, F1: 0.37990
====> Epoch: 170 Train Avg loss: 0.06814, Acc: 0.87527, F1: 0.87524#####> Valid Avg loss: 0.78815, Acc:0.36482, F1: 0.36482
====> Epoch: 171 Train Avg loss: 0.06088, Acc: 0.88667, F1: 0.88670#####> Valid Avg loss: 0.84579, Acc:0.37286, F1: 0.37286
===> Epoch: 171: Training loss decreased (0.06746 --> 0.06088), Acc: (0.87954 --> 0.88667), F1: (0.87957 --> 0.88670).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 172 Train Avg loss: 0.06725, Acc: 0.87693, F1: 0.87696#####> Valid Avg loss: 0.71541, Acc:0.29950, F1: 0.29950
====> Epoch: 173 Train Avg loss: 0.06985, Acc: 0.87669, F1: 0.87660#####> Valid Avg loss: 0.79221, Acc:0.37588, F1: 0.37588
====> Epoch: 174 Train Avg loss: 0.06320, Acc: 0.88477, F1: 0.88480#####> Valid Avg loss: 0.88486, Acc:0.39196, F1: 0.39196
====> Epoch: 175 Train Avg loss: 0.05699, Acc: 0.89475, F1: 0.89471#####> Valid Avg loss: 0.76535, Acc:0.32060, F1: 0.32060
===> Epoch: 175: Training loss decreased (0.06088 --> 0.05699), Acc: (0.88667 --> 0.89475), F1: (0.88670 --> 0.89471).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 176 Train Avg loss: 0.05826, Acc: 0.89617, F1: 0.89620#####> Valid Avg loss: 0.85341, Acc:0.36784, F1: 0.36784
====> Epoch: 177 Train Avg loss: 0.05450, Acc: 0.89950, F1: 0.89952#####> Valid Avg loss: 0.74207, Acc:0.35276, F1: 0.35276
===> Epoch: 177: Training loss decreased (0.05699 --> 0.05450), Acc: (0.89475 --> 0.89950), F1: (0.89471 --> 0.89952).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 178 Train Avg loss: 0.05972, Acc: 0.89024, F1: 0.89026#####> Valid Avg loss: 0.78726, Acc:0.38090, F1: 0.38090
====> Epoch: 179 Train Avg loss: 0.05415, Acc: 0.90259, F1: 0.90261#####> Valid Avg loss: 0.75777, Acc:0.32864, F1: 0.32864
===> Epoch: 179: Training loss decreased (0.05450 --> 0.05415), Acc: (0.89950 --> 0.90259), F1: (0.89952 --> 0.90261).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 180 Train Avg loss: 0.05066, Acc: 0.90615, F1: 0.90618#####> Valid Avg loss: 0.78332, Acc:0.34573, F1: 0.34573
===> Epoch: 180: Training loss decreased (0.05415 --> 0.05066), Acc: (0.90259 --> 0.90615), F1: (0.90261 --> 0.90618).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 181 Train Avg loss: 0.05907, Acc: 0.89903, F1: 0.89899#####> Valid Avg loss: 0.72211, Acc:0.33266, F1: 0.33266
====> Epoch: 182 Train Avg loss: 0.05419, Acc: 0.90093, F1: 0.90083#####> Valid Avg loss: 0.83544, Acc:0.35980, F1: 0.35980
====> Epoch: 183 Train Avg loss: 0.05216, Acc: 0.90497, F1: 0.90499#####> Valid Avg loss: 0.74084, Acc:0.30251, F1: 0.30251
====> Epoch: 184 Train Avg loss: 0.04818, Acc: 0.91043, F1: 0.91045#####> Valid Avg loss: 0.78453, Acc:0.35377, F1: 0.35377
===> Epoch: 184: Training loss decreased (0.05066 --> 0.04818), Acc: (0.90615 --> 0.91043), F1: (0.90618 --> 0.91045).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 185 Train Avg loss: 0.04979, Acc: 0.91589, F1: 0.91591#####> Valid Avg loss: 0.86650, Acc:0.36784, F1: 0.36784
====> Epoch: 186 Train Avg loss: 0.04459, Acc: 0.92088, F1: 0.92090#####> Valid Avg loss: 0.78889, Acc:0.37186, F1: 0.37186
===> Epoch: 186: Training loss decreased (0.04818 --> 0.04459), Acc: (0.91043 --> 0.92088), F1: (0.91045 --> 0.92090).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 187 Train Avg loss: 0.04278, Acc: 0.92373, F1: 0.92375#####> Valid Avg loss: 0.78271, Acc:0.34673, F1: 0.34673
===> Epoch: 187: Training loss decreased (0.04459 --> 0.04278), Acc: (0.92088 --> 0.92373), F1: (0.92090 --> 0.92375).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 188 Train Avg loss: 0.04867, Acc: 0.91209, F1: 0.91211#####> Valid Avg loss: 0.84305, Acc:0.35879, F1: 0.35879
====> Epoch: 189 Train Avg loss: 0.04126, Acc: 0.92706, F1: 0.92708#####> Valid Avg loss: 0.83899, Acc:0.35276, F1: 0.35276
===> Epoch: 189: Training loss decreased (0.04278 --> 0.04126), Acc: (0.92373 --> 0.92706), F1: (0.92375 --> 0.92708).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 190 Train Avg loss: 0.04179, Acc: 0.92564, F1: 0.92565#####> Valid Avg loss: 0.83005, Acc:0.36281, F1: 0.36281
====> Epoch: 191 Train Avg loss: 0.04329, Acc: 0.92682, F1: 0.92684#####> Valid Avg loss: 0.88387, Acc:0.37085, F1: 0.37085
====> Epoch: 192 Train Avg loss: 0.04951, Acc: 0.91780, F1: 0.91781#####> Valid Avg loss: 0.80949, Acc:0.37688, F1: 0.37688
====> Epoch: 193 Train Avg loss: 0.03959, Acc: 0.93158, F1: 0.93159#####> Valid Avg loss: 0.91891, Acc:0.36884, F1: 0.36884
===> Epoch: 193: Training loss decreased (0.04126 --> 0.03959), Acc: (0.92706 --> 0.93158), F1: (0.92708 --> 0.93159).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 194 Train Avg loss: 0.03185, Acc: 0.94654, F1: 0.94656#####> Valid Avg loss: 1.01993, Acc:0.35879, F1: 0.35879
===> Epoch: 194: Training loss decreased (0.03959 --> 0.03185), Acc: (0.93158 --> 0.94654), F1: (0.93159 --> 0.94656).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 195 Train Avg loss: 0.03661, Acc: 0.93443, F1: 0.93438#####> Valid Avg loss: 0.86851, Acc:0.32764, F1: 0.32764
====> Epoch: 196 Train Avg loss: 0.03679, Acc: 0.93276, F1: 0.93272#####> Valid Avg loss: 0.86898, Acc:0.34171, F1: 0.34171
====> Epoch: 197 Train Avg loss: 0.03647, Acc: 0.93823, F1: 0.93824#####> Valid Avg loss: 0.96692, Acc:0.35879, F1: 0.35879
====> Epoch: 198 Train Avg loss: 0.03866, Acc: 0.93870, F1: 0.93872#####> Valid Avg loss: 1.01712, Acc:0.36382, F1: 0.36382
====> Epoch: 199 Train Avg loss: 0.02976, Acc: 0.94607, F1: 0.94608#####> Valid Avg loss: 0.92586, Acc:0.36080, F1: 0.36080
===> Epoch: 199: Training loss decreased (0.03185 --> 0.02976), Acc: (0.94654 --> 0.94607), F1: (0.94656 --> 0.94608).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 200 Train Avg loss: 0.02882, Acc: 0.94868, F1: 0.94869#####> Valid Avg loss: 0.91212, Acc:0.38894, F1: 0.38894
===> Epoch: 200: Training loss decreased (0.02976 --> 0.02882), Acc: (0.94607 --> 0.94868), F1: (0.94608 --> 0.94869).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 201 Train Avg loss: 0.04001, Acc: 0.93276, F1: 0.93278#####> Valid Avg loss: 0.94113, Acc:0.34070, F1: 0.34070
====> Epoch: 202 Train Avg loss: 0.02846, Acc: 0.94868, F1: 0.94869#####> Valid Avg loss: 1.03143, Acc:0.38593, F1: 0.38593
===> Epoch: 202: Training loss decreased (0.02882 --> 0.02846), Acc: (0.94868 --> 0.94868), F1: (0.94869 --> 0.94869).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 203 Train Avg loss: 0.03380, Acc: 0.94108, F1: 0.94109#####> Valid Avg loss: 1.00316, Acc:0.38191, F1: 0.38191
====> Epoch: 204 Train Avg loss: 0.02848, Acc: 0.94844, F1: 0.94846#####> Valid Avg loss: 0.94457, Acc:0.37387, F1: 0.37387
====> Epoch: 205 Train Avg loss: 0.03081, Acc: 0.94559, F1: 0.94561#####> Valid Avg loss: 0.88993, Acc:0.34472, F1: 0.34472
====> Epoch: 206 Train Avg loss: 0.02706, Acc: 0.95201, F1: 0.95202#####> Valid Avg loss: 0.99933, Acc:0.37387, F1: 0.37387
===> Epoch: 206: Training loss decreased (0.02846 --> 0.02706), Acc: (0.94868 --> 0.95201), F1: (0.94869 --> 0.95202).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 207 Train Avg loss: 0.03575, Acc: 0.93942, F1: 0.93937#####> Valid Avg loss: 0.97499, Acc:0.35678, F1: 0.35678
====> Epoch: 208 Train Avg loss: 0.02556, Acc: 0.95628, F1: 0.95629#####> Valid Avg loss: 1.05507, Acc:0.36382, F1: 0.36382
===> Epoch: 208: Training loss decreased (0.02706 --> 0.02556), Acc: (0.95201 --> 0.95628), F1: (0.95202 --> 0.95629).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 209 Train Avg loss: 0.02317, Acc: 0.95914, F1: 0.95914#####> Valid Avg loss: 0.88927, Acc:0.36884, F1: 0.36884
===> Epoch: 209: Training loss decreased (0.02556 --> 0.02317), Acc: (0.95628 --> 0.95914), F1: (0.95629 --> 0.95914).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 210 Train Avg loss: 0.02839, Acc: 0.95082, F1: 0.95083#####> Valid Avg loss: 0.96893, Acc:0.36784, F1: 0.36784
====> Epoch: 211 Train Avg loss: 0.02103, Acc: 0.96460, F1: 0.96461#####> Valid Avg loss: 1.02710, Acc:0.38894, F1: 0.38894
===> Epoch: 211: Training loss decreased (0.02317 --> 0.02103), Acc: (0.95914 --> 0.96460), F1: (0.95914 --> 0.96461).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 212 Train Avg loss: 0.02619, Acc: 0.95415, F1: 0.95410#####> Valid Avg loss: 1.13721, Acc:0.35879, F1: 0.35879
====> Epoch: 213 Train Avg loss: 0.01970, Acc: 0.96721, F1: 0.96722#####> Valid Avg loss: 1.10063, Acc:0.39296, F1: 0.39296
===> Epoch: 213: Training loss decreased (0.02103 --> 0.01970), Acc: (0.96460 --> 0.96721), F1: (0.96461 --> 0.96722).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 214 Train Avg loss: 0.02438, Acc: 0.95700, F1: 0.95695#####> Valid Avg loss: 1.06994, Acc:0.36482, F1: 0.36482
====> Epoch: 215 Train Avg loss: 0.02224, Acc: 0.95937, F1: 0.95938#####> Valid Avg loss: 1.05381, Acc:0.38392, F1: 0.38392
====> Epoch: 216 Train Avg loss: 0.02092, Acc: 0.96460, F1: 0.96461#####> Valid Avg loss: 1.13881, Acc:0.38392, F1: 0.38392
====> Epoch: 217 Train Avg loss: 0.02327, Acc: 0.95771, F1: 0.95766#####> Valid Avg loss: 0.91057, Acc:0.32663, F1: 0.32663
====> Epoch: 218 Train Avg loss: 0.02104, Acc: 0.95795, F1: 0.95796#####> Valid Avg loss: 1.09741, Acc:0.38090, F1: 0.38090
====> Epoch: 219 Train Avg loss: 0.01851, Acc: 0.96603, F1: 0.96603#####> Valid Avg loss: 1.15625, Acc:0.37588, F1: 0.37588
===> Epoch: 219: Training loss decreased (0.01970 --> 0.01851), Acc: (0.96721 --> 0.96603), F1: (0.96722 --> 0.96603).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 220 Train Avg loss: 0.01755, Acc: 0.96721, F1: 0.96722#####> Valid Avg loss: 1.21389, Acc:0.39196, F1: 0.39196
===> Epoch: 220: Training loss decreased (0.01851 --> 0.01755), Acc: (0.96603 --> 0.96721), F1: (0.96603 --> 0.96722).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 221 Train Avg loss: 0.02163, Acc: 0.96270, F1: 0.96271#####> Valid Avg loss: 1.22923, Acc:0.39296, F1: 0.39296
====> Epoch: 222 Train Avg loss: 0.01964, Acc: 0.96484, F1: 0.96485#####> Valid Avg loss: 1.07174, Acc:0.38593, F1: 0.38593
====> Epoch: 223 Train Avg loss: 0.01906, Acc: 0.96674, F1: 0.96675#####> Valid Avg loss: 1.07963, Acc:0.37889, F1: 0.37889
====> Epoch: 224 Train Avg loss: 0.01838, Acc: 0.96698, F1: 0.96692#####> Valid Avg loss: 1.04203, Acc:0.38894, F1: 0.38894
====> Epoch: 225 Train Avg loss: 0.02094, Acc: 0.95937, F1: 0.95938#####> Valid Avg loss: 1.04234, Acc:0.35578, F1: 0.35578
====> Epoch: 226 Train Avg loss: 0.01203, Acc: 0.97672, F1: 0.97672#####> Valid Avg loss: 1.08742, Acc:0.37588, F1: 0.37588
===> Epoch: 226: Training loss decreased (0.01755 --> 0.01203), Acc: (0.96721 --> 0.97672), F1: (0.96722 --> 0.97672).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 227 Train Avg loss: 0.01962, Acc: 0.96531, F1: 0.96532#####> Valid Avg loss: 1.07589, Acc:0.38593, F1: 0.38593
====> Epoch: 228 Train Avg loss: 0.01645, Acc: 0.96745, F1: 0.96746#####> Valid Avg loss: 1.04719, Acc:0.37889, F1: 0.37889
====> Epoch: 229 Train Avg loss: 0.01404, Acc: 0.97101, F1: 0.97102#####> Valid Avg loss: 1.21878, Acc:0.37889, F1: 0.37889
====> Epoch: 230 Train Avg loss: 0.01376, Acc: 0.97244, F1: 0.97245#####> Valid Avg loss: 1.15059, Acc:0.36382, F1: 0.36382
====> Epoch: 231 Train Avg loss: 0.01499, Acc: 0.97173, F1: 0.97173#####> Valid Avg loss: 1.03723, Acc:0.36482, F1: 0.36482
====> Epoch: 232 Train Avg loss: 0.01342, Acc: 0.97244, F1: 0.97245#####> Valid Avg loss: 1.16881, Acc:0.38090, F1: 0.38090
====> Epoch: 233 Train Avg loss: 0.01264, Acc: 0.97553, F1: 0.97553#####> Valid Avg loss: 1.01268, Acc:0.37588, F1: 0.37588
====> Epoch: 234 Train Avg loss: 0.01598, Acc: 0.97125, F1: 0.97120#####> Valid Avg loss: 1.12888, Acc:0.37588, F1: 0.37588
====> Epoch: 235 Train Avg loss: 0.01212, Acc: 0.97648, F1: 0.97648#####> Valid Avg loss: 1.04636, Acc:0.38090, F1: 0.38090
====> Epoch: 236 Train Avg loss: 0.01504, Acc: 0.97173, F1: 0.97173#####> Valid Avg loss: 1.09207, Acc:0.36382, F1: 0.36382
====> Epoch: 237 Train Avg loss: 0.01355, Acc: 0.97292, F1: 0.97292#####> Valid Avg loss: 1.12885, Acc:0.38392, F1: 0.38392
====> Epoch: 238 Train Avg loss: 0.01214, Acc: 0.97363, F1: 0.97363#####> Valid Avg loss: 1.05855, Acc:0.35879, F1: 0.35879
====> Epoch: 239 Train Avg loss: 0.01196, Acc: 0.97624, F1: 0.97619#####> Valid Avg loss: 1.15904, Acc:0.38995, F1: 0.38995
===> Epoch: 239: Training loss decreased (0.01203 --> 0.01196), Acc: (0.97672 --> 0.97624), F1: (0.97672 --> 0.97619).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 240 Train Avg loss: 0.01383, Acc: 0.97292, F1: 0.97292#####> Valid Avg loss: 0.99689, Acc:0.34975, F1: 0.34975
====> Epoch: 241 Train Avg loss: 0.01164, Acc: 0.97790, F1: 0.97791#####> Valid Avg loss: 1.20255, Acc:0.37789, F1: 0.37789
===> Epoch: 241: Training loss decreased (0.01196 --> 0.01164), Acc: (0.97624 --> 0.97790), F1: (0.97619 --> 0.97791).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 242 Train Avg loss: 0.01105, Acc: 0.97790, F1: 0.97791#####> Valid Avg loss: 1.10921, Acc:0.38593, F1: 0.38593
===> Epoch: 242: Training loss decreased (0.01164 --> 0.01105), Acc: (0.97790 --> 0.97790), F1: (0.97791 --> 0.97791).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 243 Train Avg loss: 0.01145, Acc: 0.97648, F1: 0.97648#####> Valid Avg loss: 1.20313, Acc:0.36181, F1: 0.36181
====> Epoch: 244 Train Avg loss: 0.00990, Acc: 0.98076, F1: 0.98076#####> Valid Avg loss: 1.14622, Acc:0.36985, F1: 0.36985
===> Epoch: 244: Training loss decreased (0.01105 --> 0.00990), Acc: (0.97790 --> 0.98076), F1: (0.97791 --> 0.98076).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 245 Train Avg loss: 0.01301, Acc: 0.97363, F1: 0.97363#####> Valid Avg loss: 1.15548, Acc:0.38492, F1: 0.38492
====> Epoch: 246 Train Avg loss: 0.01083, Acc: 0.97719, F1: 0.97720#####> Valid Avg loss: 1.04934, Acc:0.32764, F1: 0.32764
====> Epoch: 247 Train Avg loss: 0.01246, Acc: 0.97505, F1: 0.97506#####> Valid Avg loss: 1.10937, Acc:0.35377, F1: 0.35377
====> Epoch: 248 Train Avg loss: 0.00993, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.13107, Acc:0.37487, F1: 0.37487
====> Epoch: 249 Train Avg loss: 0.00947, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.24909, Acc:0.37387, F1: 0.37387
===> Epoch: 249: Training loss decreased (0.00990 --> 0.00947), Acc: (0.98076 --> 0.97862), F1: (0.98076 --> 0.97862).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 250 Train Avg loss: 0.00968, Acc: 0.98099, F1: 0.98100#####> Valid Avg loss: 1.18693, Acc:0.38191, F1: 0.38191
====> Epoch: 251 Train Avg loss: 0.01005, Acc: 0.97553, F1: 0.97553#####> Valid Avg loss: 1.17313, Acc:0.36583, F1: 0.36583
====> Epoch: 252 Train Avg loss: 0.00949, Acc: 0.97981, F1: 0.97981#####> Valid Avg loss: 1.09087, Acc:0.38492, F1: 0.38492
====> Epoch: 253 Train Avg loss: 0.00883, Acc: 0.98052, F1: 0.98052#####> Valid Avg loss: 1.15497, Acc:0.37990, F1: 0.37990
===> Epoch: 253: Training loss decreased (0.00947 --> 0.00883), Acc: (0.97862 --> 0.98052), F1: (0.97862 --> 0.98052).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 254 Train Avg loss: 0.01075, Acc: 0.97862, F1: 0.97862#####> Valid Avg loss: 1.17897, Acc:0.37789, F1: 0.37789
====> Epoch: 255 Train Avg loss: 0.00852, Acc: 0.98171, F1: 0.98171#####> Valid Avg loss: 1.18433, Acc:0.37789, F1: 0.37789
===> Epoch: 255: Training loss decreased (0.00883 --> 0.00852), Acc: (0.98052 --> 0.98171), F1: (0.98052 --> 0.98171).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 256 Train Avg loss: 0.00901, Acc: 0.98052, F1: 0.98052#####> Valid Avg loss: 1.13382, Acc:0.37186, F1: 0.37186
====> Epoch: 257 Train Avg loss: 0.00900, Acc: 0.98099, F1: 0.98100#####> Valid Avg loss: 1.06063, Acc:0.37186, F1: 0.37186
====> Epoch: 258 Train Avg loss: 0.00860, Acc: 0.98313, F1: 0.98314#####> Valid Avg loss: 1.18902, Acc:0.38593, F1: 0.38593
====> Epoch: 259 Train Avg loss: 0.00819, Acc: 0.98171, F1: 0.98171#####> Valid Avg loss: 1.09797, Acc:0.37286, F1: 0.37286
===> Epoch: 259: Training loss decreased (0.00852 --> 0.00819), Acc: (0.98171 --> 0.98171), F1: (0.98171 --> 0.98171).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 260 Train Avg loss: 0.00809, Acc: 0.98123, F1: 0.98124#####> Valid Avg loss: 1.14407, Acc:0.37286, F1: 0.37286
===> Epoch: 260: Training loss decreased (0.00819 --> 0.00809), Acc: (0.98171 --> 0.98123), F1: (0.98171 --> 0.98124).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 261 Train Avg loss: 0.00796, Acc: 0.98266, F1: 0.98266#####> Valid Avg loss: 1.20967, Acc:0.37688, F1: 0.37688
===> Epoch: 261: Training loss decreased (0.00809 --> 0.00796), Acc: (0.98123 --> 0.98266), F1: (0.98124 --> 0.98266).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 262 Train Avg loss: 0.00880, Acc: 0.98004, F1: 0.98005#####> Valid Avg loss: 1.10160, Acc:0.37487, F1: 0.37487
====> Epoch: 263 Train Avg loss: 0.00754, Acc: 0.98218, F1: 0.98219#####> Valid Avg loss: 1.08903, Acc:0.36985, F1: 0.36985
===> Epoch: 263: Training loss decreased (0.00796 --> 0.00754), Acc: (0.98266 --> 0.98218), F1: (0.98266 --> 0.98219).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 264 Train Avg loss: 0.00719, Acc: 0.98361, F1: 0.98361#####> Valid Avg loss: 1.21751, Acc:0.39698, F1: 0.39698
===> Epoch: 264: Training loss decreased (0.00754 --> 0.00719), Acc: (0.98218 --> 0.98361), F1: (0.98219 --> 0.98361).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 265 Train Avg loss: 0.00742, Acc: 0.98242, F1: 0.98242#####> Valid Avg loss: 1.21566, Acc:0.37990, F1: 0.37990
====> Epoch: 266 Train Avg loss: 0.00745, Acc: 0.98289, F1: 0.98290#####> Valid Avg loss: 1.19680, Acc:0.38593, F1: 0.38593
====> Epoch: 267 Train Avg loss: 0.00791, Acc: 0.98242, F1: 0.98242#####> Valid Avg loss: 1.13992, Acc:0.38291, F1: 0.38291
====> Epoch: 268 Train Avg loss: 0.00696, Acc: 0.98361, F1: 0.98361#####> Valid Avg loss: 1.20798, Acc:0.38693, F1: 0.38693
===> Epoch: 268: Training loss decreased (0.00719 --> 0.00696), Acc: (0.98361 --> 0.98361), F1: (0.98361 --> 0.98361).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 269 Train Avg loss: 0.00757, Acc: 0.98194, F1: 0.98195#####> Valid Avg loss: 1.27194, Acc:0.39598, F1: 0.39598
====> Epoch: 270 Train Avg loss: 0.00829, Acc: 0.98147, F1: 0.98147#####> Valid Avg loss: 1.26355, Acc:0.37487, F1: 0.37487
====> Epoch: 271 Train Avg loss: 0.00714, Acc: 0.98266, F1: 0.98266#####> Valid Avg loss: 1.26705, Acc:0.38492, F1: 0.38492
====> Epoch: 272 Train Avg loss: 0.00714, Acc: 0.98289, F1: 0.98284#####> Valid Avg loss: 1.21853, Acc:0.37286, F1: 0.37286
====> Epoch: 273 Train Avg loss: 0.00697, Acc: 0.98194, F1: 0.98195#####> Valid Avg loss: 1.19022, Acc:0.38090, F1: 0.38090
====> Epoch: 274 Train Avg loss: 0.00675, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.26262, Acc:0.39196, F1: 0.39196
===> Epoch: 274: Training loss decreased (0.00696 --> 0.00675), Acc: (0.98361 --> 0.98456), F1: (0.98361 --> 0.98456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 275 Train Avg loss: 0.00663, Acc: 0.98527, F1: 0.98527#####> Valid Avg loss: 1.23543, Acc:0.38392, F1: 0.38392
===> Epoch: 275: Training loss decreased (0.00675 --> 0.00663), Acc: (0.98456 --> 0.98527), F1: (0.98456 --> 0.98527).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 276 Train Avg loss: 0.00702, Acc: 0.98361, F1: 0.98361#####> Valid Avg loss: 1.19516, Acc:0.38090, F1: 0.38090
====> Epoch: 277 Train Avg loss: 0.00650, Acc: 0.98337, F1: 0.98337#####> Valid Avg loss: 1.18756, Acc:0.38995, F1: 0.38995
===> Epoch: 277: Training loss decreased (0.00663 --> 0.00650), Acc: (0.98527 --> 0.98337), F1: (0.98527 --> 0.98337).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 278 Train Avg loss: 0.00798, Acc: 0.98052, F1: 0.98052#####> Valid Avg loss: 1.14281, Acc:0.38191, F1: 0.38191
====> Epoch: 279 Train Avg loss: 0.00692, Acc: 0.98527, F1: 0.98527#####> Valid Avg loss: 1.23092, Acc:0.38995, F1: 0.38995
====> Epoch: 280 Train Avg loss: 0.00641, Acc: 0.98384, F1: 0.98385#####> Valid Avg loss: 1.19692, Acc:0.39296, F1: 0.39296
===> Epoch: 280: Training loss decreased (0.00650 --> 0.00641), Acc: (0.98337 --> 0.98384), F1: (0.98337 --> 0.98385).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 281 Train Avg loss: 0.00666, Acc: 0.98313, F1: 0.98314#####> Valid Avg loss: 1.19657, Acc:0.38693, F1: 0.38693
====> Epoch: 282 Train Avg loss: 0.00686, Acc: 0.98361, F1: 0.98361#####> Valid Avg loss: 1.20207, Acc:0.38894, F1: 0.38894
====> Epoch: 283 Train Avg loss: 0.00696, Acc: 0.98266, F1: 0.98266#####> Valid Avg loss: 1.14321, Acc:0.38693, F1: 0.38693
====> Epoch: 284 Train Avg loss: 0.00654, Acc: 0.98408, F1: 0.98409#####> Valid Avg loss: 1.21587, Acc:0.38492, F1: 0.38492
====> Epoch: 285 Train Avg loss: 0.00716, Acc: 0.98123, F1: 0.98124#####> Valid Avg loss: 1.22006, Acc:0.38894, F1: 0.38894
====> Epoch: 286 Train Avg loss: 0.00620, Acc: 0.98456, F1: 0.98456#####> Valid Avg loss: 1.11741, Acc:0.38392, F1: 0.38392
===> Epoch: 286: Training loss decreased (0.00641 --> 0.00620), Acc: (0.98384 --> 0.98456), F1: (0.98385 --> 0.98456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 287 Train Avg loss: 0.00715, Acc: 0.98194, F1: 0.98195#####> Valid Avg loss: 1.19632, Acc:0.39296, F1: 0.39296
====> Epoch: 288 Train Avg loss: 0.00566, Acc: 0.98693, F1: 0.98694#####> Valid Avg loss: 1.22987, Acc:0.38794, F1: 0.38794
===> Epoch: 288: Training loss decreased (0.00620 --> 0.00566), Acc: (0.98456 --> 0.98693), F1: (0.98456 --> 0.98694).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597778929.066258.pth_1
====> Epoch: 289 Train Avg loss: 0.00662, Acc: 0.98788, F1: 0.98789#####> Valid Avg loss: 1.18395, Acc:0.39296, F1: 0.39296
====> Epoch: 290 Train Avg loss: 0.00653, Acc: 0.98361, F1: 0.98361#####> Valid Avg loss: 1.18238, Acc:0.38392, F1: 0.38392
====> Epoch: 291 Train Avg loss: 0.00593, Acc: 0.98622, F1: 0.98622#####> Valid Avg loss: 1.23008, Acc:0.38995, F1: 0.38995
====> Epoch: 292 Train Avg loss: 0.00682, Acc: 0.98194, F1: 0.98195#####> Valid Avg loss: 1.19050, Acc:0.39196, F1: 0.39196
====> Epoch: 293 Train Avg loss: 0.00628, Acc: 0.98551, F1: 0.98551#####> Valid Avg loss: 1.30436, Acc:0.39196, F1: 0.39196
====> Epoch: 294 Train Avg loss: 0.00575, Acc: 0.98717, F1: 0.98717#####> Valid Avg loss: 1.21431, Acc:0.39196, F1: 0.39196
====> Epoch: 295 Train Avg loss: 0.00653, Acc: 0.98147, F1: 0.98147#####> Valid Avg loss: 1.21095, Acc:0.39397, F1: 0.39397
====> Epoch: 296 Train Avg loss: 0.00668, Acc: 0.98242, F1: 0.98242#####> Valid Avg loss: 1.23048, Acc:0.39095, F1: 0.39095
====> Epoch: 297 Train Avg loss: 0.00589, Acc: 0.98574, F1: 0.98575#####> Valid Avg loss: 1.19942, Acc:0.39497, F1: 0.39497
====> Epoch: 298 Train Avg loss: 0.00613, Acc: 0.98527, F1: 0.98527#####> Valid Avg loss: 1.23552, Acc:0.39296, F1: 0.39296
====> Epoch: 299 Train Avg loss: 0.00658, Acc: 0.98242, F1: 0.98242#####> Valid Avg loss: 1.17913, Acc:0.38693, F1: 0.38693
====> Epoch: 300 Train Avg loss: 0.35195, Acc: 0.50273, F1: 0.50279#####> Valid Avg loss: 0.40463, Acc:0.42513, F1: 0.42513
====> Epoch: 301 Train Avg loss: 0.26963, Acc: 0.55856, F1: 0.55855#####> Valid Avg loss: 0.44493, Acc:0.42613, F1: 0.42613
====> Epoch: 302 Train Avg loss: 0.24779, Acc: 0.60086, F1: 0.60077#####> Valid Avg loss: 0.41625, Acc:0.41709, F1: 0.41709
====> Epoch: 303 Train Avg loss: 0.18232, Acc: 0.68449, F1: 0.68444#####> Valid Avg loss: 0.49284, Acc:0.39296, F1: 0.39296
====> Epoch: 304 Train Avg loss: 0.14814, Acc: 0.73699, F1: 0.73705#####> Valid Avg loss: 0.53042, Acc:0.34573, F1: 0.34573
====> Epoch: 305 Train Avg loss: 0.12741, Acc: 0.78593, F1: 0.78599#####> Valid Avg loss: 0.55594, Acc:0.39296, F1: 0.39296
====> Epoch: 306 Train Avg loss: 0.10991, Acc: 0.80946, F1: 0.80944#####> Valid Avg loss: 0.48809, Acc:0.33065, F1: 0.33065
====> Epoch: 307 Train Avg loss: 0.09652, Acc: 0.83416, F1: 0.83409#####> Valid Avg loss: 0.60201, Acc:0.38593, F1: 0.38593
====> Epoch: 308 Train Avg loss: 0.09783, Acc: 0.83725, F1: 0.83717#####> Valid Avg loss: 0.49193, Acc:0.28141, F1: 0.28141
====> Epoch: 309 Train Avg loss: 0.08791, Acc: 0.85222, F1: 0.85220#####> Valid Avg loss: 0.63234, Acc:0.33769, F1: 0.33769
====> Epoch: 310 Train Avg loss: 0.09926, Acc: 0.82751, F1: 0.82749#####> Valid Avg loss: 0.51683, Acc:0.32764, F1: 0.32764
====> Epoch: 311 Train Avg loss: 0.08745, Acc: 0.85816, F1: 0.85808#####> Valid Avg loss: 0.60147, Acc:0.35678, F1: 0.35678
====> Epoch: 312 Train Avg loss: 0.09518, Acc: 0.84224, F1: 0.84222#####> Valid Avg loss: 0.61116, Acc:0.36382, F1: 0.36382
====> Epoch: 313 Train Avg loss: 0.09289, Acc: 0.84509, F1: 0.84507#####> Valid Avg loss: 0.59816, Acc:0.37789, F1: 0.37789
====> Epoch: 314 Train Avg loss: 0.07577, Acc: 0.86909, F1: 0.86906#####> Valid Avg loss: 0.64663, Acc:0.31960, F1: 0.31960
====> Epoch: 315 Train Avg loss: 0.08604, Acc: 0.85246, F1: 0.85249#####> Valid Avg loss: 0.56914, Acc:0.31859, F1: 0.31859
====> Epoch: 316 Train Avg loss: 0.08727, Acc: 0.84343, F1: 0.84341#####> Valid Avg loss: 0.65580, Acc:0.32161, F1: 0.32161
====> Epoch: 317 Train Avg loss: 0.09010, Acc: 0.85103, F1: 0.85095#####> Valid Avg loss: 0.59547, Acc:0.33266, F1: 0.33266
====> Epoch: 318 Train Avg loss: 0.07705, Acc: 0.87859, F1: 0.87862#####> Valid Avg loss: 0.54447, Acc:0.32462, F1: 0.32462
====> Epoch: 319 Train Avg loss: 0.07811, Acc: 0.86505, F1: 0.86508#####> Valid Avg loss: 0.63833, Acc:0.35477, F1: 0.35477
====> Epoch: 320 Train Avg loss: 0.06977, Acc: 0.88810, F1: 0.88812#####> Valid Avg loss: 0.69787, Acc:0.37085, F1: 0.37085
====> Epoch: 321 Train Avg loss: 0.09637, Acc: 0.84391, F1: 0.84394#####> Valid Avg loss: 0.59942, Acc:0.37889, F1: 0.37889
====> Epoch: 322 Train Avg loss: 0.06339, Acc: 0.89665, F1: 0.89667#####> Valid Avg loss: 0.67196, Acc:0.30854, F1: 0.30854
====> Epoch: 323 Train Avg loss: 0.07042, Acc: 0.87598, F1: 0.87601#####> Valid Avg loss: 0.61762, Acc:0.34472, F1: 0.34472
====> Epoch: 324 Train Avg loss: 0.07570, Acc: 0.87194, F1: 0.87197#####> Valid Avg loss: 0.63101, Acc:0.37387, F1: 0.37387
====> Epoch: 325 Train Avg loss: 0.07357, Acc: 0.87455, F1: 0.87452#####> Valid Avg loss: 0.64594, Acc:0.35980, F1: 0.35980
====> Epoch: 326 Train Avg loss: 0.07044, Acc: 0.87907, F1: 0.87898#####> Valid Avg loss: 0.61107, Acc:0.35879, F1: 0.35879
====> Epoch: 327 Train Avg loss: 0.05645, Acc: 0.89950, F1: 0.89947#####> Valid Avg loss: 0.65966, Acc:0.37186, F1: 0.37186
====> Epoch: 328 Train Avg loss: 0.06611, Acc: 0.89190, F1: 0.89192#####> Valid Avg loss: 0.71005, Acc:0.33869, F1: 0.33869
====> Epoch: 329 Train Avg loss: 0.06525, Acc: 0.88810, F1: 0.88812#####> Valid Avg loss: 0.73762, Acc:0.36080, F1: 0.36080
====> Epoch: 330 Train Avg loss: 0.06590, Acc: 0.89071, F1: 0.89068#####> Valid Avg loss: 0.69437, Acc:0.34874, F1: 0.34874
====> Epoch: 331 Train Avg loss: 0.05568, Acc: 0.90235, F1: 0.90232#####> Valid Avg loss: 0.77253, Acc:0.36181, F1: 0.36181
====> Epoch: 332 Train Avg loss: 0.06937, Acc: 0.88620, F1: 0.88622#####> Valid Avg loss: 0.62823, Acc:0.34171, F1: 0.34171
====> Epoch: 333 Train Avg loss: 0.06173, Acc: 0.89427, F1: 0.89430#####> Valid Avg loss: 0.80450, Acc:0.37085, F1: 0.37085
====> Epoch: 334 Train Avg loss: 0.07189, Acc: 0.88263, F1: 0.88248#####> Valid Avg loss: 0.78949, Acc:0.38191, F1: 0.38191
====> Epoch: 335 Train Avg loss: 0.06067, Acc: 0.89808, F1: 0.89798#####> Valid Avg loss: 0.83451, Acc:0.38593, F1: 0.38593
====> Epoch: 336 Train Avg loss: 0.07623, Acc: 0.88216, F1: 0.88219#####> Valid Avg loss: 0.66949, Acc:0.38191, F1: 0.38191
====> Epoch: 337 Train Avg loss: 0.06441, Acc: 0.89475, F1: 0.89477#####> Valid Avg loss: 0.64969, Acc:0.38291, F1: 0.38291
====> Epoch: 338 Train Avg loss: 0.04988, Acc: 0.91566, F1: 0.91562#####> Valid Avg loss: 0.76219, Acc:0.33769, F1: 0.33769
====> Epoch: 339 Train Avg loss: 0.06684, Acc: 0.89926, F1: 0.89911#####> Valid Avg loss: 0.66319, Acc:0.28241, F1: 0.28241
====> Epoch: 340 Train Avg loss: 0.06530, Acc: 0.89332, F1: 0.89329#####> Valid Avg loss: 0.64756, Acc:0.36683, F1: 0.36683
====> Epoch: 341 Train Avg loss: 0.05317, Acc: 0.91257, F1: 0.91259#####> Valid Avg loss: 0.67632, Acc:0.30151, F1: 0.30151
====> Epoch: 342 Train Avg loss: 0.06261, Acc: 0.89570, F1: 0.89572#####> Valid Avg loss: 0.79249, Acc:0.36181, F1: 0.36181
====> Epoch: 343 Train Avg loss: 0.05099, Acc: 0.90948, F1: 0.90950#####> Valid Avg loss: 0.67691, Acc:0.30955, F1: 0.30955
====> Epoch: 344 Train Avg loss: 0.06884, Acc: 0.88952, F1: 0.88949#####> Valid Avg loss: 0.69097, Acc:0.33367, F1: 0.33367
====> Epoch: 345 Train Avg loss: 0.05563, Acc: 0.91043, F1: 0.91045#####> Valid Avg loss: 0.77330, Acc:0.36181, F1: 0.36181
====> Epoch: 346 Train Avg loss: 0.05499, Acc: 0.90900, F1: 0.90891#####> Valid Avg loss: 0.68965, Acc:0.36281, F1: 0.36281
====> Epoch: 347 Train Avg loss: 0.06732, Acc: 0.88620, F1: 0.88622#####> Valid Avg loss: 0.77964, Acc:0.37286, F1: 0.37286
====> Epoch: 348 Train Avg loss: 0.05244, Acc: 0.90995, F1: 0.90998#####> Valid Avg loss: 0.72235, Acc:0.37588, F1: 0.37588
====> Epoch: 349 Train Avg loss: 0.05892, Acc: 0.90592, F1: 0.90594#####> Valid Avg loss: 0.72691, Acc:0.38593, F1: 0.38593
====> Epoch: 350 Train Avg loss: 0.05282, Acc: 0.90900, F1: 0.90903#####> Valid Avg loss: 0.74224, Acc:0.36382, F1: 0.36382
====> Epoch: 351 Train Avg loss: 0.04750, Acc: 0.91827, F1: 0.91829#####> Valid Avg loss: 0.79785, Acc:0.37387, F1: 0.37387
====> Epoch: 352 Train Avg loss: 0.06354, Acc: 0.89903, F1: 0.89905#####> Valid Avg loss: 0.71444, Acc:0.34874, F1: 0.34874
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597948392.936254.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:5
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.5, upper_layer_dropout: 0.5
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 12train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 851
valid_dataloader len: 199
test_dataloader len: 142
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 4254, train dataloader len: 851
valid dataset len: 993, valid dataloader len: 199
valid dataset len: 709, test dataloader len: 199
====> Epoch: 1 Train Avg loss: 0.50278, Acc: 0.30654, F1: 0.30646#####> Valid Avg loss: 0.43369, Acc:0.44209, F1: 0.44188
===> Epoch: 1: Training loss decreased (inf --> 0.50278), Acc: (0.00000 --> 0.30654), F1: (0.00000 --> 0.30646).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.43369), Acc: (0.00000 --> 0.44209), F1: (0.00000 --> 0.44188).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.43369), Acc: (0.00000 --> 0.44209), F1: (0.00000 --> 0.44188).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
====> Epoch: 2 Train Avg loss: 0.38680, Acc: 0.41208, F1: 0.41210#####> Valid Avg loss: 0.43553, Acc:0.42800, F1: 0.42781
===> Epoch: 2: Training loss decreased (0.50278 --> 0.38680), Acc: (0.30654 --> 0.41208), F1: (0.30646 --> 0.41210).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
====> Epoch: 3 Train Avg loss: 0.33584, Acc: 0.48543, F1: 0.48537#####> Valid Avg loss: 0.43572, Acc:0.41692, F1: 0.41675
===> Epoch: 3: Training loss decreased (0.38680 --> 0.33584), Acc: (0.41208 --> 0.48543), F1: (0.41210 --> 0.48537).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
====> Epoch: 4 Train Avg loss: 0.31327, Acc: 0.51457, F1: 0.51457#####> Valid Avg loss: 0.42901, Acc:0.42800, F1: 0.42781
===> Epoch: 4: Training loss decreased (0.33584 --> 0.31327), Acc: (0.48543 --> 0.51457), F1: (0.48537 --> 0.51457).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1

####> Epoch: 4: validation loss decreased (0.43369 --> 0.42901), Acc: (0.44209 --> 0.42800), F1: (0.44188 --> 0.42781).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
====> Epoch: 5 Train Avg loss: 0.29265, Acc: 0.53432, F1: 0.53443#####> Valid Avg loss: 0.43445, Acc:0.41088, F1: 0.41072
===> Epoch: 5: Training loss decreased (0.31327 --> 0.29265), Acc: (0.51457 --> 0.53432), F1: (0.51457 --> 0.53443).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
====> Epoch: 6 Train Avg loss: 0.28452, Acc: 0.54325, F1: 0.54324#####> Valid Avg loss: 0.44228, Acc:0.40282, F1: 0.40268
===> Epoch: 6: Training loss decreased (0.29265 --> 0.28452), Acc: (0.53432 --> 0.54325), F1: (0.53443 --> 0.54324).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
====> Epoch: 7 Train Avg loss: 0.27312, Acc: 0.55783, F1: 0.55776#####> Valid Avg loss: 0.41523, Acc:0.43303, F1: 0.43283
===> Epoch: 7: Training loss decreased (0.28452 --> 0.27312), Acc: (0.54325 --> 0.55783), F1: (0.54324 --> 0.55776).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1

####> Epoch: 7: validation loss decreased (0.42901 --> 0.41523), Acc: (0.42800 --> 0.43303), F1: (0.42781 --> 0.43283).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
====> Epoch: 8 Train Avg loss: 0.26682, Acc: 0.56888, F1: 0.56892#####> Valid Avg loss: 0.40998, Acc:0.43807, F1: 0.43786
===> Epoch: 8: Training loss decreased (0.27312 --> 0.26682), Acc: (0.55783 --> 0.56888), F1: (0.55776 --> 0.56892).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1

####> Epoch: 8: validation loss decreased (0.41523 --> 0.40998), Acc: (0.43303 --> 0.43807), F1: (0.43283 --> 0.43786).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
====> Epoch: 9 Train Avg loss: 0.26327, Acc: 0.57170, F1: 0.57168#####> Valid Avg loss: 0.43151, Acc:0.39980, F1: 0.39966
===> Epoch: 9: Training loss decreased (0.26682 --> 0.26327), Acc: (0.56888 --> 0.57170), F1: (0.56892 --> 0.57168).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
====> Epoch: 10 Train Avg loss: 0.25852, Acc: 0.57287, F1: 0.57291#####> Valid Avg loss: 0.43705, Acc:0.41692, F1: 0.41675
===> Epoch: 10: Training loss decreased (0.26327 --> 0.25852), Acc: (0.57170 --> 0.57287), F1: (0.57168 --> 0.57291).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597948511.90873.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.7, upper_layer_dropout: 0.35
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597952359.89066.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 12train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1418
valid_dataloader len: 331
test_dataloader len: 237
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 4254, train dataloader len: 1418
valid dataset len: 993, valid dataloader len: 331
valid dataset len: 709, test dataloader len: 331
====> Epoch: 1 Train Avg loss: 0.99008, Acc: 0.34368, F1: 0.34368#####> Valid Avg loss: 0.85255, Acc:0.43605, F1: 0.43605
===> Epoch: 1: Training loss decreased (inf --> 0.99008), Acc: (0.00000 --> 0.34368), F1: (0.00000 --> 0.34368).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597952359.89066.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.85255), Acc: (0.00000 --> 0.43605), F1: (0.00000 --> 0.43605).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597952359.89066.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.85255), Acc: (0.00000 --> 0.43605), F1: (0.00000 --> 0.43605).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597952359.89066.pth_1
====> Epoch: 2 Train Avg loss: 0.91583, Acc: 0.41796, F1: 0.41796#####> Valid Avg loss: 0.86650, Acc:0.43605, F1: 0.43605
===> Epoch: 2: Training loss decreased (0.99008 --> 0.91583), Acc: (0.34368 --> 0.41796), F1: (0.34368 --> 0.41796).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597952359.89066.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.7, upper_layer_dropout: 0.35
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597956250.641078.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 5train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 395
valid_dataloader len: 37
test_dataloader len: 87
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 1183, train dataloader len: 395
valid dataset len: 110, valid dataloader len: 37
valid dataset len: 260, test dataloader len: 37
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.7, upper_layer_dropout: 0.35
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597956363.645695.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 5train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 395
valid_dataloader len: 37
test_dataloader len: 87
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 1183, train dataloader len: 395
valid dataset len: 110, valid dataloader len: 37
valid dataset len: 260, test dataloader len: 37
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.7, upper_layer_dropout: 0.35
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597956546.301667.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 6train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 572
valid_dataloader len: 43
test_dataloader len: 102
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 1716, train dataloader len: 572
valid dataset len: 129, valid dataloader len: 43
valid dataset len: 304, test dataloader len: 43
====> Epoch: 1 Train Avg loss: 0.55554, Acc: 0.45513, F1: 0.45513#####> Valid Avg loss: 0.85397, Acc:0.07752, F1: 0.07752
===> Epoch: 1: Training loss decreased (inf --> 0.55554), Acc: (0.00000 --> 0.45513), F1: (0.00000 --> 0.45513).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956546.301667.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.85397), Acc: (0.00000 --> 0.07752), F1: (0.00000 --> 0.07752).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597956546.301667.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.85397), Acc: (0.00000 --> 0.07752), F1: (0.00000 --> 0.07752).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597956546.301667.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 6train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 572
valid_dataloader len: 43
test_dataloader len: 102
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 1716, train dataloader len: 572
valid dataset len: 129, valid dataloader len: 43
valid dataset len: 304, test dataloader len: 43
====> Epoch: 1 Train Avg loss: 0.52719, Acc: 0.48252, F1: 0.48252#####> Valid Avg loss: 0.70379, Acc:0.23256, F1: 0.23256
===> Epoch: 1: Training loss decreased (inf --> 0.52719), Acc: (0.00000 --> 0.48252), F1: (0.00000 --> 0.48252).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.70379), Acc: (0.00000 --> 0.23256), F1: (0.00000 --> 0.23256).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.70379), Acc: (0.00000 --> 0.23256), F1: (0.00000 --> 0.23256).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 2 Train Avg loss: 0.33138, Acc: 0.69289, F1: 0.69289#####> Valid Avg loss: 1.10216, Acc:0.05426, F1: 0.05426
===> Epoch: 2: Training loss decreased (0.52719 --> 0.33138), Acc: (0.48252 --> 0.69289), F1: (0.48252 --> 0.69289).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 3 Train Avg loss: 0.28938, Acc: 0.73193, F1: 0.73193#####> Valid Avg loss: 0.65166, Acc:0.31008, F1: 0.31008
===> Epoch: 3: Training loss decreased (0.33138 --> 0.28938), Acc: (0.69289 --> 0.73193), F1: (0.69289 --> 0.73193).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1

####> Epoch: 3: validation loss decreased (0.70379 --> 0.65166), Acc: (0.23256 --> 0.31008), F1: (0.23256 --> 0.31008).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1

####> Epoch: 3: validation acc increase (0.70379 --> 0.65166), Acc: (0.23256 --> 0.31008), F1: (0.23256 --> 0.31008).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 4 Train Avg loss: 0.24211, Acc: 0.76748, F1: 0.76748#####> Valid Avg loss: 0.66212, Acc:0.34109, F1: 0.34109
===> Epoch: 4: Training loss decreased (0.28938 --> 0.24211), Acc: (0.73193 --> 0.76748), F1: (0.73193 --> 0.76748).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1

####> Epoch: 4: validation acc increase (0.65166 --> 0.66212), Acc: (0.31008 --> 0.34109), F1: (0.31008 --> 0.34109).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 5 Train Avg loss: 0.22188, Acc: 0.78730, F1: 0.78730#####> Valid Avg loss: 0.79126, Acc:0.17829, F1: 0.17829
===> Epoch: 5: Training loss decreased (0.24211 --> 0.22188), Acc: (0.76748 --> 0.78730), F1: (0.76748 --> 0.78730).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 6 Train Avg loss: 0.20800, Acc: 0.79371, F1: 0.79371#####> Valid Avg loss: 0.59187, Acc:0.37984, F1: 0.37984
===> Epoch: 6: Training loss decreased (0.22188 --> 0.20800), Acc: (0.78730 --> 0.79371), F1: (0.78730 --> 0.79371).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1

####> Epoch: 6: validation loss decreased (0.65166 --> 0.59187), Acc: (0.31008 --> 0.37984), F1: (0.31008 --> 0.37984).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1

####> Epoch: 6: validation acc increase (0.66212 --> 0.59187), Acc: (0.34109 --> 0.37984), F1: (0.34109 --> 0.37984).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 7 Train Avg loss: 0.19463, Acc: 0.80769, F1: 0.80769#####> Valid Avg loss: 0.70293, Acc:0.19380, F1: 0.19380
===> Epoch: 7: Training loss decreased (0.20800 --> 0.19463), Acc: (0.79371 --> 0.80769), F1: (0.79371 --> 0.80769).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 8 Train Avg loss: 0.18491, Acc: 0.81294, F1: 0.81294#####> Valid Avg loss: 0.84281, Acc:0.17054, F1: 0.17054
===> Epoch: 8: Training loss decreased (0.19463 --> 0.18491), Acc: (0.80769 --> 0.81294), F1: (0.80769 --> 0.81294).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 9 Train Avg loss: 0.18576, Acc: 0.81061, F1: 0.81061#####> Valid Avg loss: 0.57120, Acc:0.31008, F1: 0.31008

####> Epoch: 9: validation loss decreased (0.59187 --> 0.57120), Acc: (0.37984 --> 0.31008), F1: (0.37984 --> 0.31008).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 10 Train Avg loss: 0.16540, Acc: 0.81818, F1: 0.81818#####> Valid Avg loss: 0.71945, Acc:0.24806, F1: 0.24806
===> Epoch: 10: Training loss decreased (0.18491 --> 0.16540), Acc: (0.81294 --> 0.81818), F1: (0.81294 --> 0.81818).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 11 Train Avg loss: 0.16264, Acc: 0.83392, F1: 0.83392#####> Valid Avg loss: 0.60721, Acc:0.44961, F1: 0.44961
===> Epoch: 11: Training loss decreased (0.16540 --> 0.16264), Acc: (0.81818 --> 0.83392), F1: (0.81818 --> 0.83392).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1

####> Epoch: 11: validation acc increase (0.59187 --> 0.60721), Acc: (0.37984 --> 0.44961), F1: (0.37984 --> 0.44961).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 12 Train Avg loss: 0.15451, Acc: 0.84033, F1: 0.84033#####> Valid Avg loss: 0.73892, Acc:0.22481, F1: 0.22481
===> Epoch: 12: Training loss decreased (0.16264 --> 0.15451), Acc: (0.83392 --> 0.84033), F1: (0.83392 --> 0.84033).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 13 Train Avg loss: 0.13791, Acc: 0.85082, F1: 0.85082#####> Valid Avg loss: 0.63105, Acc:0.51163, F1: 0.51163
===> Epoch: 13: Training loss decreased (0.15451 --> 0.13791), Acc: (0.84033 --> 0.85082), F1: (0.84033 --> 0.85082).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1

####> Epoch: 13: validation acc increase (0.60721 --> 0.63105), Acc: (0.44961 --> 0.51163), F1: (0.44961 --> 0.51163).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 14 Train Avg loss: 0.14027, Acc: 0.85023, F1: 0.85023#####> Valid Avg loss: 0.61743, Acc:0.43411, F1: 0.43411
====> Epoch: 15 Train Avg loss: 0.14381, Acc: 0.84557, F1: 0.84557#####> Valid Avg loss: 0.68726, Acc:0.53488, F1: 0.53488

####> Epoch: 15: validation acc increase (0.63105 --> 0.68726), Acc: (0.51163 --> 0.53488), F1: (0.51163 --> 0.53488).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 16 Train Avg loss: 0.12220, Acc: 0.86946, F1: 0.86946#####> Valid Avg loss: 0.67773, Acc:0.47287, F1: 0.47287
===> Epoch: 16: Training loss decreased (0.13791 --> 0.12220), Acc: (0.85082 --> 0.86946), F1: (0.85082 --> 0.86946).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 17 Train Avg loss: 0.13343, Acc: 0.85606, F1: 0.85606#####> Valid Avg loss: 0.65888, Acc:0.38760, F1: 0.38760
====> Epoch: 18 Train Avg loss: 0.12042, Acc: 0.86830, F1: 0.86830#####> Valid Avg loss: 0.70580, Acc:0.27132, F1: 0.27132
===> Epoch: 18: Training loss decreased (0.12220 --> 0.12042), Acc: (0.86946 --> 0.86830), F1: (0.86946 --> 0.86830).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 19 Train Avg loss: 0.12431, Acc: 0.86655, F1: 0.86655#####> Valid Avg loss: 0.59289, Acc:0.48062, F1: 0.48062
====> Epoch: 20 Train Avg loss: 0.11489, Acc: 0.87354, F1: 0.87354#####> Valid Avg loss: 1.35869, Acc:0.13178, F1: 0.13178
===> Epoch: 20: Training loss decreased (0.12042 --> 0.11489), Acc: (0.86830 --> 0.87354), F1: (0.86830 --> 0.87354).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 21 Train Avg loss: 0.11460, Acc: 0.87529, F1: 0.87529#####> Valid Avg loss: 0.77625, Acc:0.51938, F1: 0.51938
===> Epoch: 21: Training loss decreased (0.11489 --> 0.11460), Acc: (0.87354 --> 0.87529), F1: (0.87354 --> 0.87529).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 22 Train Avg loss: 0.10178, Acc: 0.88228, F1: 0.88228#####> Valid Avg loss: 1.05593, Acc:0.27132, F1: 0.27132
===> Epoch: 22: Training loss decreased (0.11460 --> 0.10178), Acc: (0.87529 --> 0.88228), F1: (0.87529 --> 0.88228).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 23 Train Avg loss: 0.10245, Acc: 0.89685, F1: 0.89685#####> Valid Avg loss: 0.83718, Acc:0.30233, F1: 0.30233
====> Epoch: 24 Train Avg loss: 0.10212, Acc: 0.88986, F1: 0.88986#####> Valid Avg loss: 0.78746, Acc:0.29457, F1: 0.29457
====> Epoch: 25 Train Avg loss: 0.10348, Acc: 0.88578, F1: 0.88578#####> Valid Avg loss: 1.53824, Acc:0.08527, F1: 0.08527
====> Epoch: 26 Train Avg loss: 0.08754, Acc: 0.89860, F1: 0.89860#####> Valid Avg loss: 0.77624, Acc:0.32558, F1: 0.32558
===> Epoch: 26: Training loss decreased (0.10178 --> 0.08754), Acc: (0.88228 --> 0.89860), F1: (0.88228 --> 0.89860).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 27 Train Avg loss: 0.08689, Acc: 0.89802, F1: 0.89802#####> Valid Avg loss: 1.52529, Acc:0.11628, F1: 0.11628
===> Epoch: 27: Training loss decreased (0.08754 --> 0.08689), Acc: (0.89860 --> 0.89802), F1: (0.89860 --> 0.89802).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 28 Train Avg loss: 0.08571, Acc: 0.90326, F1: 0.90326#####> Valid Avg loss: 0.86296, Acc:0.41085, F1: 0.41085
===> Epoch: 28: Training loss decreased (0.08689 --> 0.08571), Acc: (0.89802 --> 0.90326), F1: (0.89802 --> 0.90326).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 29 Train Avg loss: 0.07825, Acc: 0.91492, F1: 0.91492#####> Valid Avg loss: 0.77219, Acc:0.28682, F1: 0.28682
===> Epoch: 29: Training loss decreased (0.08571 --> 0.07825), Acc: (0.90326 --> 0.91492), F1: (0.90326 --> 0.91492).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
====> Epoch: 30 Train Avg loss: 0.07705, Acc: 0.91317, F1: 0.91317#####> Valid Avg loss: 1.04028, Acc:0.13178, F1: 0.13178
===> Epoch: 30: Training loss decreased (0.07825 --> 0.07705), Acc: (0.91492 --> 0.91317), F1: (0.91492 --> 0.91317).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597956897.967852.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 4train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 380
valid_dataloader len: 37
test_dataloader len: 86
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 1139, train dataloader len: 380
valid dataset len: 110, valid dataloader len: 37
valid dataset len: 258, test dataloader len: 37
====> Epoch: 1 Train Avg loss: 0.63798, Acc: 0.38718, F1: 0.38684#####> Valid Avg loss: 0.48527, Acc:0.08182, F1: 0.08108
===> Epoch: 1: Training loss decreased (inf --> 0.63798), Acc: (0.00000 --> 0.38718), F1: (0.00000 --> 0.38684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.48527), Acc: (0.00000 --> 0.08182), F1: (0.00000 --> 0.08108).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.48527), Acc: (0.00000 --> 0.08182), F1: (0.00000 --> 0.08108).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 2 Train Avg loss: 0.46199, Acc: 0.54697, F1: 0.54649#####> Valid Avg loss: 0.33305, Acc:0.69091, F1: 0.68919
===> Epoch: 2: Training loss decreased (0.63798 --> 0.46199), Acc: (0.38718 --> 0.54697), F1: (0.38684 --> 0.54649).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1

####> Epoch: 2: validation loss decreased (0.48527 --> 0.33305), Acc: (0.08182 --> 0.69091), F1: (0.08108 --> 0.68919).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1

####> Epoch: 2: validation acc increase (0.48527 --> 0.33305), Acc: (0.08182 --> 0.69091), F1: (0.08108 --> 0.68919).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 3 Train Avg loss: 0.43138, Acc: 0.62248, F1: 0.62193#####> Valid Avg loss: 0.47577, Acc:0.25455, F1: 0.25225
===> Epoch: 3: Training loss decreased (0.46199 --> 0.43138), Acc: (0.54697 --> 0.62248), F1: (0.54649 --> 0.62193).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 4 Train Avg loss: 0.38930, Acc: 0.65847, F1: 0.65877#####> Valid Avg loss: 0.32750, Acc:0.70000, F1: 0.69820
===> Epoch: 4: Training loss decreased (0.43138 --> 0.38930), Acc: (0.62248 --> 0.65847), F1: (0.62193 --> 0.65877).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1

####> Epoch: 4: validation loss decreased (0.33305 --> 0.32750), Acc: (0.69091 --> 0.70000), F1: (0.68919 --> 0.69820).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1

####> Epoch: 4: validation acc increase (0.33305 --> 0.32750), Acc: (0.69091 --> 0.70000), F1: (0.68919 --> 0.69820).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 5 Train Avg loss: 0.38962, Acc: 0.67515, F1: 0.67544#####> Valid Avg loss: 0.41201, Acc:0.42727, F1: 0.42793
====> Epoch: 6 Train Avg loss: 0.34759, Acc: 0.72169, F1: 0.72149#####> Valid Avg loss: 0.33141, Acc:0.69091, F1: 0.68919
===> Epoch: 6: Training loss decreased (0.38930 --> 0.34759), Acc: (0.65847 --> 0.72169), F1: (0.65877 --> 0.72149).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 7 Train Avg loss: 0.34102, Acc: 0.71993, F1: 0.71974#####> Valid Avg loss: 0.38286, Acc:0.48182, F1: 0.48198
===> Epoch: 7: Training loss decreased (0.34759 --> 0.34102), Acc: (0.72169 --> 0.71993), F1: (0.72149 --> 0.71974).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 8 Train Avg loss: 0.31758, Acc: 0.73486, F1: 0.73509#####> Valid Avg loss: 0.25947, Acc:0.73636, F1: 0.73423
===> Epoch: 8: Training loss decreased (0.34102 --> 0.31758), Acc: (0.71993 --> 0.73486), F1: (0.71974 --> 0.73509).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1

####> Epoch: 8: validation loss decreased (0.32750 --> 0.25947), Acc: (0.70000 --> 0.73636), F1: (0.69820 --> 0.73423).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1

####> Epoch: 8: validation acc increase (0.32750 --> 0.25947), Acc: (0.70000 --> 0.73636), F1: (0.69820 --> 0.73423).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 9 Train Avg loss: 0.33682, Acc: 0.71554, F1: 0.71535#####> Valid Avg loss: 0.36526, Acc:0.70909, F1: 0.70721
====> Epoch: 10 Train Avg loss: 0.31082, Acc: 0.74012, F1: 0.73947#####> Valid Avg loss: 0.36573, Acc:0.71818, F1: 0.71622
===> Epoch: 10: Training loss decreased (0.31758 --> 0.31082), Acc: (0.73486 --> 0.74012), F1: (0.73509 --> 0.73947).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 11 Train Avg loss: 0.30221, Acc: 0.74451, F1: 0.74430#####> Valid Avg loss: 0.68264, Acc:0.54545, F1: 0.54505
===> Epoch: 11: Training loss decreased (0.31082 --> 0.30221), Acc: (0.74012 --> 0.74451), F1: (0.73947 --> 0.74430).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 12 Train Avg loss: 0.30083, Acc: 0.74978, F1: 0.75000#####> Valid Avg loss: 0.51966, Acc:0.48182, F1: 0.48198
===> Epoch: 12: Training loss decreased (0.30221 --> 0.30083), Acc: (0.74451 --> 0.74978), F1: (0.74430 --> 0.75000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 13 Train Avg loss: 0.29583, Acc: 0.74715, F1: 0.74737#####> Valid Avg loss: 0.56812, Acc:0.61818, F1: 0.61712
===> Epoch: 13: Training loss decreased (0.30083 --> 0.29583), Acc: (0.74978 --> 0.74715), F1: (0.75000 --> 0.74737).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 14 Train Avg loss: 0.28525, Acc: 0.75680, F1: 0.75702#####> Valid Avg loss: 0.45998, Acc:0.60000, F1: 0.59910
===> Epoch: 14: Training loss decreased (0.29583 --> 0.28525), Acc: (0.74715 --> 0.75680), F1: (0.74737 --> 0.75702).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 15 Train Avg loss: 0.29413, Acc: 0.74188, F1: 0.74167#####> Valid Avg loss: 0.43083, Acc:0.41818, F1: 0.41892
====> Epoch: 16 Train Avg loss: 0.26826, Acc: 0.77524, F1: 0.77456#####> Valid Avg loss: 0.48501, Acc:0.48182, F1: 0.48198
===> Epoch: 16: Training loss decreased (0.28525 --> 0.26826), Acc: (0.75680 --> 0.77524), F1: (0.75702 --> 0.77456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 17 Train Avg loss: 0.26102, Acc: 0.77173, F1: 0.77193#####> Valid Avg loss: 0.37129, Acc:0.61818, F1: 0.61712
===> Epoch: 17: Training loss decreased (0.26826 --> 0.26102), Acc: (0.77524 --> 0.77173), F1: (0.77456 --> 0.77193).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 18 Train Avg loss: 0.25933, Acc: 0.78139, F1: 0.78158#####> Valid Avg loss: 0.50407, Acc:0.50000, F1: 0.50000
===> Epoch: 18: Training loss decreased (0.26102 --> 0.25933), Acc: (0.77173 --> 0.78139), F1: (0.77193 --> 0.78158).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 19 Train Avg loss: 0.26605, Acc: 0.76471, F1: 0.76491#####> Valid Avg loss: 0.50054, Acc:0.57273, F1: 0.57207
====> Epoch: 20 Train Avg loss: 0.23947, Acc: 0.77436, F1: 0.77412#####> Valid Avg loss: 0.72680, Acc:0.23636, F1: 0.23874
===> Epoch: 20: Training loss decreased (0.25933 --> 0.23947), Acc: (0.78139 --> 0.77436), F1: (0.78158 --> 0.77412).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 21 Train Avg loss: 0.21605, Acc: 0.79368, F1: 0.79342#####> Valid Avg loss: 1.65063, Acc:0.17273, F1: 0.17568
===> Epoch: 21: Training loss decreased (0.23947 --> 0.21605), Acc: (0.77436 --> 0.79368), F1: (0.77412 --> 0.79342).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 22 Train Avg loss: 0.24305, Acc: 0.78314, F1: 0.78289#####> Valid Avg loss: 0.28623, Acc:0.70000, F1: 0.69820
====> Epoch: 23 Train Avg loss: 0.23857, Acc: 0.76997, F1: 0.77018#####> Valid Avg loss: 0.37598, Acc:0.55455, F1: 0.55405
====> Epoch: 24 Train Avg loss: 0.18450, Acc: 0.80685, F1: 0.80702#####> Valid Avg loss: 0.53395, Acc:0.50000, F1: 0.50000
===> Epoch: 24: Training loss decreased (0.21605 --> 0.18450), Acc: (0.79368 --> 0.80685), F1: (0.79342 --> 0.80702).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 25 Train Avg loss: 0.17051, Acc: 0.81826, F1: 0.81842#####> Valid Avg loss: 0.46000, Acc:0.57273, F1: 0.57207
===> Epoch: 25: Training loss decreased (0.18450 --> 0.17051), Acc: (0.80685 --> 0.81826), F1: (0.80702 --> 0.81842).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 26 Train Avg loss: 0.16610, Acc: 0.81651, F1: 0.81623#####> Valid Avg loss: 0.57461, Acc:0.47273, F1: 0.47297
===> Epoch: 26: Training loss decreased (0.17051 --> 0.16610), Acc: (0.81826 --> 0.81651), F1: (0.81842 --> 0.81623).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 27 Train Avg loss: 0.15482, Acc: 0.82353, F1: 0.82368#####> Valid Avg loss: 0.95609, Acc:0.42727, F1: 0.42793
===> Epoch: 27: Training loss decreased (0.16610 --> 0.15482), Acc: (0.81651 --> 0.82353), F1: (0.81623 --> 0.82368).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 28 Train Avg loss: 0.15185, Acc: 0.83231, F1: 0.83246#####> Valid Avg loss: 0.67113, Acc:0.48182, F1: 0.48198
===> Epoch: 28: Training loss decreased (0.15482 --> 0.15185), Acc: (0.82353 --> 0.83231), F1: (0.82368 --> 0.83246).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 29 Train Avg loss: 0.13806, Acc: 0.83933, F1: 0.83947#####> Valid Avg loss: 0.56581, Acc:0.33636, F1: 0.33784
===> Epoch: 29: Training loss decreased (0.15185 --> 0.13806), Acc: (0.83231 --> 0.83933), F1: (0.83246 --> 0.83947).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 30 Train Avg loss: 0.12502, Acc: 0.85953, F1: 0.85965#####> Valid Avg loss: 0.41919, Acc:0.67273, F1: 0.67117
===> Epoch: 30: Training loss decreased (0.13806 --> 0.12502), Acc: (0.83933 --> 0.85953), F1: (0.83947 --> 0.85965).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 31 Train Avg loss: 0.12716, Acc: 0.85601, F1: 0.85614#####> Valid Avg loss: 0.54705, Acc:0.45455, F1: 0.45495
====> Epoch: 32 Train Avg loss: 0.11221, Acc: 0.86128, F1: 0.86140#####> Valid Avg loss: 0.56845, Acc:0.54545, F1: 0.54505
===> Epoch: 32: Training loss decreased (0.12502 --> 0.11221), Acc: (0.85953 --> 0.86128), F1: (0.85965 --> 0.86140).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 33 Train Avg loss: 0.12301, Acc: 0.85162, F1: 0.85175#####> Valid Avg loss: 0.63987, Acc:0.41818, F1: 0.41892
====> Epoch: 34 Train Avg loss: 0.10979, Acc: 0.86831, F1: 0.86842#####> Valid Avg loss: 0.55134, Acc:0.54545, F1: 0.54505
===> Epoch: 34: Training loss decreased (0.11221 --> 0.10979), Acc: (0.86128 --> 0.86831), F1: (0.86140 --> 0.86842).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 35 Train Avg loss: 0.10978, Acc: 0.87094, F1: 0.87105#####> Valid Avg loss: 1.05474, Acc:0.34545, F1: 0.34685
===> Epoch: 35: Training loss decreased (0.10979 --> 0.10978), Acc: (0.86831 --> 0.87094), F1: (0.86842 --> 0.87105).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 36 Train Avg loss: 0.13487, Acc: 0.85953, F1: 0.85965#####> Valid Avg loss: 0.59466, Acc:0.48182, F1: 0.48198
====> Epoch: 37 Train Avg loss: 0.09033, Acc: 0.88762, F1: 0.88772#####> Valid Avg loss: 0.47896, Acc:0.53636, F1: 0.53604
===> Epoch: 37: Training loss decreased (0.10978 --> 0.09033), Acc: (0.87094 --> 0.88762), F1: (0.87105 --> 0.88772).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 38 Train Avg loss: 0.09592, Acc: 0.87533, F1: 0.87544#####> Valid Avg loss: 0.48718, Acc:0.51818, F1: 0.51802
====> Epoch: 39 Train Avg loss: 0.10062, Acc: 0.88323, F1: 0.88333#####> Valid Avg loss: 0.55710, Acc:0.54545, F1: 0.54505
====> Epoch: 40 Train Avg loss: 0.07839, Acc: 0.90606, F1: 0.90614#####> Valid Avg loss: 0.57907, Acc:0.49091, F1: 0.49099
===> Epoch: 40: Training loss decreased (0.09033 --> 0.07839), Acc: (0.88762 --> 0.90606), F1: (0.88772 --> 0.90614).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 41 Train Avg loss: 0.07934, Acc: 0.90606, F1: 0.90614#####> Valid Avg loss: 0.67631, Acc:0.34545, F1: 0.34685
====> Epoch: 42 Train Avg loss: 0.08765, Acc: 0.89377, F1: 0.89386#####> Valid Avg loss: 0.56706, Acc:0.52727, F1: 0.52703
====> Epoch: 43 Train Avg loss: 0.07263, Acc: 0.91133, F1: 0.91140#####> Valid Avg loss: 0.54608, Acc:0.47273, F1: 0.47297
===> Epoch: 43: Training loss decreased (0.07839 --> 0.07263), Acc: (0.90606 --> 0.91133), F1: (0.90614 --> 0.91140).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 44 Train Avg loss: 0.06867, Acc: 0.90606, F1: 0.90614#####> Valid Avg loss: 0.60071, Acc:0.51818, F1: 0.51802
===> Epoch: 44: Training loss decreased (0.07263 --> 0.06867), Acc: (0.91133 --> 0.90606), F1: (0.91140 --> 0.90614).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 45 Train Avg loss: 0.07209, Acc: 0.90518, F1: 0.90526#####> Valid Avg loss: 0.83938, Acc:0.51818, F1: 0.51802
====> Epoch: 46 Train Avg loss: 0.06710, Acc: 0.91835, F1: 0.91842#####> Valid Avg loss: 0.64096, Acc:0.40909, F1: 0.40991
===> Epoch: 46: Training loss decreased (0.06867 --> 0.06710), Acc: (0.90606 --> 0.91835), F1: (0.90614 --> 0.91842).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 47 Train Avg loss: 0.05831, Acc: 0.92537, F1: 0.92544#####> Valid Avg loss: 0.70029, Acc:0.42727, F1: 0.42793
===> Epoch: 47: Training loss decreased (0.06710 --> 0.05831), Acc: (0.91835 --> 0.92537), F1: (0.91842 --> 0.92544).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 48 Train Avg loss: 0.05728, Acc: 0.92450, F1: 0.92456#####> Valid Avg loss: 1.02163, Acc:0.37273, F1: 0.37387
===> Epoch: 48: Training loss decreased (0.05831 --> 0.05728), Acc: (0.92537 --> 0.92450), F1: (0.92544 --> 0.92456).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 49 Train Avg loss: 0.06473, Acc: 0.92186, F1: 0.92193#####> Valid Avg loss: 0.81497, Acc:0.47273, F1: 0.47297
====> Epoch: 50 Train Avg loss: 0.06408, Acc: 0.92450, F1: 0.92456#####> Valid Avg loss: 0.91506, Acc:0.37273, F1: 0.37387
====> Epoch: 51 Train Avg loss: 0.07036, Acc: 0.90781, F1: 0.90789#####> Valid Avg loss: 0.92257, Acc:0.32727, F1: 0.32883
====> Epoch: 52 Train Avg loss: 0.05319, Acc: 0.93415, F1: 0.93421#####> Valid Avg loss: 0.69210, Acc:0.40000, F1: 0.40090
===> Epoch: 52: Training loss decreased (0.05728 --> 0.05319), Acc: (0.92450 --> 0.93415), F1: (0.92456 --> 0.93421).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 53 Train Avg loss: 0.04719, Acc: 0.93415, F1: 0.93421#####> Valid Avg loss: 0.89107, Acc:0.38182, F1: 0.37838
===> Epoch: 53: Training loss decreased (0.05319 --> 0.04719), Acc: (0.93415 --> 0.93415), F1: (0.93421 --> 0.93421).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 54 Train Avg loss: 0.04736, Acc: 0.93327, F1: 0.93333#####> Valid Avg loss: 0.81294, Acc:0.46364, F1: 0.46396
====> Epoch: 55 Train Avg loss: 0.04775, Acc: 0.93854, F1: 0.93860#####> Valid Avg loss: 0.78199, Acc:0.50000, F1: 0.50000
====> Epoch: 56 Train Avg loss: 0.04435, Acc: 0.94118, F1: 0.94123#####> Valid Avg loss: 0.76059, Acc:0.40909, F1: 0.40991
===> Epoch: 56: Training loss decreased (0.04719 --> 0.04435), Acc: (0.93415 --> 0.94118), F1: (0.93421 --> 0.94123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 57 Train Avg loss: 0.06164, Acc: 0.93064, F1: 0.93070#####> Valid Avg loss: 0.83112, Acc:0.44545, F1: 0.44595
====> Epoch: 58 Train Avg loss: 0.04707, Acc: 0.94293, F1: 0.94298#####> Valid Avg loss: 0.76775, Acc:0.37273, F1: 0.37387
====> Epoch: 59 Train Avg loss: 0.03913, Acc: 0.94820, F1: 0.94825#####> Valid Avg loss: 0.71160, Acc:0.44545, F1: 0.44595
===> Epoch: 59: Training loss decreased (0.04435 --> 0.03913), Acc: (0.94118 --> 0.94820), F1: (0.94123 --> 0.94825).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 60 Train Avg loss: 0.03890, Acc: 0.94293, F1: 0.94298#####> Valid Avg loss: 0.95194, Acc:0.30000, F1: 0.29730
===> Epoch: 60: Training loss decreased (0.03913 --> 0.03890), Acc: (0.94820 --> 0.94293), F1: (0.94825 --> 0.94298).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 61 Train Avg loss: 0.03847, Acc: 0.94908, F1: 0.94912#####> Valid Avg loss: 0.92930, Acc:0.45455, F1: 0.45495
===> Epoch: 61: Training loss decreased (0.03890 --> 0.03847), Acc: (0.94293 --> 0.94908), F1: (0.94298 --> 0.94912).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
====> Epoch: 62 Train Avg loss: 0.03495, Acc: 0.95171, F1: 0.95175#####> Valid Avg loss: 0.73967, Acc:0.43636, F1: 0.43694
===> Epoch: 62: Training loss decreased (0.03847 --> 0.03495), Acc: (0.94908 --> 0.95171), F1: (0.94912 --> 0.95175).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1597963868.276702.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.6, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann_5_sec, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1599767252.686205.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.6, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1599767336.971759.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.6, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann/fe_embed_cropped
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1599767913.755695.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.6, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside', 'outside']
embed_dir_base: /project/Driver_in_the_loop/ann/fe_embed
modalities:['inside', 'outside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1015
valid_dataloader len: 55
test_dataloader len: 27
train performers ids: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [8]
test performers ids: [7]
train dataset len: 3044, train dataloader len: 1015
valid dataset len: 163, valid dataloader len: 55
valid dataset len: 80, test dataloader len: 55
====> Epoch: 1 Train Avg loss: 0.92465, Acc: 0.24967, F1: 0.24975#####> Valid Avg loss: 1.12641, Acc:0.07362, F1: 0.08485
===> Epoch: 1: Training loss decreased (inf --> 0.92465), Acc: (0.00000 --> 0.24967), F1: (0.00000 --> 0.24975).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.12641), Acc: (0.00000 --> 0.07362), F1: (0.00000 --> 0.08485).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1

####> Epoch: 1: validation acc increase (inf --> 1.12641), Acc: (0.00000 --> 0.07362), F1: (0.00000 --> 0.08485).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 2 Train Avg loss: 0.74532, Acc: 0.41820, F1: 0.41823#####> Valid Avg loss: 1.17266, Acc:0.00000, F1: 0.00000
===> Epoch: 2: Training loss decreased (0.92465 --> 0.74532), Acc: (0.24967 --> 0.41820), F1: (0.24975 --> 0.41823).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 3 Train Avg loss: 0.69112, Acc: 0.47240, F1: 0.47241#####> Valid Avg loss: 1.10980, Acc:0.20245, F1: 0.21212
===> Epoch: 3: Training loss decreased (0.74532 --> 0.69112), Acc: (0.41820 --> 0.47240), F1: (0.41823 --> 0.47241).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1

####> Epoch: 3: validation loss decreased (1.12641 --> 1.10980), Acc: (0.07362 --> 0.20245), F1: (0.08485 --> 0.21212).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1

####> Epoch: 3: validation acc increase (1.12641 --> 1.10980), Acc: (0.07362 --> 0.20245), F1: (0.08485 --> 0.21212).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 4 Train Avg loss: 0.63821, Acc: 0.50263, F1: 0.50279#####> Valid Avg loss: 1.11399, Acc:0.07975, F1: 0.07879
===> Epoch: 4: Training loss decreased (0.69112 --> 0.63821), Acc: (0.47240 --> 0.50263), F1: (0.47241 --> 0.50279).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 5 Train Avg loss: 0.62262, Acc: 0.52431, F1: 0.52447#####> Valid Avg loss: 1.09897, Acc:0.12883, F1: 0.12727
===> Epoch: 5: Training loss decreased (0.63821 --> 0.62262), Acc: (0.50263 --> 0.52431), F1: (0.50279 --> 0.52447).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1

####> Epoch: 5: validation loss decreased (1.10980 --> 1.09897), Acc: (0.20245 --> 0.12883), F1: (0.21212 --> 0.12727).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 6 Train Avg loss: 0.58954, Acc: 0.53351, F1: 0.53350#####> Valid Avg loss: 1.07566, Acc:0.17178, F1: 0.16970
===> Epoch: 6: Training loss decreased (0.62262 --> 0.58954), Acc: (0.52431 --> 0.53351), F1: (0.52447 --> 0.53350).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1

####> Epoch: 6: validation loss decreased (1.09897 --> 1.07566), Acc: (0.12883 --> 0.17178), F1: (0.12727 --> 0.16970).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 7 Train Avg loss: 0.56852, Acc: 0.55749, F1: 0.55747#####> Valid Avg loss: 1.17223, Acc:0.10429, F1: 0.10303
===> Epoch: 7: Training loss decreased (0.58954 --> 0.56852), Acc: (0.53351 --> 0.55749), F1: (0.53350 --> 0.55747).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 8 Train Avg loss: 0.54565, Acc: 0.57162, F1: 0.57159#####> Valid Avg loss: 1.21073, Acc:0.16564, F1: 0.16364
===> Epoch: 8: Training loss decreased (0.56852 --> 0.54565), Acc: (0.55749 --> 0.57162), F1: (0.55747 --> 0.57159).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 9 Train Avg loss: 0.52929, Acc: 0.57523, F1: 0.57504#####> Valid Avg loss: 1.28479, Acc:0.15951, F1: 0.15758
===> Epoch: 9: Training loss decreased (0.54565 --> 0.52929), Acc: (0.57162 --> 0.57523), F1: (0.57159 --> 0.57504).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 10 Train Avg loss: 0.52274, Acc: 0.58443, F1: 0.58440#####> Valid Avg loss: 1.21903, Acc:0.20245, F1: 0.21212
===> Epoch: 10: Training loss decreased (0.52929 --> 0.52274), Acc: (0.57523 --> 0.58443), F1: (0.57504 --> 0.58440).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 11 Train Avg loss: 0.50626, Acc: 0.59166, F1: 0.59163#####> Valid Avg loss: 1.14600, Acc:0.19632, F1: 0.20606
===> Epoch: 11: Training loss decreased (0.52274 --> 0.50626), Acc: (0.58443 --> 0.59166), F1: (0.58440 --> 0.59163).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 12 Train Avg loss: 0.49036, Acc: 0.60677, F1: 0.60690#####> Valid Avg loss: 1.23821, Acc:0.21472, F1: 0.22424
===> Epoch: 12: Training loss decreased (0.50626 --> 0.49036), Acc: (0.59166 --> 0.60677), F1: (0.59163 --> 0.60690).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1

####> Epoch: 12: validation acc increase (1.10980 --> 1.23821), Acc: (0.20245 --> 0.21472), F1: (0.21212 --> 0.22424).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 13 Train Avg loss: 0.48518, Acc: 0.59855, F1: 0.59869#####> Valid Avg loss: 1.17670, Acc:0.12883, F1: 0.12727
===> Epoch: 13: Training loss decreased (0.49036 --> 0.48518), Acc: (0.60677 --> 0.59855), F1: (0.60690 --> 0.59869).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 14 Train Avg loss: 0.47851, Acc: 0.61597, F1: 0.61593#####> Valid Avg loss: 1.15116, Acc:0.15337, F1: 0.16364
===> Epoch: 14: Training loss decreased (0.48518 --> 0.47851), Acc: (0.59855 --> 0.61597), F1: (0.59869 --> 0.61593).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 15 Train Avg loss: 0.47225, Acc: 0.61104, F1: 0.61100#####> Valid Avg loss: 1.18424, Acc:0.19632, F1: 0.19394
===> Epoch: 15: Training loss decreased (0.47851 --> 0.47225), Acc: (0.61597 --> 0.61104), F1: (0.61593 --> 0.61100).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 16 Train Avg loss: 0.45788, Acc: 0.62221, F1: 0.62217#####> Valid Avg loss: 1.16256, Acc:0.11656, F1: 0.11515
===> Epoch: 16: Training loss decreased (0.47225 --> 0.45788), Acc: (0.61104 --> 0.62221), F1: (0.61100 --> 0.62217).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 17 Train Avg loss: 0.45414, Acc: 0.62549, F1: 0.62545#####> Valid Avg loss: 1.10921, Acc:0.19018, F1: 0.20000
===> Epoch: 17: Training loss decreased (0.45788 --> 0.45414), Acc: (0.62221 --> 0.62549), F1: (0.62217 --> 0.62545).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 18 Train Avg loss: 0.43567, Acc: 0.63699, F1: 0.63711#####> Valid Avg loss: 1.23731, Acc:0.17791, F1: 0.17576
===> Epoch: 18: Training loss decreased (0.45414 --> 0.43567), Acc: (0.62549 --> 0.63699), F1: (0.62545 --> 0.63711).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 19 Train Avg loss: 0.43174, Acc: 0.62976, F1: 0.62956#####> Valid Avg loss: 1.32641, Acc:0.17791, F1: 0.17576
===> Epoch: 19: Training loss decreased (0.43567 --> 0.43174), Acc: (0.63699 --> 0.62976), F1: (0.63711 --> 0.62956).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 20 Train Avg loss: 0.45869, Acc: 0.62089, F1: 0.62069#####> Valid Avg loss: 1.16104, Acc:0.16564, F1: 0.16364
====> Epoch: 21 Train Avg loss: 0.43842, Acc: 0.63633, F1: 0.63629#####> Valid Avg loss: 1.22683, Acc:0.21472, F1: 0.22424
====> Epoch: 22 Train Avg loss: 0.42237, Acc: 0.63830, F1: 0.63842#####> Valid Avg loss: 1.16538, Acc:0.19632, F1: 0.20606
===> Epoch: 22: Training loss decreased (0.43174 --> 0.42237), Acc: (0.62976 --> 0.63830), F1: (0.62956 --> 0.63842).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 23 Train Avg loss: 0.42868, Acc: 0.63371, F1: 0.63350#####> Valid Avg loss: 1.22742, Acc:0.15951, F1: 0.16970
====> Epoch: 24 Train Avg loss: 0.41306, Acc: 0.64915, F1: 0.64910#####> Valid Avg loss: 1.23029, Acc:0.21472, F1: 0.22424
===> Epoch: 24: Training loss decreased (0.42237 --> 0.41306), Acc: (0.63830 --> 0.64915), F1: (0.63842 --> 0.64910).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
====> Epoch: 25 Train Avg loss: 0.40794, Acc: 0.64947, F1: 0.64959#####> Valid Avg loss: 1.31001, Acc:0.19018, F1: 0.18788
===> Epoch: 25: Training loss decreased (0.41306 --> 0.40794), Acc: (0.64915 --> 0.64947), F1: (0.64910 --> 0.64959).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1599768157.796103.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.6, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann/fe_embed
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1015
valid_dataloader len: 55
test_dataloader len: 27
train performers ids: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [8]
test performers ids: [7]
train dataset len: 3044, train dataloader len: 1015
valid dataset len: 163, valid dataloader len: 55
valid dataset len: 80, test dataloader len: 55
====> Epoch: 1 Train Avg loss: 0.87400, Acc: 0.20434, F1: 0.20460#####> Valid Avg loss: 0.99303, Acc:0.00613, F1: 0.00606
===> Epoch: 1: Training loss decreased (inf --> 0.87400), Acc: (0.00000 --> 0.20434), F1: (0.00000 --> 0.20460).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.99303), Acc: (0.00000 --> 0.00613), F1: (0.00000 --> 0.00606).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.99303), Acc: (0.00000 --> 0.00613), F1: (0.00000 --> 0.00606).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 2 Train Avg loss: 0.74725, Acc: 0.34724, F1: 0.34713#####> Valid Avg loss: 0.97408, Acc:0.00613, F1: 0.00606
===> Epoch: 2: Training loss decreased (0.87400 --> 0.74725), Acc: (0.20434 --> 0.34724), F1: (0.20460 --> 0.34713).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1

####> Epoch: 2: validation loss decreased (0.99303 --> 0.97408), Acc: (0.00613 --> 0.00613), F1: (0.00606 --> 0.00606).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 3 Train Avg loss: 0.67972, Acc: 0.43134, F1: 0.43136#####> Valid Avg loss: 0.95032, Acc:0.00000, F1: 0.00000
===> Epoch: 3: Training loss decreased (0.74725 --> 0.67972), Acc: (0.34724 --> 0.43134), F1: (0.34713 --> 0.43136).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1

####> Epoch: 3: validation loss decreased (0.97408 --> 0.95032), Acc: (0.00613 --> 0.00000), F1: (0.00606 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 4 Train Avg loss: 0.66226, Acc: 0.43265, F1: 0.43284#####> Valid Avg loss: 0.92852, Acc:0.06748, F1: 0.06667
===> Epoch: 4: Training loss decreased (0.67972 --> 0.66226), Acc: (0.43134 --> 0.43265), F1: (0.43136 --> 0.43284).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1

####> Epoch: 4: validation loss decreased (0.95032 --> 0.92852), Acc: (0.00000 --> 0.06748), F1: (0.00000 --> 0.06667).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1

####> Epoch: 4: validation acc increase (0.99303 --> 0.92852), Acc: (0.00613 --> 0.06748), F1: (0.00606 --> 0.06667).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 5 Train Avg loss: 0.62892, Acc: 0.47339, F1: 0.47340#####> Valid Avg loss: 0.96185, Acc:0.04908, F1: 0.04848
===> Epoch: 5: Training loss decreased (0.66226 --> 0.62892), Acc: (0.43265 --> 0.47339), F1: (0.43284 --> 0.47340).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 6 Train Avg loss: 0.61884, Acc: 0.48095, F1: 0.48095#####> Valid Avg loss: 0.90915, Acc:0.22086, F1: 0.23030
===> Epoch: 6: Training loss decreased (0.62892 --> 0.61884), Acc: (0.47339 --> 0.48095), F1: (0.47340 --> 0.48095).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1

####> Epoch: 6: validation loss decreased (0.92852 --> 0.90915), Acc: (0.06748 --> 0.22086), F1: (0.06667 --> 0.23030).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1

####> Epoch: 6: validation acc increase (0.92852 --> 0.90915), Acc: (0.06748 --> 0.22086), F1: (0.06667 --> 0.23030).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 7 Train Avg loss: 0.59629, Acc: 0.50591, F1: 0.50591#####> Valid Avg loss: 0.97185, Acc:0.08589, F1: 0.09697
===> Epoch: 7: Training loss decreased (0.61884 --> 0.59629), Acc: (0.48095 --> 0.50591), F1: (0.48095 --> 0.50591).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 8 Train Avg loss: 0.59228, Acc: 0.50624, F1: 0.50640#####> Valid Avg loss: 0.98135, Acc:0.11043, F1: 0.12121
===> Epoch: 8: Training loss decreased (0.59629 --> 0.59228), Acc: (0.50591 --> 0.50624), F1: (0.50591 --> 0.50640).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 9 Train Avg loss: 0.57859, Acc: 0.51610, F1: 0.51593#####> Valid Avg loss: 1.02065, Acc:0.01840, F1: 0.01818
===> Epoch: 9: Training loss decreased (0.59228 --> 0.57859), Acc: (0.50624 --> 0.51610), F1: (0.50640 --> 0.51593).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 10 Train Avg loss: 0.56942, Acc: 0.52694, F1: 0.52709#####> Valid Avg loss: 1.01085, Acc:0.07362, F1: 0.08485
===> Epoch: 10: Training loss decreased (0.57859 --> 0.56942), Acc: (0.51610 --> 0.52694), F1: (0.51593 --> 0.52709).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 11 Train Avg loss: 0.55970, Acc: 0.52694, F1: 0.52693#####> Valid Avg loss: 0.96944, Acc:0.20245, F1: 0.21212
===> Epoch: 11: Training loss decreased (0.56942 --> 0.55970), Acc: (0.52694 --> 0.52694), F1: (0.52709 --> 0.52693).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 12 Train Avg loss: 0.55013, Acc: 0.54271, F1: 0.54286#####> Valid Avg loss: 0.95740, Acc:0.16564, F1: 0.17576
===> Epoch: 12: Training loss decreased (0.55970 --> 0.55013), Acc: (0.52694 --> 0.54271), F1: (0.52693 --> 0.54286).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 13 Train Avg loss: 0.54617, Acc: 0.53318, F1: 0.53317#####> Valid Avg loss: 1.13050, Acc:0.09816, F1: 0.10909
===> Epoch: 13: Training loss decreased (0.55013 --> 0.54617), Acc: (0.54271 --> 0.53318), F1: (0.54286 --> 0.53317).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
====> Epoch: 14 Train Avg loss: 0.53863, Acc: 0.54731, F1: 0.54729#####> Valid Avg loss: 1.05961, Acc:0.03067, F1: 0.03030
===> Epoch: 14: Training loss decreased (0.54617 --> 0.53863), Acc: (0.53318 --> 0.54731), F1: (0.53317 --> 0.54729).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600142829.36475.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.6, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600143408.915237.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 11train person_ids: [ 7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 357
valid_dataloader len: 26
test_dataloader len: 20
train performers ids: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [8]
test performers ids: [7]
train dataset len: 1069, train dataloader len: 357
valid dataset len: 76, valid dataloader len: 26
valid dataset len: 59, test dataloader len: 26
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 64, feature_embed_size:128
lstm_hidden_size: 128
lower_layer_dropout:0.6, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 11train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 907
valid_dataloader len: 292
test_dataloader len: 143
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2720, train dataloader len: 907
valid dataset len: 876, valid dataloader len: 292
valid dataset len: 428, test dataloader len: 292
====> Epoch: 1 Train Avg loss: 0.80154, Acc: 0.46985, F1: 0.46986#####> Valid Avg loss: 0.62790, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 0.80154), Acc: (0.00000 --> 0.46985), F1: (0.00000 --> 0.46986).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.62790), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.62790), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 2 Train Avg loss: 0.67441, Acc: 0.48824, F1: 0.48806#####> Valid Avg loss: 0.52938, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (0.80154 --> 0.67441), Acc: (0.46985 --> 0.48824), F1: (0.46986 --> 0.48806).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1

####> Epoch: 2: validation loss decreased (0.62790 --> 0.52938), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 3 Train Avg loss: 0.62090, Acc: 0.50846, F1: 0.50845#####> Valid Avg loss: 0.56260, Acc:0.48630, F1: 0.48630
===> Epoch: 3: Training loss decreased (0.67441 --> 0.62090), Acc: (0.48824 --> 0.50846), F1: (0.48806 --> 0.50845).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 4 Train Avg loss: 0.59877, Acc: 0.51544, F1: 0.51562#####> Valid Avg loss: 0.51368, Acc:0.48630, F1: 0.48630
===> Epoch: 4: Training loss decreased (0.62090 --> 0.59877), Acc: (0.50846 --> 0.51544), F1: (0.50845 --> 0.51562).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1

####> Epoch: 4: validation loss decreased (0.52938 --> 0.51368), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 5 Train Avg loss: 0.56862, Acc: 0.52353, F1: 0.52334#####> Valid Avg loss: 0.51691, Acc:0.48630, F1: 0.48630
===> Epoch: 5: Training loss decreased (0.59877 --> 0.56862), Acc: (0.51544 --> 0.52353), F1: (0.51562 --> 0.52334).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 6 Train Avg loss: 0.55385, Acc: 0.52390, F1: 0.52389#####> Valid Avg loss: 0.51875, Acc:0.48630, F1: 0.48630
===> Epoch: 6: Training loss decreased (0.56862 --> 0.55385), Acc: (0.52353 --> 0.52390), F1: (0.52334 --> 0.52389).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 7 Train Avg loss: 0.54842, Acc: 0.52574, F1: 0.52554#####> Valid Avg loss: 0.55241, Acc:0.48630, F1: 0.48630
===> Epoch: 7: Training loss decreased (0.55385 --> 0.54842), Acc: (0.52390 --> 0.52574), F1: (0.52389 --> 0.52554).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 8 Train Avg loss: 0.53996, Acc: 0.52537, F1: 0.52536#####> Valid Avg loss: 0.51848, Acc:0.48630, F1: 0.48630
===> Epoch: 8: Training loss decreased (0.54842 --> 0.53996), Acc: (0.52574 --> 0.52537), F1: (0.52554 --> 0.52536).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 9 Train Avg loss: 0.52632, Acc: 0.52537, F1: 0.52554#####> Valid Avg loss: 0.52207, Acc:0.48630, F1: 0.48630
===> Epoch: 9: Training loss decreased (0.53996 --> 0.52632), Acc: (0.52537 --> 0.52537), F1: (0.52536 --> 0.52554).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 10 Train Avg loss: 0.52977, Acc: 0.52831, F1: 0.52848#####> Valid Avg loss: 0.52790, Acc:0.48630, F1: 0.48630
====> Epoch: 11 Train Avg loss: 0.51724, Acc: 0.52794, F1: 0.52775#####> Valid Avg loss: 0.53368, Acc:0.48630, F1: 0.48630
===> Epoch: 11: Training loss decreased (0.52632 --> 0.51724), Acc: (0.52537 --> 0.52794), F1: (0.52554 --> 0.52775).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 12 Train Avg loss: 0.51511, Acc: 0.52684, F1: 0.52683#####> Valid Avg loss: 0.56653, Acc:0.48630, F1: 0.48630
===> Epoch: 12: Training loss decreased (0.51724 --> 0.51511), Acc: (0.52794 --> 0.52684), F1: (0.52775 --> 0.52683).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 13 Train Avg loss: 0.50271, Acc: 0.52978, F1: 0.52958#####> Valid Avg loss: 0.52620, Acc:0.48630, F1: 0.48630
===> Epoch: 13: Training loss decreased (0.51511 --> 0.50271), Acc: (0.52684 --> 0.52978), F1: (0.52683 --> 0.52958).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 14 Train Avg loss: 0.50959, Acc: 0.53015, F1: 0.53014#####> Valid Avg loss: 0.53227, Acc:0.48630, F1: 0.48630
====> Epoch: 15 Train Avg loss: 0.49618, Acc: 0.52941, F1: 0.52958#####> Valid Avg loss: 0.53413, Acc:0.48630, F1: 0.48630
===> Epoch: 15: Training loss decreased (0.50271 --> 0.49618), Acc: (0.52978 --> 0.52941), F1: (0.52958 --> 0.52958).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 16 Train Avg loss: 0.49384, Acc: 0.53456, F1: 0.53455#####> Valid Avg loss: 0.54322, Acc:0.48630, F1: 0.48630
===> Epoch: 16: Training loss decreased (0.49618 --> 0.49384), Acc: (0.52941 --> 0.53456), F1: (0.52958 --> 0.53455).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 17 Train Avg loss: 0.49054, Acc: 0.53566, F1: 0.53565#####> Valid Avg loss: 0.55254, Acc:0.48630, F1: 0.48630
===> Epoch: 17: Training loss decreased (0.49384 --> 0.49054), Acc: (0.53456 --> 0.53566), F1: (0.53455 --> 0.53565).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
====> Epoch: 18 Train Avg loss: 0.48954, Acc: 0.53162, F1: 0.53161#####> Valid Avg loss: 0.54100, Acc:0.48630, F1: 0.48630
===> Epoch: 18: Training loss decreased (0.49054 --> 0.48954), Acc: (0.53566 --> 0.53162), F1: (0.53565 --> 0.53161).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600143585.899765.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 16, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.65, upper_layer_dropout: 0.65
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 11train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 272
valid_dataloader len: 88
test_dataloader len: 43
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2720, train dataloader len: 272
valid dataset len: 876, valid dataloader len: 88
valid dataset len: 428, test dataloader len: 88
====> Epoch: 1 Train Avg loss: 0.29317, Acc: 0.44007, F1: 0.44007#####> Valid Avg loss: 0.19040, Acc:0.48630, F1: 0.48712
===> Epoch: 1: Training loss decreased (inf --> 0.29317), Acc: (0.00000 --> 0.44007), F1: (0.00000 --> 0.44007).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.19040), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48712).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.19040), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48712).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1
====> Epoch: 2 Train Avg loss: 0.23858, Acc: 0.45368, F1: 0.45368#####> Valid Avg loss: 0.16466, Acc:0.48630, F1: 0.48712
===> Epoch: 2: Training loss decreased (0.29317 --> 0.23858), Acc: (0.44007 --> 0.45368), F1: (0.44007 --> 0.45368).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1

####> Epoch: 2: validation loss decreased (0.19040 --> 0.16466), Acc: (0.48630 --> 0.48630), F1: (0.48712 --> 0.48712).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1
====> Epoch: 3 Train Avg loss: 0.21356, Acc: 0.46176, F1: 0.46176#####> Valid Avg loss: 0.16168, Acc:0.48630, F1: 0.48712
===> Epoch: 3: Training loss decreased (0.23858 --> 0.21356), Acc: (0.45368 --> 0.46176), F1: (0.45368 --> 0.46176).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1

####> Epoch: 3: validation loss decreased (0.16466 --> 0.16168), Acc: (0.48630 --> 0.48630), F1: (0.48712 --> 0.48712).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1
====> Epoch: 4 Train Avg loss: 0.20007, Acc: 0.48272, F1: 0.48272#####> Valid Avg loss: 0.16406, Acc:0.48630, F1: 0.48712
===> Epoch: 4: Training loss decreased (0.21356 --> 0.20007), Acc: (0.46176 --> 0.48272), F1: (0.46176 --> 0.48272).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1
====> Epoch: 5 Train Avg loss: 0.18899, Acc: 0.49375, F1: 0.49375#####> Valid Avg loss: 0.16244, Acc:0.48630, F1: 0.48712
===> Epoch: 5: Training loss decreased (0.20007 --> 0.18899), Acc: (0.48272 --> 0.49375), F1: (0.48272 --> 0.49375).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1
====> Epoch: 6 Train Avg loss: 0.17869, Acc: 0.51066, F1: 0.51066#####> Valid Avg loss: 0.15956, Acc:0.48630, F1: 0.48712
===> Epoch: 6: Training loss decreased (0.18899 --> 0.17869), Acc: (0.49375 --> 0.51066), F1: (0.49375 --> 0.51066).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1

####> Epoch: 6: validation loss decreased (0.16168 --> 0.15956), Acc: (0.48630 --> 0.48630), F1: (0.48712 --> 0.48712).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1
====> Epoch: 7 Train Avg loss: 0.17364, Acc: 0.51066, F1: 0.51066#####> Valid Avg loss: 0.17263, Acc:0.48630, F1: 0.48712
===> Epoch: 7: Training loss decreased (0.17869 --> 0.17364), Acc: (0.51066 --> 0.51066), F1: (0.51066 --> 0.51066).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1
====> Epoch: 8 Train Avg loss: 0.16817, Acc: 0.51618, F1: 0.51618#####> Valid Avg loss: 0.15924, Acc:0.48630, F1: 0.48712
===> Epoch: 8: Training loss decreased (0.17364 --> 0.16817), Acc: (0.51066 --> 0.51618), F1: (0.51066 --> 0.51618).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1

####> Epoch: 8: validation loss decreased (0.15956 --> 0.15924), Acc: (0.48630 --> 0.48630), F1: (0.48712 --> 0.48712).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144168.469033.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:10
cnn_out_channel: 128, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.35, upper_layer_dropout: 0.35
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600144341.4196.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 11train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 272
valid_dataloader len: 88
test_dataloader len: 43
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2720, train dataloader len: 272
valid dataset len: 876, valid dataloader len: 88
valid dataset len: 428, test dataloader len: 88
====> Epoch: 1 Train Avg loss: 0.20364, Acc: 0.47132, F1: 0.47132#####> Valid Avg loss: 0.15957, Acc:0.48630, F1: 0.48712
===> Epoch: 1: Training loss decreased (inf --> 0.20364), Acc: (0.00000 --> 0.47132), F1: (0.00000 --> 0.47132).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144341.4196.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.15957), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48712).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144341.4196.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.15957), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48712).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600144341.4196.pth_1
====> Epoch: 2 Train Avg loss: 0.17498, Acc: 0.49816, F1: 0.49816#####> Valid Avg loss: 0.17285, Acc:0.48630, F1: 0.48712
===> Epoch: 2: Training loss decreased (0.20364 --> 0.17498), Acc: (0.47132 --> 0.49816), F1: (0.47132 --> 0.49816).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144341.4196.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:3
cnn_out_channel: 128, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600144442.059192.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 11train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 907
valid_dataloader len: 292
test_dataloader len: 143
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2720, train dataloader len: 907
valid dataset len: 876, valid dataloader len: 292
valid dataset len: 428, test dataloader len: 292
====> Epoch: 1 Train Avg loss: 0.67559, Acc: 0.48787, F1: 0.48806#####> Valid Avg loss: 0.56144, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 0.67559), Acc: (0.00000 --> 0.48787), F1: (0.00000 --> 0.48806).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144442.059192.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.56144), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144442.059192.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.56144), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600144442.059192.pth_1
====> Epoch: 2 Train Avg loss: 0.58290, Acc: 0.51066, F1: 0.51047#####> Valid Avg loss: 0.53893, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (0.67559 --> 0.58290), Acc: (0.48787 --> 0.51066), F1: (0.48806 --> 0.51047).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144442.059192.pth_1

####> Epoch: 2: validation loss decreased (0.56144 --> 0.53893), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144442.059192.pth_1
====> Epoch: 3 Train Avg loss: 0.56691, Acc: 0.52316, F1: 0.52315#####> Valid Avg loss: 0.54165, Acc:0.48630, F1: 0.48630
===> Epoch: 3: Training loss decreased (0.58290 --> 0.56691), Acc: (0.51066 --> 0.52316), F1: (0.51047 --> 0.52315).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144442.059192.pth_1
====> Epoch: 4 Train Avg loss: 0.55427, Acc: 0.52500, F1: 0.52481#####> Valid Avg loss: 0.56450, Acc:0.48630, F1: 0.48630
===> Epoch: 4: Training loss decreased (0.56691 --> 0.55427), Acc: (0.52316 --> 0.52500), F1: (0.52315 --> 0.52481).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144442.059192.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:3
cnn_out_channel: 128, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600144633.972629.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 11train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 907
valid_dataloader len: 292
test_dataloader len: 143
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2720, train dataloader len: 907
valid dataset len: 876, valid dataloader len: 292
valid dataset len: 428, test dataloader len: 292
====> Epoch: 1 Train Avg loss: 0.81858, Acc: 0.47721, F1: 0.47740#####> Valid Avg loss: 0.59169, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 0.81858), Acc: (0.00000 --> 0.47721), F1: (0.00000 --> 0.47740).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144633.972629.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.59169), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144633.972629.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.59169), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600144633.972629.pth_1
====> Epoch: 2 Train Avg loss: 0.67261, Acc: 0.48566, F1: 0.48548#####> Valid Avg loss: 0.61259, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (0.81858 --> 0.67261), Acc: (0.47721 --> 0.48566), F1: (0.47740 --> 0.48548).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144633.972629.pth_1
====> Epoch: 3 Train Avg loss: 0.63382, Acc: 0.49375, F1: 0.49375#####> Valid Avg loss: 0.59512, Acc:0.48630, F1: 0.48630
===> Epoch: 3: Training loss decreased (0.67261 --> 0.63382), Acc: (0.48566 --> 0.49375), F1: (0.48548 --> 0.49375).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144633.972629.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:3
cnn_out_channel: 128, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 4train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 56
valid_dataloader len: 15
test_dataloader len: 10
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 166, train dataloader len: 56
valid dataset len: 44, valid dataloader len: 15
valid dataset len: 29, test dataloader len: 15
====> Epoch: 1 Train Avg loss: 0.89785, Acc: 0.44578, F1: 0.45238#####> Valid Avg loss: 1.74049, Acc:0.25000, F1: 0.25556
===> Epoch: 1: Training loss decreased (inf --> 0.89785), Acc: (0.00000 --> 0.44578), F1: (0.00000 --> 0.45238).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.74049), Acc: (0.00000 --> 0.25000), F1: (0.00000 --> 0.25556).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1

####> Epoch: 1: validation acc increase (inf --> 1.74049), Acc: (0.00000 --> 0.25000), F1: (0.00000 --> 0.25556).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 2 Train Avg loss: 0.48458, Acc: 0.62048, F1: 0.62500#####> Valid Avg loss: 1.87772, Acc:0.25000, F1: 0.25556
===> Epoch: 2: Training loss decreased (0.89785 --> 0.48458), Acc: (0.44578 --> 0.62048), F1: (0.45238 --> 0.62500).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 3 Train Avg loss: 0.45662, Acc: 0.62651, F1: 0.63095#####> Valid Avg loss: 1.72794, Acc:0.25000, F1: 0.25556
===> Epoch: 3: Training loss decreased (0.48458 --> 0.45662), Acc: (0.62048 --> 0.62651), F1: (0.62500 --> 0.63095).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1

####> Epoch: 3: validation loss decreased (1.74049 --> 1.72794), Acc: (0.25000 --> 0.25000), F1: (0.25556 --> 0.25556).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 4 Train Avg loss: 0.41626, Acc: 0.65060, F1: 0.65476#####> Valid Avg loss: 1.74895, Acc:0.25000, F1: 0.25556
===> Epoch: 4: Training loss decreased (0.45662 --> 0.41626), Acc: (0.62651 --> 0.65060), F1: (0.63095 --> 0.65476).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 5 Train Avg loss: 0.38854, Acc: 0.72892, F1: 0.73214#####> Valid Avg loss: 1.83347, Acc:0.25000, F1: 0.25556
===> Epoch: 5: Training loss decreased (0.41626 --> 0.38854), Acc: (0.65060 --> 0.72892), F1: (0.65476 --> 0.73214).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 6 Train Avg loss: 0.41483, Acc: 0.65060, F1: 0.64286#####> Valid Avg loss: 1.66312, Acc:0.25000, F1: 0.25556

####> Epoch: 6: validation loss decreased (1.72794 --> 1.66312), Acc: (0.25000 --> 0.25000), F1: (0.25556 --> 0.25556).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 7 Train Avg loss: 0.32879, Acc: 0.74699, F1: 0.75000#####> Valid Avg loss: 1.61451, Acc:0.25000, F1: 0.25556
===> Epoch: 7: Training loss decreased (0.38854 --> 0.32879), Acc: (0.72892 --> 0.74699), F1: (0.73214 --> 0.75000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1

####> Epoch: 7: validation loss decreased (1.66312 --> 1.61451), Acc: (0.25000 --> 0.25000), F1: (0.25556 --> 0.25556).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 8 Train Avg loss: 0.33943, Acc: 0.74699, F1: 0.75000#####> Valid Avg loss: 1.54992, Acc:0.25000, F1: 0.25556

####> Epoch: 8: validation loss decreased (1.61451 --> 1.54992), Acc: (0.25000 --> 0.25000), F1: (0.25556 --> 0.25556).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 9 Train Avg loss: 0.33139, Acc: 0.78916, F1: 0.79167#####> Valid Avg loss: 1.56927, Acc:0.25000, F1: 0.25556
====> Epoch: 10 Train Avg loss: 0.28388, Acc: 0.78916, F1: 0.79167#####> Valid Avg loss: 1.54207, Acc:0.25000, F1: 0.25556
===> Epoch: 10: Training loss decreased (0.32879 --> 0.28388), Acc: (0.74699 --> 0.78916), F1: (0.75000 --> 0.79167).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1

####> Epoch: 10: validation loss decreased (1.54992 --> 1.54207), Acc: (0.25000 --> 0.25000), F1: (0.25556 --> 0.25556).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 11 Train Avg loss: 0.32359, Acc: 0.75301, F1: 0.74405#####> Valid Avg loss: 1.61961, Acc:0.09091, F1: 0.08889
====> Epoch: 12 Train Avg loss: 0.29206, Acc: 0.78313, F1: 0.78571#####> Valid Avg loss: 1.52981, Acc:0.13636, F1: 0.13333

####> Epoch: 12: validation loss decreased (1.54207 --> 1.52981), Acc: (0.25000 --> 0.13636), F1: (0.25556 --> 0.13333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 13 Train Avg loss: 0.28090, Acc: 0.80120, F1: 0.80357#####> Valid Avg loss: 1.54858, Acc:0.00000, F1: 0.00000
===> Epoch: 13: Training loss decreased (0.28388 --> 0.28090), Acc: (0.78916 --> 0.80120), F1: (0.79167 --> 0.80357).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 14 Train Avg loss: 0.25179, Acc: 0.82530, F1: 0.82738#####> Valid Avg loss: 1.52830, Acc:0.15909, F1: 0.15556
===> Epoch: 14: Training loss decreased (0.28090 --> 0.25179), Acc: (0.80120 --> 0.82530), F1: (0.80357 --> 0.82738).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1

####> Epoch: 14: validation loss decreased (1.52981 --> 1.52830), Acc: (0.13636 --> 0.15909), F1: (0.13333 --> 0.15556).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 15 Train Avg loss: 0.25088, Acc: 0.80120, F1: 0.80357#####> Valid Avg loss: 1.17937, Acc:0.09091, F1: 0.08889
===> Epoch: 15: Training loss decreased (0.25179 --> 0.25088), Acc: (0.82530 --> 0.80120), F1: (0.82738 --> 0.80357).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1

####> Epoch: 15: validation loss decreased (1.52830 --> 1.17937), Acc: (0.15909 --> 0.09091), F1: (0.15556 --> 0.08889).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 16 Train Avg loss: 0.20604, Acc: 0.84940, F1: 0.85119#####> Valid Avg loss: 1.38691, Acc:0.00000, F1: 0.00000
===> Epoch: 16: Training loss decreased (0.25088 --> 0.20604), Acc: (0.80120 --> 0.84940), F1: (0.80357 --> 0.85119).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 17 Train Avg loss: 0.22447, Acc: 0.81325, F1: 0.81548#####> Valid Avg loss: 1.41373, Acc:0.15909, F1: 0.15556
====> Epoch: 18 Train Avg loss: 0.23678, Acc: 0.83133, F1: 0.83333#####> Valid Avg loss: 1.25286, Acc:0.13636, F1: 0.13333
====> Epoch: 19 Train Avg loss: 0.21376, Acc: 0.83735, F1: 0.83929#####> Valid Avg loss: 1.15880, Acc:0.13636, F1: 0.13333

####> Epoch: 19: validation loss decreased (1.17937 --> 1.15880), Acc: (0.09091 --> 0.13636), F1: (0.08889 --> 0.13333).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 20 Train Avg loss: 0.24210, Acc: 0.86145, F1: 0.85119#####> Valid Avg loss: 1.26646, Acc:0.11364, F1: 0.11111
====> Epoch: 21 Train Avg loss: 0.21803, Acc: 0.80723, F1: 0.80952#####> Valid Avg loss: 1.54439, Acc:0.02273, F1: 0.02222
====> Epoch: 22 Train Avg loss: 0.19629, Acc: 0.81928, F1: 0.82143#####> Valid Avg loss: 1.20785, Acc:0.22727, F1: 0.22222
===> Epoch: 22: Training loss decreased (0.20604 --> 0.19629), Acc: (0.84940 --> 0.81928), F1: (0.85119 --> 0.82143).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 23 Train Avg loss: 0.17245, Acc: 0.86145, F1: 0.86310#####> Valid Avg loss: 1.44484, Acc:0.11364, F1: 0.11111
===> Epoch: 23: Training loss decreased (0.19629 --> 0.17245), Acc: (0.81928 --> 0.86145), F1: (0.82143 --> 0.86310).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 24 Train Avg loss: 0.17144, Acc: 0.87349, F1: 0.87500#####> Valid Avg loss: 1.52543, Acc:0.06818, F1: 0.06667
===> Epoch: 24: Training loss decreased (0.17245 --> 0.17144), Acc: (0.86145 --> 0.87349), F1: (0.86310 --> 0.87500).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 25 Train Avg loss: 0.15625, Acc: 0.87349, F1: 0.87500#####> Valid Avg loss: 1.41104, Acc:0.13636, F1: 0.13333
===> Epoch: 25: Training loss decreased (0.17144 --> 0.15625), Acc: (0.87349 --> 0.87349), F1: (0.87500 --> 0.87500).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 26 Train Avg loss: 0.16557, Acc: 0.87952, F1: 0.88095#####> Valid Avg loss: 1.17004, Acc:0.13636, F1: 0.13333
====> Epoch: 27 Train Avg loss: 0.15543, Acc: 0.87952, F1: 0.88095#####> Valid Avg loss: 1.42666, Acc:0.02273, F1: 0.02222
===> Epoch: 27: Training loss decreased (0.15625 --> 0.15543), Acc: (0.87349 --> 0.87952), F1: (0.87500 --> 0.88095).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 28 Train Avg loss: 0.13634, Acc: 0.89759, F1: 0.89881#####> Valid Avg loss: 1.49288, Acc:0.15909, F1: 0.15556
===> Epoch: 28: Training loss decreased (0.15543 --> 0.13634), Acc: (0.87952 --> 0.89759), F1: (0.88095 --> 0.89881).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144809.328709.pth_1
====> Epoch: 29 Train Avg loss: 0.15283, Acc: 0.87349, F1: 0.86310#####> Valid Avg loss: 1.37290, Acc:0.13636, F1: 0.13333
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:2
cnn_out_channel: 16, feature_embed_size:64
lstm_hidden_size: 64
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 4train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 83
valid_dataloader len: 22
test_dataloader len: 15
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 166, train dataloader len: 83
valid dataset len: 44, valid dataloader len: 22
valid dataset len: 29, test dataloader len: 22
====> Epoch: 1 Train Avg loss: 1.62179, Acc: 0.15663, F1: 0.15663#####> Valid Avg loss: 1.70854, Acc:0.25000, F1: 0.25000
===> Epoch: 1: Training loss decreased (inf --> 1.62179), Acc: (0.00000 --> 0.15663), F1: (0.00000 --> 0.15663).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.70854), Acc: (0.00000 --> 0.25000), F1: (0.00000 --> 0.25000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1

####> Epoch: 1: validation acc increase (inf --> 1.70854), Acc: (0.00000 --> 0.25000), F1: (0.00000 --> 0.25000).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 2 Train Avg loss: 1.45181, Acc: 0.25904, F1: 0.25904#####> Valid Avg loss: 1.62822, Acc:0.25000, F1: 0.25000
===> Epoch: 2: Training loss decreased (1.62179 --> 1.45181), Acc: (0.15663 --> 0.25904), F1: (0.15663 --> 0.25904).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1

####> Epoch: 2: validation loss decreased (1.70854 --> 1.62822), Acc: (0.25000 --> 0.25000), F1: (0.25000 --> 0.25000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 3 Train Avg loss: 1.34034, Acc: 0.30120, F1: 0.30120#####> Valid Avg loss: 1.58362, Acc:0.25000, F1: 0.25000
===> Epoch: 3: Training loss decreased (1.45181 --> 1.34034), Acc: (0.25904 --> 0.30120), F1: (0.25904 --> 0.30120).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1

####> Epoch: 3: validation loss decreased (1.62822 --> 1.58362), Acc: (0.25000 --> 0.25000), F1: (0.25000 --> 0.25000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 4 Train Avg loss: 1.30035, Acc: 0.31325, F1: 0.31325#####> Valid Avg loss: 1.52248, Acc:0.25000, F1: 0.25000
===> Epoch: 4: Training loss decreased (1.34034 --> 1.30035), Acc: (0.30120 --> 0.31325), F1: (0.30120 --> 0.31325).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1

####> Epoch: 4: validation loss decreased (1.58362 --> 1.52248), Acc: (0.25000 --> 0.25000), F1: (0.25000 --> 0.25000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 5 Train Avg loss: 1.12863, Acc: 0.38554, F1: 0.38554#####> Valid Avg loss: 1.49280, Acc:0.25000, F1: 0.25000
===> Epoch: 5: Training loss decreased (1.30035 --> 1.12863), Acc: (0.31325 --> 0.38554), F1: (0.31325 --> 0.38554).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1

####> Epoch: 5: validation loss decreased (1.52248 --> 1.49280), Acc: (0.25000 --> 0.25000), F1: (0.25000 --> 0.25000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 6 Train Avg loss: 1.23565, Acc: 0.31928, F1: 0.31928#####> Valid Avg loss: 1.49420, Acc:0.25000, F1: 0.25000
====> Epoch: 7 Train Avg loss: 1.20393, Acc: 0.34940, F1: 0.34940#####> Valid Avg loss: 1.53332, Acc:0.25000, F1: 0.25000
====> Epoch: 8 Train Avg loss: 1.10587, Acc: 0.42771, F1: 0.42771#####> Valid Avg loss: 1.51590, Acc:0.25000, F1: 0.25000
===> Epoch: 8: Training loss decreased (1.12863 --> 1.10587), Acc: (0.38554 --> 0.42771), F1: (0.38554 --> 0.42771).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 9 Train Avg loss: 1.11271, Acc: 0.40361, F1: 0.40361#####> Valid Avg loss: 1.56102, Acc:0.25000, F1: 0.25000
====> Epoch: 10 Train Avg loss: 1.07680, Acc: 0.37952, F1: 0.37952#####> Valid Avg loss: 1.47863, Acc:0.25000, F1: 0.25000
===> Epoch: 10: Training loss decreased (1.10587 --> 1.07680), Acc: (0.42771 --> 0.37952), F1: (0.42771 --> 0.37952).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1

####> Epoch: 10: validation loss decreased (1.49280 --> 1.47863), Acc: (0.25000 --> 0.25000), F1: (0.25000 --> 0.25000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 11 Train Avg loss: 1.13074, Acc: 0.34940, F1: 0.34940#####> Valid Avg loss: 1.47256, Acc:0.25000, F1: 0.25000

####> Epoch: 11: validation loss decreased (1.47863 --> 1.47256), Acc: (0.25000 --> 0.25000), F1: (0.25000 --> 0.25000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 12 Train Avg loss: 1.07356, Acc: 0.37349, F1: 0.37349#####> Valid Avg loss: 1.48777, Acc:0.25000, F1: 0.25000
===> Epoch: 12: Training loss decreased (1.07680 --> 1.07356), Acc: (0.37952 --> 0.37349), F1: (0.37952 --> 0.37349).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 13 Train Avg loss: 1.11509, Acc: 0.42771, F1: 0.42771#####> Valid Avg loss: 1.54395, Acc:0.25000, F1: 0.25000
====> Epoch: 14 Train Avg loss: 1.07683, Acc: 0.34337, F1: 0.34337#####> Valid Avg loss: 1.57984, Acc:0.20455, F1: 0.20455
====> Epoch: 15 Train Avg loss: 1.08523, Acc: 0.38554, F1: 0.38554#####> Valid Avg loss: 1.50395, Acc:0.25000, F1: 0.25000
====> Epoch: 16 Train Avg loss: 1.05488, Acc: 0.39759, F1: 0.39759#####> Valid Avg loss: 1.54839, Acc:0.25000, F1: 0.25000
===> Epoch: 16: Training loss decreased (1.07356 --> 1.05488), Acc: (0.37349 --> 0.39759), F1: (0.37349 --> 0.39759).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 17 Train Avg loss: 1.04503, Acc: 0.45181, F1: 0.45181#####> Valid Avg loss: 1.53521, Acc:0.25000, F1: 0.25000
===> Epoch: 17: Training loss decreased (1.05488 --> 1.04503), Acc: (0.39759 --> 0.45181), F1: (0.39759 --> 0.45181).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 18 Train Avg loss: 1.00080, Acc: 0.49398, F1: 0.49398#####> Valid Avg loss: 1.58795, Acc:0.25000, F1: 0.25000
===> Epoch: 18: Training loss decreased (1.04503 --> 1.00080), Acc: (0.45181 --> 0.49398), F1: (0.45181 --> 0.49398).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 19 Train Avg loss: 1.07868, Acc: 0.42771, F1: 0.42771#####> Valid Avg loss: 1.69600, Acc:0.06818, F1: 0.06818
====> Epoch: 20 Train Avg loss: 0.97102, Acc: 0.51205, F1: 0.51205#####> Valid Avg loss: 1.59236, Acc:0.25000, F1: 0.25000
===> Epoch: 20: Training loss decreased (1.00080 --> 0.97102), Acc: (0.49398 --> 0.51205), F1: (0.49398 --> 0.51205).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600144945.631317.pth_1
====> Epoch: 21 Train Avg loss: 0.99330, Acc: 0.46988, F1: 0.46988#####> Valid Avg loss: 1.60839, Acc:0.18182, F1: 0.18182
====> Epoch: 22 Train Avg loss: 0.96101, Acc: 0.54819, F1: 0.54819validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:2
cnn_out_channel: 16, feature_embed_size:64
lstm_hidden_size: 64
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600145070.13904.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 5train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1255
valid_dataloader len: 416
test_dataloader len: 199
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2510, train dataloader len: 1255
valid dataset len: 832, valid dataloader len: 416
valid dataset len: 398, test dataloader len: 416
====> Epoch: 1 Train Avg loss: 1.33445, Acc: 0.32032, F1: 0.32032#####> Valid Avg loss: 0.99059, Acc:0.51202, F1: 0.51202
===> Epoch: 1: Training loss decreased (inf --> 1.33445), Acc: (0.00000 --> 0.32032), F1: (0.00000 --> 0.32032).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145070.13904.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.99059), Acc: (0.00000 --> 0.51202), F1: (0.00000 --> 0.51202).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145070.13904.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.99059), Acc: (0.00000 --> 0.51202), F1: (0.00000 --> 0.51202).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600145070.13904.pth_1
====> Epoch: 2 Train Avg loss: 1.13748, Acc: 0.45378, F1: 0.45378#####> Valid Avg loss: 1.02151, Acc:0.51202, F1: 0.51202
===> Epoch: 2: Training loss decreased (1.33445 --> 1.13748), Acc: (0.32032 --> 0.45378), F1: (0.32032 --> 0.45378).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145070.13904.pth_1
====> Epoch: 3 Train Avg loss: 1.07258, Acc: 0.46773, F1: 0.46773#####> Valid Avg loss: 0.97009, Acc:0.51202, F1: 0.51202
===> Epoch: 3: Training loss decreased (1.13748 --> 1.07258), Acc: (0.45378 --> 0.46773), F1: (0.45378 --> 0.46773).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145070.13904.pth_1

####> Epoch: 3: validation loss decreased (0.99059 --> 0.97009), Acc: (0.51202 --> 0.51202), F1: (0.51202 --> 0.51202).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145070.13904.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:2
cnn_out_channel: 16, feature_embed_size:64
lstm_hidden_size: 64
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 10train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1306
valid_dataloader len: 438
test_dataloader len: 215
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2612, train dataloader len: 1306
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 429, test dataloader len: 438
====> Epoch: 1 Train Avg loss: 1.32294, Acc: 0.42994, F1: 0.42994#####> Valid Avg loss: 1.12091, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 1.32294), Acc: (0.00000 --> 0.42994), F1: (0.00000 --> 0.42994).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.12091), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1

####> Epoch: 1: validation acc increase (inf --> 1.12091), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 2 Train Avg loss: 1.17941, Acc: 0.49770, F1: 0.49770#####> Valid Avg loss: 1.06915, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (1.32294 --> 1.17941), Acc: (0.42994 --> 0.49770), F1: (0.42994 --> 0.49770).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1

####> Epoch: 2: validation loss decreased (1.12091 --> 1.06915), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 3 Train Avg loss: 1.15184, Acc: 0.49885, F1: 0.49885#####> Valid Avg loss: 1.05901, Acc:0.48630, F1: 0.48630
===> Epoch: 3: Training loss decreased (1.17941 --> 1.15184), Acc: (0.49770 --> 0.49885), F1: (0.49770 --> 0.49885).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1

####> Epoch: 3: validation loss decreased (1.06915 --> 1.05901), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 4 Train Avg loss: 1.10352, Acc: 0.50574, F1: 0.50574#####> Valid Avg loss: 1.05147, Acc:0.48630, F1: 0.48630
===> Epoch: 4: Training loss decreased (1.15184 --> 1.10352), Acc: (0.49885 --> 0.50574), F1: (0.49885 --> 0.50574).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1

####> Epoch: 4: validation loss decreased (1.05901 --> 1.05147), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 5 Train Avg loss: 1.08463, Acc: 0.51455, F1: 0.51455#####> Valid Avg loss: 1.04456, Acc:0.48630, F1: 0.48630
===> Epoch: 5: Training loss decreased (1.10352 --> 1.08463), Acc: (0.50574 --> 0.51455), F1: (0.50574 --> 0.51455).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1

####> Epoch: 5: validation loss decreased (1.05147 --> 1.04456), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 6 Train Avg loss: 1.06859, Acc: 0.51608, F1: 0.51608#####> Valid Avg loss: 1.00262, Acc:0.48630, F1: 0.48630
===> Epoch: 6: Training loss decreased (1.08463 --> 1.06859), Acc: (0.51455 --> 0.51608), F1: (0.51455 --> 0.51608).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1

####> Epoch: 6: validation loss decreased (1.04456 --> 1.00262), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 7 Train Avg loss: 1.03439, Acc: 0.52986, F1: 0.52986#####> Valid Avg loss: 1.00966, Acc:0.48630, F1: 0.48630
===> Epoch: 7: Training loss decreased (1.06859 --> 1.03439), Acc: (0.51608 --> 0.52986), F1: (0.51608 --> 0.52986).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 8 Train Avg loss: 1.03100, Acc: 0.51914, F1: 0.51914#####> Valid Avg loss: 0.98880, Acc:0.48630, F1: 0.48630
===> Epoch: 8: Training loss decreased (1.03439 --> 1.03100), Acc: (0.52986 --> 0.51914), F1: (0.52986 --> 0.51914).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1

####> Epoch: 8: validation loss decreased (1.00262 --> 0.98880), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 9 Train Avg loss: 1.00377, Acc: 0.53560, F1: 0.53560#####> Valid Avg loss: 0.97455, Acc:0.48630, F1: 0.48630
===> Epoch: 9: Training loss decreased (1.03100 --> 1.00377), Acc: (0.51914 --> 0.53560), F1: (0.51914 --> 0.53560).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1

####> Epoch: 9: validation loss decreased (0.98880 --> 0.97455), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 10 Train Avg loss: 1.00246, Acc: 0.53331, F1: 0.53331#####> Valid Avg loss: 0.98179, Acc:0.48630, F1: 0.48630
===> Epoch: 10: Training loss decreased (1.00377 --> 1.00246), Acc: (0.53560 --> 0.53331), F1: (0.53560 --> 0.53331).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 11 Train Avg loss: 0.98355, Acc: 0.53828, F1: 0.53828#####> Valid Avg loss: 0.97746, Acc:0.48630, F1: 0.48630
===> Epoch: 11: Training loss decreased (1.00246 --> 0.98355), Acc: (0.53331 --> 0.53828), F1: (0.53331 --> 0.53828).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
====> Epoch: 12 Train Avg loss: 0.97051, Acc: 0.54518, F1: 0.54518#####> Valid Avg loss: 0.97566, Acc:0.48630, F1: 0.48630
===> Epoch: 12: Training loss decreased (0.98355 --> 0.97051), Acc: (0.53828 --> 0.54518), F1: (0.53828 --> 0.54518).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145254.666951.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:2
cnn_out_channel: 16, feature_embed_size:64
lstm_hidden_size: 64
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600145787.585398.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 5train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1255
valid_dataloader len: 416
test_dataloader len: 199
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2510, train dataloader len: 1255
valid dataset len: 832, valid dataloader len: 416
valid dataset len: 398, test dataloader len: 416
====> Epoch: 1 Train Avg loss: 1.33460, Acc: 0.36853, F1: 0.36853#####> Valid Avg loss: 1.13660, Acc:0.51202, F1: 0.51202
===> Epoch: 1: Training loss decreased (inf --> 1.33460), Acc: (0.00000 --> 0.36853), F1: (0.00000 --> 0.36853).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145787.585398.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.13660), Acc: (0.00000 --> 0.51202), F1: (0.00000 --> 0.51202).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145787.585398.pth_1

####> Epoch: 1: validation acc increase (inf --> 1.13660), Acc: (0.00000 --> 0.51202), F1: (0.00000 --> 0.51202).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600145787.585398.pth_1
====> Epoch: 2 Train Avg loss: 1.20144, Acc: 0.45976, F1: 0.45976#####> Valid Avg loss: 1.05822, Acc:0.51202, F1: 0.51202
===> Epoch: 2: Training loss decreased (1.33460 --> 1.20144), Acc: (0.36853 --> 0.45976), F1: (0.36853 --> 0.45976).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145787.585398.pth_1

####> Epoch: 2: validation loss decreased (1.13660 --> 1.05822), Acc: (0.51202 --> 0.51202), F1: (0.51202 --> 0.51202).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145787.585398.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.01, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:64
lstm_hidden_size: 64
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 5train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1255
valid_dataloader len: 416
test_dataloader len: 199
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2510, train dataloader len: 1255
valid dataset len: 832, valid dataloader len: 416
valid dataset len: 398, test dataloader len: 416
====> Epoch: 1 Train Avg loss: 0.80691, Acc: 0.54064, F1: 0.54064#####> Valid Avg loss: 0.61887, Acc:0.51202, F1: 0.51202
===> Epoch: 1: Training loss decreased (inf --> 0.80691), Acc: (0.00000 --> 0.54064), F1: (0.00000 --> 0.54064).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.61887), Acc: (0.00000 --> 0.51202), F1: (0.00000 --> 0.51202).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.61887), Acc: (0.00000 --> 0.51202), F1: (0.00000 --> 0.51202).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1
====> Epoch: 2 Train Avg loss: 0.67598, Acc: 0.56534, F1: 0.56534#####> Valid Avg loss: 0.64436, Acc:0.51202, F1: 0.51202
===> Epoch: 2: Training loss decreased (0.80691 --> 0.67598), Acc: (0.54064 --> 0.56534), F1: (0.54064 --> 0.56534).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1
====> Epoch: 3 Train Avg loss: 0.65335, Acc: 0.55737, F1: 0.55737#####> Valid Avg loss: 0.66027, Acc:0.51202, F1: 0.51202
===> Epoch: 3: Training loss decreased (0.67598 --> 0.65335), Acc: (0.56534 --> 0.55737), F1: (0.56534 --> 0.55737).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1
====> Epoch: 4 Train Avg loss: 0.65126, Acc: 0.56295, F1: 0.56295#####> Valid Avg loss: 0.66481, Acc:0.51202, F1: 0.51202
===> Epoch: 4: Training loss decreased (0.65335 --> 0.65126), Acc: (0.55737 --> 0.56295), F1: (0.55737 --> 0.56295).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1
====> Epoch: 5 Train Avg loss: 0.64820, Acc: 0.56733, F1: 0.56733#####> Valid Avg loss: 0.62839, Acc:0.51202, F1: 0.51202
===> Epoch: 5: Training loss decreased (0.65126 --> 0.64820), Acc: (0.56295 --> 0.56733), F1: (0.56295 --> 0.56733).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1
====> Epoch: 6 Train Avg loss: 0.64900, Acc: 0.55817, F1: 0.55817#####> Valid Avg loss: 0.63008, Acc:0.51202, F1: 0.51202
====> Epoch: 7 Train Avg loss: 0.64748, Acc: 0.56693, F1: 0.56693#####> Valid Avg loss: 0.60975, Acc:0.51202, F1: 0.51202
===> Epoch: 7: Training loss decreased (0.64820 --> 0.64748), Acc: (0.56733 --> 0.56693), F1: (0.56733 --> 0.56693).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1

####> Epoch: 7: validation loss decreased (0.61887 --> 0.60975), Acc: (0.51202 --> 0.51202), F1: (0.51202 --> 0.51202).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1
====> Epoch: 8 Train Avg loss: 0.64330, Acc: 0.56773, F1: 0.56773#####> Valid Avg loss: 0.63469, Acc:0.51202, F1: 0.51202
===> Epoch: 8: Training loss decreased (0.64748 --> 0.64330), Acc: (0.56693 --> 0.56773), F1: (0.56693 --> 0.56773).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1
====> Epoch: 9 Train Avg loss: 0.63933, Acc: 0.56614, F1: 0.56614#####> Valid Avg loss: 0.61404, Acc:0.51202, F1: 0.51202
===> Epoch: 9: Training loss decreased (0.64330 --> 0.63933), Acc: (0.56773 --> 0.56614), F1: (0.56773 --> 0.56614).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600145892.283419.pth_1
====> Epoch: 10 Train Avg loss: 0.64163, Acc: 0.56534, F1: 0.56534#####> Valid Avg loss: 0.61485, Acc:0.51202, F1: 0.51202
====> Epoch: 11 Train Avg loss: 0.64484, Acc: 0.56733, F1: 0.56733#####> Valid Avg loss: 0.63544, Acc:0.51202, F1: 0.51202
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.01, epoch:500, batch_size:2
cnn_out_channel: 32, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann/fe_embed
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600146331.240192.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 14train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3411
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6822, train dataloader len: 3411
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
====> Epoch: 1 Train Avg loss: 2.43412, Acc: 0.13105, F1: 0.13105#####> Valid Avg loss: 2.93483, Acc:0.00000, F1: 0.00000
===> Epoch: 1: Training loss decreased (inf --> 2.43412), Acc: (0.00000 --> 0.13105), F1: (0.00000 --> 0.13105).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600146331.240192.pth_1

####> Epoch: 1: validation loss decreased (inf --> 2.93483), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600146331.240192.pth_1
====> Epoch: 2 Train Avg loss: 2.23365, Acc: 0.18220, F1: 0.18220#####> Valid Avg loss: 2.94516, Acc:0.00000, F1: 0.00000
===> Epoch: 2: Training loss decreased (2.43412 --> 2.23365), Acc: (0.13105 --> 0.18220), F1: (0.13105 --> 0.18220).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600146331.240192.pth_1
====> Epoch: 3 Train Avg loss: 2.23376, Acc: 0.17517, F1: 0.17517#####> Valid Avg loss: 2.94639, Acc:0.00000, F1: 0.00000
====> Epoch: 4 Train Avg loss: 2.23346, Acc: 0.17561, F1: 0.17561#####> Valid Avg loss: 2.90990, Acc:0.00000, F1: 0.00000
===> Epoch: 4: Training loss decreased (2.23365 --> 2.23346), Acc: (0.18220 --> 0.17561), F1: (0.18220 --> 0.17561).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600146331.240192.pth_1

####> Epoch: 4: validation loss decreased (2.93483 --> 2.90990), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600146331.240192.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.01, epoch:500, batch_size:2
cnn_out_channel: 32, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann/fe_embed
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600146975.866816.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 4train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1297
valid_dataloader len: 455
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2593, train dataloader len: 1297
valid dataset len: 910, valid dataloader len: 455
valid dataset len: 428, test dataloader len: 455
====> Epoch: 1 Train Avg loss: 1.40736, Acc: 0.56151, F1: 0.56130#####> Valid Avg loss: 1.74764, Acc:0.50110, F1: 0.50110
===> Epoch: 1: Training loss decreased (inf --> 1.40736), Acc: (0.00000 --> 0.56151), F1: (0.00000 --> 0.56130).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600146975.866816.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.74764), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600146975.866816.pth_1

####> Epoch: 1: validation acc increase (inf --> 1.74764), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600146975.866816.pth_1
====> Epoch: 2 Train Avg loss: 1.26317, Acc: 0.58465, F1: 0.58443#####> Valid Avg loss: 1.72630, Acc:0.50110, F1: 0.50110
===> Epoch: 2: Training loss decreased (1.40736 --> 1.26317), Acc: (0.56151 --> 0.58465), F1: (0.56130 --> 0.58443).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600146975.866816.pth_1

####> Epoch: 2: validation loss decreased (1.74764 --> 1.72630), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600146975.866816.pth_1
====> Epoch: 3 Train Avg loss: 1.25877, Acc: 0.57964, F1: 0.57980#####> Valid Avg loss: 1.64837, Acc:0.50110, F1: 0.50110
===> Epoch: 3: Training loss decreased (1.26317 --> 1.25877), Acc: (0.58465 --> 0.57964), F1: (0.58443 --> 0.57980).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600146975.866816.pth_1

####> Epoch: 3: validation loss decreased (1.72630 --> 1.64837), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600146975.866816.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:10
cnn_out_channel: 16, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann/fe_embed
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 4train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 260
valid_dataloader len: 91
test_dataloader len: 43
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2593, train dataloader len: 260
valid dataset len: 910, valid dataloader len: 91
valid dataset len: 428, test dataloader len: 91
====> Epoch: 1 Train Avg loss: 0.34279, Acc: 0.47860, F1: 0.47821#####> Valid Avg loss: 0.22189, Acc:0.50110, F1: 0.50110
===> Epoch: 1: Training loss decreased (inf --> 0.34279), Acc: (0.00000 --> 0.47860), F1: (0.00000 --> 0.47821).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.22189), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.22189), Acc: (0.00000 --> 0.50110), F1: (0.00000 --> 0.50110).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth_1
====> Epoch: 2 Train Avg loss: 0.24930, Acc: 0.51253, F1: 0.51295#####> Valid Avg loss: 0.19682, Acc:0.50110, F1: 0.50110
===> Epoch: 2: Training loss decreased (0.34279 --> 0.24930), Acc: (0.47860 --> 0.51253), F1: (0.47821 --> 0.51295).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth_1

####> Epoch: 2: validation loss decreased (0.22189 --> 0.19682), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth_1
====> Epoch: 3 Train Avg loss: 0.23110, Acc: 0.53374, F1: 0.53410#####> Valid Avg loss: 0.19587, Acc:0.50110, F1: 0.50110
===> Epoch: 3: Training loss decreased (0.24930 --> 0.23110), Acc: (0.51253 --> 0.53374), F1: (0.51295 --> 0.53410).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth_1

####> Epoch: 3: validation loss decreased (0.19682 --> 0.19587), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth_1
====> Epoch: 4 Train Avg loss: 0.22308, Acc: 0.52102, F1: 0.52051#####> Valid Avg loss: 0.17609, Acc:0.50110, F1: 0.50110
===> Epoch: 4: Training loss decreased (0.23110 --> 0.22308), Acc: (0.53374 --> 0.52102), F1: (0.53410 --> 0.52051).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth_1

####> Epoch: 4: validation loss decreased (0.19587 --> 0.17609), Acc: (0.50110 --> 0.50110), F1: (0.50110 --> 0.50110).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147155.558811.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:10
cnn_out_channel: 16, feature_embed_size:512
lstm_hidden_size: 512
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 4train person_ids: [ 1  2  4  5  6  8  7  9 10 11 12 14 15 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 7
valid_dataloader len: 4
test_dataloader len: 2
train performers ids: [4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 64, train dataloader len: 7
valid dataset len: 33, valid dataloader len: 4
valid dataset len: 17, test dataloader len: 4
====> Epoch: 1 Train Avg loss: 0.64816, Acc: 0.01562, F1: 0.03571#####> Valid Avg loss: 0.65304, Acc:0.00000, F1: 0.00000
===> Epoch: 1: Training loss decreased (inf --> 0.64816), Acc: (0.00000 --> 0.01562), F1: (0.00000 --> 0.03571).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.65304), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 2 Train Avg loss: 0.52053, Acc: 0.10938, F1: 0.12143#####> Valid Avg loss: 0.64838, Acc:0.00000, F1: 0.00000
===> Epoch: 2: Training loss decreased (0.64816 --> 0.52053), Acc: (0.01562 --> 0.10938), F1: (0.03571 --> 0.12143).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 2: validation loss decreased (0.65304 --> 0.64838), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 3 Train Avg loss: 0.40024, Acc: 0.28125, F1: 0.27857#####> Valid Avg loss: 0.63888, Acc:0.00000, F1: 0.00000
===> Epoch: 3: Training loss decreased (0.52053 --> 0.40024), Acc: (0.10938 --> 0.28125), F1: (0.12143 --> 0.27857).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 3: validation loss decreased (0.64838 --> 0.63888), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 4 Train Avg loss: 0.30018, Acc: 0.56250, F1: 0.53571#####> Valid Avg loss: 0.61933, Acc:0.00000, F1: 0.00000
===> Epoch: 4: Training loss decreased (0.40024 --> 0.30018), Acc: (0.28125 --> 0.56250), F1: (0.27857 --> 0.53571).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 4: validation loss decreased (0.63888 --> 0.61933), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 5 Train Avg loss: 0.26136, Acc: 0.62500, F1: 0.65714#####> Valid Avg loss: 0.59464, Acc:0.00000, F1: 0.00000
===> Epoch: 5: Training loss decreased (0.30018 --> 0.26136), Acc: (0.56250 --> 0.62500), F1: (0.53571 --> 0.65714).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 5: validation loss decreased (0.61933 --> 0.59464), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 6 Train Avg loss: 0.28121, Acc: 0.67188, F1: 0.63571#####> Valid Avg loss: 0.57654, Acc:0.00000, F1: 0.00000

####> Epoch: 6: validation loss decreased (0.59464 --> 0.57654), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 7 Train Avg loss: 0.25930, Acc: 0.70312, F1: 0.70714#####> Valid Avg loss: 0.56904, Acc:0.00000, F1: 0.00000
===> Epoch: 7: Training loss decreased (0.26136 --> 0.25930), Acc: (0.62500 --> 0.70312), F1: (0.65714 --> 0.70714).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 7: validation loss decreased (0.57654 --> 0.56904), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 8 Train Avg loss: 0.21177, Acc: 0.75000, F1: 0.77143#####> Valid Avg loss: 0.58050, Acc:0.00000, F1: 0.00000
===> Epoch: 8: Training loss decreased (0.25930 --> 0.21177), Acc: (0.70312 --> 0.75000), F1: (0.70714 --> 0.77143).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 9 Train Avg loss: 0.24255, Acc: 0.78125, F1: 0.75714#####> Valid Avg loss: 0.59266, Acc:0.00000, F1: 0.00000
====> Epoch: 10 Train Avg loss: 0.23215, Acc: 0.76562, F1: 0.76429#####> Valid Avg loss: 0.58248, Acc:0.00000, F1: 0.00000
====> Epoch: 11 Train Avg loss: 0.24396, Acc: 0.73438, F1: 0.71429#####> Valid Avg loss: 0.57368, Acc:0.00000, F1: 0.00000
====> Epoch: 12 Train Avg loss: 0.19419, Acc: 0.78125, F1: 0.80000#####> Valid Avg loss: 0.56213, Acc:0.00000, F1: 0.00000
===> Epoch: 12: Training loss decreased (0.21177 --> 0.19419), Acc: (0.75000 --> 0.78125), F1: (0.77143 --> 0.80000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 12: validation loss decreased (0.56904 --> 0.56213), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 13 Train Avg loss: 0.21484, Acc: 0.76562, F1: 0.76429#####> Valid Avg loss: 0.56605, Acc:0.00000, F1: 0.00000
====> Epoch: 14 Train Avg loss: 0.21080, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.53919, Acc:0.00000, F1: 0.00000

####> Epoch: 14: validation loss decreased (0.56213 --> 0.53919), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 15 Train Avg loss: 0.25441, Acc: 0.70312, F1: 0.68571#####> Valid Avg loss: 0.54631, Acc:0.00000, F1: 0.00000
====> Epoch: 16 Train Avg loss: 0.24766, Acc: 0.76562, F1: 0.74286#####> Valid Avg loss: 0.54550, Acc:0.00000, F1: 0.00000
====> Epoch: 17 Train Avg loss: 0.19815, Acc: 0.76562, F1: 0.78571#####> Valid Avg loss: 0.52849, Acc:0.00000, F1: 0.00000

####> Epoch: 17: validation loss decreased (0.53919 --> 0.52849), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 18 Train Avg loss: 0.20649, Acc: 0.76562, F1: 0.72143#####> Valid Avg loss: 0.52814, Acc:0.00000, F1: 0.00000

####> Epoch: 18: validation loss decreased (0.52849 --> 0.52814), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 19 Train Avg loss: 0.18917, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.51987, Acc:0.00000, F1: 0.00000
===> Epoch: 19: Training loss decreased (0.19419 --> 0.18917), Acc: (0.78125 --> 0.78125), F1: (0.80000 --> 0.77857).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 19: validation loss decreased (0.52814 --> 0.51987), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 20 Train Avg loss: 0.19103, Acc: 0.78125, F1: 0.80000#####> Valid Avg loss: 0.51562, Acc:0.00000, F1: 0.00000

####> Epoch: 20: validation loss decreased (0.51987 --> 0.51562), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 21 Train Avg loss: 0.19466, Acc: 0.75000, F1: 0.77143#####> Valid Avg loss: 0.52788, Acc:0.00000, F1: 0.00000
====> Epoch: 22 Train Avg loss: 0.20192, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.52850, Acc:0.00000, F1: 0.00000
====> Epoch: 23 Train Avg loss: 0.20262, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.51937, Acc:0.00000, F1: 0.00000
====> Epoch: 24 Train Avg loss: 0.18648, Acc: 0.78125, F1: 0.75714#####> Valid Avg loss: 0.49268, Acc:0.00000, F1: 0.00000
===> Epoch: 24: Training loss decreased (0.18917 --> 0.18648), Acc: (0.78125 --> 0.78125), F1: (0.77857 --> 0.75714).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 24: validation loss decreased (0.51562 --> 0.49268), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 25 Train Avg loss: 0.17533, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.45040, Acc:0.00000, F1: 0.00000
===> Epoch: 25: Training loss decreased (0.18648 --> 0.17533), Acc: (0.78125 --> 0.78125), F1: (0.75714 --> 0.77857).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 25: validation loss decreased (0.49268 --> 0.45040), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 26 Train Avg loss: 0.17416, Acc: 0.76562, F1: 0.78571#####> Valid Avg loss: 0.44574, Acc:0.00000, F1: 0.00000
===> Epoch: 26: Training loss decreased (0.17533 --> 0.17416), Acc: (0.78125 --> 0.76562), F1: (0.77857 --> 0.78571).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 26: validation loss decreased (0.45040 --> 0.44574), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 27 Train Avg loss: 0.18364, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.47017, Acc:0.00000, F1: 0.00000
====> Epoch: 28 Train Avg loss: 0.17233, Acc: 0.76562, F1: 0.76429#####> Valid Avg loss: 0.46942, Acc:0.00000, F1: 0.00000
===> Epoch: 28: Training loss decreased (0.17416 --> 0.17233), Acc: (0.76562 --> 0.76562), F1: (0.78571 --> 0.76429).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 29 Train Avg loss: 0.17272, Acc: 0.75000, F1: 0.77143#####> Valid Avg loss: 0.47788, Acc:0.00000, F1: 0.00000
====> Epoch: 30 Train Avg loss: 0.17792, Acc: 0.78125, F1: 0.80000#####> Valid Avg loss: 0.47034, Acc:0.00000, F1: 0.00000
====> Epoch: 31 Train Avg loss: 0.15771, Acc: 0.78125, F1: 0.75714#####> Valid Avg loss: 0.46547, Acc:0.00000, F1: 0.00000
===> Epoch: 31: Training loss decreased (0.17233 --> 0.15771), Acc: (0.76562 --> 0.78125), F1: (0.76429 --> 0.75714).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 32 Train Avg loss: 0.15538, Acc: 0.78125, F1: 0.80000#####> Valid Avg loss: 0.45939, Acc:0.00000, F1: 0.00000
===> Epoch: 32: Training loss decreased (0.15771 --> 0.15538), Acc: (0.78125 --> 0.78125), F1: (0.75714 --> 0.80000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 33 Train Avg loss: 0.15132, Acc: 0.79688, F1: 0.77143#####> Valid Avg loss: 0.46678, Acc:0.00000, F1: 0.00000
===> Epoch: 33: Training loss decreased (0.15538 --> 0.15132), Acc: (0.78125 --> 0.79688), F1: (0.80000 --> 0.77143).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 34 Train Avg loss: 0.15667, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.44267, Acc:0.00000, F1: 0.00000

####> Epoch: 34: validation loss decreased (0.44574 --> 0.44267), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 35 Train Avg loss: 0.15724, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.43728, Acc:0.00000, F1: 0.00000

####> Epoch: 35: validation loss decreased (0.44267 --> 0.43728), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 36 Train Avg loss: 0.16692, Acc: 0.76562, F1: 0.74286#####> Valid Avg loss: 0.43891, Acc:0.00000, F1: 0.00000
====> Epoch: 37 Train Avg loss: 0.15836, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.44596, Acc:0.00000, F1: 0.00000
====> Epoch: 38 Train Avg loss: 0.17752, Acc: 0.75000, F1: 0.72857#####> Valid Avg loss: 0.44495, Acc:0.00000, F1: 0.00000
====> Epoch: 39 Train Avg loss: 0.13670, Acc: 0.78125, F1: 0.80000#####> Valid Avg loss: 0.44182, Acc:0.00000, F1: 0.00000
===> Epoch: 39: Training loss decreased (0.15132 --> 0.13670), Acc: (0.79688 --> 0.78125), F1: (0.77143 --> 0.80000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 40 Train Avg loss: 0.16744, Acc: 0.79688, F1: 0.79286#####> Valid Avg loss: 0.45848, Acc:0.00000, F1: 0.00000
====> Epoch: 41 Train Avg loss: 0.15216, Acc: 0.78125, F1: 0.80000#####> Valid Avg loss: 0.45594, Acc:0.00000, F1: 0.00000
====> Epoch: 42 Train Avg loss: 0.15626, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.43399, Acc:0.00000, F1: 0.00000

####> Epoch: 42: validation loss decreased (0.43728 --> 0.43399), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 43 Train Avg loss: 0.13293, Acc: 0.81250, F1: 0.82857#####> Valid Avg loss: 0.41143, Acc:0.00000, F1: 0.00000
===> Epoch: 43: Training loss decreased (0.13670 --> 0.13293), Acc: (0.78125 --> 0.81250), F1: (0.80000 --> 0.82857).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 43: validation loss decreased (0.43399 --> 0.41143), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 44 Train Avg loss: 0.14365, Acc: 0.81250, F1: 0.80714#####> Valid Avg loss: 0.40995, Acc:0.00000, F1: 0.00000

####> Epoch: 44: validation loss decreased (0.41143 --> 0.40995), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 45 Train Avg loss: 0.15110, Acc: 0.78125, F1: 0.80000#####> Valid Avg loss: 0.41942, Acc:0.00000, F1: 0.00000
====> Epoch: 46 Train Avg loss: 0.18120, Acc: 0.79688, F1: 0.77143#####> Valid Avg loss: 0.43524, Acc:0.00000, F1: 0.00000
====> Epoch: 47 Train Avg loss: 0.16031, Acc: 0.75000, F1: 0.72857#####> Valid Avg loss: 0.42793, Acc:0.00000, F1: 0.00000
====> Epoch: 48 Train Avg loss: 0.14378, Acc: 0.79688, F1: 0.79286#####> Valid Avg loss: 0.42291, Acc:0.00000, F1: 0.00000
====> Epoch: 49 Train Avg loss: 0.16143, Acc: 0.78125, F1: 0.75714#####> Valid Avg loss: 0.42116, Acc:0.00000, F1: 0.00000
====> Epoch: 50 Train Avg loss: 0.13421, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.42119, Acc:0.00000, F1: 0.00000
====> Epoch: 51 Train Avg loss: 0.15156, Acc: 0.78125, F1: 0.75714#####> Valid Avg loss: 0.41955, Acc:0.00000, F1: 0.00000
====> Epoch: 52 Train Avg loss: 0.13923, Acc: 0.79688, F1: 0.81429#####> Valid Avg loss: 0.41469, Acc:0.00000, F1: 0.00000
====> Epoch: 53 Train Avg loss: 0.14375, Acc: 0.79688, F1: 0.79286#####> Valid Avg loss: 0.41652, Acc:0.00000, F1: 0.00000
====> Epoch: 54 Train Avg loss: 0.13216, Acc: 0.81250, F1: 0.78571#####> Valid Avg loss: 0.41729, Acc:0.00000, F1: 0.00000
===> Epoch: 54: Training loss decreased (0.13293 --> 0.13216), Acc: (0.81250 --> 0.81250), F1: (0.82857 --> 0.78571).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 55 Train Avg loss: 0.13109, Acc: 0.79688, F1: 0.79286#####> Valid Avg loss: 0.40852, Acc:0.00000, F1: 0.00000
===> Epoch: 55: Training loss decreased (0.13216 --> 0.13109), Acc: (0.81250 --> 0.79688), F1: (0.78571 --> 0.79286).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1

####> Epoch: 55: validation loss decreased (0.40995 --> 0.40852), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 56 Train Avg loss: 0.13749, Acc: 0.87500, F1: 0.88571#####> Valid Avg loss: 0.40462, Acc:0.00000, F1: 0.00000

####> Epoch: 56: validation loss decreased (0.40852 --> 0.40462), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 57 Train Avg loss: 0.12505, Acc: 0.85938, F1: 0.85000#####> Valid Avg loss: 0.41671, Acc:0.00000, F1: 0.00000
===> Epoch: 57: Training loss decreased (0.13109 --> 0.12505), Acc: (0.79688 --> 0.85938), F1: (0.79286 --> 0.85000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 58 Train Avg loss: 0.15135, Acc: 0.78125, F1: 0.75714#####> Valid Avg loss: 0.43511, Acc:0.00000, F1: 0.00000
====> Epoch: 59 Train Avg loss: 0.11702, Acc: 0.85938, F1: 0.87143#####> Valid Avg loss: 0.43694, Acc:0.00000, F1: 0.00000
===> Epoch: 59: Training loss decreased (0.12505 --> 0.11702), Acc: (0.85938 --> 0.85938), F1: (0.85000 --> 0.87143).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 60 Train Avg loss: 0.11872, Acc: 0.85938, F1: 0.87143#####> Valid Avg loss: 0.42924, Acc:0.00000, F1: 0.00000
====> Epoch: 61 Train Avg loss: 0.10327, Acc: 0.79688, F1: 0.81429#####> Valid Avg loss: 0.42877, Acc:0.00000, F1: 0.00000
===> Epoch: 61: Training loss decreased (0.11702 --> 0.10327), Acc: (0.85938 --> 0.79688), F1: (0.87143 --> 0.81429).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 62 Train Avg loss: 0.12115, Acc: 0.82812, F1: 0.84286#####> Valid Avg loss: 0.42584, Acc:0.00000, F1: 0.00000
====> Epoch: 63 Train Avg loss: 0.13706, Acc: 0.82812, F1: 0.82143#####> Valid Avg loss: 0.41776, Acc:0.00000, F1: 0.00000
====> Epoch: 64 Train Avg loss: 0.11118, Acc: 0.87500, F1: 0.88571#####> Valid Avg loss: 0.41392, Acc:0.00000, F1: 0.00000
====> Epoch: 65 Train Avg loss: 0.12134, Acc: 0.85938, F1: 0.85000#####> Valid Avg loss: 0.40850, Acc:0.00000, F1: 0.00000
====> Epoch: 66 Train Avg loss: 0.13610, Acc: 0.81250, F1: 0.82857#####> Valid Avg loss: 0.41092, Acc:0.00000, F1: 0.00000
====> Epoch: 67 Train Avg loss: 0.14790, Acc: 0.82812, F1: 0.82143#####> Valid Avg loss: 0.42046, Acc:0.00000, F1: 0.00000
====> Epoch: 68 Train Avg loss: 0.12754, Acc: 0.81250, F1: 0.80714#####> Valid Avg loss: 0.43093, Acc:0.00000, F1: 0.00000
====> Epoch: 69 Train Avg loss: 0.12322, Acc: 0.81250, F1: 0.82857#####> Valid Avg loss: 0.43405, Acc:0.00000, F1: 0.00000
====> Epoch: 70 Train Avg loss: 0.12901, Acc: 0.82812, F1: 0.84286#####> Valid Avg loss: 0.42857, Acc:0.00000, F1: 0.00000
====> Epoch: 71 Train Avg loss: 0.11061, Acc: 0.85938, F1: 0.87143#####> Valid Avg loss: 0.42768, Acc:0.00000, F1: 0.00000
====> Epoch: 72 Train Avg loss: 0.11665, Acc: 0.81250, F1: 0.82857#####> Valid Avg loss: 0.42102, Acc:0.00000, F1: 0.00000
====> Epoch: 73 Train Avg loss: 0.11273, Acc: 0.84375, F1: 0.85714#####> Valid Avg loss: 0.41885, Acc:0.00000, F1: 0.00000
====> Epoch: 74 Train Avg loss: 0.10535, Acc: 0.82812, F1: 0.84286#####> Valid Avg loss: 0.41807, Acc:0.00000, F1: 0.00000
====> Epoch: 75 Train Avg loss: 0.11169, Acc: 0.84375, F1: 0.83571#####> Valid Avg loss: 0.41659, Acc:0.00000, F1: 0.00000
====> Epoch: 76 Train Avg loss: 0.11464, Acc: 0.85938, F1: 0.87143#####> Valid Avg loss: 0.41799, Acc:0.00000, F1: 0.00000
====> Epoch: 77 Train Avg loss: 0.11630, Acc: 0.84375, F1: 0.83571#####> Valid Avg loss: 0.41740, Acc:0.00000, F1: 0.00000
====> Epoch: 78 Train Avg loss: 0.11790, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.41750, Acc:0.00000, F1: 0.00000
====> Epoch: 79 Train Avg loss: 0.12163, Acc: 0.82812, F1: 0.82143#####> Valid Avg loss: 0.41563, Acc:0.00000, F1: 0.00000
====> Epoch: 80 Train Avg loss: 0.13872, Acc: 0.81250, F1: 0.78571#####> Valid Avg loss: 0.41477, Acc:0.00000, F1: 0.00000
====> Epoch: 81 Train Avg loss: 0.10829, Acc: 0.82812, F1: 0.80000#####> Valid Avg loss: 0.41340, Acc:0.00000, F1: 0.00000
====> Epoch: 82 Train Avg loss: 0.10639, Acc: 0.84375, F1: 0.85714#####> Valid Avg loss: 0.41087, Acc:0.00000, F1: 0.00000
====> Epoch: 83 Train Avg loss: 0.09480, Acc: 0.85938, F1: 0.87143#####> Valid Avg loss: 0.40885, Acc:0.00000, F1: 0.00000
===> Epoch: 83: Training loss decreased (0.10327 --> 0.09480), Acc: (0.79688 --> 0.85938), F1: (0.81429 --> 0.87143).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147352.310626.pth_1
====> Epoch: 84 Train Avg loss: 0.11931, Acc: 0.81250, F1: 0.78571#####> Valid Avg loss: 0.41023, Acc:0.00000, F1: 0.00000
====> Epoch: 85 Train Avg loss: 0.12604, Acc: 0.81250, F1: 0.80714#####> Valid Avg loss: 0.41069, Acc:0.00000, F1: 0.00000
====> Epoch: 86 Train Avg loss: 0.10376, Acc: 0.84375, F1: 0.83571#####> Valid Avg loss: 0.41091, Acc:0.00000, F1: 0.00000
====> Epoch: 87 Train Avg loss: 0.12223, Acc: 0.78125, F1: 0.77857#####> Valid Avg loss: 0.40942, Acc:0.00000, F1: 0.00000
====> Epoch: 88 Train Avg loss: 0.10560, Acc: 0.84375, F1: 0.85714#####> Valid Avg loss: 0.40943, Acc:0.00000, F1: 0.00000
====> Epoch: 89 Train Avg loss: 0.11444, Acc: 0.87500, F1: 0.88571#####> Valid Avg loss: 0.41057, Acc:0.00000, F1: 0.00000
====> Epoch: 90 Train Avg loss: 0.10258, Acc: 0.84375, F1: 0.83571#####> Valid Avg loss: 0.41122, Acc:0.00000, F1: 0.00000
====> Epoch: 91 Train Avg loss: 0.12027, Acc: 0.79688, F1: 0.81429#####> Valid Avg loss: 0.41191, Acc:0.00000, F1: 0.00000
====> Epoch: 92 Train Avg loss: 0.11537, Acc: 0.87500, F1: 0.86429#####> Valid Avg loss: 0.41235, Acc:0.00000, F1: 0.00000
====> Epoch: 93 Train Avg loss: 0.10450, Acc: 0.84375, F1: 0.83571#####> Valid Avg loss: 0.41254, Acc:0.00000, F1: 0.00000
====> Epoch: 94 Train Avg loss: 0.12765, Acc: 0.81250, F1: 0.82857#####> Valid Avg loss: 0.41267, Acc:0.00000, F1: 0.00000
====> Epoch: 95 Train Avg loss: 0.11407, Acc: 0.82812, F1: 0.84286#####> Valid Avg loss: 0.41246, Acc:0.00000, F1: 0.00000
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:2
cnn_out_channel: 16, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600147526.541391.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 4train person_ids: [ 1  2  4  5  6  8  7  9 10 11 12 14 15 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 32
valid_dataloader len: 17
test_dataloader len: 9
train performers ids: [4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 64, train dataloader len: 32
valid dataset len: 33, valid dataloader len: 17
valid dataset len: 17, test dataloader len: 17
====> Epoch: 1 Train Avg loss: 1.39150, Acc: 0.12500, F1: 0.12500#####> Valid Avg loss: 1.53672, Acc:0.00000, F1: 0.00000
===> Epoch: 1: Training loss decreased (inf --> 1.39150), Acc: (0.00000 --> 0.12500), F1: (0.00000 --> 0.12500).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147526.541391.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.53672), Acc: (0.00000 --> 0.00000), F1: (0.00000 --> 0.00000).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147526.541391.pth_1
====> Epoch: 2 Train Avg loss: 1.29477, Acc: 0.23438, F1: 0.23438#####> Valid Avg loss: 1.67903, Acc:0.00000, F1: 0.00000
===> Epoch: 2: Training loss decreased (1.39150 --> 1.29477), Acc: (0.12500 --> 0.23438), F1: (0.12500 --> 0.23438).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147526.541391.pth_1
====> Epoch: 3 Train Avg loss: 1.17893, Acc: 0.23438, F1: 0.23438#####> Valid Avg loss: 1.64106, Acc:0.00000, F1: 0.00000
===> Epoch: 3: Training loss decreased (1.29477 --> 1.17893), Acc: (0.23438 --> 0.23438), F1: (0.23438 --> 0.23438).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147526.541391.pth_1
====> Epoch: 4 Train Avg loss: 1.19482, Acc: 0.20312, F1: 0.20312#####> Valid Avg loss: 1.69931, Acc:0.00000, F1: 0.00000
====> Epoch: 5 Train Avg loss: 1.24495, Acc: 0.10938, F1: 0.10938#####> Valid Avg loss: 1.70927, Acc:0.00000, F1: 0.00000
====> Epoch: 6 Train Avg loss: 1.07222, Acc: 0.20312, F1: 0.20312#####> Valid Avg loss: 1.70845, Acc:0.00000, F1: 0.00000
===> Epoch: 6: Training loss decreased (1.17893 --> 1.07222), Acc: (0.23438 --> 0.20312), F1: (0.23438 --> 0.20312).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147526.541391.pth_1
====> Epoch: 7 Train Avg loss: 1.26356, Acc: 0.12500, F1: 0.12500#####> Valid Avg loss: 1.69636, Acc:0.00000, F1: 0.00000
====> Epoch: 8 Train Avg loss: 1.11404, Acc: 0.26562, F1: 0.26562#####> Valid Avg loss: 1.65516, Acc:0.00000, F1: 0.00000
====> Epoch: 9 Train Avg loss: 1.27415, Acc: 0.15625, F1: 0.15625#####> Valid Avg loss: 1.72795, Acc:0.00000, F1: 0.00000
====> Epoch: 10 Train Avg loss: 1.21008, Acc: 0.20312, F1: 0.20312#####> Valid Avg loss: 1.64025, Acc:0.00000, F1: 0.00000
====> Epoch: 11 Train Avg loss: 1.18321, Acc: 0.20312, F1: 0.20312#####> Valid Avg loss: 1.69456, Acc:0.00000, F1: 0.00000
====> Epoch: 12 Train Avg loss: 1.18074, Acc: 0.14062, F1: 0.14062#####> Valid Avg loss: 1.65130, Acc:0.00000, F1: 0.00000
====> Epoch: 13 Train Avg loss: 1.22863, Acc: 0.21875, F1: 0.21875#####> Valid Avg loss: 1.65279, Acc:0.00000, F1: 0.00000
====> Epoch: 14 Train Avg loss: 1.24687, Acc: 0.17188, F1: 0.17188#####> Valid Avg loss: 1.68197, Acc:0.00000, F1: 0.00000
====> Epoch: 15 Train Avg loss: 1.19611, Acc: 0.31250, F1: 0.31250#####> Valid Avg loss: 1.64229, Acc:0.00000, F1: 0.00000
====> Epoch: 16 Train Avg loss: 1.13198, Acc: 0.18750, F1: 0.18750#####> Valid Avg loss: 1.64042, Acc:0.00000, F1: 0.00000
====> Epoch: 17 Train Avg loss: 1.13998, Acc: 0.29688, F1: 0.29688#####> Valid Avg loss: 1.65703, Acc:0.00000, F1: 0.00000
====> Epoch: 18 Train Avg loss: 1.13265, Acc: 0.21875, F1: 0.21875#####> Valid Avg loss: 1.67841, Acc:0.00000, F1: 0.00000
====> Epoch: 19 Train Avg loss: 1.18437, Acc: 0.20312, F1: 0.20312#####> Valid Avg loss: 1.66400, Acc:0.00000, F1: 0.00000
====> Epoch: 20 Train Avg loss: 1.22889, Acc: 0.23438, F1: 0.23438#####> Valid Avg loss: 1.67031, Acc:0.00000, F1: 0.00000
====> Epoch: 21 Train Avg loss: 1.21744, Acc: 0.20312, F1: 0.20312#####> Valid Avg loss: 1.69524, Acc:0.00000, F1: 0.00000
====> Epoch: 22 Train Avg loss: 1.05146, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.66217, Acc:0.00000, F1: 0.00000
===> Epoch: 22: Training loss decreased (1.07222 --> 1.05146), Acc: (0.20312 --> 0.25000), F1: (0.20312 --> 0.25000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147526.541391.pth_1
====> Epoch: 23 Train Avg loss: 1.08136, Acc: 0.28125, F1: 0.28125#####> Valid Avg loss: 1.65228, Acc:0.00000, F1: 0.00000
====> Epoch: 24 Train Avg loss: 1.07600, Acc: 0.26562, F1: 0.26562#####> Valid Avg loss: 1.65765, Acc:0.00000, F1: 0.00000
====> Epoch: 25 Train Avg loss: 1.13589, Acc: 0.34375, F1: 0.34375#####> Valid Avg loss: 1.68194, Acc:0.00000, F1: 0.00000
====> Epoch: 26 Train Avg loss: 1.18490, Acc: 0.23438, F1: 0.23438#####> Valid Avg loss: 1.66610, Acc:0.00000, F1: 0.00000
====> Epoch: 27 Train Avg loss: 1.13619, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.68919, Acc:0.00000, F1: 0.00000
====> Epoch: 28 Train Avg loss: 1.12258, Acc: 0.29688, F1: 0.29688#####> Valid Avg loss: 1.66715, Acc:0.00000, F1: 0.00000
====> Epoch: 29 Train Avg loss: 1.07957, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.66921, Acc:0.00000, F1: 0.00000
====> Epoch: 30 Train Avg loss: 1.02739, Acc: 0.28125, F1: 0.28125#####> Valid Avg loss: 1.63070, Acc:0.00000, F1: 0.00000
===> Epoch: 30: Training loss decreased (1.05146 --> 1.02739), Acc: (0.25000 --> 0.28125), F1: (0.25000 --> 0.28125).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147526.541391.pth_1
====> Epoch: 31 Train Avg loss: 1.12874, Acc: 0.21875, F1: 0.21875#####> Valid Avg loss: 1.66912, Acc:0.00000, F1: 0.00000
====> Epoch: 32 Train Avg loss: 1.16482, Acc: 0.18750, F1: 0.18750#####> Valid Avg loss: 1.69042, Acc:0.00000, F1: 0.00000
====> Epoch: 33 Train Avg loss: 1.06455, Acc: 0.31250, F1: 0.31250#####> Valid Avg loss: 1.64524, Acc:0.00000, F1: 0.00000
====> Epoch: 34 Train Avg loss: 1.13179, Acc: 0.29688, F1: 0.29688#####> Valid Avg loss: 1.68687, Acc:0.00000, F1: 0.00000
====> Epoch: 35 Train Avg loss: 1.13057, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.69839, Acc:0.00000, F1: 0.00000
====> Epoch: 36 Train Avg loss: 1.15107, Acc: 0.32812, F1: 0.32812#####> Valid Avg loss: 1.64705, Acc:0.00000, F1: 0.00000
====> Epoch: 37 Train Avg loss: 1.15539, Acc: 0.28125, F1: 0.28125#####> Valid Avg loss: 1.63894, Acc:0.00000, F1: 0.00000
====> Epoch: 38 Train Avg loss: 1.05831, Acc: 0.29688, F1: 0.29688#####> Valid Avg loss: 1.65814, Acc:0.00000, F1: 0.00000
====> Epoch: 39 Train Avg loss: 1.14260, Acc: 0.21875, F1: 0.21875#####> Valid Avg loss: 1.68114, Acc:0.00000, F1: 0.00000
====> Epoch: 40 Train Avg loss: 1.09390, Acc: 0.21875, F1: 0.21875#####> Valid Avg loss: 1.67593, Acc:0.00000, F1: 0.00000
====> Epoch: 41 Train Avg loss: 1.21427, Acc: 0.14062, F1: 0.14062#####> Valid Avg loss: 1.65294, Acc:0.00000, F1: 0.00000
====> Epoch: 42 Train Avg loss: 1.09232, Acc: 0.29688, F1: 0.29688#####> Valid Avg loss: 1.67982, Acc:0.00000, F1: 0.00000
====> Epoch: 43 Train Avg loss: 1.03872, Acc: 0.26562, F1: 0.26562#####> Valid Avg loss: 1.64050, Acc:0.00000, F1: 0.00000
====> Epoch: 44 Train Avg loss: 1.08689, Acc: 0.23438, F1: 0.23438#####> Valid Avg loss: 1.68947, Acc:0.00000, F1: 0.00000
====> Epoch: 45 Train Avg loss: 1.14293, Acc: 0.21875, F1: 0.21875#####> Valid Avg loss: 1.67791, Acc:0.00000, F1: 0.00000
====> Epoch: 46 Train Avg loss: 1.17081, Acc: 0.31250, F1: 0.31250#####> Valid Avg loss: 1.66544, Acc:0.00000, F1: 0.00000
====> Epoch: 47 Train Avg loss: 1.20551, Acc: 0.26562, F1: 0.26562#####> Valid Avg loss: 1.66628, Acc:0.00000, F1: 0.00000
====> Epoch: 48 Train Avg loss: 1.05115, Acc: 0.29688, F1: 0.29688#####> Valid Avg loss: 1.67038, Acc:0.00000, F1: 0.00000
====> Epoch: 49 Train Avg loss: 1.06438, Acc: 0.29688, F1: 0.29688#####> Valid Avg loss: 1.66549, Acc:0.00000, F1: 0.00000
====> Epoch: 50 Train Avg loss: 1.12794, Acc: 0.29688, F1: 0.29688#####> Valid Avg loss: 1.68535, Acc:0.00000, F1: 0.00000
====> Epoch: 51 Train Avg loss: 1.05405, Acc: 0.31250, F1: 0.31250#####> Valid Avg loss: 1.67175, Acc:0.00000, F1: 0.00000
====> Epoch: 52 Train Avg loss: 1.04048, Acc: 0.34375, F1: 0.34375#####> Valid Avg loss: 1.65920, Acc:0.00000, F1: 0.00000
====> Epoch: 53 Train Avg loss: 1.09376, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.66420, Acc:0.00000, F1: 0.00000
====> Epoch: 54 Train Avg loss: 1.10482, Acc: 0.26562, F1: 0.26562#####> Valid Avg loss: 1.65157, Acc:0.00000, F1: 0.00000
====> Epoch: 55 Train Avg loss: 1.08885, Acc: 0.18750, F1: 0.18750#####> Valid Avg loss: 1.66761, Acc:0.00000, F1: 0.00000
====> Epoch: 56 Train Avg loss: 1.13113, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.67861, Acc:0.00000, F1: 0.00000
====> Epoch: 57 Train Avg loss: 1.10607, Acc: 0.21875, F1: 0.21875#####> Valid Avg loss: 1.67594, Acc:0.00000, F1: 0.00000
====> Epoch: 58 Train Avg loss: 1.16298, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.64215, Acc:0.00000, F1: 0.00000
====> Epoch: 59 Train Avg loss: 1.18653, Acc: 0.23438, F1: 0.23438#####> Valid Avg loss: 1.66145, Acc:0.00000, F1: 0.00000
====> Epoch: 60 Train Avg loss: 1.11578, Acc: 0.32812, F1: 0.32812#####> Valid Avg loss: 1.64387, Acc:0.00000, F1: 0.00000
====> Epoch: 61 Train Avg loss: 0.96038, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.62436, Acc:0.00000, F1: 0.00000
===> Epoch: 61: Training loss decreased (1.02739 --> 0.96038), Acc: (0.28125 --> 0.25000), F1: (0.28125 --> 0.25000).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147526.541391.pth_1
====> Epoch: 62 Train Avg loss: 1.20391, Acc: 0.28125, F1: 0.28125#####> Valid Avg loss: 1.69198, Acc:0.00000, F1: 0.00000
====> Epoch: 63 Train Avg loss: 1.11358, Acc: 0.23438, F1: 0.23438#####> Valid Avg loss: 1.65104, Acc:0.00000, F1: 0.00000
====> Epoch: 64 Train Avg loss: 1.17324, Acc: 0.26562, F1: 0.26562#####> Valid Avg loss: 1.64802, Acc:0.00000, F1: 0.00000
====> Epoch: 65 Train Avg loss: 1.14601, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.68914, Acc:0.00000, F1: 0.00000
====> Epoch: 66 Train Avg loss: 1.08603, Acc: 0.17188, F1: 0.17188#####> Valid Avg loss: 1.66188, Acc:0.00000, F1: 0.00000
====> Epoch: 67 Train Avg loss: 1.12306, Acc: 0.12500, F1: 0.12500#####> Valid Avg loss: 1.70813, Acc:0.00000, F1: 0.00000
====> Epoch: 68 Train Avg loss: 1.13317, Acc: 0.28125, F1: 0.28125#####> Valid Avg loss: 1.65194, Acc:0.00000, F1: 0.00000
====> Epoch: 69 Train Avg loss: 0.99954, Acc: 0.31250, F1: 0.31250#####> Valid Avg loss: 1.69545, Acc:0.00000, F1: 0.00000
====> Epoch: 70 Train Avg loss: 1.13333, Acc: 0.26562, F1: 0.26562#####> Valid Avg loss: 1.68299, Acc:0.00000, F1: 0.00000
====> Epoch: 71 Train Avg loss: 1.09301, Acc: 0.32812, F1: 0.32812#####> Valid Avg loss: 1.67799, Acc:0.00000, F1: 0.00000
====> Epoch: 72 Train Avg loss: 1.09749, Acc: 0.20312, F1: 0.20312#####> Valid Avg loss: 1.68728, Acc:0.00000, F1: 0.00000
====> Epoch: 73 Train Avg loss: 1.02880, Acc: 0.31250, F1: 0.31250#####> Valid Avg loss: 1.74023, Acc:0.00000, F1: 0.00000
====> Epoch: 74 Train Avg loss: 1.20325, Acc: 0.28125, F1: 0.28125#####> Valid Avg loss: 1.67402, Acc:0.00000, F1: 0.00000
====> Epoch: 75 Train Avg loss: 1.08069, Acc: 0.25000, F1: 0.25000#####> Valid Avg loss: 1.65314, Acc:0.00000, F1: 0.00000
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:1e-05, epoch:500, batch_size:2
cnn_out_channel: 16, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 11train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1353
valid_dataloader len: 438
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2706, train dataloader len: 1353
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 428, test dataloader len: 438
====> Epoch: 1 Train Avg loss: 1.37901, Acc: 0.20843, F1: 0.20843#####> Valid Avg loss: 1.13530, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 1.37901), Acc: (0.00000 --> 0.20843), F1: (0.00000 --> 0.20843).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth_1

####> Epoch: 1: validation loss decreased (inf --> 1.13530), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth_1

####> Epoch: 1: validation acc increase (inf --> 1.13530), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth_1
====> Epoch: 2 Train Avg loss: 1.30340, Acc: 0.24945, F1: 0.24945#####> Valid Avg loss: 1.13309, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (1.37901 --> 1.30340), Acc: (0.20843 --> 0.24945), F1: (0.20843 --> 0.24945).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth_1

####> Epoch: 2: validation loss decreased (1.13530 --> 1.13309), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth_1
====> Epoch: 3 Train Avg loss: 1.29765, Acc: 0.27827, F1: 0.27827#####> Valid Avg loss: 1.10661, Acc:0.48630, F1: 0.48630
===> Epoch: 3: Training loss decreased (1.30340 --> 1.29765), Acc: (0.24945 --> 0.27827), F1: (0.24945 --> 0.27827).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth_1

####> Epoch: 3: validation loss decreased (1.13309 --> 1.10661), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth_1
====> Epoch: 4 Train Avg loss: 1.26752, Acc: 0.32890, F1: 0.32890#####> Valid Avg loss: 1.10984, Acc:0.48630, F1: 0.48630
===> Epoch: 4: Training loss decreased (1.29765 --> 1.26752), Acc: (0.27827 --> 0.32890), F1: (0.27827 --> 0.32890).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth_1
====> Epoch: 5 Train Avg loss: 1.27351, Acc: 0.31966, F1: 0.31966#####> Valid Avg loss: 1.11446, Acc:0.48630, F1: 0.48630
====> Epoch: 6 Train Avg loss: 1.24760, Acc: 0.34220, F1: 0.34220#####> Valid Avg loss: 1.11506, Acc:0.48630, F1: 0.48630
===> Epoch: 6: Training loss decreased (1.26752 --> 1.24760), Acc: (0.32890 --> 0.34220), F1: (0.32890 --> 0.34220).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147684.174891.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.001, epoch:500, batch_size:2
cnn_out_channel: 16, feature_embed_size:32
lstm_hidden_size: 32
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600147983.35197.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 11train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1353
valid_dataloader len: 438
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2706, train dataloader len: 1353
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 428, test dataloader len: 438
====> Epoch: 1 Train Avg loss: 1.13249, Acc: 0.48854, F1: 0.48854#####> Valid Avg loss: 0.97372, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 1.13249), Acc: (0.00000 --> 0.48854), F1: (0.00000 --> 0.48854).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147983.35197.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.97372), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147983.35197.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.97372), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600147983.35197.pth_1
====> Epoch: 2 Train Avg loss: 0.98482, Acc: 0.52846, F1: 0.52846#####> Valid Avg loss: 0.87840, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (1.13249 --> 0.98482), Acc: (0.48854 --> 0.52846), F1: (0.48854 --> 0.52846).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600147983.35197.pth_1

####> Epoch: 2: validation loss decreased (0.97372 --> 0.87840), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600147983.35197.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 32, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.6, upper_layer_dropout: 0.6
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 9train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1298
valid_dataloader len: 438
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2595, train dataloader len: 1298
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 428, test dataloader len: 438
====> Epoch: 1 Train Avg loss: 1.21352, Acc: 0.46050, F1: 0.46032#####> Valid Avg loss: 0.81141, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 1.21352), Acc: (0.00000 --> 0.46050), F1: (0.00000 --> 0.46032).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.81141), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.81141), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 2 Train Avg loss: 0.92884, Acc: 0.50829, F1: 0.50809#####> Valid Avg loss: 0.76549, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (1.21352 --> 0.92884), Acc: (0.46050 --> 0.50829), F1: (0.46032 --> 0.50809).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1

####> Epoch: 2: validation loss decreased (0.81141 --> 0.76549), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 3 Train Avg loss: 0.85792, Acc: 0.53757, F1: 0.53775#####> Valid Avg loss: 0.78324, Acc:0.48630, F1: 0.48630
===> Epoch: 3: Training loss decreased (0.92884 --> 0.85792), Acc: (0.50829 --> 0.53757), F1: (0.50809 --> 0.53775).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 4 Train Avg loss: 0.81444, Acc: 0.54682, F1: 0.54661#####> Valid Avg loss: 0.78207, Acc:0.48630, F1: 0.48630
===> Epoch: 4: Training loss decreased (0.85792 --> 0.81444), Acc: (0.53757 --> 0.54682), F1: (0.53775 --> 0.54661).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 5 Train Avg loss: 0.76338, Acc: 0.55029, F1: 0.55046#####> Valid Avg loss: 0.78369, Acc:0.48630, F1: 0.48630
===> Epoch: 5: Training loss decreased (0.81444 --> 0.76338), Acc: (0.54682 --> 0.55029), F1: (0.54661 --> 0.55046).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 6 Train Avg loss: 0.75795, Acc: 0.54952, F1: 0.54969#####> Valid Avg loss: 0.80763, Acc:0.48630, F1: 0.48630
===> Epoch: 6: Training loss decreased (0.76338 --> 0.75795), Acc: (0.55029 --> 0.54952), F1: (0.55046 --> 0.54969).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 7 Train Avg loss: 0.76100, Acc: 0.54875, F1: 0.54854#####> Valid Avg loss: 0.81021, Acc:0.48630, F1: 0.48630
====> Epoch: 8 Train Avg loss: 0.73781, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80664, Acc:0.48630, F1: 0.48630
===> Epoch: 8: Training loss decreased (0.75795 --> 0.73781), Acc: (0.54952 --> 0.55106), F1: (0.54969 --> 0.55085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 9 Train Avg loss: 0.73532, Acc: 0.55029, F1: 0.55008#####> Valid Avg loss: 0.80979, Acc:0.48630, F1: 0.48630
===> Epoch: 9: Training loss decreased (0.73781 --> 0.73532), Acc: (0.55106 --> 0.55029), F1: (0.55085 --> 0.55008).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 10 Train Avg loss: 0.73509, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82175, Acc:0.48630, F1: 0.48630
===> Epoch: 10: Training loss decreased (0.73532 --> 0.73509), Acc: (0.55029 --> 0.55106), F1: (0.55008 --> 0.55085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 11 Train Avg loss: 0.71708, Acc: 0.54990, F1: 0.54969#####> Valid Avg loss: 0.81472, Acc:0.48630, F1: 0.48630
===> Epoch: 11: Training loss decreased (0.73509 --> 0.71708), Acc: (0.55106 --> 0.54990), F1: (0.55085 --> 0.54969).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 12 Train Avg loss: 0.72415, Acc: 0.55067, F1: 0.55085#####> Valid Avg loss: 0.83574, Acc:0.48630, F1: 0.48630
====> Epoch: 13 Train Avg loss: 0.71681, Acc: 0.54990, F1: 0.54969#####> Valid Avg loss: 0.82041, Acc:0.48630, F1: 0.48630
===> Epoch: 13: Training loss decreased (0.71708 --> 0.71681), Acc: (0.54990 --> 0.54990), F1: (0.54969 --> 0.54969).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 14 Train Avg loss: 0.71506, Acc: 0.55145, F1: 0.55162#####> Valid Avg loss: 0.81076, Acc:0.48630, F1: 0.48630
===> Epoch: 14: Training loss decreased (0.71681 --> 0.71506), Acc: (0.54990 --> 0.55145), F1: (0.54969 --> 0.55162).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 15 Train Avg loss: 0.70214, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.84839, Acc:0.48630, F1: 0.48630
===> Epoch: 15: Training loss decreased (0.71506 --> 0.70214), Acc: (0.55145 --> 0.55106), F1: (0.55162 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 16 Train Avg loss: 0.70866, Acc: 0.55067, F1: 0.55046#####> Valid Avg loss: 0.85427, Acc:0.48630, F1: 0.48630
====> Epoch: 17 Train Avg loss: 0.70998, Acc: 0.55029, F1: 0.55046#####> Valid Avg loss: 0.84397, Acc:0.48630, F1: 0.48630
====> Epoch: 18 Train Avg loss: 0.70993, Acc: 0.55067, F1: 0.55046#####> Valid Avg loss: 0.82865, Acc:0.48630, F1: 0.48630
====> Epoch: 19 Train Avg loss: 0.70625, Acc: 0.55067, F1: 0.55046#####> Valid Avg loss: 0.83220, Acc:0.48630, F1: 0.48630
====> Epoch: 20 Train Avg loss: 0.70220, Acc: 0.55067, F1: 0.55085#####> Valid Avg loss: 0.83231, Acc:0.48630, F1: 0.48630
====> Epoch: 21 Train Avg loss: 0.70663, Acc: 0.55029, F1: 0.55046#####> Valid Avg loss: 0.82622, Acc:0.48630, F1: 0.48630
====> Epoch: 22 Train Avg loss: 0.70313, Acc: 0.54913, F1: 0.54892#####> Valid Avg loss: 0.83559, Acc:0.48630, F1: 0.48630
====> Epoch: 23 Train Avg loss: 0.70278, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82974, Acc:0.48630, F1: 0.48630
====> Epoch: 24 Train Avg loss: 0.70154, Acc: 0.55183, F1: 0.55200#####> Valid Avg loss: 0.84515, Acc:0.48630, F1: 0.48630
===> Epoch: 24: Training loss decreased (0.70214 --> 0.70154), Acc: (0.55106 --> 0.55183), F1: (0.55123 --> 0.55200).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 25 Train Avg loss: 0.70807, Acc: 0.55145, F1: 0.55123#####> Valid Avg loss: 0.82358, Acc:0.48630, F1: 0.48630
====> Epoch: 26 Train Avg loss: 0.69952, Acc: 0.55067, F1: 0.55046#####> Valid Avg loss: 0.83607, Acc:0.48630, F1: 0.48630
===> Epoch: 26: Training loss decreased (0.70154 --> 0.69952), Acc: (0.55183 --> 0.55067), F1: (0.55200 --> 0.55046).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 27 Train Avg loss: 0.69805, Acc: 0.55029, F1: 0.55008#####> Valid Avg loss: 0.84019, Acc:0.48630, F1: 0.48630
===> Epoch: 27: Training loss decreased (0.69952 --> 0.69805), Acc: (0.55067 --> 0.55029), F1: (0.55046 --> 0.55008).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 28 Train Avg loss: 0.70320, Acc: 0.54990, F1: 0.55008#####> Valid Avg loss: 0.81933, Acc:0.48630, F1: 0.48630
====> Epoch: 29 Train Avg loss: 0.69807, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.83274, Acc:0.48630, F1: 0.48630
====> Epoch: 30 Train Avg loss: 0.70024, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81330, Acc:0.48630, F1: 0.48630
====> Epoch: 31 Train Avg loss: 0.69931, Acc: 0.55145, F1: 0.55162#####> Valid Avg loss: 0.83015, Acc:0.48630, F1: 0.48630
====> Epoch: 32 Train Avg loss: 0.69504, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.85080, Acc:0.48630, F1: 0.48630
===> Epoch: 32: Training loss decreased (0.69805 --> 0.69504), Acc: (0.55029 --> 0.55106), F1: (0.55008 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 33 Train Avg loss: 0.69772, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.83423, Acc:0.48630, F1: 0.48630
====> Epoch: 34 Train Avg loss: 0.69622, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81992, Acc:0.48630, F1: 0.48630
====> Epoch: 35 Train Avg loss: 0.70068, Acc: 0.55067, F1: 0.55046#####> Valid Avg loss: 0.82886, Acc:0.48630, F1: 0.48630
====> Epoch: 36 Train Avg loss: 0.69614, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82913, Acc:0.48630, F1: 0.48630
====> Epoch: 37 Train Avg loss: 0.69511, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82360, Acc:0.48630, F1: 0.48630
====> Epoch: 38 Train Avg loss: 0.69381, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81268, Acc:0.48630, F1: 0.48630
===> Epoch: 38: Training loss decreased (0.69504 --> 0.69381), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 39 Train Avg loss: 0.69470, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81245, Acc:0.48630, F1: 0.48630
====> Epoch: 40 Train Avg loss: 0.69209, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82773, Acc:0.48630, F1: 0.48630
===> Epoch: 40: Training loss decreased (0.69381 --> 0.69209), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 41 Train Avg loss: 0.69116, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82458, Acc:0.48630, F1: 0.48630
===> Epoch: 41: Training loss decreased (0.69209 --> 0.69116), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 42 Train Avg loss: 0.69108, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79927, Acc:0.48630, F1: 0.48630
===> Epoch: 42: Training loss decreased (0.69116 --> 0.69108), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 43 Train Avg loss: 0.69386, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81131, Acc:0.48630, F1: 0.48630
====> Epoch: 44 Train Avg loss: 0.68951, Acc: 0.55067, F1: 0.55085#####> Valid Avg loss: 0.80690, Acc:0.48630, F1: 0.48630
===> Epoch: 44: Training loss decreased (0.69108 --> 0.68951), Acc: (0.55106 --> 0.55067), F1: (0.55123 --> 0.55085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 45 Train Avg loss: 0.68956, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80998, Acc:0.48630, F1: 0.48630
====> Epoch: 46 Train Avg loss: 0.69524, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81458, Acc:0.48630, F1: 0.48630
====> Epoch: 47 Train Avg loss: 0.68893, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80764, Acc:0.48630, F1: 0.48630
===> Epoch: 47: Training loss decreased (0.68951 --> 0.68893), Acc: (0.55067 --> 0.55106), F1: (0.55085 --> 0.55085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 48 Train Avg loss: 0.69150, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82425, Acc:0.48630, F1: 0.48630
====> Epoch: 49 Train Avg loss: 0.68915, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80338, Acc:0.48630, F1: 0.48630
====> Epoch: 50 Train Avg loss: 0.68817, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81628, Acc:0.48630, F1: 0.48630
===> Epoch: 50: Training loss decreased (0.68893 --> 0.68817), Acc: (0.55106 --> 0.55106), F1: (0.55085 --> 0.55085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 51 Train Avg loss: 0.68782, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81609, Acc:0.48630, F1: 0.48630
===> Epoch: 51: Training loss decreased (0.68817 --> 0.68782), Acc: (0.55106 --> 0.55106), F1: (0.55085 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 52 Train Avg loss: 0.69320, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81405, Acc:0.48630, F1: 0.48630
====> Epoch: 53 Train Avg loss: 0.69098, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80093, Acc:0.48630, F1: 0.48630
====> Epoch: 54 Train Avg loss: 0.69067, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81340, Acc:0.48630, F1: 0.48630
====> Epoch: 55 Train Avg loss: 0.68793, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82139, Acc:0.48630, F1: 0.48630
====> Epoch: 56 Train Avg loss: 0.68860, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80175, Acc:0.48630, F1: 0.48630
====> Epoch: 57 Train Avg loss: 0.68834, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81578, Acc:0.48630, F1: 0.48630
====> Epoch: 58 Train Avg loss: 0.69182, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81214, Acc:0.48630, F1: 0.48630
====> Epoch: 59 Train Avg loss: 0.68772, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81986, Acc:0.48630, F1: 0.48630
===> Epoch: 59: Training loss decreased (0.68782 --> 0.68772), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 60 Train Avg loss: 0.68871, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80203, Acc:0.48630, F1: 0.48630
====> Epoch: 61 Train Avg loss: 0.69065, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80786, Acc:0.48630, F1: 0.48630
====> Epoch: 62 Train Avg loss: 0.68930, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81428, Acc:0.48630, F1: 0.48630
====> Epoch: 63 Train Avg loss: 0.69211, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80864, Acc:0.48630, F1: 0.48630
====> Epoch: 64 Train Avg loss: 0.68586, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82274, Acc:0.48630, F1: 0.48630
===> Epoch: 64: Training loss decreased (0.68772 --> 0.68586), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 65 Train Avg loss: 0.68978, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81358, Acc:0.48630, F1: 0.48630
====> Epoch: 66 Train Avg loss: 0.68780, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80842, Acc:0.48630, F1: 0.48630
====> Epoch: 67 Train Avg loss: 0.68648, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82134, Acc:0.48630, F1: 0.48630
====> Epoch: 68 Train Avg loss: 0.68375, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81477, Acc:0.48630, F1: 0.48630
===> Epoch: 68: Training loss decreased (0.68586 --> 0.68375), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 69 Train Avg loss: 0.68374, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81358, Acc:0.48630, F1: 0.48630
===> Epoch: 69: Training loss decreased (0.68375 --> 0.68374), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 70 Train Avg loss: 0.68670, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80955, Acc:0.48630, F1: 0.48630
====> Epoch: 71 Train Avg loss: 0.68664, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80782, Acc:0.48630, F1: 0.48630
====> Epoch: 72 Train Avg loss: 0.68706, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81231, Acc:0.48630, F1: 0.48630
====> Epoch: 73 Train Avg loss: 0.68445, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80754, Acc:0.48630, F1: 0.48630
====> Epoch: 74 Train Avg loss: 0.68581, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80899, Acc:0.48630, F1: 0.48630
====> Epoch: 75 Train Avg loss: 0.68668, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81144, Acc:0.48630, F1: 0.48630
====> Epoch: 76 Train Avg loss: 0.68612, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81271, Acc:0.48630, F1: 0.48630
====> Epoch: 77 Train Avg loss: 0.68534, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81872, Acc:0.48630, F1: 0.48630
====> Epoch: 78 Train Avg loss: 0.68740, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81356, Acc:0.48630, F1: 0.48630
====> Epoch: 79 Train Avg loss: 0.68494, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80920, Acc:0.48630, F1: 0.48630
====> Epoch: 80 Train Avg loss: 0.68525, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81343, Acc:0.48630, F1: 0.48630
====> Epoch: 81 Train Avg loss: 0.68651, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81866, Acc:0.48630, F1: 0.48630
====> Epoch: 82 Train Avg loss: 0.68179, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81047, Acc:0.48630, F1: 0.48630
===> Epoch: 82: Training loss decreased (0.68374 --> 0.68179), Acc: (0.55106 --> 0.55106), F1: (0.55085 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 83 Train Avg loss: 0.68542, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81110, Acc:0.48630, F1: 0.48630
====> Epoch: 84 Train Avg loss: 0.68532, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81233, Acc:0.48630, F1: 0.48630
====> Epoch: 85 Train Avg loss: 0.68525, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80897, Acc:0.48630, F1: 0.48630
====> Epoch: 86 Train Avg loss: 0.68798, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81194, Acc:0.48630, F1: 0.48630
====> Epoch: 87 Train Avg loss: 0.68442, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80713, Acc:0.48630, F1: 0.48630
====> Epoch: 88 Train Avg loss: 0.68320, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81010, Acc:0.48630, F1: 0.48630
====> Epoch: 89 Train Avg loss: 0.68436, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81174, Acc:0.48630, F1: 0.48630
====> Epoch: 90 Train Avg loss: 0.68406, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81025, Acc:0.48630, F1: 0.48630
====> Epoch: 91 Train Avg loss: 0.68190, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81101, Acc:0.48630, F1: 0.48630
====> Epoch: 92 Train Avg loss: 0.68224, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81471, Acc:0.48630, F1: 0.48630
====> Epoch: 93 Train Avg loss: 0.68428, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81291, Acc:0.48630, F1: 0.48630
====> Epoch: 94 Train Avg loss: 0.68561, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80763, Acc:0.48630, F1: 0.48630
====> Epoch: 95 Train Avg loss: 0.68396, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81099, Acc:0.48630, F1: 0.48630
====> Epoch: 96 Train Avg loss: 0.68705, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81518, Acc:0.48630, F1: 0.48630
====> Epoch: 97 Train Avg loss: 0.68500, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80661, Acc:0.48630, F1: 0.48630
====> Epoch: 98 Train Avg loss: 0.68489, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81025, Acc:0.48630, F1: 0.48630
====> Epoch: 99 Train Avg loss: 0.68322, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81112, Acc:0.48630, F1: 0.48630
====> Epoch: 100 Train Avg loss: 0.69233, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81385, Acc:0.48630, F1: 0.48630
====> Epoch: 101 Train Avg loss: 0.69190, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80697, Acc:0.48630, F1: 0.48630
====> Epoch: 102 Train Avg loss: 0.69060, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79889, Acc:0.48630, F1: 0.48630
====> Epoch: 103 Train Avg loss: 0.69332, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79603, Acc:0.48630, F1: 0.48630
====> Epoch: 104 Train Avg loss: 0.68907, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81439, Acc:0.48630, F1: 0.48630
====> Epoch: 105 Train Avg loss: 0.69093, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79383, Acc:0.48630, F1: 0.48630
====> Epoch: 106 Train Avg loss: 0.69352, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81739, Acc:0.48630, F1: 0.48630
====> Epoch: 107 Train Avg loss: 0.69021, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80462, Acc:0.48630, F1: 0.48630
====> Epoch: 108 Train Avg loss: 0.69198, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82042, Acc:0.48630, F1: 0.48630
====> Epoch: 109 Train Avg loss: 0.69381, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81385, Acc:0.48630, F1: 0.48630
====> Epoch: 110 Train Avg loss: 0.69248, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.78310, Acc:0.48630, F1: 0.48630
====> Epoch: 111 Train Avg loss: 0.69366, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80216, Acc:0.48630, F1: 0.48630
====> Epoch: 112 Train Avg loss: 0.69409, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79078, Acc:0.48630, F1: 0.48630
====> Epoch: 113 Train Avg loss: 0.69237, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79505, Acc:0.48630, F1: 0.48630
====> Epoch: 114 Train Avg loss: 0.68960, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79717, Acc:0.48630, F1: 0.48630
====> Epoch: 115 Train Avg loss: 0.69282, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79821, Acc:0.48630, F1: 0.48630
====> Epoch: 116 Train Avg loss: 0.69192, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81109, Acc:0.48630, F1: 0.48630
====> Epoch: 117 Train Avg loss: 0.69331, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80389, Acc:0.48630, F1: 0.48630
====> Epoch: 118 Train Avg loss: 0.68879, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81148, Acc:0.48630, F1: 0.48630
====> Epoch: 119 Train Avg loss: 0.69313, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81407, Acc:0.48630, F1: 0.48630
====> Epoch: 120 Train Avg loss: 0.69309, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.78435, Acc:0.48630, F1: 0.48630
====> Epoch: 121 Train Avg loss: 0.68725, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79580, Acc:0.48630, F1: 0.48630
====> Epoch: 122 Train Avg loss: 0.68967, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82641, Acc:0.48630, F1: 0.48630
====> Epoch: 123 Train Avg loss: 0.69285, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81562, Acc:0.48630, F1: 0.48630
====> Epoch: 124 Train Avg loss: 0.68924, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80214, Acc:0.48630, F1: 0.48630
====> Epoch: 125 Train Avg loss: 0.68848, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80028, Acc:0.48630, F1: 0.48630
====> Epoch: 126 Train Avg loss: 0.69353, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79895, Acc:0.48630, F1: 0.48630
====> Epoch: 127 Train Avg loss: 0.69112, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79812, Acc:0.48630, F1: 0.48630
====> Epoch: 128 Train Avg loss: 0.68611, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81465, Acc:0.48630, F1: 0.48630
====> Epoch: 129 Train Avg loss: 0.69151, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80919, Acc:0.48630, F1: 0.48630
====> Epoch: 130 Train Avg loss: 0.69174, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81696, Acc:0.48630, F1: 0.48630
====> Epoch: 131 Train Avg loss: 0.69157, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79797, Acc:0.48630, F1: 0.48630
====> Epoch: 132 Train Avg loss: 0.68807, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.77994, Acc:0.48630, F1: 0.48630
====> Epoch: 133 Train Avg loss: 0.69013, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79506, Acc:0.48630, F1: 0.48630
====> Epoch: 134 Train Avg loss: 0.68967, Acc: 0.55067, F1: 0.55085#####> Valid Avg loss: 0.81297, Acc:0.48630, F1: 0.48630
====> Epoch: 135 Train Avg loss: 0.68610, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80659, Acc:0.48630, F1: 0.48630
====> Epoch: 136 Train Avg loss: 0.69267, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.78947, Acc:0.48630, F1: 0.48630
====> Epoch: 137 Train Avg loss: 0.68717, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80606, Acc:0.48630, F1: 0.48630
====> Epoch: 138 Train Avg loss: 0.69109, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81264, Acc:0.48630, F1: 0.48630
====> Epoch: 139 Train Avg loss: 0.68883, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80302, Acc:0.48630, F1: 0.48630
====> Epoch: 140 Train Avg loss: 0.68767, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80544, Acc:0.48630, F1: 0.48630
====> Epoch: 141 Train Avg loss: 0.68893, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79580, Acc:0.48630, F1: 0.48630
====> Epoch: 142 Train Avg loss: 0.68919, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80491, Acc:0.48630, F1: 0.48630
====> Epoch: 143 Train Avg loss: 0.68968, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80645, Acc:0.48630, F1: 0.48630
====> Epoch: 144 Train Avg loss: 0.68853, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80222, Acc:0.48630, F1: 0.48630
====> Epoch: 145 Train Avg loss: 0.68854, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81663, Acc:0.48630, F1: 0.48630
====> Epoch: 146 Train Avg loss: 0.68750, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79873, Acc:0.48630, F1: 0.48630
====> Epoch: 147 Train Avg loss: 0.69034, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81689, Acc:0.48630, F1: 0.48630
====> Epoch: 148 Train Avg loss: 0.69058, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81855, Acc:0.48630, F1: 0.48630
====> Epoch: 149 Train Avg loss: 0.68758, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.78748, Acc:0.48630, F1: 0.48630
====> Epoch: 150 Train Avg loss: 0.68885, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80133, Acc:0.48630, F1: 0.48630
====> Epoch: 151 Train Avg loss: 0.68914, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80809, Acc:0.48630, F1: 0.48630
====> Epoch: 152 Train Avg loss: 0.68857, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79685, Acc:0.48630, F1: 0.48630
====> Epoch: 153 Train Avg loss: 0.68908, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79867, Acc:0.48630, F1: 0.48630
====> Epoch: 154 Train Avg loss: 0.68847, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81068, Acc:0.48630, F1: 0.48630
====> Epoch: 155 Train Avg loss: 0.68806, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80529, Acc:0.48630, F1: 0.48630
====> Epoch: 156 Train Avg loss: 0.68770, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80539, Acc:0.48630, F1: 0.48630
====> Epoch: 157 Train Avg loss: 0.68900, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81252, Acc:0.48630, F1: 0.48630
====> Epoch: 158 Train Avg loss: 0.69077, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82334, Acc:0.48630, F1: 0.48630
====> Epoch: 159 Train Avg loss: 0.68522, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.83115, Acc:0.48630, F1: 0.48630
====> Epoch: 160 Train Avg loss: 0.68964, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81247, Acc:0.48630, F1: 0.48630
====> Epoch: 161 Train Avg loss: 0.69036, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80856, Acc:0.48630, F1: 0.48630
====> Epoch: 162 Train Avg loss: 0.68805, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.78841, Acc:0.48630, F1: 0.48630
====> Epoch: 163 Train Avg loss: 0.68976, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.78710, Acc:0.48630, F1: 0.48630
====> Epoch: 164 Train Avg loss: 0.68838, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80228, Acc:0.48630, F1: 0.48630
====> Epoch: 165 Train Avg loss: 0.68562, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80346, Acc:0.48630, F1: 0.48630
====> Epoch: 166 Train Avg loss: 0.68659, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80890, Acc:0.48630, F1: 0.48630
====> Epoch: 167 Train Avg loss: 0.68622, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81224, Acc:0.48630, F1: 0.48630
====> Epoch: 168 Train Avg loss: 0.68700, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80285, Acc:0.48630, F1: 0.48630
====> Epoch: 169 Train Avg loss: 0.68745, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79977, Acc:0.48630, F1: 0.48630
====> Epoch: 170 Train Avg loss: 0.68758, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.78614, Acc:0.48630, F1: 0.48630
====> Epoch: 171 Train Avg loss: 0.68788, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79353, Acc:0.48630, F1: 0.48630
====> Epoch: 172 Train Avg loss: 0.68634, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80494, Acc:0.48630, F1: 0.48630
====> Epoch: 173 Train Avg loss: 0.68961, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80990, Acc:0.48630, F1: 0.48630
====> Epoch: 174 Train Avg loss: 0.68936, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.78875, Acc:0.48630, F1: 0.48630
====> Epoch: 175 Train Avg loss: 0.68613, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81180, Acc:0.48630, F1: 0.48630
====> Epoch: 176 Train Avg loss: 0.68821, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81668, Acc:0.48630, F1: 0.48630
====> Epoch: 177 Train Avg loss: 0.68903, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.83194, Acc:0.48630, F1: 0.48630
====> Epoch: 178 Train Avg loss: 0.68807, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79132, Acc:0.48630, F1: 0.48630
====> Epoch: 179 Train Avg loss: 0.68490, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82042, Acc:0.48630, F1: 0.48630
====> Epoch: 180 Train Avg loss: 0.68422, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81309, Acc:0.48630, F1: 0.48630
====> Epoch: 181 Train Avg loss: 0.68648, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80843, Acc:0.48630, F1: 0.48630
====> Epoch: 182 Train Avg loss: 0.68749, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80233, Acc:0.48630, F1: 0.48630
====> Epoch: 183 Train Avg loss: 0.68686, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80714, Acc:0.48630, F1: 0.48630
====> Epoch: 184 Train Avg loss: 0.68919, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80921, Acc:0.48630, F1: 0.48630
====> Epoch: 185 Train Avg loss: 0.68492, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79721, Acc:0.48630, F1: 0.48630
====> Epoch: 186 Train Avg loss: 0.68737, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81442, Acc:0.48630, F1: 0.48630
====> Epoch: 187 Train Avg loss: 0.68466, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79240, Acc:0.48630, F1: 0.48630
====> Epoch: 188 Train Avg loss: 0.68677, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82088, Acc:0.48630, F1: 0.48630
====> Epoch: 189 Train Avg loss: 0.68491, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81127, Acc:0.48630, F1: 0.48630
====> Epoch: 190 Train Avg loss: 0.68721, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79366, Acc:0.48630, F1: 0.48630
====> Epoch: 191 Train Avg loss: 0.68768, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80594, Acc:0.48630, F1: 0.48630
====> Epoch: 192 Train Avg loss: 0.68814, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79428, Acc:0.48630, F1: 0.48630
====> Epoch: 193 Train Avg loss: 0.68659, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79975, Acc:0.48630, F1: 0.48630
====> Epoch: 194 Train Avg loss: 0.68608, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80077, Acc:0.48630, F1: 0.48630
====> Epoch: 195 Train Avg loss: 0.68575, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81059, Acc:0.48630, F1: 0.48630
====> Epoch: 196 Train Avg loss: 0.68719, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79895, Acc:0.48630, F1: 0.48630
====> Epoch: 197 Train Avg loss: 0.68696, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81622, Acc:0.48630, F1: 0.48630
====> Epoch: 198 Train Avg loss: 0.68566, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80043, Acc:0.48630, F1: 0.48630
====> Epoch: 199 Train Avg loss: 0.68603, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81072, Acc:0.48630, F1: 0.48630
====> Epoch: 200 Train Avg loss: 0.68634, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79761, Acc:0.48630, F1: 0.48630
====> Epoch: 201 Train Avg loss: 0.68475, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79159, Acc:0.48630, F1: 0.48630
====> Epoch: 202 Train Avg loss: 0.68712, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80052, Acc:0.48630, F1: 0.48630
====> Epoch: 203 Train Avg loss: 0.68547, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79379, Acc:0.48630, F1: 0.48630
====> Epoch: 204 Train Avg loss: 0.68735, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80174, Acc:0.48630, F1: 0.48630
====> Epoch: 205 Train Avg loss: 0.68581, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79698, Acc:0.48630, F1: 0.48630
====> Epoch: 206 Train Avg loss: 0.68417, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80783, Acc:0.48630, F1: 0.48630
====> Epoch: 207 Train Avg loss: 0.68413, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80009, Acc:0.48630, F1: 0.48630
====> Epoch: 208 Train Avg loss: 0.68526, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80517, Acc:0.48630, F1: 0.48630
====> Epoch: 209 Train Avg loss: 0.68583, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80525, Acc:0.48630, F1: 0.48630
====> Epoch: 210 Train Avg loss: 0.68678, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79886, Acc:0.48630, F1: 0.48630
====> Epoch: 211 Train Avg loss: 0.68429, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80264, Acc:0.48630, F1: 0.48630
====> Epoch: 212 Train Avg loss: 0.68527, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80445, Acc:0.48630, F1: 0.48630
====> Epoch: 213 Train Avg loss: 0.68417, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80441, Acc:0.48630, F1: 0.48630
====> Epoch: 214 Train Avg loss: 0.68487, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80651, Acc:0.48630, F1: 0.48630
====> Epoch: 215 Train Avg loss: 0.68596, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79691, Acc:0.48630, F1: 0.48630
====> Epoch: 216 Train Avg loss: 0.68498, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80013, Acc:0.48630, F1: 0.48630
====> Epoch: 217 Train Avg loss: 0.68750, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80231, Acc:0.48630, F1: 0.48630
====> Epoch: 218 Train Avg loss: 0.68658, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80623, Acc:0.48630, F1: 0.48630
====> Epoch: 219 Train Avg loss: 0.68452, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81709, Acc:0.48630, F1: 0.48630
====> Epoch: 220 Train Avg loss: 0.68610, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80002, Acc:0.48630, F1: 0.48630
====> Epoch: 221 Train Avg loss: 0.68544, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79873, Acc:0.48630, F1: 0.48630
====> Epoch: 222 Train Avg loss: 0.68475, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80921, Acc:0.48630, F1: 0.48630
====> Epoch: 223 Train Avg loss: 0.68490, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79727, Acc:0.48630, F1: 0.48630
====> Epoch: 224 Train Avg loss: 0.68346, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80942, Acc:0.48630, F1: 0.48630
====> Epoch: 225 Train Avg loss: 0.68466, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81358, Acc:0.48630, F1: 0.48630
====> Epoch: 226 Train Avg loss: 0.68454, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79888, Acc:0.48630, F1: 0.48630
====> Epoch: 227 Train Avg loss: 0.68308, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80556, Acc:0.48630, F1: 0.48630
====> Epoch: 228 Train Avg loss: 0.68722, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80544, Acc:0.48630, F1: 0.48630
====> Epoch: 229 Train Avg loss: 0.68467, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79343, Acc:0.48630, F1: 0.48630
====> Epoch: 230 Train Avg loss: 0.68489, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81089, Acc:0.48630, F1: 0.48630
====> Epoch: 231 Train Avg loss: 0.68398, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80278, Acc:0.48630, F1: 0.48630
====> Epoch: 232 Train Avg loss: 0.68353, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79400, Acc:0.48630, F1: 0.48630
====> Epoch: 233 Train Avg loss: 0.68518, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79803, Acc:0.48630, F1: 0.48630
====> Epoch: 234 Train Avg loss: 0.68270, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80397, Acc:0.48630, F1: 0.48630
====> Epoch: 235 Train Avg loss: 0.68369, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81008, Acc:0.48630, F1: 0.48630
====> Epoch: 236 Train Avg loss: 0.68532, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80450, Acc:0.48630, F1: 0.48630
====> Epoch: 237 Train Avg loss: 0.68288, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81203, Acc:0.48630, F1: 0.48630
====> Epoch: 238 Train Avg loss: 0.68476, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80654, Acc:0.48630, F1: 0.48630
====> Epoch: 239 Train Avg loss: 0.68407, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80295, Acc:0.48630, F1: 0.48630
====> Epoch: 240 Train Avg loss: 0.68395, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80463, Acc:0.48630, F1: 0.48630
====> Epoch: 241 Train Avg loss: 0.68370, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80496, Acc:0.48630, F1: 0.48630
====> Epoch: 242 Train Avg loss: 0.68372, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80666, Acc:0.48630, F1: 0.48630
====> Epoch: 243 Train Avg loss: 0.68303, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80231, Acc:0.48630, F1: 0.48630
====> Epoch: 244 Train Avg loss: 0.68387, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81502, Acc:0.48630, F1: 0.48630
====> Epoch: 245 Train Avg loss: 0.68263, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80501, Acc:0.48630, F1: 0.48630
====> Epoch: 246 Train Avg loss: 0.68430, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80584, Acc:0.48630, F1: 0.48630
====> Epoch: 247 Train Avg loss: 0.68240, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80818, Acc:0.48630, F1: 0.48630
====> Epoch: 248 Train Avg loss: 0.68279, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80828, Acc:0.48630, F1: 0.48630
====> Epoch: 249 Train Avg loss: 0.68053, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80763, Acc:0.48630, F1: 0.48630
===> Epoch: 249: Training loss decreased (0.68179 --> 0.68053), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 250 Train Avg loss: 0.68083, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80465, Acc:0.48630, F1: 0.48630
====> Epoch: 251 Train Avg loss: 0.68155, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80591, Acc:0.48630, F1: 0.48630
====> Epoch: 252 Train Avg loss: 0.68450, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80682, Acc:0.48630, F1: 0.48630
====> Epoch: 253 Train Avg loss: 0.68263, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80664, Acc:0.48630, F1: 0.48630
====> Epoch: 254 Train Avg loss: 0.68307, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80724, Acc:0.48630, F1: 0.48630
====> Epoch: 255 Train Avg loss: 0.68374, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80590, Acc:0.48630, F1: 0.48630
====> Epoch: 256 Train Avg loss: 0.68117, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80375, Acc:0.48630, F1: 0.48630
====> Epoch: 257 Train Avg loss: 0.68322, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80600, Acc:0.48630, F1: 0.48630
====> Epoch: 258 Train Avg loss: 0.68375, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80289, Acc:0.48630, F1: 0.48630
====> Epoch: 259 Train Avg loss: 0.68217, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80553, Acc:0.48630, F1: 0.48630
====> Epoch: 260 Train Avg loss: 0.68423, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80717, Acc:0.48630, F1: 0.48630
====> Epoch: 261 Train Avg loss: 0.68316, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80844, Acc:0.48630, F1: 0.48630
====> Epoch: 262 Train Avg loss: 0.68300, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80480, Acc:0.48630, F1: 0.48630
====> Epoch: 263 Train Avg loss: 0.68238, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80673, Acc:0.48630, F1: 0.48630
====> Epoch: 264 Train Avg loss: 0.68174, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80738, Acc:0.48630, F1: 0.48630
====> Epoch: 265 Train Avg loss: 0.68136, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80607, Acc:0.48630, F1: 0.48630
====> Epoch: 266 Train Avg loss: 0.67998, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80019, Acc:0.48630, F1: 0.48630
===> Epoch: 266: Training loss decreased (0.68053 --> 0.67998), Acc: (0.55106 --> 0.55106), F1: (0.55085 --> 0.55123).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 267 Train Avg loss: 0.67774, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80620, Acc:0.48630, F1: 0.48630
===> Epoch: 267: Training loss decreased (0.67998 --> 0.67774), Acc: (0.55106 --> 0.55106), F1: (0.55123 --> 0.55085).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600213614.928753.pth_1
====> Epoch: 268 Train Avg loss: 0.68280, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80613, Acc:0.48630, F1: 0.48630
====> Epoch: 269 Train Avg loss: 0.68210, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80339, Acc:0.48630, F1: 0.48630
====> Epoch: 270 Train Avg loss: 0.68252, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80365, Acc:0.48630, F1: 0.48630
====> Epoch: 271 Train Avg loss: 0.68262, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80485, Acc:0.48630, F1: 0.48630
====> Epoch: 272 Train Avg loss: 0.68236, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80395, Acc:0.48630, F1: 0.48630
====> Epoch: 273 Train Avg loss: 0.68193, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80513, Acc:0.48630, F1: 0.48630
====> Epoch: 274 Train Avg loss: 0.68410, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80431, Acc:0.48630, F1: 0.48630
====> Epoch: 275 Train Avg loss: 0.68332, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80534, Acc:0.48630, F1: 0.48630
====> Epoch: 276 Train Avg loss: 0.68292, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80303, Acc:0.48630, F1: 0.48630
====> Epoch: 277 Train Avg loss: 0.68102, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80267, Acc:0.48630, F1: 0.48630
====> Epoch: 278 Train Avg loss: 0.68127, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80168, Acc:0.48630, F1: 0.48630
====> Epoch: 279 Train Avg loss: 0.68278, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80157, Acc:0.48630, F1: 0.48630
====> Epoch: 280 Train Avg loss: 0.68144, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80317, Acc:0.48630, F1: 0.48630
====> Epoch: 281 Train Avg loss: 0.68172, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80327, Acc:0.48630, F1: 0.48630
====> Epoch: 282 Train Avg loss: 0.68264, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80168, Acc:0.48630, F1: 0.48630
====> Epoch: 283 Train Avg loss: 0.68100, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79968, Acc:0.48630, F1: 0.48630
====> Epoch: 284 Train Avg loss: 0.68184, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80145, Acc:0.48630, F1: 0.48630
====> Epoch: 285 Train Avg loss: 0.68192, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80230, Acc:0.48630, F1: 0.48630
====> Epoch: 286 Train Avg loss: 0.68065, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80193, Acc:0.48630, F1: 0.48630
====> Epoch: 287 Train Avg loss: 0.68345, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80188, Acc:0.48630, F1: 0.48630
====> Epoch: 288 Train Avg loss: 0.67875, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80327, Acc:0.48630, F1: 0.48630
====> Epoch: 289 Train Avg loss: 0.68047, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80183, Acc:0.48630, F1: 0.48630
====> Epoch: 290 Train Avg loss: 0.67902, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80384, Acc:0.48630, F1: 0.48630
====> Epoch: 291 Train Avg loss: 0.68029, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80071, Acc:0.48630, F1: 0.48630
====> Epoch: 292 Train Avg loss: 0.67876, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80135, Acc:0.48630, F1: 0.48630
====> Epoch: 293 Train Avg loss: 0.68123, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80184, Acc:0.48630, F1: 0.48630
====> Epoch: 294 Train Avg loss: 0.68086, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80180, Acc:0.48630, F1: 0.48630
====> Epoch: 295 Train Avg loss: 0.67970, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80229, Acc:0.48630, F1: 0.48630
====> Epoch: 296 Train Avg loss: 0.67854, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80124, Acc:0.48630, F1: 0.48630
====> Epoch: 297 Train Avg loss: 0.68061, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80192, Acc:0.48630, F1: 0.48630
====> Epoch: 298 Train Avg loss: 0.68085, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80064, Acc:0.48630, F1: 0.48630
====> Epoch: 299 Train Avg loss: 0.67823, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80226, Acc:0.48630, F1: 0.48630
====> Epoch: 300 Train Avg loss: 0.68526, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82271, Acc:0.48630, F1: 0.48630
====> Epoch: 301 Train Avg loss: 0.68943, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80401, Acc:0.48630, F1: 0.48630
====> Epoch: 302 Train Avg loss: 0.68594, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79625, Acc:0.48630, F1: 0.48630
====> Epoch: 303 Train Avg loss: 0.69078, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79567, Acc:0.48630, F1: 0.48630
====> Epoch: 304 Train Avg loss: 0.69025, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80806, Acc:0.48630, F1: 0.48630
====> Epoch: 305 Train Avg loss: 0.68678, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79121, Acc:0.48630, F1: 0.48630
====> Epoch: 306 Train Avg loss: 0.68793, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81276, Acc:0.48630, F1: 0.48630
====> Epoch: 307 Train Avg loss: 0.69142, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79093, Acc:0.48630, F1: 0.48630
====> Epoch: 308 Train Avg loss: 0.69260, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.78411, Acc:0.48630, F1: 0.48630
====> Epoch: 309 Train Avg loss: 0.68806, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79089, Acc:0.48630, F1: 0.48630
====> Epoch: 310 Train Avg loss: 0.69204, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80155, Acc:0.48630, F1: 0.48630
====> Epoch: 311 Train Avg loss: 0.68737, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80210, Acc:0.48630, F1: 0.48630
====> Epoch: 312 Train Avg loss: 0.68809, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81797, Acc:0.48630, F1: 0.48630
====> Epoch: 313 Train Avg loss: 0.68689, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81053, Acc:0.48630, F1: 0.48630
====> Epoch: 314 Train Avg loss: 0.68943, Acc: 0.55067, F1: 0.55046#####> Valid Avg loss: 0.80786, Acc:0.48630, F1: 0.48630
====> Epoch: 315 Train Avg loss: 0.69096, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80087, Acc:0.48630, F1: 0.48630
====> Epoch: 316 Train Avg loss: 0.69161, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79033, Acc:0.48630, F1: 0.48630
====> Epoch: 317 Train Avg loss: 0.69128, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80762, Acc:0.48630, F1: 0.48630
====> Epoch: 318 Train Avg loss: 0.69030, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79344, Acc:0.48630, F1: 0.48630
====> Epoch: 319 Train Avg loss: 0.68708, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82793, Acc:0.48630, F1: 0.48630
====> Epoch: 320 Train Avg loss: 0.69063, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81351, Acc:0.48630, F1: 0.48630
====> Epoch: 321 Train Avg loss: 0.69027, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79365, Acc:0.48630, F1: 0.48630
====> Epoch: 322 Train Avg loss: 0.68867, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82423, Acc:0.48630, F1: 0.48630
====> Epoch: 323 Train Avg loss: 0.68813, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81992, Acc:0.48630, F1: 0.48630
====> Epoch: 324 Train Avg loss: 0.69202, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81140, Acc:0.48630, F1: 0.48630
====> Epoch: 325 Train Avg loss: 0.68947, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79184, Acc:0.48630, F1: 0.48630
====> Epoch: 326 Train Avg loss: 0.69033, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79485, Acc:0.48630, F1: 0.48630
====> Epoch: 327 Train Avg loss: 0.68993, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80661, Acc:0.48630, F1: 0.48630
====> Epoch: 328 Train Avg loss: 0.69114, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81158, Acc:0.48630, F1: 0.48630
====> Epoch: 329 Train Avg loss: 0.68870, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81074, Acc:0.48630, F1: 0.48630
====> Epoch: 330 Train Avg loss: 0.69010, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81487, Acc:0.48630, F1: 0.48630
====> Epoch: 331 Train Avg loss: 0.69075, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80171, Acc:0.48630, F1: 0.48630
====> Epoch: 332 Train Avg loss: 0.68755, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80052, Acc:0.48630, F1: 0.48630
====> Epoch: 333 Train Avg loss: 0.69007, Acc: 0.55067, F1: 0.55085#####> Valid Avg loss: 0.80117, Acc:0.48630, F1: 0.48630
====> Epoch: 334 Train Avg loss: 0.68919, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81204, Acc:0.48630, F1: 0.48630
====> Epoch: 335 Train Avg loss: 0.68840, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80027, Acc:0.48630, F1: 0.48630
====> Epoch: 336 Train Avg loss: 0.69033, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.78914, Acc:0.48630, F1: 0.48630
====> Epoch: 337 Train Avg loss: 0.69017, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80586, Acc:0.48630, F1: 0.48630
====> Epoch: 338 Train Avg loss: 0.68898, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.78730, Acc:0.48630, F1: 0.48630
====> Epoch: 339 Train Avg loss: 0.69001, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80546, Acc:0.48630, F1: 0.48630
====> Epoch: 340 Train Avg loss: 0.68918, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79993, Acc:0.48630, F1: 0.48630
====> Epoch: 341 Train Avg loss: 0.68943, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.78983, Acc:0.48630, F1: 0.48630
====> Epoch: 342 Train Avg loss: 0.68956, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79767, Acc:0.48630, F1: 0.48630
====> Epoch: 343 Train Avg loss: 0.68909, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79793, Acc:0.48630, F1: 0.48630
====> Epoch: 344 Train Avg loss: 0.68894, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79574, Acc:0.48630, F1: 0.48630
====> Epoch: 345 Train Avg loss: 0.68959, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80981, Acc:0.48630, F1: 0.48630
====> Epoch: 346 Train Avg loss: 0.69017, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81936, Acc:0.48630, F1: 0.48630
====> Epoch: 347 Train Avg loss: 0.69046, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80793, Acc:0.48630, F1: 0.48630
====> Epoch: 348 Train Avg loss: 0.68851, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81661, Acc:0.48630, F1: 0.48630
====> Epoch: 349 Train Avg loss: 0.69029, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79156, Acc:0.48630, F1: 0.48630
====> Epoch: 350 Train Avg loss: 0.69133, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79774, Acc:0.48630, F1: 0.48630
====> Epoch: 351 Train Avg loss: 0.69096, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81171, Acc:0.48630, F1: 0.48630
====> Epoch: 352 Train Avg loss: 0.69053, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80745, Acc:0.48630, F1: 0.48630
====> Epoch: 353 Train Avg loss: 0.68830, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81266, Acc:0.48630, F1: 0.48630
====> Epoch: 354 Train Avg loss: 0.68883, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80125, Acc:0.48630, F1: 0.48630
====> Epoch: 355 Train Avg loss: 0.68911, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82140, Acc:0.48630, F1: 0.48630
====> Epoch: 356 Train Avg loss: 0.68947, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82271, Acc:0.48630, F1: 0.48630
====> Epoch: 357 Train Avg loss: 0.68710, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79594, Acc:0.48630, F1: 0.48630
====> Epoch: 358 Train Avg loss: 0.68929, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79929, Acc:0.48630, F1: 0.48630
====> Epoch: 359 Train Avg loss: 0.68891, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79770, Acc:0.48630, F1: 0.48630
====> Epoch: 360 Train Avg loss: 0.68860, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.78526, Acc:0.48630, F1: 0.48630
====> Epoch: 361 Train Avg loss: 0.68865, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81528, Acc:0.48630, F1: 0.48630
====> Epoch: 362 Train Avg loss: 0.69052, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.82283, Acc:0.48630, F1: 0.48630
====> Epoch: 363 Train Avg loss: 0.69085, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80302, Acc:0.48630, F1: 0.48630
====> Epoch: 364 Train Avg loss: 0.68978, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79201, Acc:0.48630, F1: 0.48630
====> Epoch: 365 Train Avg loss: 0.69126, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80369, Acc:0.48630, F1: 0.48630
====> Epoch: 366 Train Avg loss: 0.68843, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80946, Acc:0.48630, F1: 0.48630
====> Epoch: 367 Train Avg loss: 0.68834, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80643, Acc:0.48630, F1: 0.48630
====> Epoch: 368 Train Avg loss: 0.68758, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79732, Acc:0.48630, F1: 0.48630
====> Epoch: 369 Train Avg loss: 0.68987, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81113, Acc:0.48630, F1: 0.48630
====> Epoch: 370 Train Avg loss: 0.68680, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80310, Acc:0.48630, F1: 0.48630
====> Epoch: 371 Train Avg loss: 0.68919, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80905, Acc:0.48630, F1: 0.48630
====> Epoch: 372 Train Avg loss: 0.68933, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80430, Acc:0.48630, F1: 0.48630
====> Epoch: 373 Train Avg loss: 0.68855, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80102, Acc:0.48630, F1: 0.48630
====> Epoch: 374 Train Avg loss: 0.68628, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79786, Acc:0.48630, F1: 0.48630
====> Epoch: 375 Train Avg loss: 0.69140, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80738, Acc:0.48630, F1: 0.48630
====> Epoch: 376 Train Avg loss: 0.68957, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82374, Acc:0.48630, F1: 0.48630
====> Epoch: 377 Train Avg loss: 0.68707, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.80340, Acc:0.48630, F1: 0.48630
====> Epoch: 378 Train Avg loss: 0.68835, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79314, Acc:0.48630, F1: 0.48630
====> Epoch: 379 Train Avg loss: 0.68710, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.81964, Acc:0.48630, F1: 0.48630
====> Epoch: 380 Train Avg loss: 0.68849, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81019, Acc:0.48630, F1: 0.48630
====> Epoch: 381 Train Avg loss: 0.68784, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.79545, Acc:0.48630, F1: 0.48630
====> Epoch: 382 Train Avg loss: 0.68775, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.80952, Acc:0.48630, F1: 0.48630
====> Epoch: 383 Train Avg loss: 0.68754, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79835, Acc:0.48630, F1: 0.48630
====> Epoch: 384 Train Avg loss: 0.68721, Acc: 0.55106, F1: 0.55085#####> Valid Avg loss: 0.78541, Acc:0.48630, F1: 0.48630
====> Epoch: 385 Train Avg loss: 0.68833, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81148, Acc:0.48630, F1: 0.48630
====> Epoch: 386 Train Avg loss: 0.68498, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.79382, Acc:0.48630, F1: 0.48630
====> Epoch: 387 Train Avg loss: 0.69005, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.81823, Acc:0.48630, F1: 0.48630
====> Epoch: 388 Train Avg loss: 0.68601, Acc: 0.55106, F1: 0.55123#####> Valid Avg loss: 0.82624, Acc:0.48630, F1: 0.48630
====> Epoch: 389 Train Avg loss: 0.69016, Acc: 0.55106, F1: 0.55085validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 9train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1298
valid_dataloader len: 438
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2595, train dataloader len: 1298
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 428, test dataloader len: 438
====> Epoch: 1 Train Avg loss: 0.90681, Acc: 0.51869, F1: 0.51888#####> Valid Avg loss: 0.80232, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 0.90681), Acc: (0.00000 --> 0.51869), F1: (0.00000 --> 0.51888).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.80232), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.80232), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 2 Train Avg loss: 0.77501, Acc: 0.54104, F1: 0.54083#####> Valid Avg loss: 0.77848, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (0.90681 --> 0.77501), Acc: (0.51869 --> 0.54104), F1: (0.51888 --> 0.54083).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1

####> Epoch: 2: validation loss decreased (0.80232 --> 0.77848), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 3 Train Avg loss: 0.72997, Acc: 0.54875, F1: 0.54892#####> Valid Avg loss: 0.80581, Acc:0.48630, F1: 0.48630
===> Epoch: 3: Training loss decreased (0.77501 --> 0.72997), Acc: (0.54104 --> 0.54875), F1: (0.54083 --> 0.54892).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 4 Train Avg loss: 0.71681, Acc: 0.55067, F1: 0.55046#####> Valid Avg loss: 0.81771, Acc:0.48630, F1: 0.48630
===> Epoch: 4: Training loss decreased (0.72997 --> 0.71681), Acc: (0.54875 --> 0.55067), F1: (0.54892 --> 0.55046).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 5 Train Avg loss: 0.69117, Acc: 0.55029, F1: 0.55008#####> Valid Avg loss: 0.79143, Acc:0.48630, F1: 0.48630
===> Epoch: 5: Training loss decreased (0.71681 --> 0.69117), Acc: (0.55067 --> 0.55029), F1: (0.55046 --> 0.55008).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 6 Train Avg loss: 0.68404, Acc: 0.55299, F1: 0.55277#####> Valid Avg loss: 0.79227, Acc:0.48630, F1: 0.48630
===> Epoch: 6: Training loss decreased (0.69117 --> 0.68404), Acc: (0.55029 --> 0.55299), F1: (0.55008 --> 0.55277).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 7 Train Avg loss: 0.68058, Acc: 0.54798, F1: 0.54777#####> Valid Avg loss: 0.78477, Acc:0.48630, F1: 0.48630
===> Epoch: 7: Training loss decreased (0.68404 --> 0.68058), Acc: (0.55299 --> 0.54798), F1: (0.55277 --> 0.54777).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 8 Train Avg loss: 0.66956, Acc: 0.54913, F1: 0.54931#####> Valid Avg loss: 0.84684, Acc:0.48630, F1: 0.48630
===> Epoch: 8: Training loss decreased (0.68058 --> 0.66956), Acc: (0.54798 --> 0.54913), F1: (0.54777 --> 0.54931).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 9 Train Avg loss: 0.67411, Acc: 0.54759, F1: 0.54738#####> Valid Avg loss: 0.79998, Acc:0.48630, F1: 0.48630
====> Epoch: 10 Train Avg loss: 0.66821, Acc: 0.54412, F1: 0.54430#####> Valid Avg loss: 0.81769, Acc:0.48630, F1: 0.48630
===> Epoch: 10: Training loss decreased (0.66956 --> 0.66821), Acc: (0.54913 --> 0.54412), F1: (0.54931 --> 0.54430).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 11 Train Avg loss: 0.66227, Acc: 0.54875, F1: 0.54854#####> Valid Avg loss: 0.80113, Acc:0.48630, F1: 0.48630
===> Epoch: 11: Training loss decreased (0.66821 --> 0.66227), Acc: (0.54412 --> 0.54875), F1: (0.54430 --> 0.54854).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 12 Train Avg loss: 0.65316, Acc: 0.55491, F1: 0.55508#####> Valid Avg loss: 0.81190, Acc:0.48630, F1: 0.48630
===> Epoch: 12: Training loss decreased (0.66227 --> 0.65316), Acc: (0.54875 --> 0.55491), F1: (0.54854 --> 0.55508).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 13 Train Avg loss: 0.65671, Acc: 0.56262, F1: 0.56279#####> Valid Avg loss: 0.80823, Acc:0.48630, F1: 0.48630
====> Epoch: 14 Train Avg loss: 0.65358, Acc: 0.55453, F1: 0.55431#####> Valid Avg loss: 0.81395, Acc:0.48630, F1: 0.48630
====> Epoch: 15 Train Avg loss: 0.64794, Acc: 0.56108, F1: 0.56125#####> Valid Avg loss: 0.78875, Acc:0.48630, F1: 0.48630
===> Epoch: 15: Training loss decreased (0.65316 --> 0.64794), Acc: (0.55491 --> 0.56108), F1: (0.55508 --> 0.56125).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 16 Train Avg loss: 0.64981, Acc: 0.57033, F1: 0.57049#####> Valid Avg loss: 0.80475, Acc:0.48630, F1: 0.48630
====> Epoch: 17 Train Avg loss: 0.64388, Acc: 0.57033, F1: 0.57049#####> Valid Avg loss: 0.85139, Acc:0.46575, F1: 0.46575
===> Epoch: 17: Training loss decreased (0.64794 --> 0.64388), Acc: (0.56108 --> 0.57033), F1: (0.56125 --> 0.57049).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 18 Train Avg loss: 0.63929, Acc: 0.57110, F1: 0.57126#####> Valid Avg loss: 0.81348, Acc:0.48516, F1: 0.48516
===> Epoch: 18: Training loss decreased (0.64388 --> 0.63929), Acc: (0.57033 --> 0.57110), F1: (0.57049 --> 0.57126).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 19 Train Avg loss: 0.63673, Acc: 0.57225, F1: 0.57242#####> Valid Avg loss: 0.82622, Acc:0.46347, F1: 0.46347
===> Epoch: 19: Training loss decreased (0.63929 --> 0.63673), Acc: (0.57110 --> 0.57225), F1: (0.57126 --> 0.57242).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 20 Train Avg loss: 0.63887, Acc: 0.56647, F1: 0.56664#####> Valid Avg loss: 0.80709, Acc:0.48516, F1: 0.48516
====> Epoch: 21 Train Avg loss: 0.63257, Acc: 0.56879, F1: 0.56895#####> Valid Avg loss: 0.82000, Acc:0.48744, F1: 0.48744
===> Epoch: 21: Training loss decreased (0.63673 --> 0.63257), Acc: (0.57225 --> 0.56879), F1: (0.57242 --> 0.56895).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1

####> Epoch: 21: validation acc increase (0.80232 --> 0.82000), Acc: (0.48630 --> 0.48744), F1: (0.48630 --> 0.48744).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 22 Train Avg loss: 0.63397, Acc: 0.57842, F1: 0.57858#####> Valid Avg loss: 0.81712, Acc:0.48402, F1: 0.48402
====> Epoch: 23 Train Avg loss: 0.63023, Acc: 0.57495, F1: 0.57512#####> Valid Avg loss: 0.85219, Acc:0.40982, F1: 0.40982
===> Epoch: 23: Training loss decreased (0.63257 --> 0.63023), Acc: (0.56879 --> 0.57495), F1: (0.56895 --> 0.57512).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 24 Train Avg loss: 0.63151, Acc: 0.57726, F1: 0.57704#####> Valid Avg loss: 0.80066, Acc:0.48402, F1: 0.48402
====> Epoch: 25 Train Avg loss: 0.63328, Acc: 0.57264, F1: 0.57280#####> Valid Avg loss: 0.81570, Acc:0.47945, F1: 0.47945
====> Epoch: 26 Train Avg loss: 0.62564, Acc: 0.57765, F1: 0.57743#####> Valid Avg loss: 0.81024, Acc:0.48402, F1: 0.48402
===> Epoch: 26: Training loss decreased (0.63023 --> 0.62564), Acc: (0.57495 --> 0.57765), F1: (0.57512 --> 0.57743).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 27 Train Avg loss: 0.62307, Acc: 0.57688, F1: 0.57666#####> Valid Avg loss: 0.82818, Acc:0.48288, F1: 0.48288
===> Epoch: 27: Training loss decreased (0.62564 --> 0.62307), Acc: (0.57765 --> 0.57688), F1: (0.57743 --> 0.57666).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 28 Train Avg loss: 0.62401, Acc: 0.58035, F1: 0.58012#####> Valid Avg loss: 0.79314, Acc:0.48630, F1: 0.48630
====> Epoch: 29 Train Avg loss: 0.62330, Acc: 0.57765, F1: 0.57743#####> Valid Avg loss: 0.88845, Acc:0.41438, F1: 0.41438
====> Epoch: 30 Train Avg loss: 0.61867, Acc: 0.57765, F1: 0.57781#####> Valid Avg loss: 0.81403, Acc:0.48630, F1: 0.48630
===> Epoch: 30: Training loss decreased (0.62307 --> 0.61867), Acc: (0.57688 --> 0.57765), F1: (0.57666 --> 0.57781).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 31 Train Avg loss: 0.61520, Acc: 0.57649, F1: 0.57666#####> Valid Avg loss: 0.85622, Acc:0.48630, F1: 0.48630
===> Epoch: 31: Training loss decreased (0.61867 --> 0.61520), Acc: (0.57765 --> 0.57649), F1: (0.57781 --> 0.57666).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 32 Train Avg loss: 0.61692, Acc: 0.57341, F1: 0.57319#####> Valid Avg loss: 0.89511, Acc:0.30251, F1: 0.30251
====> Epoch: 33 Train Avg loss: 0.61585, Acc: 0.57688, F1: 0.57704#####> Valid Avg loss: 0.96953, Acc:0.37329, F1: 0.37329
====> Epoch: 34 Train Avg loss: 0.61943, Acc: 0.57572, F1: 0.57589#####> Valid Avg loss: 0.88206, Acc:0.43721, F1: 0.43721
====> Epoch: 35 Train Avg loss: 0.60937, Acc: 0.58150, F1: 0.58166#####> Valid Avg loss: 0.84489, Acc:0.46461, F1: 0.46461
===> Epoch: 35: Training loss decreased (0.61520 --> 0.60937), Acc: (0.57649 --> 0.58150), F1: (0.57666 --> 0.58166).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 36 Train Avg loss: 0.61196, Acc: 0.58073, F1: 0.58089#####> Valid Avg loss: 0.92015, Acc:0.34932, F1: 0.34932
====> Epoch: 37 Train Avg loss: 0.60251, Acc: 0.58073, F1: 0.58089#####> Valid Avg loss: 1.17538, Acc:0.27283, F1: 0.27283
===> Epoch: 37: Training loss decreased (0.60937 --> 0.60251), Acc: (0.58150 --> 0.58073), F1: (0.58166 --> 0.58089).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600223836.100507.pth_1
====> Epoch: 38 Train Avg loss: 0.60585, Acc: 0.57958, F1: 0.57935#####> Valid Avg loss: 1.01853, Acc:0.40525, F1: 0.40525
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600224923.212436.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 9train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1298
valid_dataloader len: 438
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2595, train dataloader len: 1298
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 428, test dataloader len: 438
====> Epoch: 1 Train Avg loss: 0.84066, Acc: 0.52640, F1: 0.52658#####> Valid Avg loss: 0.78238, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 0.84066), Acc: (0.00000 --> 0.52640), F1: (0.00000 --> 0.52658).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.78238), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.78238), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth_1
====> Epoch: 2 Train Avg loss: 0.75059, Acc: 0.53410, F1: 0.53428#####> Valid Avg loss: 0.81564, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (0.84066 --> 0.75059), Acc: (0.52640 --> 0.53410), F1: (0.52658 --> 0.53428).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth_1
====> Epoch: 3 Train Avg loss: 0.72937, Acc: 0.55260, F1: 0.55239#####> Valid Avg loss: 0.80275, Acc:0.48402, F1: 0.48402
===> Epoch: 3: Training loss decreased (0.75059 --> 0.72937), Acc: (0.53410 --> 0.55260), F1: (0.53428 --> 0.55239).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth_1
====> Epoch: 4 Train Avg loss: 0.70877, Acc: 0.56146, F1: 0.56163#####> Valid Avg loss: 0.79129, Acc:0.48630, F1: 0.48630
===> Epoch: 4: Training loss decreased (0.72937 --> 0.70877), Acc: (0.55260 --> 0.56146), F1: (0.55239 --> 0.56163).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth_1
====> Epoch: 5 Train Avg loss: 0.69849, Acc: 0.56146, F1: 0.56125#####> Valid Avg loss: 0.74757, Acc:0.48630, F1: 0.48630
===> Epoch: 5: Training loss decreased (0.70877 --> 0.69849), Acc: (0.56146 --> 0.56146), F1: (0.56163 --> 0.56125).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth_1

####> Epoch: 5: validation loss decreased (0.78238 --> 0.74757), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth_1
====> Epoch: 6 Train Avg loss: 0.69329, Acc: 0.56686, F1: 0.56703#####> Valid Avg loss: 0.81328, Acc:0.48516, F1: 0.48516
===> Epoch: 6: Training loss decreased (0.69849 --> 0.69329), Acc: (0.56146 --> 0.56686), F1: (0.56125 --> 0.56703).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600224992.727051.pth_1
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600225275.163475.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 9train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1298
valid_dataloader len: 438
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2595, train dataloader len: 1298
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 428, test dataloader len: 438
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600225343.436028.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 9train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1298
valid_dataloader len: 438
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2595, train dataloader len: 1298
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 428, test dataloader len: 438
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600225437.78758.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 9train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1298
valid_dataloader len: 438
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2595, train dataloader len: 1298
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 428, test dataloader len: 438
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 9train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 1298
valid_dataloader len: 438
test_dataloader len: 214
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 2595, train dataloader len: 1298
valid dataset len: 876, valid dataloader len: 438
valid dataset len: 428, test dataloader len: 438
====> Epoch: 1 Train Avg loss: 1.13988, Acc: 0.53719, F1: 0.53737#####> Valid Avg loss: 0.93338, Acc:0.48630, F1: 0.48630
===> Epoch: 1: Training loss decreased (inf --> 1.13988), Acc: (0.00000 --> 0.53719), F1: (0.00000 --> 0.53737).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1

####> Epoch: 1: validation loss decreased (inf --> 0.93338), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1

####> Epoch: 1: validation acc increase (inf --> 0.93338), Acc: (0.00000 --> 0.48630), F1: (0.00000 --> 0.48630).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 2 Train Avg loss: 0.75836, Acc: 0.52447, F1: 0.52427#####> Valid Avg loss: 0.78164, Acc:0.48630, F1: 0.48630
===> Epoch: 2: Training loss decreased (1.13988 --> 0.75836), Acc: (0.53719 --> 0.52447), F1: (0.53737 --> 0.52427).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1

####> Epoch: 2: validation loss decreased (0.93338 --> 0.78164), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 3 Train Avg loss: 0.69911, Acc: 0.54489, F1: 0.54507#####> Valid Avg loss: 0.83049, Acc:0.48630, F1: 0.48630
===> Epoch: 3: Training loss decreased (0.75836 --> 0.69911), Acc: (0.52447 --> 0.54489), F1: (0.52427 --> 0.54507).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 4 Train Avg loss: 0.68432, Acc: 0.56378, F1: 0.56356#####> Valid Avg loss: 0.78705, Acc:0.48059, F1: 0.48059
===> Epoch: 4: Training loss decreased (0.69911 --> 0.68432), Acc: (0.54489 --> 0.56378), F1: (0.54507 --> 0.56356).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 5 Train Avg loss: 0.66681, Acc: 0.56686, F1: 0.56703#####> Valid Avg loss: 0.82552, Acc:0.47146, F1: 0.47146
===> Epoch: 5: Training loss decreased (0.68432 --> 0.66681), Acc: (0.56378 --> 0.56686), F1: (0.56356 --> 0.56703).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 6 Train Avg loss: 0.66467, Acc: 0.56455, F1: 0.56471#####> Valid Avg loss: 0.78048, Acc:0.48630, F1: 0.48630
===> Epoch: 6: Training loss decreased (0.66681 --> 0.66467), Acc: (0.56686 --> 0.56455), F1: (0.56703 --> 0.56471).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1

####> Epoch: 6: validation loss decreased (0.78164 --> 0.78048), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 7 Train Avg loss: 0.65216, Acc: 0.57418, F1: 0.57435#####> Valid Avg loss: 0.80724, Acc:0.48174, F1: 0.48174
===> Epoch: 7: Training loss decreased (0.66467 --> 0.65216), Acc: (0.56455 --> 0.57418), F1: (0.56471 --> 0.57435).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 8 Train Avg loss: 0.64200, Acc: 0.57726, F1: 0.57743#####> Valid Avg loss: 0.79629, Acc:0.48630, F1: 0.48630
===> Epoch: 8: Training loss decreased (0.65216 --> 0.64200), Acc: (0.57418 --> 0.57726), F1: (0.57435 --> 0.57743).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 9 Train Avg loss: 0.63665, Acc: 0.57726, F1: 0.57743#####> Valid Avg loss: 0.79767, Acc:0.48516, F1: 0.48516
===> Epoch: 9: Training loss decreased (0.64200 --> 0.63665), Acc: (0.57726 --> 0.57726), F1: (0.57743 --> 0.57743).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 10 Train Avg loss: 0.63998, Acc: 0.57726, F1: 0.57704#####> Valid Avg loss: 0.81840, Acc:0.48630, F1: 0.48630
====> Epoch: 11 Train Avg loss: 0.63186, Acc: 0.57919, F1: 0.57935#####> Valid Avg loss: 0.79311, Acc:0.48288, F1: 0.48288
===> Epoch: 11: Training loss decreased (0.63665 --> 0.63186), Acc: (0.57726 --> 0.57919), F1: (0.57743 --> 0.57935).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 12 Train Avg loss: 0.62205, Acc: 0.58150, F1: 0.58166#####> Valid Avg loss: 0.79037, Acc:0.48630, F1: 0.48630
===> Epoch: 12: Training loss decreased (0.63186 --> 0.62205), Acc: (0.57919 --> 0.58150), F1: (0.57935 --> 0.58166).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 13 Train Avg loss: 0.62890, Acc: 0.57534, F1: 0.57550#####> Valid Avg loss: 0.80532, Acc:0.48630, F1: 0.48630
====> Epoch: 14 Train Avg loss: 0.61911, Acc: 0.57842, F1: 0.57858#####> Valid Avg loss: 0.78645, Acc:0.48516, F1: 0.48516
===> Epoch: 14: Training loss decreased (0.62205 --> 0.61911), Acc: (0.58150 --> 0.57842), F1: (0.58166 --> 0.57858).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 15 Train Avg loss: 0.61758, Acc: 0.57534, F1: 0.57550#####> Valid Avg loss: 0.86734, Acc:0.41324, F1: 0.41324
===> Epoch: 15: Training loss decreased (0.61911 --> 0.61758), Acc: (0.57842 --> 0.57534), F1: (0.57858 --> 0.57550).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 16 Train Avg loss: 0.61630, Acc: 0.58112, F1: 0.58089#####> Valid Avg loss: 0.80351, Acc:0.48516, F1: 0.48516
===> Epoch: 16: Training loss decreased (0.61758 --> 0.61630), Acc: (0.57534 --> 0.58112), F1: (0.57550 --> 0.58089).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 17 Train Avg loss: 0.60800, Acc: 0.57881, F1: 0.57897#####> Valid Avg loss: 0.80282, Acc:0.47374, F1: 0.47374
===> Epoch: 17: Training loss decreased (0.61630 --> 0.60800), Acc: (0.58112 --> 0.57881), F1: (0.58089 --> 0.57897).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 18 Train Avg loss: 0.61206, Acc: 0.57842, F1: 0.57858#####> Valid Avg loss: 0.78858, Acc:0.48174, F1: 0.48174
====> Epoch: 19 Train Avg loss: 0.60536, Acc: 0.57803, F1: 0.57820#####> Valid Avg loss: 0.80729, Acc:0.48516, F1: 0.48516
===> Epoch: 19: Training loss decreased (0.60800 --> 0.60536), Acc: (0.57881 --> 0.57803), F1: (0.57897 --> 0.57820).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 20 Train Avg loss: 0.60100, Acc: 0.58227, F1: 0.58205#####> Valid Avg loss: 0.79477, Acc:0.48630, F1: 0.48630
===> Epoch: 20: Training loss decreased (0.60536 --> 0.60100), Acc: (0.57803 --> 0.58227), F1: (0.57820 --> 0.58205).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 21 Train Avg loss: 0.60135, Acc: 0.58459, F1: 0.58436#####> Valid Avg loss: 0.79854, Acc:0.48630, F1: 0.48630
====> Epoch: 22 Train Avg loss: 0.60339, Acc: 0.57996, F1: 0.58012#####> Valid Avg loss: 0.79165, Acc:0.48630, F1: 0.48630
====> Epoch: 23 Train Avg loss: 0.59720, Acc: 0.57534, F1: 0.57512#####> Valid Avg loss: 0.78739, Acc:0.48402, F1: 0.48402
===> Epoch: 23: Training loss decreased (0.60100 --> 0.59720), Acc: (0.58227 --> 0.57534), F1: (0.58205 --> 0.57512).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 24 Train Avg loss: 0.60210, Acc: 0.58073, F1: 0.58089#####> Valid Avg loss: 0.90079, Acc:0.33333, F1: 0.33333
====> Epoch: 25 Train Avg loss: 0.60411, Acc: 0.58073, F1: 0.58089#####> Valid Avg loss: 0.80245, Acc:0.48630, F1: 0.48630
====> Epoch: 26 Train Avg loss: 0.59132, Acc: 0.58035, F1: 0.58051#####> Valid Avg loss: 0.81848, Acc:0.48402, F1: 0.48402
===> Epoch: 26: Training loss decreased (0.59720 --> 0.59132), Acc: (0.57534 --> 0.58035), F1: (0.57512 --> 0.58051).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 27 Train Avg loss: 0.59618, Acc: 0.57611, F1: 0.57589#####> Valid Avg loss: 0.82730, Acc:0.43493, F1: 0.43493
====> Epoch: 28 Train Avg loss: 0.59216, Acc: 0.57996, F1: 0.57974#####> Valid Avg loss: 0.81863, Acc:0.48288, F1: 0.48288
====> Epoch: 29 Train Avg loss: 0.58890, Acc: 0.58459, F1: 0.58475#####> Valid Avg loss: 0.82084, Acc:0.48516, F1: 0.48516
===> Epoch: 29: Training loss decreased (0.59132 --> 0.58890), Acc: (0.58035 --> 0.58459), F1: (0.58051 --> 0.58475).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 30 Train Avg loss: 0.58401, Acc: 0.58382, F1: 0.58359#####> Valid Avg loss: 0.82789, Acc:0.47032, F1: 0.47032
===> Epoch: 30: Training loss decreased (0.58890 --> 0.58401), Acc: (0.58459 --> 0.58382), F1: (0.58475 --> 0.58359).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 31 Train Avg loss: 0.58501, Acc: 0.58921, F1: 0.58937#####> Valid Avg loss: 0.77761, Acc:0.48630, F1: 0.48630

####> Epoch: 31: validation loss decreased (0.78048 --> 0.77761), Acc: (0.48630 --> 0.48630), F1: (0.48630 --> 0.48630).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 32 Train Avg loss: 0.58378, Acc: 0.58690, F1: 0.58667#####> Valid Avg loss: 0.79110, Acc:0.48059, F1: 0.48059
===> Epoch: 32: Training loss decreased (0.58401 --> 0.58378), Acc: (0.58382 --> 0.58690), F1: (0.58359 --> 0.58667).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 33 Train Avg loss: 0.57893, Acc: 0.59075, F1: 0.59052#####> Valid Avg loss: 0.81504, Acc:0.41324, F1: 0.41324
===> Epoch: 33: Training loss decreased (0.58378 --> 0.57893), Acc: (0.58690 --> 0.59075), F1: (0.58667 --> 0.59052).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 34 Train Avg loss: 0.57505, Acc: 0.58805, F1: 0.58783#####> Valid Avg loss: 0.86740, Acc:0.33447, F1: 0.33447
===> Epoch: 34: Training loss decreased (0.57893 --> 0.57505), Acc: (0.59075 --> 0.58805), F1: (0.59052 --> 0.58783).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 35 Train Avg loss: 0.57807, Acc: 0.59037, F1: 0.59052#####> Valid Avg loss: 0.82446, Acc:0.46689, F1: 0.46689
====> Epoch: 36 Train Avg loss: 0.57010, Acc: 0.59730, F1: 0.59707#####> Valid Avg loss: 0.82345, Acc:0.46918, F1: 0.46918
===> Epoch: 36: Training loss decreased (0.57505 --> 0.57010), Acc: (0.58805 --> 0.59730), F1: (0.58783 --> 0.59707).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 37 Train Avg loss: 0.56897, Acc: 0.58998, F1: 0.59014#####> Valid Avg loss: 0.86673, Acc:0.37900, F1: 0.37900
===> Epoch: 37: Training loss decreased (0.57010 --> 0.56897), Acc: (0.59730 --> 0.58998), F1: (0.59707 --> 0.59014).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 38 Train Avg loss: 0.56833, Acc: 0.59653, F1: 0.59669#####> Valid Avg loss: 0.78535, Acc:0.48402, F1: 0.48402
===> Epoch: 38: Training loss decreased (0.56897 --> 0.56833), Acc: (0.58998 --> 0.59653), F1: (0.59014 --> 0.59669).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 39 Train Avg loss: 0.56862, Acc: 0.59769, F1: 0.59784#####> Valid Avg loss: 0.82874, Acc:0.45776, F1: 0.45776
====> Epoch: 40 Train Avg loss: 0.56624, Acc: 0.59345, F1: 0.59322#####> Valid Avg loss: 0.80921, Acc:0.47146, F1: 0.47146
===> Epoch: 40: Training loss decreased (0.56833 --> 0.56624), Acc: (0.59653 --> 0.59345), F1: (0.59669 --> 0.59322).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 41 Train Avg loss: 0.55492, Acc: 0.60540, F1: 0.60516#####> Valid Avg loss: 0.81936, Acc:0.47945, F1: 0.47945
===> Epoch: 41: Training loss decreased (0.56624 --> 0.55492), Acc: (0.59345 --> 0.60540), F1: (0.59322 --> 0.60516).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 42 Train Avg loss: 0.55891, Acc: 0.59461, F1: 0.59476#####> Valid Avg loss: 0.90452, Acc:0.40525, F1: 0.40525
====> Epoch: 43 Train Avg loss: 0.55273, Acc: 0.60501, F1: 0.60516#####> Valid Avg loss: 0.81092, Acc:0.46233, F1: 0.46233
===> Epoch: 43: Training loss decreased (0.55492 --> 0.55273), Acc: (0.60540 --> 0.60501), F1: (0.60516 --> 0.60516).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 44 Train Avg loss: 0.55455, Acc: 0.59461, F1: 0.59476#####> Valid Avg loss: 0.79666, Acc:0.43950, F1: 0.43950
====> Epoch: 45 Train Avg loss: 0.55431, Acc: 0.59769, F1: 0.59746#####> Valid Avg loss: 0.81411, Acc:0.48174, F1: 0.48174
====> Epoch: 46 Train Avg loss: 0.55061, Acc: 0.60694, F1: 0.60670#####> Valid Avg loss: 0.83519, Acc:0.40297, F1: 0.40297
===> Epoch: 46: Training loss decreased (0.55273 --> 0.55061), Acc: (0.60501 --> 0.60694), F1: (0.60516 --> 0.60670).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 47 Train Avg loss: 0.55005, Acc: 0.61233, F1: 0.61210#####> Valid Avg loss: 0.82390, Acc:0.46804, F1: 0.46804
===> Epoch: 47: Training loss decreased (0.55061 --> 0.55005), Acc: (0.60694 --> 0.61233), F1: (0.60670 --> 0.61210).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 48 Train Avg loss: 0.53801, Acc: 0.61927, F1: 0.61941#####> Valid Avg loss: 0.83472, Acc:0.45091, F1: 0.45091
===> Epoch: 48: Training loss decreased (0.55005 --> 0.53801), Acc: (0.61233 --> 0.61927), F1: (0.61210 --> 0.61941).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 49 Train Avg loss: 0.53645, Acc: 0.61195, F1: 0.61171#####> Valid Avg loss: 0.81647, Acc:0.45662, F1: 0.45662
===> Epoch: 49: Training loss decreased (0.53801 --> 0.53645), Acc: (0.61927 --> 0.61195), F1: (0.61941 --> 0.61171).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 50 Train Avg loss: 0.54025, Acc: 0.61541, F1: 0.61556#####> Valid Avg loss: 0.83908, Acc:0.44977, F1: 0.44977
====> Epoch: 51 Train Avg loss: 0.53212, Acc: 0.62235, F1: 0.62211#####> Valid Avg loss: 0.82518, Acc:0.43151, F1: 0.43151
===> Epoch: 51: Training loss decreased (0.53645 --> 0.53212), Acc: (0.61195 --> 0.62235), F1: (0.61171 --> 0.62211).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 52 Train Avg loss: 0.52914, Acc: 0.61734, F1: 0.61749#####> Valid Avg loss: 0.86763, Acc:0.40183, F1: 0.40183
===> Epoch: 52: Training loss decreased (0.53212 --> 0.52914), Acc: (0.62235 --> 0.61734), F1: (0.62211 --> 0.61749).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 53 Train Avg loss: 0.52531, Acc: 0.62505, F1: 0.62481#####> Valid Avg loss: 0.82949, Acc:0.39269, F1: 0.39269
===> Epoch: 53: Training loss decreased (0.52914 --> 0.52531), Acc: (0.61734 --> 0.62505), F1: (0.61749 --> 0.62481).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 54 Train Avg loss: 0.52212, Acc: 0.62890, F1: 0.62904#####> Valid Avg loss: 0.81909, Acc:0.42808, F1: 0.42808
===> Epoch: 54: Training loss decreased (0.52531 --> 0.52212), Acc: (0.62505 --> 0.62890), F1: (0.62481 --> 0.62904).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 55 Train Avg loss: 0.51663, Acc: 0.62967, F1: 0.62982#####> Valid Avg loss: 0.88717, Acc:0.37100, F1: 0.37100
===> Epoch: 55: Training loss decreased (0.52212 --> 0.51663), Acc: (0.62890 --> 0.62967), F1: (0.62904 --> 0.62982).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 56 Train Avg loss: 0.51689, Acc: 0.63353, F1: 0.63367#####> Valid Avg loss: 0.86634, Acc:0.38813, F1: 0.38813
====> Epoch: 57 Train Avg loss: 0.50989, Acc: 0.63892, F1: 0.63867#####> Valid Avg loss: 0.93387, Acc:0.38927, F1: 0.38927
===> Epoch: 57: Training loss decreased (0.51663 --> 0.50989), Acc: (0.62967 --> 0.63892), F1: (0.62982 --> 0.63867).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 58 Train Avg loss: 0.50062, Acc: 0.63661, F1: 0.63675#####> Valid Avg loss: 0.87527, Acc:0.42009, F1: 0.42009
===> Epoch: 58: Training loss decreased (0.50989 --> 0.50062), Acc: (0.63892 --> 0.63661), F1: (0.63867 --> 0.63675).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 59 Train Avg loss: 0.49730, Acc: 0.64624, F1: 0.64638#####> Valid Avg loss: 0.89147, Acc:0.40753, F1: 0.40753
===> Epoch: 59: Training loss decreased (0.50062 --> 0.49730), Acc: (0.63661 --> 0.64624), F1: (0.63675 --> 0.64638).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 60 Train Avg loss: 0.50186, Acc: 0.64277, F1: 0.64291#####> Valid Avg loss: 0.89586, Acc:0.40068, F1: 0.40068
====> Epoch: 61 Train Avg loss: 0.49428, Acc: 0.64547, F1: 0.64561#####> Valid Avg loss: 0.90609, Acc:0.37329, F1: 0.37329
===> Epoch: 61: Training loss decreased (0.49730 --> 0.49428), Acc: (0.64624 --> 0.64547), F1: (0.64638 --> 0.64561).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 62 Train Avg loss: 0.48564, Acc: 0.65048, F1: 0.65062#####> Valid Avg loss: 0.91810, Acc:0.37557, F1: 0.37557
===> Epoch: 62: Training loss decreased (0.49428 --> 0.48564), Acc: (0.64547 --> 0.65048), F1: (0.64561 --> 0.65062).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 63 Train Avg loss: 0.48511, Acc: 0.64933, F1: 0.64946#####> Valid Avg loss: 0.92340, Acc:0.39498, F1: 0.39498
===> Epoch: 63: Training loss decreased (0.48564 --> 0.48511), Acc: (0.65048 --> 0.64933), F1: (0.65062 --> 0.64946).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 64 Train Avg loss: 0.47625, Acc: 0.65125, F1: 0.65100#####> Valid Avg loss: 0.89652, Acc:0.41210, F1: 0.41210
===> Epoch: 64: Training loss decreased (0.48511 --> 0.47625), Acc: (0.64933 --> 0.65125), F1: (0.64946 --> 0.65100).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 65 Train Avg loss: 0.46825, Acc: 0.66204, F1: 0.66217#####> Valid Avg loss: 0.98050, Acc:0.33219, F1: 0.33219
===> Epoch: 65: Training loss decreased (0.47625 --> 0.46825), Acc: (0.65125 --> 0.66204), F1: (0.65100 --> 0.66217).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 66 Train Avg loss: 0.46301, Acc: 0.66012, F1: 0.65986#####> Valid Avg loss: 0.95670, Acc:0.35616, F1: 0.35616
===> Epoch: 66: Training loss decreased (0.46825 --> 0.46301), Acc: (0.66204 --> 0.66012), F1: (0.66217 --> 0.65986).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 67 Train Avg loss: 0.46023, Acc: 0.66590, F1: 0.66564#####> Valid Avg loss: 0.96416, Acc:0.35731, F1: 0.35731
===> Epoch: 67: Training loss decreased (0.46301 --> 0.46023), Acc: (0.66012 --> 0.66590), F1: (0.65986 --> 0.66564).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 68 Train Avg loss: 0.45439, Acc: 0.67399, F1: 0.67411#####> Valid Avg loss: 0.98259, Acc:0.36872, F1: 0.36872
===> Epoch: 68: Training loss decreased (0.46023 --> 0.45439), Acc: (0.66590 --> 0.67399), F1: (0.66564 --> 0.67411).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 69 Train Avg loss: 0.44990, Acc: 0.67476, F1: 0.67488#####> Valid Avg loss: 0.94406, Acc:0.39384, F1: 0.39384
===> Epoch: 69: Training loss decreased (0.45439 --> 0.44990), Acc: (0.67399 --> 0.67476), F1: (0.67411 --> 0.67488).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 70 Train Avg loss: 0.44488, Acc: 0.66744, F1: 0.66718#####> Valid Avg loss: 0.97495, Acc:0.38927, F1: 0.38927
===> Epoch: 70: Training loss decreased (0.44990 --> 0.44488), Acc: (0.67476 --> 0.66744), F1: (0.67488 --> 0.66718).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 71 Train Avg loss: 0.43235, Acc: 0.68516, F1: 0.68529#####> Valid Avg loss: 1.02074, Acc:0.34475, F1: 0.34475
===> Epoch: 71: Training loss decreased (0.44488 --> 0.43235), Acc: (0.66744 --> 0.68516), F1: (0.66718 --> 0.68529).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 72 Train Avg loss: 0.42610, Acc: 0.68709, F1: 0.68721#####> Valid Avg loss: 1.01882, Acc:0.34132, F1: 0.34132
===> Epoch: 72: Training loss decreased (0.43235 --> 0.42610), Acc: (0.68516 --> 0.68709), F1: (0.68529 --> 0.68721).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 73 Train Avg loss: 0.42115, Acc: 0.69094, F1: 0.69106#####> Valid Avg loss: 1.05992, Acc:0.32991, F1: 0.32991
===> Epoch: 73: Training loss decreased (0.42610 --> 0.42115), Acc: (0.68709 --> 0.69094), F1: (0.68721 --> 0.69106).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 74 Train Avg loss: 0.41828, Acc: 0.69017, F1: 0.69029#####> Valid Avg loss: 0.99056, Acc:0.36416, F1: 0.36416
===> Epoch: 74: Training loss decreased (0.42115 --> 0.41828), Acc: (0.69094 --> 0.69017), F1: (0.69106 --> 0.69029).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 75 Train Avg loss: 0.41462, Acc: 0.69672, F1: 0.69684#####> Valid Avg loss: 1.04409, Acc:0.34589, F1: 0.34589
===> Epoch: 75: Training loss decreased (0.41828 --> 0.41462), Acc: (0.69017 --> 0.69672), F1: (0.69029 --> 0.69684).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 76 Train Avg loss: 0.40143, Acc: 0.70173, F1: 0.70146#####> Valid Avg loss: 1.04553, Acc:0.36416, F1: 0.36416
===> Epoch: 76: Training loss decreased (0.41462 --> 0.40143), Acc: (0.69672 --> 0.70173), F1: (0.69684 --> 0.70146).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 77 Train Avg loss: 0.39546, Acc: 0.71291, F1: 0.71302#####> Valid Avg loss: 1.06449, Acc:0.34817, F1: 0.34817
===> Epoch: 77: Training loss decreased (0.40143 --> 0.39546), Acc: (0.70173 --> 0.71291), F1: (0.70146 --> 0.71302).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 78 Train Avg loss: 0.39003, Acc: 0.70790, F1: 0.70763#####> Valid Avg loss: 1.07125, Acc:0.35959, F1: 0.35959
===> Epoch: 78: Training loss decreased (0.39546 --> 0.39003), Acc: (0.71291 --> 0.70790), F1: (0.71302 --> 0.70763).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 79 Train Avg loss: 0.38276, Acc: 0.71021, F1: 0.70994#####> Valid Avg loss: 1.13356, Acc:0.33333, F1: 0.33333
===> Epoch: 79: Training loss decreased (0.39003 --> 0.38276), Acc: (0.70790 --> 0.71021), F1: (0.70763 --> 0.70994).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 80 Train Avg loss: 0.38616, Acc: 0.71676, F1: 0.71687#####> Valid Avg loss: 1.10738, Acc:0.33676, F1: 0.33676
====> Epoch: 81 Train Avg loss: 0.37177, Acc: 0.72216, F1: 0.72227#####> Valid Avg loss: 1.07993, Acc:0.36416, F1: 0.36416
===> Epoch: 81: Training loss decreased (0.38276 --> 0.37177), Acc: (0.71021 --> 0.72216), F1: (0.70994 --> 0.72227).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 82 Train Avg loss: 0.36695, Acc: 0.72370, F1: 0.72381#####> Valid Avg loss: 1.10010, Acc:0.36644, F1: 0.36644
===> Epoch: 82: Training loss decreased (0.37177 --> 0.36695), Acc: (0.72216 --> 0.72370), F1: (0.72227 --> 0.72381).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 83 Train Avg loss: 0.35828, Acc: 0.73218, F1: 0.73228#####> Valid Avg loss: 1.15109, Acc:0.35731, F1: 0.35731
===> Epoch: 83: Training loss decreased (0.36695 --> 0.35828), Acc: (0.72370 --> 0.73218), F1: (0.72381 --> 0.73228).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 84 Train Avg loss: 0.36219, Acc: 0.73218, F1: 0.73228#####> Valid Avg loss: 1.13830, Acc:0.35160, F1: 0.35160
====> Epoch: 85 Train Avg loss: 0.35114, Acc: 0.74489, F1: 0.74499#####> Valid Avg loss: 1.16254, Acc:0.33562, F1: 0.33562
===> Epoch: 85: Training loss decreased (0.35828 --> 0.35114), Acc: (0.73218 --> 0.74489), F1: (0.73228 --> 0.74499).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 86 Train Avg loss: 0.34624, Acc: 0.74566, F1: 0.74576#####> Valid Avg loss: 1.18310, Acc:0.34703, F1: 0.34703
===> Epoch: 86: Training loss decreased (0.35114 --> 0.34624), Acc: (0.74489 --> 0.74566), F1: (0.74499 --> 0.74576).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 87 Train Avg loss: 0.34250, Acc: 0.75183, F1: 0.75193#####> Valid Avg loss: 1.20580, Acc:0.34589, F1: 0.34589
===> Epoch: 87: Training loss decreased (0.34624 --> 0.34250), Acc: (0.74566 --> 0.75183), F1: (0.74576 --> 0.75193).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 88 Train Avg loss: 0.34398, Acc: 0.75106, F1: 0.75077#####> Valid Avg loss: 1.17633, Acc:0.34817, F1: 0.34817
====> Epoch: 89 Train Avg loss: 0.33116, Acc: 0.76108, F1: 0.76117#####> Valid Avg loss: 1.20550, Acc:0.35046, F1: 0.35046
===> Epoch: 89: Training loss decreased (0.34250 --> 0.33116), Acc: (0.75183 --> 0.76108), F1: (0.75193 --> 0.76117).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 90 Train Avg loss: 0.33302, Acc: 0.75067, F1: 0.75077#####> Valid Avg loss: 1.18999, Acc:0.34932, F1: 0.34932
====> Epoch: 91 Train Avg loss: 0.33338, Acc: 0.75607, F1: 0.75578#####> Valid Avg loss: 1.19840, Acc:0.35274, F1: 0.35274
====> Epoch: 92 Train Avg loss: 0.32885, Acc: 0.75684, F1: 0.75693#####> Valid Avg loss: 1.20512, Acc:0.34018, F1: 0.34018
===> Epoch: 92: Training loss decreased (0.33116 --> 0.32885), Acc: (0.76108 --> 0.75684), F1: (0.76117 --> 0.75693).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 93 Train Avg loss: 0.32722, Acc: 0.75684, F1: 0.75693#####> Valid Avg loss: 1.21251, Acc:0.33790, F1: 0.33790
===> Epoch: 93: Training loss decreased (0.32885 --> 0.32722), Acc: (0.75684 --> 0.75684), F1: (0.75693 --> 0.75693).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 94 Train Avg loss: 0.32056, Acc: 0.77225, F1: 0.77196#####> Valid Avg loss: 1.21298, Acc:0.36073, F1: 0.36073
===> Epoch: 94: Training loss decreased (0.32722 --> 0.32056), Acc: (0.75684 --> 0.77225), F1: (0.75693 --> 0.77196).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 95 Train Avg loss: 0.32110, Acc: 0.76647, F1: 0.76618#####> Valid Avg loss: 1.22807, Acc:0.35046, F1: 0.35046
====> Epoch: 96 Train Avg loss: 0.32450, Acc: 0.75915, F1: 0.75924#####> Valid Avg loss: 1.22025, Acc:0.34817, F1: 0.34817
====> Epoch: 97 Train Avg loss: 0.32119, Acc: 0.76879, F1: 0.76888#####> Valid Avg loss: 1.21258, Acc:0.34703, F1: 0.34703
====> Epoch: 98 Train Avg loss: 0.32540, Acc: 0.75530, F1: 0.75539#####> Valid Avg loss: 1.22489, Acc:0.34817, F1: 0.34817
====> Epoch: 99 Train Avg loss: 0.32203, Acc: 0.77341, F1: 0.77350#####> Valid Avg loss: 1.22636, Acc:0.34817, F1: 0.34817
====> Epoch: 100 Train Avg loss: 0.56650, Acc: 0.60424, F1: 0.60439#####> Valid Avg loss: 0.86135, Acc:0.39840, F1: 0.39840
====> Epoch: 101 Train Avg loss: 0.54772, Acc: 0.61426, F1: 0.61441#####> Valid Avg loss: 0.88905, Acc:0.41781, F1: 0.41781
====> Epoch: 102 Train Avg loss: 0.54566, Acc: 0.61503, F1: 0.61479#####> Valid Avg loss: 0.80235, Acc:0.46119, F1: 0.46119
====> Epoch: 103 Train Avg loss: 0.56239, Acc: 0.60154, F1: 0.60169#####> Valid Avg loss: 0.82242, Acc:0.40753, F1: 0.40753
====> Epoch: 104 Train Avg loss: 0.55663, Acc: 0.61387, F1: 0.61402#####> Valid Avg loss: 0.81148, Acc:0.41667, F1: 0.41667
====> Epoch: 105 Train Avg loss: 0.54881, Acc: 0.61002, F1: 0.61017#####> Valid Avg loss: 0.80336, Acc:0.46005, F1: 0.46005
====> Epoch: 106 Train Avg loss: 0.55223, Acc: 0.61002, F1: 0.61017#####> Valid Avg loss: 0.82491, Acc:0.45662, F1: 0.45662
====> Epoch: 107 Train Avg loss: 0.55420, Acc: 0.60771, F1: 0.60786#####> Valid Avg loss: 0.85061, Acc:0.46347, F1: 0.46347
====> Epoch: 108 Train Avg loss: 0.55437, Acc: 0.61233, F1: 0.61210#####> Valid Avg loss: 0.81535, Acc:0.46575, F1: 0.46575
====> Epoch: 109 Train Avg loss: 0.54321, Acc: 0.62042, F1: 0.62057#####> Valid Avg loss: 0.88876, Acc:0.36644, F1: 0.36644
====> Epoch: 110 Train Avg loss: 0.54314, Acc: 0.61503, F1: 0.61518#####> Valid Avg loss: 0.84389, Acc:0.48288, F1: 0.48288
====> Epoch: 111 Train Avg loss: 0.55930, Acc: 0.60655, F1: 0.60670#####> Valid Avg loss: 0.79371, Acc:0.46689, F1: 0.46689
====> Epoch: 112 Train Avg loss: 0.55873, Acc: 0.60270, F1: 0.60247#####> Valid Avg loss: 0.82620, Acc:0.43265, F1: 0.43265
====> Epoch: 113 Train Avg loss: 0.53064, Acc: 0.62582, F1: 0.62596#####> Valid Avg loss: 0.80817, Acc:0.47374, F1: 0.47374
====> Epoch: 114 Train Avg loss: 0.53791, Acc: 0.61965, F1: 0.61980#####> Valid Avg loss: 0.87935, Acc:0.38699, F1: 0.38699
====> Epoch: 115 Train Avg loss: 0.53834, Acc: 0.61773, F1: 0.61749#####> Valid Avg loss: 0.81808, Acc:0.47717, F1: 0.47717
====> Epoch: 116 Train Avg loss: 0.54053, Acc: 0.61618, F1: 0.61595#####> Valid Avg loss: 0.82725, Acc:0.41781, F1: 0.41781
====> Epoch: 117 Train Avg loss: 0.53163, Acc: 0.62620, F1: 0.62596#####> Valid Avg loss: 0.83001, Acc:0.48059, F1: 0.48059
====> Epoch: 118 Train Avg loss: 0.53576, Acc: 0.61927, F1: 0.61941#####> Valid Avg loss: 0.83820, Acc:0.40525, F1: 0.40525
====> Epoch: 119 Train Avg loss: 0.52803, Acc: 0.63237, F1: 0.63213#####> Valid Avg loss: 0.78528, Acc:0.46575, F1: 0.46575
====> Epoch: 120 Train Avg loss: 0.53144, Acc: 0.62042, F1: 0.62057#####> Valid Avg loss: 0.81661, Acc:0.46005, F1: 0.46005
====> Epoch: 121 Train Avg loss: 0.53086, Acc: 0.62659, F1: 0.62673#####> Valid Avg loss: 0.81956, Acc:0.43607, F1: 0.43607
====> Epoch: 122 Train Avg loss: 0.52783, Acc: 0.62466, F1: 0.62442#####> Valid Avg loss: 0.94457, Acc:0.44406, F1: 0.44406
====> Epoch: 123 Train Avg loss: 0.51954, Acc: 0.62967, F1: 0.62982#####> Valid Avg loss: 0.85449, Acc:0.44292, F1: 0.44292
====> Epoch: 124 Train Avg loss: 0.52042, Acc: 0.62582, F1: 0.62596#####> Valid Avg loss: 0.87763, Acc:0.36758, F1: 0.36758
====> Epoch: 125 Train Avg loss: 0.51883, Acc: 0.62697, F1: 0.62712#####> Valid Avg loss: 0.89177, Acc:0.43265, F1: 0.43265
====> Epoch: 126 Train Avg loss: 0.54264, Acc: 0.62158, F1: 0.62173#####> Valid Avg loss: 0.99730, Acc:0.16895, F1: 0.16895
====> Epoch: 127 Train Avg loss: 0.52667, Acc: 0.63353, F1: 0.63367#####> Valid Avg loss: 0.83464, Acc:0.48174, F1: 0.48174
====> Epoch: 128 Train Avg loss: 0.52627, Acc: 0.62312, F1: 0.62327#####> Valid Avg loss: 0.86288, Acc:0.46918, F1: 0.46918
====> Epoch: 129 Train Avg loss: 0.52184, Acc: 0.62235, F1: 0.62250#####> Valid Avg loss: 0.91371, Acc:0.40639, F1: 0.40639
====> Epoch: 130 Train Avg loss: 0.51823, Acc: 0.63353, F1: 0.63367#####> Valid Avg loss: 0.91292, Acc:0.39612, F1: 0.39612
====> Epoch: 131 Train Avg loss: 0.51139, Acc: 0.63622, F1: 0.63636#####> Valid Avg loss: 0.86046, Acc:0.43721, F1: 0.43721
====> Epoch: 132 Train Avg loss: 0.51681, Acc: 0.63622, F1: 0.63636#####> Valid Avg loss: 0.98493, Acc:0.36758, F1: 0.36758
====> Epoch: 133 Train Avg loss: 0.51554, Acc: 0.63391, F1: 0.63405#####> Valid Avg loss: 0.91544, Acc:0.38813, F1: 0.38813
====> Epoch: 134 Train Avg loss: 0.51013, Acc: 0.63776, F1: 0.63752#####> Valid Avg loss: 0.86981, Acc:0.44749, F1: 0.44749
====> Epoch: 135 Train Avg loss: 0.50854, Acc: 0.63276, F1: 0.63251#####> Valid Avg loss: 0.89663, Acc:0.42009, F1: 0.42009
====> Epoch: 136 Train Avg loss: 0.49617, Acc: 0.64470, F1: 0.64484#####> Valid Avg loss: 0.87059, Acc:0.40639, F1: 0.40639
====> Epoch: 137 Train Avg loss: 0.49857, Acc: 0.64663, F1: 0.64638#####> Valid Avg loss: 0.83017, Acc:0.47260, F1: 0.47260
====> Epoch: 138 Train Avg loss: 0.50037, Acc: 0.64432, F1: 0.64407#####> Valid Avg loss: 0.90270, Acc:0.36758, F1: 0.36758
====> Epoch: 139 Train Avg loss: 0.50520, Acc: 0.64085, F1: 0.64099#####> Valid Avg loss: 0.90412, Acc:0.40411, F1: 0.40411
====> Epoch: 140 Train Avg loss: 0.51830, Acc: 0.64470, F1: 0.64445#####> Valid Avg loss: 1.00312, Acc:0.30936, F1: 0.30936
====> Epoch: 141 Train Avg loss: 0.49433, Acc: 0.64740, F1: 0.64715#####> Valid Avg loss: 0.95208, Acc:0.39384, F1: 0.39384
====> Epoch: 142 Train Avg loss: 0.50526, Acc: 0.63430, F1: 0.63444#####> Valid Avg loss: 0.89002, Acc:0.38584, F1: 0.38584
====> Epoch: 143 Train Avg loss: 0.50462, Acc: 0.64624, F1: 0.64599#####> Valid Avg loss: 0.87694, Acc:0.38813, F1: 0.38813
====> Epoch: 144 Train Avg loss: 0.50627, Acc: 0.64123, F1: 0.64137#####> Valid Avg loss: 0.88093, Acc:0.43379, F1: 0.43379
====> Epoch: 145 Train Avg loss: 0.50293, Acc: 0.63892, F1: 0.63867#####> Valid Avg loss: 0.89703, Acc:0.39726, F1: 0.39726
====> Epoch: 146 Train Avg loss: 0.50139, Acc: 0.64046, F1: 0.64060#####> Valid Avg loss: 0.86550, Acc:0.40183, F1: 0.40183
====> Epoch: 147 Train Avg loss: 0.49366, Acc: 0.65356, F1: 0.65331#####> Valid Avg loss: 0.86439, Acc:0.44521, F1: 0.44521
====> Epoch: 148 Train Avg loss: 0.48905, Acc: 0.65434, F1: 0.65408#####> Valid Avg loss: 0.85145, Acc:0.41553, F1: 0.41553
====> Epoch: 149 Train Avg loss: 0.49294, Acc: 0.65241, F1: 0.65254#####> Valid Avg loss: 0.89557, Acc:0.41553, F1: 0.41553
====> Epoch: 150 Train Avg loss: 0.48191, Acc: 0.65087, F1: 0.65062#####> Valid Avg loss: 0.89324, Acc:0.43721, F1: 0.43721
====> Epoch: 151 Train Avg loss: 0.48256, Acc: 0.65934, F1: 0.65948#####> Valid Avg loss: 0.89562, Acc:0.41096, F1: 0.41096
====> Epoch: 152 Train Avg loss: 0.48617, Acc: 0.64817, F1: 0.64792#####> Valid Avg loss: 1.01006, Acc:0.32877, F1: 0.32877
====> Epoch: 153 Train Avg loss: 0.49013, Acc: 0.64316, F1: 0.64330#####> Valid Avg loss: 0.86857, Acc:0.42466, F1: 0.42466
====> Epoch: 154 Train Avg loss: 0.49119, Acc: 0.65087, F1: 0.65100#####> Valid Avg loss: 0.86348, Acc:0.46804, F1: 0.46804
====> Epoch: 155 Train Avg loss: 0.47608, Acc: 0.65857, F1: 0.65871#####> Valid Avg loss: 0.89583, Acc:0.40297, F1: 0.40297
====> Epoch: 156 Train Avg loss: 0.47450, Acc: 0.65780, F1: 0.65794#####> Valid Avg loss: 0.97387, Acc:0.38699, F1: 0.38699
====> Epoch: 157 Train Avg loss: 0.48168, Acc: 0.64701, F1: 0.64676#####> Valid Avg loss: 0.97150, Acc:0.32648, F1: 0.32648
====> Epoch: 158 Train Avg loss: 0.46839, Acc: 0.65318, F1: 0.65331#####> Valid Avg loss: 0.94761, Acc:0.41781, F1: 0.41781
====> Epoch: 159 Train Avg loss: 0.47051, Acc: 0.66204, F1: 0.66217#####> Valid Avg loss: 1.00366, Acc:0.31164, F1: 0.31164
====> Epoch: 160 Train Avg loss: 0.45925, Acc: 0.66204, F1: 0.66179#####> Valid Avg loss: 1.10515, Acc:0.34018, F1: 0.34018
====> Epoch: 161 Train Avg loss: 0.45825, Acc: 0.67360, F1: 0.67334#####> Valid Avg loss: 0.96819, Acc:0.38470, F1: 0.38470
====> Epoch: 162 Train Avg loss: 0.45126, Acc: 0.66936, F1: 0.66911#####> Valid Avg loss: 0.95747, Acc:0.38014, F1: 0.38014
====> Epoch: 163 Train Avg loss: 0.44830, Acc: 0.66936, F1: 0.66949#####> Valid Avg loss: 0.88159, Acc:0.39954, F1: 0.39954
====> Epoch: 164 Train Avg loss: 0.44937, Acc: 0.67013, F1: 0.67026#####> Valid Avg loss: 1.00850, Acc:0.35731, F1: 0.35731
====> Epoch: 165 Train Avg loss: 0.44394, Acc: 0.67360, F1: 0.67334#####> Valid Avg loss: 0.93741, Acc:0.44521, F1: 0.44521
====> Epoch: 166 Train Avg loss: 0.44369, Acc: 0.68247, F1: 0.68259#####> Valid Avg loss: 1.07054, Acc:0.31963, F1: 0.31963
====> Epoch: 167 Train Avg loss: 0.45384, Acc: 0.66859, F1: 0.66834#####> Valid Avg loss: 1.05554, Acc:0.34018, F1: 0.34018
====> Epoch: 168 Train Avg loss: 0.42621, Acc: 0.68478, F1: 0.68490#####> Valid Avg loss: 1.01573, Acc:0.36644, F1: 0.36644
====> Epoch: 169 Train Avg loss: 0.44260, Acc: 0.67091, F1: 0.67065#####> Valid Avg loss: 1.04938, Acc:0.36416, F1: 0.36416
====> Epoch: 170 Train Avg loss: 0.42466, Acc: 0.68940, F1: 0.68952#####> Valid Avg loss: 0.96773, Acc:0.41781, F1: 0.41781
====> Epoch: 171 Train Avg loss: 0.42726, Acc: 0.68208, F1: 0.68220#####> Valid Avg loss: 0.93728, Acc:0.41895, F1: 0.41895
====> Epoch: 172 Train Avg loss: 0.42569, Acc: 0.67977, F1: 0.67951#####> Valid Avg loss: 0.99600, Acc:0.38584, F1: 0.38584
====> Epoch: 173 Train Avg loss: 0.42536, Acc: 0.69634, F1: 0.69646#####> Valid Avg loss: 1.03252, Acc:0.40297, F1: 0.40297
====> Epoch: 174 Train Avg loss: 0.42166, Acc: 0.69557, F1: 0.69569#####> Valid Avg loss: 0.96458, Acc:0.39498, F1: 0.39498
====> Epoch: 175 Train Avg loss: 0.40934, Acc: 0.69133, F1: 0.69145#####> Valid Avg loss: 1.03414, Acc:0.36530, F1: 0.36530
====> Epoch: 176 Train Avg loss: 0.41298, Acc: 0.69403, F1: 0.69414#####> Valid Avg loss: 0.89927, Acc:0.44064, F1: 0.44064
====> Epoch: 177 Train Avg loss: 0.40361, Acc: 0.69441, F1: 0.69453#####> Valid Avg loss: 0.91656, Acc:0.42123, F1: 0.42123
====> Epoch: 178 Train Avg loss: 0.40175, Acc: 0.68902, F1: 0.68875#####> Valid Avg loss: 0.90735, Acc:0.44064, F1: 0.44064
====> Epoch: 179 Train Avg loss: 0.40011, Acc: 0.69210, F1: 0.69222#####> Valid Avg loss: 0.96760, Acc:0.43151, F1: 0.43151
====> Epoch: 180 Train Avg loss: 0.39641, Acc: 0.69403, F1: 0.69414#####> Valid Avg loss: 1.17907, Acc:0.33562, F1: 0.33562
====> Epoch: 181 Train Avg loss: 0.38754, Acc: 0.70173, F1: 0.70185#####> Valid Avg loss: 0.95211, Acc:0.43265, F1: 0.43265
====> Epoch: 182 Train Avg loss: 0.38759, Acc: 0.70058, F1: 0.70069#####> Valid Avg loss: 1.07067, Acc:0.36301, F1: 0.36301
====> Epoch: 183 Train Avg loss: 0.38814, Acc: 0.70829, F1: 0.70840#####> Valid Avg loss: 1.04479, Acc:0.39498, F1: 0.39498
====> Epoch: 184 Train Avg loss: 0.39223, Acc: 0.70058, F1: 0.70031#####> Valid Avg loss: 1.01812, Acc:0.41210, F1: 0.41210
====> Epoch: 185 Train Avg loss: 0.36951, Acc: 0.71869, F1: 0.71880#####> Valid Avg loss: 1.04722, Acc:0.41438, F1: 0.41438
====> Epoch: 186 Train Avg loss: 0.36538, Acc: 0.72601, F1: 0.72612#####> Valid Avg loss: 1.08065, Acc:0.39726, F1: 0.39726
====> Epoch: 187 Train Avg loss: 0.36017, Acc: 0.71985, F1: 0.71995#####> Valid Avg loss: 1.06001, Acc:0.42580, F1: 0.42580
====> Epoch: 188 Train Avg loss: 0.35592, Acc: 0.72216, F1: 0.72227#####> Valid Avg loss: 1.15705, Acc:0.38584, F1: 0.38584
====> Epoch: 189 Train Avg loss: 0.35410, Acc: 0.72755, F1: 0.72766#####> Valid Avg loss: 1.03559, Acc:0.40753, F1: 0.40753
====> Epoch: 190 Train Avg loss: 0.33212, Acc: 0.73988, F1: 0.73998#####> Valid Avg loss: 1.25220, Acc:0.34018, F1: 0.34018
====> Epoch: 191 Train Avg loss: 0.35827, Acc: 0.72216, F1: 0.72227#####> Valid Avg loss: 1.00039, Acc:0.44635, F1: 0.44635
====> Epoch: 192 Train Avg loss: 0.33899, Acc: 0.74297, F1: 0.74307#####> Valid Avg loss: 1.26699, Acc:0.34589, F1: 0.34589
====> Epoch: 193 Train Avg loss: 0.33968, Acc: 0.73256, F1: 0.73267#####> Valid Avg loss: 1.18579, Acc:0.40753, F1: 0.40753
====> Epoch: 194 Train Avg loss: 0.32556, Acc: 0.74297, F1: 0.74307#####> Valid Avg loss: 1.25843, Acc:0.35616, F1: 0.35616
====> Epoch: 195 Train Avg loss: 0.31129, Acc: 0.75761, F1: 0.75732#####> Valid Avg loss: 1.15065, Acc:0.41324, F1: 0.41324
===> Epoch: 195: Training loss decreased (0.32056 --> 0.31129), Acc: (0.77225 --> 0.75761), F1: (0.77196 --> 0.75732).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 196 Train Avg loss: 0.31788, Acc: 0.75183, F1: 0.75193#####> Valid Avg loss: 1.09283, Acc:0.39155, F1: 0.39155
====> Epoch: 197 Train Avg loss: 0.31267, Acc: 0.75414, F1: 0.75424#####> Valid Avg loss: 1.26433, Acc:0.41096, F1: 0.41096
====> Epoch: 198 Train Avg loss: 0.29155, Acc: 0.76724, F1: 0.76733#####> Valid Avg loss: 1.21996, Acc:0.40525, F1: 0.40525
===> Epoch: 198: Training loss decreased (0.31129 --> 0.29155), Acc: (0.75761 --> 0.76724), F1: (0.75732 --> 0.76733).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 199 Train Avg loss: 0.28716, Acc: 0.77225, F1: 0.77234#####> Valid Avg loss: 1.52183, Acc:0.38128, F1: 0.38128
===> Epoch: 199: Training loss decreased (0.29155 --> 0.28716), Acc: (0.76724 --> 0.77225), F1: (0.76733 --> 0.77234).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 200 Train Avg loss: 0.28561, Acc: 0.76570, F1: 0.76579#####> Valid Avg loss: 1.33266, Acc:0.39155, F1: 0.39155
===> Epoch: 200: Training loss decreased (0.28716 --> 0.28561), Acc: (0.77225 --> 0.76570), F1: (0.77234 --> 0.76579).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 201 Train Avg loss: 0.27199, Acc: 0.78382, F1: 0.78351#####> Valid Avg loss: 1.27289, Acc:0.40868, F1: 0.40868
===> Epoch: 201: Training loss decreased (0.28561 --> 0.27199), Acc: (0.76570 --> 0.78382), F1: (0.76579 --> 0.78351).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 202 Train Avg loss: 0.26489, Acc: 0.78613, F1: 0.78621#####> Valid Avg loss: 1.53994, Acc:0.38242, F1: 0.38242
===> Epoch: 202: Training loss decreased (0.27199 --> 0.26489), Acc: (0.78382 --> 0.78613), F1: (0.78351 --> 0.78621).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 203 Train Avg loss: 0.26059, Acc: 0.79653, F1: 0.79622#####> Valid Avg loss: 1.28904, Acc:0.40068, F1: 0.40068
===> Epoch: 203: Training loss decreased (0.26489 --> 0.26059), Acc: (0.78613 --> 0.79653), F1: (0.78621 --> 0.79622).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 204 Train Avg loss: 0.24613, Acc: 0.80925, F1: 0.80932#####> Valid Avg loss: 1.45727, Acc:0.38813, F1: 0.38813
===> Epoch: 204: Training loss decreased (0.26059 --> 0.24613), Acc: (0.79653 --> 0.80925), F1: (0.79622 --> 0.80932).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 205 Train Avg loss: 0.24288, Acc: 0.80347, F1: 0.80354#####> Valid Avg loss: 1.59327, Acc:0.38927, F1: 0.38927
===> Epoch: 205: Training loss decreased (0.24613 --> 0.24288), Acc: (0.80925 --> 0.80347), F1: (0.80932 --> 0.80354).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 206 Train Avg loss: 0.24641, Acc: 0.80424, F1: 0.80431#####> Valid Avg loss: 1.55671, Acc:0.38699, F1: 0.38699
====> Epoch: 207 Train Avg loss: 0.23406, Acc: 0.80886, F1: 0.80894#####> Valid Avg loss: 1.75967, Acc:0.35845, F1: 0.35845
===> Epoch: 207: Training loss decreased (0.24288 --> 0.23406), Acc: (0.80347 --> 0.80886), F1: (0.80354 --> 0.80894).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 208 Train Avg loss: 0.22587, Acc: 0.82312, F1: 0.82319#####> Valid Avg loss: 1.75307, Acc:0.35502, F1: 0.35502
===> Epoch: 208: Training loss decreased (0.23406 --> 0.22587), Acc: (0.80886 --> 0.82312), F1: (0.80894 --> 0.82319).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 209 Train Avg loss: 0.20702, Acc: 0.84046, F1: 0.84052#####> Valid Avg loss: 1.61374, Acc:0.37215, F1: 0.37215
===> Epoch: 209: Training loss decreased (0.22587 --> 0.20702), Acc: (0.82312 --> 0.84046), F1: (0.82319 --> 0.84052).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 210 Train Avg loss: 0.21409, Acc: 0.83738, F1: 0.83744#####> Valid Avg loss: 1.67386, Acc:0.37900, F1: 0.37900
====> Epoch: 211 Train Avg loss: 0.19885, Acc: 0.84624, F1: 0.84630#####> Valid Avg loss: 1.70657, Acc:0.36301, F1: 0.36301
===> Epoch: 211: Training loss decreased (0.20702 --> 0.19885), Acc: (0.84046 --> 0.84624), F1: (0.84052 --> 0.84630).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 212 Train Avg loss: 0.18915, Acc: 0.85703, F1: 0.85709#####> Valid Avg loss: 1.68408, Acc:0.37329, F1: 0.37329
===> Epoch: 212: Training loss decreased (0.19885 --> 0.18915), Acc: (0.84624 --> 0.85703), F1: (0.84630 --> 0.85709).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 213 Train Avg loss: 0.19268, Acc: 0.84855, F1: 0.84861#####> Valid Avg loss: 1.80151, Acc:0.37785, F1: 0.37785
====> Epoch: 214 Train Avg loss: 0.18695, Acc: 0.85356, F1: 0.85362#####> Valid Avg loss: 1.88459, Acc:0.37329, F1: 0.37329
===> Epoch: 214: Training loss decreased (0.18915 --> 0.18695), Acc: (0.85703 --> 0.85356), F1: (0.85709 --> 0.85362).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 215 Train Avg loss: 0.17279, Acc: 0.86975, F1: 0.86980#####> Valid Avg loss: 1.97606, Acc:0.34817, F1: 0.34817
===> Epoch: 215: Training loss decreased (0.18695 --> 0.17279), Acc: (0.85356 --> 0.86975), F1: (0.85362 --> 0.86980).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 216 Train Avg loss: 0.17709, Acc: 0.86667, F1: 0.86672#####> Valid Avg loss: 1.90629, Acc:0.35845, F1: 0.35845
====> Epoch: 217 Train Avg loss: 0.16312, Acc: 0.87669, F1: 0.87673#####> Valid Avg loss: 1.91543, Acc:0.36986, F1: 0.36986
===> Epoch: 217: Training loss decreased (0.17279 --> 0.16312), Acc: (0.86975 --> 0.87669), F1: (0.86980 --> 0.87673).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 218 Train Avg loss: 0.15573, Acc: 0.88671, F1: 0.88636#####> Valid Avg loss: 1.89091, Acc:0.36530, F1: 0.36530
===> Epoch: 218: Training loss decreased (0.16312 --> 0.15573), Acc: (0.87669 --> 0.88671), F1: (0.87673 --> 0.88636).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 219 Train Avg loss: 0.14288, Acc: 0.89210, F1: 0.89214#####> Valid Avg loss: 2.17429, Acc:0.33562, F1: 0.33562
===> Epoch: 219: Training loss decreased (0.15573 --> 0.14288), Acc: (0.88671 --> 0.89210), F1: (0.88636 --> 0.89214).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 220 Train Avg loss: 0.15116, Acc: 0.88439, F1: 0.88444#####> Valid Avg loss: 2.15669, Acc:0.36530, F1: 0.36530
====> Epoch: 221 Train Avg loss: 0.14578, Acc: 0.89171, F1: 0.89176#####> Valid Avg loss: 2.18253, Acc:0.35160, F1: 0.35160
====> Epoch: 222 Train Avg loss: 0.14812, Acc: 0.89518, F1: 0.89522#####> Valid Avg loss: 2.27615, Acc:0.35616, F1: 0.35616
====> Epoch: 223 Train Avg loss: 0.13286, Acc: 0.89595, F1: 0.89599#####> Valid Avg loss: 2.24952, Acc:0.33790, F1: 0.33790
===> Epoch: 223: Training loss decreased (0.14288 --> 0.13286), Acc: (0.89210 --> 0.89595), F1: (0.89214 --> 0.89599).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 224 Train Avg loss: 0.13093, Acc: 0.90212, F1: 0.90216#####> Valid Avg loss: 2.32788, Acc:0.37100, F1: 0.37100
===> Epoch: 224: Training loss decreased (0.13286 --> 0.13093), Acc: (0.89595 --> 0.90212), F1: (0.89599 --> 0.90216).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 225 Train Avg loss: 0.11883, Acc: 0.91638, F1: 0.91641#####> Valid Avg loss: 2.42647, Acc:0.33904, F1: 0.33904
===> Epoch: 225: Training loss decreased (0.13093 --> 0.11883), Acc: (0.90212 --> 0.91638), F1: (0.90216 --> 0.91641).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 226 Train Avg loss: 0.11710, Acc: 0.91252, F1: 0.91256#####> Valid Avg loss: 2.38990, Acc:0.34475, F1: 0.34475
===> Epoch: 226: Training loss decreased (0.11883 --> 0.11710), Acc: (0.91638 --> 0.91252), F1: (0.91641 --> 0.91256).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 227 Train Avg loss: 0.10568, Acc: 0.92370, F1: 0.92373#####> Valid Avg loss: 2.37998, Acc:0.34703, F1: 0.34703
===> Epoch: 227: Training loss decreased (0.11710 --> 0.10568), Acc: (0.91252 --> 0.92370), F1: (0.91256 --> 0.92373).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 228 Train Avg loss: 0.10710, Acc: 0.92062, F1: 0.92065#####> Valid Avg loss: 2.47759, Acc:0.36758, F1: 0.36758
====> Epoch: 229 Train Avg loss: 0.09944, Acc: 0.92948, F1: 0.92951#####> Valid Avg loss: 2.53879, Acc:0.36758, F1: 0.36758
===> Epoch: 229: Training loss decreased (0.10568 --> 0.09944), Acc: (0.92370 --> 0.92948), F1: (0.92373 --> 0.92951).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 230 Train Avg loss: 0.09291, Acc: 0.93796, F1: 0.93798#####> Valid Avg loss: 2.66172, Acc:0.35160, F1: 0.35160
===> Epoch: 230: Training loss decreased (0.09944 --> 0.09291), Acc: (0.92948 --> 0.93796), F1: (0.92951 --> 0.93798).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 231 Train Avg loss: 0.10435, Acc: 0.92948, F1: 0.92951#####> Valid Avg loss: 2.34046, Acc:0.37215, F1: 0.37215
====> Epoch: 232 Train Avg loss: 0.09378, Acc: 0.93449, F1: 0.93451#####> Valid Avg loss: 2.62022, Acc:0.35502, F1: 0.35502
====> Epoch: 233 Train Avg loss: 0.08518, Acc: 0.93873, F1: 0.93875#####> Valid Avg loss: 2.68078, Acc:0.36872, F1: 0.36872
===> Epoch: 233: Training loss decreased (0.09291 --> 0.08518), Acc: (0.93796 --> 0.93873), F1: (0.93798 --> 0.93875).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 234 Train Avg loss: 0.08030, Acc: 0.94836, F1: 0.94838#####> Valid Avg loss: 2.80717, Acc:0.34247, F1: 0.34247
===> Epoch: 234: Training loss decreased (0.08518 --> 0.08030), Acc: (0.93873 --> 0.94836), F1: (0.93875 --> 0.94838).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 235 Train Avg loss: 0.07947, Acc: 0.94451, F1: 0.94453#####> Valid Avg loss: 2.71435, Acc:0.38584, F1: 0.38584
===> Epoch: 235: Training loss decreased (0.08030 --> 0.07947), Acc: (0.94836 --> 0.94451), F1: (0.94838 --> 0.94453).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 236 Train Avg loss: 0.08043, Acc: 0.94374, F1: 0.94376#####> Valid Avg loss: 2.82480, Acc:0.35616, F1: 0.35616
====> Epoch: 237 Train Avg loss: 0.07699, Acc: 0.94451, F1: 0.94453#####> Valid Avg loss: 2.75635, Acc:0.36530, F1: 0.36530
===> Epoch: 237: Training loss decreased (0.07947 --> 0.07699), Acc: (0.94451 --> 0.94451), F1: (0.94453 --> 0.94453).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 238 Train Avg loss: 0.06579, Acc: 0.95684, F1: 0.95686#####> Valid Avg loss: 2.81890, Acc:0.38584, F1: 0.38584
===> Epoch: 238: Training loss decreased (0.07699 --> 0.06579), Acc: (0.94451 --> 0.95684), F1: (0.94453 --> 0.95686).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 239 Train Avg loss: 0.07187, Acc: 0.95029, F1: 0.95031#####> Valid Avg loss: 2.87048, Acc:0.37215, F1: 0.37215
====> Epoch: 240 Train Avg loss: 0.06323, Acc: 0.95607, F1: 0.95609#####> Valid Avg loss: 2.84092, Acc:0.34132, F1: 0.34132
===> Epoch: 240: Training loss decreased (0.06579 --> 0.06323), Acc: (0.95684 --> 0.95607), F1: (0.95686 --> 0.95609).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 241 Train Avg loss: 0.06771, Acc: 0.95877, F1: 0.95878#####> Valid Avg loss: 2.77993, Acc:0.36758, F1: 0.36758
====> Epoch: 242 Train Avg loss: 0.06077, Acc: 0.95954, F1: 0.95955#####> Valid Avg loss: 2.95580, Acc:0.36530, F1: 0.36530
===> Epoch: 242: Training loss decreased (0.06323 --> 0.06077), Acc: (0.95607 --> 0.95954), F1: (0.95609 --> 0.95955).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 243 Train Avg loss: 0.05145, Acc: 0.96570, F1: 0.96572#####> Valid Avg loss: 3.01872, Acc:0.37443, F1: 0.37443
===> Epoch: 243: Training loss decreased (0.06077 --> 0.05145), Acc: (0.95954 --> 0.96570), F1: (0.95955 --> 0.96572).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 244 Train Avg loss: 0.06047, Acc: 0.96108, F1: 0.96109#####> Valid Avg loss: 2.84572, Acc:0.38470, F1: 0.38470
====> Epoch: 245 Train Avg loss: 0.05077, Acc: 0.96917, F1: 0.96918#####> Valid Avg loss: 3.07443, Acc:0.36073, F1: 0.36073
===> Epoch: 245: Training loss decreased (0.05145 --> 0.05077), Acc: (0.96570 --> 0.96917), F1: (0.96572 --> 0.96918).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 246 Train Avg loss: 0.05210, Acc: 0.96609, F1: 0.96610#####> Valid Avg loss: 3.03638, Acc:0.37557, F1: 0.37557
====> Epoch: 247 Train Avg loss: 0.05359, Acc: 0.96724, F1: 0.96726#####> Valid Avg loss: 3.12100, Acc:0.38927, F1: 0.38927
====> Epoch: 248 Train Avg loss: 0.04972, Acc: 0.96609, F1: 0.96610#####> Valid Avg loss: 2.94569, Acc:0.37215, F1: 0.37215
===> Epoch: 248: Training loss decreased (0.05077 --> 0.04972), Acc: (0.96917 --> 0.96609), F1: (0.96918 --> 0.96610).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 249 Train Avg loss: 0.04025, Acc: 0.97495, F1: 0.97496#####> Valid Avg loss: 3.14159, Acc:0.37100, F1: 0.37100
===> Epoch: 249: Training loss decreased (0.04972 --> 0.04025), Acc: (0.96609 --> 0.97495), F1: (0.96610 --> 0.97496).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 250 Train Avg loss: 0.04285, Acc: 0.97418, F1: 0.97419#####> Valid Avg loss: 3.13788, Acc:0.36758, F1: 0.36758
====> Epoch: 251 Train Avg loss: 0.03846, Acc: 0.97765, F1: 0.97766#####> Valid Avg loss: 3.11380, Acc:0.37100, F1: 0.37100
===> Epoch: 251: Training loss decreased (0.04025 --> 0.03846), Acc: (0.97495 --> 0.97765), F1: (0.97496 --> 0.97766).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 252 Train Avg loss: 0.04144, Acc: 0.97225, F1: 0.97227#####> Valid Avg loss: 3.32312, Acc:0.36872, F1: 0.36872
====> Epoch: 253 Train Avg loss: 0.03537, Acc: 0.98150, F1: 0.98151#####> Valid Avg loss: 3.34814, Acc:0.36758, F1: 0.36758
===> Epoch: 253: Training loss decreased (0.03846 --> 0.03537), Acc: (0.97765 --> 0.98150), F1: (0.97766 --> 0.98151).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 254 Train Avg loss: 0.03881, Acc: 0.97649, F1: 0.97650#####> Valid Avg loss: 3.25954, Acc:0.36416, F1: 0.36416
====> Epoch: 255 Train Avg loss: 0.03353, Acc: 0.98189, F1: 0.98190#####> Valid Avg loss: 3.37118, Acc:0.35502, F1: 0.35502
===> Epoch: 255: Training loss decreased (0.03537 --> 0.03353), Acc: (0.98150 --> 0.98189), F1: (0.98151 --> 0.98190).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 256 Train Avg loss: 0.03117, Acc: 0.98343, F1: 0.98344#####> Valid Avg loss: 3.50556, Acc:0.34817, F1: 0.34817
===> Epoch: 256: Training loss decreased (0.03353 --> 0.03117), Acc: (0.98189 --> 0.98343), F1: (0.98190 --> 0.98344).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 257 Train Avg loss: 0.03051, Acc: 0.98613, F1: 0.98613#####> Valid Avg loss: 3.32979, Acc:0.37671, F1: 0.37671
===> Epoch: 257: Training loss decreased (0.03117 --> 0.03051), Acc: (0.98343 --> 0.98613), F1: (0.98344 --> 0.98613).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 258 Train Avg loss: 0.03320, Acc: 0.97996, F1: 0.97997#####> Valid Avg loss: 3.30761, Acc:0.37329, F1: 0.37329
====> Epoch: 259 Train Avg loss: 0.03076, Acc: 0.98420, F1: 0.98421#####> Valid Avg loss: 3.57306, Acc:0.35274, F1: 0.35274
====> Epoch: 260 Train Avg loss: 0.02755, Acc: 0.98574, F1: 0.98575#####> Valid Avg loss: 3.32582, Acc:0.37100, F1: 0.37100
===> Epoch: 260: Training loss decreased (0.03051 --> 0.02755), Acc: (0.98613 --> 0.98574), F1: (0.98613 --> 0.98575).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 261 Train Avg loss: 0.02646, Acc: 0.98690, F1: 0.98690#####> Valid Avg loss: 3.45767, Acc:0.38356, F1: 0.38356
===> Epoch: 261: Training loss decreased (0.02755 --> 0.02646), Acc: (0.98574 --> 0.98690), F1: (0.98575 --> 0.98690).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 262 Train Avg loss: 0.03188, Acc: 0.98189, F1: 0.98190#####> Valid Avg loss: 3.40642, Acc:0.35845, F1: 0.35845
====> Epoch: 263 Train Avg loss: 0.02534, Acc: 0.98805, F1: 0.98806#####> Valid Avg loss: 3.43017, Acc:0.36758, F1: 0.36758
===> Epoch: 263: Training loss decreased (0.02646 --> 0.02534), Acc: (0.98690 --> 0.98805), F1: (0.98690 --> 0.98806).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 264 Train Avg loss: 0.02728, Acc: 0.98690, F1: 0.98690#####> Valid Avg loss: 3.62836, Acc:0.35731, F1: 0.35731
====> Epoch: 265 Train Avg loss: 0.02343, Acc: 0.98844, F1: 0.98844#####> Valid Avg loss: 3.54160, Acc:0.35959, F1: 0.35959
===> Epoch: 265: Training loss decreased (0.02534 --> 0.02343), Acc: (0.98805 --> 0.98844), F1: (0.98806 --> 0.98844).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 266 Train Avg loss: 0.02581, Acc: 0.98805, F1: 0.98806#####> Valid Avg loss: 3.52559, Acc:0.37671, F1: 0.37671
====> Epoch: 267 Train Avg loss: 0.02449, Acc: 0.98921, F1: 0.98921#####> Valid Avg loss: 3.54827, Acc:0.36644, F1: 0.36644
====> Epoch: 268 Train Avg loss: 0.02250, Acc: 0.98805, F1: 0.98806#####> Valid Avg loss: 3.54987, Acc:0.35845, F1: 0.35845
===> Epoch: 268: Training loss decreased (0.02343 --> 0.02250), Acc: (0.98844 --> 0.98805), F1: (0.98844 --> 0.98806).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 269 Train Avg loss: 0.02160, Acc: 0.99114, F1: 0.99114#####> Valid Avg loss: 3.63365, Acc:0.36872, F1: 0.36872
===> Epoch: 269: Training loss decreased (0.02250 --> 0.02160), Acc: (0.98805 --> 0.99114), F1: (0.98806 --> 0.99114).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 270 Train Avg loss: 0.02306, Acc: 0.98613, F1: 0.98613#####> Valid Avg loss: 3.69347, Acc:0.36530, F1: 0.36530
====> Epoch: 271 Train Avg loss: 0.02103, Acc: 0.99114, F1: 0.99114#####> Valid Avg loss: 3.69105, Acc:0.36530, F1: 0.36530
===> Epoch: 271: Training loss decreased (0.02160 --> 0.02103), Acc: (0.99114 --> 0.99114), F1: (0.99114 --> 0.99114).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 272 Train Avg loss: 0.02167, Acc: 0.98728, F1: 0.98729#####> Valid Avg loss: 3.65953, Acc:0.35845, F1: 0.35845
====> Epoch: 273 Train Avg loss: 0.01985, Acc: 0.99037, F1: 0.99037#####> Valid Avg loss: 3.62066, Acc:0.35502, F1: 0.35502
===> Epoch: 273: Training loss decreased (0.02103 --> 0.01985), Acc: (0.99114 --> 0.99037), F1: (0.99114 --> 0.99037).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 274 Train Avg loss: 0.02017, Acc: 0.99152, F1: 0.99153#####> Valid Avg loss: 3.66321, Acc:0.35274, F1: 0.35274
====> Epoch: 275 Train Avg loss: 0.02062, Acc: 0.98998, F1: 0.98998#####> Valid Avg loss: 3.54750, Acc:0.36416, F1: 0.36416
====> Epoch: 276 Train Avg loss: 0.02056, Acc: 0.99037, F1: 0.99037#####> Valid Avg loss: 3.70257, Acc:0.35845, F1: 0.35845
====> Epoch: 277 Train Avg loss: 0.02000, Acc: 0.99114, F1: 0.99114#####> Valid Avg loss: 3.64428, Acc:0.36530, F1: 0.36530
====> Epoch: 278 Train Avg loss: 0.01986, Acc: 0.99075, F1: 0.99076#####> Valid Avg loss: 3.76147, Acc:0.36644, F1: 0.36644
====> Epoch: 279 Train Avg loss: 0.01922, Acc: 0.99075, F1: 0.99076#####> Valid Avg loss: 3.74222, Acc:0.35845, F1: 0.35845
===> Epoch: 279: Training loss decreased (0.01985 --> 0.01922), Acc: (0.99037 --> 0.99075), F1: (0.99037 --> 0.99076).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 280 Train Avg loss: 0.02039, Acc: 0.98844, F1: 0.98844#####> Valid Avg loss: 3.66816, Acc:0.35845, F1: 0.35845
====> Epoch: 281 Train Avg loss: 0.01991, Acc: 0.98960, F1: 0.98960#####> Valid Avg loss: 3.70457, Acc:0.36187, F1: 0.36187
====> Epoch: 282 Train Avg loss: 0.01830, Acc: 0.99114, F1: 0.99114#####> Valid Avg loss: 3.65715, Acc:0.36644, F1: 0.36644
===> Epoch: 282: Training loss decreased (0.01922 --> 0.01830), Acc: (0.99075 --> 0.99114), F1: (0.99076 --> 0.99114).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 283 Train Avg loss: 0.01930, Acc: 0.98998, F1: 0.98998#####> Valid Avg loss: 3.70551, Acc:0.36073, F1: 0.36073
====> Epoch: 284 Train Avg loss: 0.01759, Acc: 0.99191, F1: 0.99191#####> Valid Avg loss: 3.72971, Acc:0.36530, F1: 0.36530
===> Epoch: 284: Training loss decreased (0.01830 --> 0.01759), Acc: (0.99114 --> 0.99191), F1: (0.99114 --> 0.99191).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_1
====> Epoch: 285 Train Avg loss: 0.01900, Acc: 0.98921, F1: 0.98921#####> Valid Avg loss: 3.67601, Acc:0.36416, F1: 0.36416
====> Epoch: 286 Train Avg loss: 0.01808, Acc: 0.99191, F1: 0.99191#####> Valid Avg loss: 3.92379, Acc:0.37215, F1: 0.37215
====> Epoch: 287 Train Avg loss: 0.01864, Acc: 0.99075, F1: 0.99076#####> Valid Avg loss: 3.71672, Acc:0.37100, F1: 0.37100
====> Epoch: 288 Train Avg loss: 0.01769, Acc: 0.99268, F1: 0.99268#####> Valid Avg loss: 3.74138, Acc:0.36986, F1: 0.36986
====> Epoch: 289 Train Avg loss: 0.01930, Acc: 0.99037, F1: 0.99037#####> Valid Avg loss: 3.79912, Acc:0.36986, F1: 0.36986
====> Epoch: 290 Train Avg loss: 0.01789, Acc: 0.99268, F1: 0.99268#####> Valid Avg loss: 3.79051, Acc:0.36758, F1: 0.36758
====> Epoch: 291 Train Avg loss: 0.01911, Acc: 0.99152, F1: 0.99153#####> Valid Avg loss: 3.82607, Acc:0.36644, F1: 0.36644
====> Epoch: 292 Train Avg loss: 0.01820, Acc: 0.99152, F1: 0.99153#####> Valid Avg loss: 3.77402, Acc:0.36530, F1: 0.36530
====> Epoch: 293 Train Avg loss: 0.01932, Acc: 0.99152, F1: 0.99153#####> Valid Avg loss: 3.68611, Acc:0.36416, F1: 0.36416
====> Epoch: 294 Train Avg loss: 0.01796, Acc: 0.99268, F1: 0.99268#####> Valid Avg loss: 3.77195, Acc:0.36644, F1: 0.36644
====> Epoch: 295 Train Avg loss: 0.01810, Acc: 0.99152, F1: 0.99153#####> Valid Avg loss: 3.78710, Acc:0.36986, F1: 0.36986
====> Epoch: 296 Train Avg loss: 0.01928, Acc: 0.99152, F1: 0.99153#####> Valid Avg loss: 3.78953, Acc:0.36986, F1: 0.36986
====> Epoch: 297 Train Avg loss: 0.02000, Acc: 0.99075, F1: 0.99076#####> Valid Avg loss: 3.75463, Acc:0.36986, F1: 0.36986
====> Epoch: 298 Train Avg loss: 0.01761, Acc: 0.99075, F1: 0.99076#####> Valid Avg loss: 3.69555, Acc:0.36872, F1: 0.36872
====> Epoch: 299 Train Avg loss: 0.01799, Acc: 0.99229, F1: 0.99230#####> Valid Avg loss: 3.69903, Acc:0.36986, F1: 0.36986
====> Epoch: 300 Train Avg loss: 1.36692, Acc: 0.56224, F1: 0.56202#####> Valid Avg loss: 1.70599, Acc:0.43265, F1: 0.43265
====> Epoch: 301 Train Avg loss: 0.89952, Acc: 0.53025, F1: 0.53043#####> Valid Avg loss: 0.80778, Acc:0.46347, F1: 0.46347
====> Epoch: 302 Train Avg loss: 0.65147, Acc: 0.58073, F1: 0.58089#####> Valid Avg loss: 0.83372, Acc:0.46689, F1: 0.46689
====> Epoch: 303 Train Avg loss: 0.59795, Acc: 0.59769, F1: 0.59784#####> Valid Avg loss: 0.79611, Acc:0.47603, F1: 0.47603
====> Epoch: 304 Train Avg loss: 0.57844, Acc: 0.60771, F1: 0.60786#####> Valid Avg loss: 0.79685, Acc:0.45205, F1: 0.45205
====> Epoch: 305 Train Avg loss: 0.55442, Acc: 0.60809, F1: 0.60824#####> Valid Avg loss: 0.84142, Acc:0.41324, F1: 0.41324
====> Epoch: 306 Train Avg loss: 0.54543, Acc: 0.61426, F1: 0.61402#####> Valid Avg loss: 0.80876, Acc:0.45205, F1: 0.45205
====> Epoch: 307 Train Avg loss: 0.54181, Acc: 0.62389, F1: 0.62365#####> Valid Avg loss: 0.93646, Acc:0.41324, F1: 0.41324
====> Epoch: 308 Train Avg loss: 0.53084, Acc: 0.63699, F1: 0.63675#####> Valid Avg loss: 0.87926, Acc:0.42922, F1: 0.42922
====> Epoch: 309 Train Avg loss: 0.53678, Acc: 0.61850, F1: 0.61864#####> Valid Avg loss: 0.82339, Acc:0.45548, F1: 0.45548
====> Epoch: 310 Train Avg loss: 0.52134, Acc: 0.63237, F1: 0.63213#####> Valid Avg loss: 0.88142, Acc:0.38242, F1: 0.38242
====> Epoch: 311 Train Avg loss: 0.52309, Acc: 0.63353, F1: 0.63328#####> Valid Avg loss: 0.86513, Acc:0.41438, F1: 0.41438
====> Epoch: 312 Train Avg loss: 0.50839, Acc: 0.64162, F1: 0.64176#####> Valid Avg loss: 0.85224, Acc:0.43493, F1: 0.43493
====> Epoch: 313 Train Avg loss: 0.51436, Acc: 0.63661, F1: 0.63636#####> Valid Avg loss: 0.86291, Acc:0.43836, F1: 0.43836
====> Epoch: 314 Train Avg loss: 0.51447, Acc: 0.63391, F1: 0.63405#####> Valid Avg loss: 1.06616, Acc:0.28082, F1: 0.28082
====> Epoch: 315 Train Avg loss: 0.49947, Acc: 0.63430, F1: 0.63444#####> Valid Avg loss: 0.84234, Acc:0.44635, F1: 0.44635
====> Epoch: 316 Train Avg loss: 0.50137, Acc: 0.64355, F1: 0.64368#####> Valid Avg loss: 0.95760, Acc:0.35388, F1: 0.35388
====> Epoch: 317 Train Avg loss: 0.49508, Acc: 0.64778, F1: 0.64792#####> Valid Avg loss: 0.91844, Acc:0.41210, F1: 0.41210
====> Epoch: 318 Train Avg loss: 0.50723, Acc: 0.63121, F1: 0.63097#####> Valid Avg loss: 1.01018, Acc:0.39384, F1: 0.39384
====> Epoch: 319 Train Avg loss: 0.50658, Acc: 0.63699, F1: 0.63675#####> Valid Avg loss: 1.01854, Acc:0.25114, F1: 0.25114
====> Epoch: 320 Train Avg loss: 0.49890, Acc: 0.64740, F1: 0.64753#####> Valid Avg loss: 0.87008, Acc:0.41667, F1: 0.41667
====> Epoch: 321 Train Avg loss: 0.49277, Acc: 0.64162, F1: 0.64176#####> Valid Avg loss: 0.86881, Acc:0.40525, F1: 0.40525
====> Epoch: 322 Train Avg loss: 0.48659, Acc: 0.65549, F1: 0.65562#####> Valid Avg loss: 0.94930, Acc:0.34247, F1: 0.34247
====> Epoch: 323 Train Avg loss: 0.48400, Acc: 0.65202, F1: 0.65216#####> Valid Avg loss: 1.03187, Acc:0.34247, F1: 0.34247
====> Epoch: 324 Train Avg loss: 0.49181, Acc: 0.63661, F1: 0.63636#####> Valid Avg loss: 0.91122, Acc:0.40183, F1: 0.40183
====> Epoch: 325 Train Avg loss: 0.47156, Acc: 0.65549, F1: 0.65524#####> Valid Avg loss: 0.91074, Acc:0.43379, F1: 0.43379
====> Epoch: 326 Train Avg loss: 0.47906, Acc: 0.64663, F1: 0.64676#####> Valid Avg loss: 0.92746, Acc:0.40411, F1: 0.40411
====> Epoch: 327 Train Avg loss: 0.48320, Acc: 0.64586, F1: 0.64599#####> Valid Avg loss: 0.85571, Acc:0.44977, F1: 0.44977
====> Epoch: 328 Train Avg loss: 0.46886, Acc: 0.66474, F1: 0.66487#####> Valid Avg loss: 0.90756, Acc:0.37100, F1: 0.37100
====> Epoch: 329 Train Avg loss: 0.46701, Acc: 0.65356, F1: 0.65370#####> Valid Avg loss: 0.88421, Acc:0.42352, F1: 0.42352
====> Epoch: 330 Train Avg loss: 0.47884, Acc: 0.65549, F1: 0.65562#####> Valid Avg loss: 0.97027, Acc:0.35160, F1: 0.35160
====> Epoch: 331 Train Avg loss: 0.45351, Acc: 0.66936, F1: 0.66949#####> Valid Avg loss: 0.85724, Acc:0.44292, F1: 0.44292
====> Epoch: 332 Train Avg loss: 0.46937, Acc: 0.66551, F1: 0.66525#####> Valid Avg loss: 0.91414, Acc:0.38356, F1: 0.38356
====> Epoch: 333 Train Avg loss: 0.47859, Acc: 0.65241, F1: 0.65254#####> Valid Avg loss: 0.85610, Acc:0.39954, F1: 0.39954
====> Epoch: 334 Train Avg loss: 0.46480, Acc: 0.65395, F1: 0.65408#####> Valid Avg loss: 0.84940, Acc:0.43721, F1: 0.43721
====> Epoch: 335 Train Avg loss: 0.45128, Acc: 0.67322, F1: 0.67334#####> Valid Avg loss: 0.86682, Acc:0.44521, F1: 0.44521
====> Epoch: 336 Train Avg loss: 0.46975, Acc: 0.65356, F1: 0.65370#####> Valid Avg loss: 0.90963, Acc:0.43836, F1: 0.43836
====> Epoch: 337 Train Avg loss: 0.45974, Acc: 0.66397, F1: 0.66371#####> Valid Avg loss: 1.07466, Acc:0.35731, F1: 0.35731
====> Epoch: 338 Train Avg loss: 0.47294, Acc: 0.64855, F1: 0.64869#####> Valid Avg loss: 1.02819, Acc:0.33562, F1: 0.33562
====> Epoch: 339 Train Avg loss: 0.46307, Acc: 0.66127, F1: 0.66140#####> Valid Avg loss: 1.00506, Acc:0.41210, F1: 0.41210
====> Epoch: 340 Train Avg loss: 0.45233, Acc: 0.66936, F1: 0.66949#####> Valid Avg loss: 1.01290, Acc:0.38584, F1: 0.38584
====> Epoch: 341 Train Avg loss: 0.45431, Acc: 0.66127, F1: 0.66140#####> Valid Avg loss: 0.90854, Acc:0.40068, F1: 0.40068
====> Epoch: 342 Train Avg loss: 0.47330, Acc: 0.66127, F1: 0.66102#####> Valid Avg loss: 0.91680, Acc:0.43836, F1: 0.43836
====> Epoch: 343 Train Avg loss: 0.44986, Acc: 0.66012, F1: 0.66025#####> Valid Avg loss: 0.91095, Acc:0.41438, F1: 0.41438
====> Epoch: 344 Train Avg loss: 0.45783, Acc: 0.66667, F1: 0.66641#####> Valid Avg loss: 0.91764, Acc:0.45662, F1: 0.45662
====> Epoch: 345 Train Avg loss: 0.44624, Acc: 0.66513, F1: 0.66525#####> Valid Avg loss: 0.87221, Acc:0.44977, F1: 0.44977
====> Epoch: 346 Train Avg loss: 0.45460, Acc: 0.68092, F1: 0.68105#####> Valid Avg loss: 0.91510, Acc:0.38699, F1: 0.38699
====> Epoch: 347 Train Avg loss: 0.44426, Acc: 0.67938, F1: 0.67912#####> Valid Avg loss: 1.01488, Acc:0.40753, F1: 0.40753
====> Epoch: 348 Train Avg loss: 0.43830, Acc: 0.67322, F1: 0.67296#####> Valid Avg loss: 0.97799, Acc:0.39612, F1: 0.39612
====> Epoch: 349 Train Avg loss: 0.46092, Acc: 0.66243, F1: 0.66256#####> Valid Avg loss: 0.90126, Acc:0.45320, F1: 0.45320
====> Epoch: 350 Train Avg loss: 0.42680, Acc: 0.68555, F1: 0.68567#####> Valid Avg loss: 0.91183, Acc:0.48516, F1: 0.48516
====> Epoch: 351 Train Avg loss: 0.44779, Acc: 0.65626, F1: 0.65639#####> Valid Avg loss: 0.87491, Acc:0.44521, F1: 0.44521
====> Epoch: 352 Train Avg loss: 0.44568, Acc: 0.67129, F1: 0.67103#####> Valid Avg loss: 1.04060, Acc:0.37671, F1: 0.37671
====> Epoch: 353 Train Avg loss: 0.43135, Acc: 0.67592, F1: 0.67565#####> Valid Avg loss: 0.95324, Acc:0.41210, F1: 0.41210
====> Epoch: 354 Train Avg loss: 0.42111, Acc: 0.68324, F1: 0.68336#####> Valid Avg loss: 1.05298, Acc:0.38813, F1: 0.38813
====> Epoch: 355 Train Avg loss: 0.41885, Acc: 0.67977, F1: 0.67989#####> Valid Avg loss: 1.11379, Acc:0.35616, F1: 0.35616
====> Epoch: 356 Train Avg loss: 0.41457, Acc: 0.68170, F1: 0.68143#####> Valid Avg loss: 1.05022, Acc:0.41895, F1: 0.41895
====> Epoch: 357 Train Avg loss: 0.43001, Acc: 0.68940, F1: 0.68952#####> Valid Avg loss: 1.00961, Acc:0.36530, F1: 0.36530
====> Epoch: 358 Train Avg loss: 0.42936, Acc: 0.68439, F1: 0.68451#####> Valid Avg loss: 1.14739, Acc:0.37443, F1: 0.37443
====> Epoch: 359 Train Avg loss: 0.40808, Acc: 0.69017, F1: 0.69029#####> Valid Avg loss: 1.02263, Acc:0.40753, F1: 0.40753
====> Epoch: 360 Train Avg loss: 0.39255, Acc: 0.70328, F1: 0.70339#####> Valid Avg loss: 1.05456, Acc:0.39041, F1: 0.39041
====> Epoch: 361 Train Avg loss: 0.39851, Acc: 0.69441, F1: 0.69414#####> Valid Avg loss: 1.09291, Acc:0.33904, F1: 0.33904
====> Epoch: 362 Train Avg loss: 0.41965, Acc: 0.69480, F1: 0.69492#####> Valid Avg loss: 0.94139, Acc:0.45548, F1: 0.45548
====> Epoch: 363 Train Avg loss: 0.40268, Acc: 0.68632, F1: 0.68644#####> Valid Avg loss: 0.99662, Acc:0.41781, F1: 0.41781
====> Epoch: 364 Train Avg loss: 0.41759, Acc: 0.68863, F1: 0.68875#####> Valid Avg loss: 1.05875, Acc:0.38927, F1: 0.38927
====> Epoch: 365 Train Avg loss: 0.40405, Acc: 0.69480, F1: 0.69453#####> Valid Avg loss: 0.94925, Acc:0.41895, F1: 0.41895
====> Epoch: 366 Train Avg loss: 0.39517, Acc: 0.70019, F1: 0.70031#####> Valid Avg loss: 1.14265, Acc:0.36758, F1: 0.36758
====> Epoch: 367 Train Avg loss: 0.38929, Acc: 0.69865, F1: 0.69877#####> Valid Avg loss: 1.07703, Acc:0.36872, F1: 0.36872
====> Epoch: 368 Train Avg loss: 0.39452, Acc: 0.69480, F1: 0.69492#####> Valid Avg loss: 1.06775, Acc:0.39726, F1: 0.39726
====> Epoch: 369 Train Avg loss: 0.39123, Acc: 0.70250, F1: 0.70262#####> Valid Avg loss: 0.95053, Acc:0.46233, F1: 0.46233
====> Epoch: 370 Train Avg loss: 0.39512, Acc: 0.69326, F1: 0.69337#####> Valid Avg loss: 1.07361, Acc:0.41438, F1: 0.41438
====> Epoch: 371 Train Avg loss: 0.39006, Acc: 0.70482, F1: 0.70493#####> Valid Avg loss: 1.07180, Acc:0.39612, F1: 0.39612
====> Epoch: 372 Train Avg loss: 0.38361, Acc: 0.70559, F1: 0.70570#####> Valid Avg loss: 1.05000, Acc:0.39498, F1: 0.39498
====> Epoch: 373 Train Avg loss: 0.36963, Acc: 0.71985, F1: 0.71995#####> Valid Avg loss: 1.00103, Acc:0.43379, F1: 0.43379
====> Epoch: 374 Train Avg loss: 0.35704, Acc: 0.72293, F1: 0.72304#####> Valid Avg loss: 1.07317, Acc:0.39726, F1: 0.39726
====> Epoch: 375 Train Avg loss: 0.36006, Acc: 0.72755, F1: 0.72766#####> Valid Avg loss: 1.09183, Acc:0.39384, F1: 0.39384
====> Epoch: 376 Train Avg loss: 0.38296, Acc: 0.70636, F1: 0.70647#####> Valid Avg loss: 1.06560, Acc:0.40297, F1: 0.40297
====> Epoch: 377 Train Avg loss: 0.35483, Acc: 0.72062, F1: 0.72072#####> Valid Avg loss: 1.27928, Acc:0.33676, F1: 0.33676
====> Epoch: 378 Train Avg loss: 0.36351, Acc: 0.73256, F1: 0.73228#####> Valid Avg loss: 1.13182, Acc:0.37785, F1: 0.37785
====> Epoch: 379 Train Avg loss: 0.36145, Acc: 0.71792, F1: 0.71803#####> Valid Avg loss: 1.11223, Acc:0.38813, F1: 0.38813
====> Epoch: 380 Train Avg loss: 0.36387, Acc: 0.70751, F1: 0.70763#####> Valid Avg loss: 1.12077, Acc:0.38356, F1: 0.38356
====> Epoch: 381 Train Avg loss: 0.35571, Acc: 0.72948, F1: 0.72958#####> Valid Avg loss: 1.06384, Acc:0.43037, F1: 0.43037
====> Epoch: 382 Train Avg loss: 0.35235, Acc: 0.73295, F1: 0.73305#####> Valid Avg loss: 1.11401, Acc:0.42580, F1: 0.42580
====> Epoch: 383 Train Avg loss: 0.35904, Acc: 0.72486, F1: 0.72496#####> Valid Avg loss: 1.28018, Acc:0.38356, F1: 0.38356
====> Epoch: 384 Train Avg loss: 0.35107, Acc: 0.73295, F1: 0.73305#####> Valid Avg loss: 1.06944, Acc:0.41438, F1: 0.41438
====> Epoch: 385 Train Avg loss: 0.34769, Acc: 0.73642, F1: 0.73652#####> Valid Avg loss: 1.20638, Acc:0.40183, F1: 0.40183
====> Epoch: 386 Train Avg loss: 0.34420, Acc: 0.73372, F1: 0.73382#####> Valid Avg loss: 1.18862, Acc:0.36872, F1: 0.36872
====> Epoch: 387 Train Avg loss: 0.35209, Acc: 0.72370, F1: 0.72381#####> Valid Avg loss: 1.22284, Acc:0.36416, F1: 0.36416
====> Epoch: 388 Train Avg loss: 0.33457, Acc: 0.74451, F1: 0.74461#####> Valid Avg loss: 1.21803, Acc:0.40982, F1: 0.40982
====> Epoch: 389 Train Avg loss: 0.34957, Acc: 0.73102, F1: 0.73112#####> Valid Avg loss: 1.20440, Acc:0.40068, F1: 0.40068
====> Epoch: 390 Train Avg loss: 0.34661, Acc: 0.73796, F1: 0.73806#####> Valid Avg loss: 1.07458, Acc:0.41324, F1: 0.41324
====> Epoch: 391 Train Avg loss: 0.34845, Acc: 0.73333, F1: 0.73344#####> Valid Avg loss: 1.14018, Acc:0.39498, F1: 0.39498
====> Epoch: 392 Train Avg loss: 0.34484, Acc: 0.74374, F1: 0.74384#####> Valid Avg loss: 1.23642, Acc:0.39155, F1: 0.39155
====> Epoch: 393 Train Avg loss: 0.32316, Acc: 0.75337, F1: 0.75347#####> Valid Avg loss: 1.43806, Acc:0.36416, F1: 0.36416
====> Epoch: 394 Train Avg loss: 0.32586, Acc: 0.74682, F1: 0.74692#####> Valid Avg loss: 1.22488, Acc:0.36301, F1: 0.36301
====> Epoch: 395 Train Avg loss: 0.30969, Acc: 0.76802, F1: 0.76810#####> Valid Avg loss: 1.23583, Acc:0.41667, F1: 0.41667
====> Epoch: 396 Train Avg loss: 0.32596, Acc: 0.74875, F1: 0.74884#####> Valid Avg loss: 1.30242, Acc:0.38014, F1: 0.38014
====> Epoch: 397 Train Avg loss: 0.31525, Acc: 0.75915, F1: 0.75924#####> Valid Avg loss: 1.54440, Acc:0.39612, F1: 0.39612
====> Epoch: 398 Train Avg loss: 0.31408, Acc: 0.76031, F1: 0.76040#####> Valid Avg loss: 1.31475, Acc:0.40982, F1: 0.40982
====> Epoch: 399 Train Avg loss: 0.30316, Acc: 0.76378, F1: 0.76387#####> Valid Avg loss: 1.44224, Acc:0.37785, F1: 0.37785
====> Epoch: 400 Train Avg loss: 0.30658, Acc: 0.76262, F1: 0.76271#####> Valid Avg loss: 1.33132, Acc:0.38128, F1: 0.38128
====> Epoch: 401 Train Avg loss: 0.30439, Acc: 0.76724, F1: 0.76733#####> Valid Avg loss: 1.54135, Acc:0.38356, F1: 0.38356
====> Epoch: 402 Train Avg loss: 0.29645, Acc: 0.76994, F1: 0.76965#####> Valid Avg loss: 1.34786, Acc:0.41667, F1: 0.41667
====> Epoch: 403 Train Avg loss: 0.29191, Acc: 0.77996, F1: 0.77966#####> Valid Avg loss: 1.48134, Acc:0.37557, F1: 0.37557
====> Epoch: 404 Train Avg loss: 0.30178, Acc: 0.77457, F1: 0.77427#####> Valid Avg loss: 1.38525, Acc:0.31507, F1: 0.31507
====> Epoch: 405 Train Avg loss: 0.27845, Acc: 0.79152, F1: 0.79160#####> Valid Avg loss: 1.37507, Acc:0.37671, F1: 0.37671
====> Epoch: 406 Train Avg loss: 0.29274, Acc: 0.76802, F1: 0.76810#####> Valid Avg loss: 1.40953, Acc:0.34932, F1: 0.34932
====> Epoch: 407 Train Avg loss: 0.29797, Acc: 0.76994, F1: 0.76965#####> Valid Avg loss: 1.41386, Acc:0.35388, F1: 0.35388
====> Epoch: 408 Train Avg loss: 0.29393, Acc: 0.77303, F1: 0.77273#####> Valid Avg loss: 1.38335, Acc:0.39269, F1: 0.39269
====> Epoch: 409 Train Avg loss: 0.27956, Acc: 0.77881, F1: 0.77889#####> Valid Avg loss: 1.36330, Acc:0.38813, F1: 0.38813
====> Epoch: 410 Train Avg loss: 0.28000, Acc: 0.78497, F1: 0.78505#####> Valid Avg loss: 1.44154, Acc:0.37215, F1: 0.37215
====> Epoch: 411 Train Avg loss: 0.27773, Acc: 0.78998, F1: 0.79006#####> Valid Avg loss: 1.33626, Acc:0.40183, F1: 0.40183
====> Epoch: 412 Train Avg loss: 0.27410, Acc: 0.78189, F1: 0.78197#####> Valid Avg loss: 1.65342, Acc:0.32534, F1: 0.32534
====> Epoch: 413 Train Avg loss: 0.26827, Acc: 0.79538, F1: 0.79545#####> Valid Avg loss: 1.49415, Acc:0.38470, F1: 0.38470
====> Epoch: 414 Train Avg loss: 0.27857, Acc: 0.78459, F1: 0.78428#####> Valid Avg loss: 1.40761, Acc:0.38242, F1: 0.38242
====> Epoch: 415 Train Avg loss: 0.25997, Acc: 0.79306, F1: 0.79314#####> Valid Avg loss: 1.54131, Acc:0.39041, F1: 0.39041
====> Epoch: 416 Train Avg loss: 0.24617, Acc: 0.81156, F1: 0.81163#####> Valid Avg loss: 1.62181, Acc:0.40525, F1: 0.40525
====> Epoch: 417 Train Avg loss: 0.25326, Acc: 0.79807, F1: 0.79777#####> Valid Avg loss: 1.71836, Acc:0.32648, F1: 0.32648
====> Epoch: 418 Train Avg loss: 0.24040, Acc: 0.81426, F1: 0.81433#####> Valid Avg loss: 1.42844, Acc:0.39384, F1: 0.39384
====> Epoch: 419 Train Avg loss: 0.24402, Acc: 0.81541, F1: 0.81549#####> Valid Avg loss: 1.49351, Acc:0.39041, F1: 0.39041
====> Epoch: 420 Train Avg loss: 0.24810, Acc: 0.80963, F1: 0.80932#####> Valid Avg loss: 1.60368, Acc:0.25913, F1: 0.25913
====> Epoch: 421 Train Avg loss: 0.24470, Acc: 0.80617, F1: 0.80586#####> Valid Avg loss: 1.69838, Acc:0.35959, F1: 0.35959
====> Epoch: 422 Train Avg loss: 0.22208, Acc: 0.83237, F1: 0.83243#####> Valid Avg loss: 1.45102, Acc:0.44749, F1: 0.44749
====> Epoch: 423 Train Avg loss: 0.25331, Acc: 0.80886, F1: 0.80894#####> Valid Avg loss: 1.37818, Acc:0.42808, F1: 0.42808
====> Epoch: 424 Train Avg loss: 0.24031, Acc: 0.81927, F1: 0.81895#####> Valid Avg loss: 1.55283, Acc:0.42580, F1: 0.42580
====> Epoch: 425 Train Avg loss: 0.24921, Acc: 0.81850, F1: 0.81857#####> Valid Avg loss: 1.37642, Acc:0.39498, F1: 0.39498
====> Epoch: 426 Train Avg loss: 0.23977, Acc: 0.82119, F1: 0.82126#####> Valid Avg loss: 1.45679, Acc:0.39612, F1: 0.39612
====> Epoch: 427 Train Avg loss: 0.22431, Acc: 0.82967, F1: 0.82974#####> Valid Avg loss: 1.53159, Acc:0.41895, F1: 0.41895
====> Epoch: 428 Train Avg loss: 0.22644, Acc: 0.83044, F1: 0.83051#####> Valid Avg loss: 1.52379, Acc:0.37100, F1: 0.37100
====> Epoch: 429 Train Avg loss: 0.21759, Acc: 0.83160, F1: 0.83166#####> Valid Avg loss: 1.50164, Acc:0.41667, F1: 0.41667
====> Epoch: 430 Train Avg loss: 0.21926, Acc: 0.82813, F1: 0.82820#####> Valid Avg loss: 1.65105, Acc:0.41210, F1: 0.41210
====> Epoch: 431 Train Avg loss: 0.21151, Acc: 0.84701, F1: 0.84707#####> Valid Avg loss: 1.68588, Acc:0.33562, F1: 0.33562
====> Epoch: 432 Train Avg loss: 0.22642, Acc: 0.82852, F1: 0.82858#####> Valid Avg loss: 1.64351, Acc:0.42466, F1: 0.42466
====> Epoch: 433 Train Avg loss: 0.20890, Acc: 0.84085, F1: 0.84091#####> Valid Avg loss: 1.63645, Acc:0.40297, F1: 0.40297
====> Epoch: 434 Train Avg loss: 0.21237, Acc: 0.83892, F1: 0.83898#####> Valid Avg loss: 1.75813, Acc:0.35274, F1: 0.35274
====> Epoch: 435 Train Avg loss: 0.19520, Acc: 0.85202, F1: 0.85208#####> Valid Avg loss: 1.76338, Acc:0.39840, F1: 0.39840
====> Epoch: 436 Train Avg loss: 0.19511, Acc: 0.84817, F1: 0.84823#####> Valid Avg loss: 1.76846, Acc:0.36530, F1: 0.36530
====> Epoch: 437 Train Avg loss: 0.19503, Acc: 0.85087, F1: 0.85092#####> Valid Avg loss: 1.54515, Acc:0.40982, F1: 0.40982
====> Epoch: 438 Train Avg loss: 0.20922, Acc: 0.84316, F1: 0.84322#####> Valid Avg loss: 1.71673, Acc:0.36758, F1: 0.36758
====> Epoch: 439 Train Avg loss: 0.20520, Acc: 0.84933, F1: 0.84938#####> Valid Avg loss: 1.79776, Acc:0.37100, F1: 0.37100
====> Epoch: 440 Train Avg loss: 0.19793, Acc: 0.85318, F1: 0.85324#####> Valid Avg loss: 1.63060, Acc:0.40868, F1: 0.40868
====> Epoch: 441 Train Avg loss: 0.19289, Acc: 0.85318, F1: 0.85324#####> Valid Avg loss: 1.87756, Acc:0.40411, F1: 0.40411
====> Epoch: 442 Train Avg loss: 0.19103, Acc: 0.85626, F1: 0.85632#####> Valid Avg loss: 1.79467, Acc:0.38242, F1: 0.38242
====> Epoch: 443 Train Avg loss: 0.18226, Acc: 0.85973, F1: 0.85978#####> Valid Avg loss: 1.70816, Acc:0.40068, F1: 0.40068
====> Epoch: 444 Train Avg loss: 0.16742, Acc: 0.87977, F1: 0.87982#####> Valid Avg loss: 1.85854, Acc:0.40183, F1: 0.40183
====> Epoch: 445 Train Avg loss: 0.16683, Acc: 0.87707, F1: 0.87712#####> Valid Avg loss: 1.83059, Acc:0.41096, F1: 0.41096
====> Epoch: 446 Train Avg loss: 0.16881, Acc: 0.87052, F1: 0.87057#####> Valid Avg loss: 1.91876, Acc:0.41895, F1: 0.41895
====> Epoch: 447 Train Avg loss: 0.16578, Acc: 0.88478, F1: 0.88482#####> Valid Avg loss: 1.96371, Acc:0.35274, F1: 0.35274
====> Epoch: 448 Train Avg loss: 0.15882, Acc: 0.87669, F1: 0.87673#####> Valid Avg loss: 1.92395, Acc:0.38927, F1: 0.38927
====> Epoch: 449 Train Avg loss: 0.15935, Acc: 0.89017, F1: 0.89022#####> Valid Avg loss: 1.75322, Acc:0.39155, F1: 0.39155
====> Epoch: 450 Train Avg loss: 0.15389, Acc: 0.88324, F1: 0.88328#####> Valid Avg loss: 1.78501, Acc:0.37900, F1: 0.37900
====> Epoch: 451 Train Avg loss: 0.15185, Acc: 0.88632, F1: 0.88598#####> Valid Avg loss: 1.98558, Acc:0.35274, F1: 0.35274
====> Epoch: 452 Train Avg loss: 0.14764, Acc: 0.89133, F1: 0.89137#####> Valid Avg loss: 1.79313, Acc:0.40868, F1: 0.40868
====> Epoch: 453 Train Avg loss: 0.16401, Acc: 0.87592, F1: 0.87596#####> Valid Avg loss: 1.63981, Acc:0.38927, F1: 0.38927
====> Epoch: 454 Train Avg loss: 0.14450, Acc: 0.89364, F1: 0.89368#####> Valid Avg loss: 1.99099, Acc:0.37329, F1: 0.37329
====> Epoch: 455 Train Avg loss: 0.13715, Acc: 0.89788, F1: 0.89792#####> Valid Avg loss: 2.02175, Acc:0.40982, F1: 0.40982
====> Epoch: 456 Train Avg loss: 0.16897, Acc: 0.88478, F1: 0.88482#####> Valid Avg loss: 2.05266, Acc:0.35160, F1: 0.35160
====> Epoch: 457 Train Avg loss: 0.14280, Acc: 0.89672, F1: 0.89676#####> Valid Avg loss: 1.92349, Acc:0.41553, F1: 0.41553
====> Epoch: 458 Train Avg loss: 0.13969, Acc: 0.90559, F1: 0.90524#####> Valid Avg loss: 1.87741, Acc:0.38470, F1: 0.38470
====> Epoch: 459 Train Avg loss: 0.13510, Acc: 0.90058, F1: 0.90062#####> Valid Avg loss: 2.08443, Acc:0.41438, F1: 0.41438
====> Epoch: 460 Train Avg loss: 0.12638, Acc: 0.90482, F1: 0.90485#####> Valid Avg loss: 2.24565, Acc:0.36644, F1: 0.36644
====> Epoch: 461 Train Avg loss: 0.12867, Acc: 0.90751, F1: 0.90755#####> Valid Avg loss: 2.11969, Acc:0.39384, F1: 0.39384
====> Epoch: 462 Train Avg loss: 0.13523, Acc: 0.89865, F1: 0.89869#####> Valid Avg loss: 2.14589, Acc:0.38813, F1: 0.38813
====> Epoch: 463 Train Avg loss: 0.15111, Acc: 0.89249, F1: 0.89253#####> Valid Avg loss: 2.10208, Acc:0.39041, F1: 0.39041
====> Epoch: 464 Train Avg loss: 0.13372, Acc: 0.90366, F1: 0.90370#####> Valid Avg loss: 2.05280, Acc:0.39269, F1: 0.39269
====> Epoch: 465 Train Avg loss: 0.13414, Acc: 0.89942, F1: 0.89946#####> Valid Avg loss: 2.13059, Acc:0.36073, F1: 0.36073
====> Epoch: 466 Train Avg loss: 0.12003, Acc: 0.91252, F1: 0.91256#####> Valid Avg loss: 2.32642, Acc:0.40411, F1: 0.40411
====> Epoch: 467 Train Avg loss: 0.12845, Acc: 0.90867, F1: 0.90832#####> Valid Avg loss: 2.13866, Acc:0.37557, F1: 0.37557
====> Epoch: 468 Train Avg loss: 0.11181, Acc: 0.91715, F1: 0.91718#####> Valid Avg loss: 2.33550, Acc:0.39498, F1: 0.39498
====> Epoch: 469 Train Avg loss: 0.13642, Acc: 0.90520, F1: 0.90524#####> Valid Avg loss: 1.97969, Acc:0.42237, F1: 0.42237
====> Epoch: 470 Train Avg loss: 0.12884, Acc: 0.90366, F1: 0.90370#####> Valid Avg loss: 2.05360, Acc:0.42808, F1: 0.42808
====> Epoch: 471 Train Avg loss: 0.12193, Acc: 0.91329, F1: 0.91294#####> Valid Avg loss: 2.15614, Acc:0.40411, F1: 0.40411
====> Epoch: 472 Train Avg loss: 0.11968, Acc: 0.91753, F1: 0.91757#####> Valid Avg loss: 1.95002, Acc:0.40411, F1: 0.40411
====> Epoch: 473 Train Avg loss: 0.10124, Acc: 0.93141, F1: 0.93143#####> Valid Avg loss: 2.07339, Acc:0.37671, F1: 0.37671
====> Epoch: 474 Train Avg loss: 0.11238, Acc: 0.92216, F1: 0.92219#####> Valid Avg loss: 2.01379, Acc:0.41324, F1: 0.41324
====> Epoch: 475 Train Avg loss: 0.11131, Acc: 0.92254, F1: 0.92257#####> Valid Avg loss: 2.24955, Acc:0.38584, F1: 0.38584
====> Epoch: 476 Train Avg loss: 0.11643, Acc: 0.92447, F1: 0.92450#####> Valid Avg loss: 1.82218, Acc:0.37215, F1: 0.37215
====> Epoch: 477 Train Avg loss: 0.09925, Acc: 0.93025, F1: 0.93028#####> Valid Avg loss: 2.04545, Acc:0.39612, F1: 0.39612
====> Epoch: 478 Train Avg loss: 0.08500, Acc: 0.93950, F1: 0.93952#####> Valid Avg loss: 2.20124, Acc:0.40183, F1: 0.40183
====> Epoch: 479 Train Avg loss: 0.10143, Acc: 0.92987, F1: 0.92989#####> Valid Avg loss: 2.27021, Acc:0.40411, F1: 0.40411
====> Epoch: 480 Train Avg loss: 0.10247, Acc: 0.92909, F1: 0.92912#####> Valid Avg loss: 2.27770, Acc:0.37900, F1: 0.37900
====> Epoch: 481 Train Avg loss: 0.09455, Acc: 0.93873, F1: 0.93875#####> Valid Avg loss: 2.27046, Acc:0.35731, F1: 0.35731
====> Epoch: 482 Train Avg loss: 0.08401, Acc: 0.94181, F1: 0.94183#####> Valid Avg loss: 2.34414, Acc:0.39269, F1: 0.39269
====> Epoch: 483 Train Avg loss: 0.10720, Acc: 0.92794, F1: 0.92797#####> Valid Avg loss: 2.12416, Acc:0.36872, F1: 0.36872
====> Epoch: 484 Train Avg loss: 0.08944, Acc: 0.93449, F1: 0.93451#####> Valid Avg loss: 2.16292, Acc:0.41553, F1: 0.41553
====> Epoch: 485 Train Avg loss: 0.07803, Acc: 0.94412, F1: 0.94414#####> Valid Avg loss: 2.24792, Acc:0.39612, F1: 0.39612
====> Epoch: 486 Train Avg loss: 0.11619, Acc: 0.92447, F1: 0.92450#####> Valid Avg loss: 2.07070, Acc:0.38813, F1: 0.38813
====> Epoch: 487 Train Avg loss: 0.08110, Acc: 0.94412, F1: 0.94414#####> Valid Avg loss: 2.18298, Acc:0.39498, F1: 0.39498
====> Epoch: 488 Train Avg loss: 0.08781, Acc: 0.93950, F1: 0.93914#####> Valid Avg loss: 2.28985, Acc:0.38470, F1: 0.38470
====> Epoch: 489 Train Avg loss: 0.08001, Acc: 0.94220, F1: 0.94222#####> Valid Avg loss: 2.31988, Acc:0.40753, F1: 0.40753
====> Epoch: 490 Train Avg loss: 0.08264, Acc: 0.94258, F1: 0.94260#####> Valid Avg loss: 2.33523, Acc:0.40639, F1: 0.40639
====> Epoch: 491 Train Avg loss: 0.07495, Acc: 0.94836, F1: 0.94838#####> Valid Avg loss: 2.24505, Acc:0.41438, F1: 0.41438
====> Epoch: 492 Train Avg loss: 0.06581, Acc: 0.95645, F1: 0.95647#####> Valid Avg loss: 2.62931, Acc:0.39155, F1: 0.39155
====> Epoch: 493 Train Avg loss: 0.08697, Acc: 0.93565, F1: 0.93567#####> Valid Avg loss: 2.41834, Acc:0.40411, F1: 0.40411
====> Epoch: 494 Train Avg loss: 0.05691, Acc: 0.96301, F1: 0.96302#####> Valid Avg loss: 2.41276, Acc:0.38584, F1: 0.38584
====> Epoch: 495 Train Avg loss: 0.07425, Acc: 0.94566, F1: 0.94569#####> Valid Avg loss: 2.37761, Acc:0.40982, F1: 0.40982
====> Epoch: 496 Train Avg loss: 0.07472, Acc: 0.95106, F1: 0.95108#####> Valid Avg loss: 2.44727, Acc:0.41096, F1: 0.41096
====> Epoch: 497 Train Avg loss: 0.08259, Acc: 0.94952, F1: 0.94954#####> Valid Avg loss: 2.53455, Acc:0.36872, F1: 0.36872
====> Epoch: 498 Train Avg loss: 0.06203, Acc: 0.95800, F1: 0.95801#####> Valid Avg loss: 2.64232, Acc:0.34932, F1: 0.34932
====> Epoch: 499 Train Avg loss: 0.06488, Acc: 0.95299, F1: 0.95300#####> Valid Avg loss: 2.50601, Acc:0.37100, F1: 0.37100
====> Epoch: 500 Train Avg loss: 0.08521, Acc: 0.94374, F1: 0.94337#####> Valid Avg loss: 2.78638, Acc:0.32420, F1: 0.32420
#####> Valid Avg loss: 3.90798, Acc:0.30841, F1: 0.30841


$$$$$$> Test it 1: (from train best model) Final Test Avg loss:3.90798, Acc:0.30841, F1:0.30841\n
#####> Valid Avg loss: 0.78818, Acc:0.56542, F1: 0.56542


$$$$$$> Test it 1: (from max acc valid model) Final Test Avg loss:0.78818, Acc:0.56542, F1:0.56542\n
#####> Valid Avg loss: 0.74106, Acc:0.55841, F1: 0.55841


$$$$$$> Test it 1: (from min loss valid model) Final Test Avg loss:0.74106, Acc:0.55841, F1:0.55841\n


	Start execution training validation it 2 

train_dataloader len: 1298
valid_dataloader len: 214
test_dataloader len: 438
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [1]
test performers ids: [2]
train dataset len: 2595, train dataloader len: 1298
valid dataset len: 428, valid dataloader len: 214
valid dataset len: 876, test dataloader len: 214
====> Epoch: 1 Train Avg loss: 0.96003, Acc: 0.52023, F1: 0.52042#####> Valid Avg loss: 0.85210, Acc:0.56542, F1: 0.56542
===> Epoch: 1: Training loss decreased (inf --> 0.96003), Acc: (0.00000 --> 0.52023), F1: (0.00000 --> 0.52042).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2

####> Epoch: 1: validation loss decreased (inf --> 0.85210), Acc: (0.00000 --> 0.56542), F1: (0.00000 --> 0.56542).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2

####> Epoch: 1: validation acc increase (inf --> 0.85210), Acc: (0.00000 --> 0.56542), F1: (0.00000 --> 0.56542).  Saving model ...
Best valid model (acc) save to best_acc_metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 2 Train Avg loss: 0.90925, Acc: 0.53834, F1: 0.53814#####> Valid Avg loss: 0.87694, Acc:0.56308, F1: 0.56308
===> Epoch: 2: Training loss decreased (0.96003 --> 0.90925), Acc: (0.52023 --> 0.53834), F1: (0.52042 --> 0.53814).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 3 Train Avg loss: 0.88351, Acc: 0.55376, F1: 0.55393#####> Valid Avg loss: 0.94877, Acc:0.29673, F1: 0.29673
===> Epoch: 3: Training loss decreased (0.90925 --> 0.88351), Acc: (0.53834 --> 0.55376), F1: (0.53814 --> 0.55393).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 4 Train Avg loss: 0.80640, Acc: 0.54644, F1: 0.54622#####> Valid Avg loss: 0.74991, Acc:0.56542, F1: 0.56542
===> Epoch: 4: Training loss decreased (0.88351 --> 0.80640), Acc: (0.55376 --> 0.54644), F1: (0.55393 --> 0.54622).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2

####> Epoch: 4: validation loss decreased (0.85210 --> 0.74991), Acc: (0.56542 --> 0.56542), F1: (0.56542 --> 0.56542).  Saving model ...
Best valid model save to best_metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 5 Train Avg loss: 0.71703, Acc: 0.56416, F1: 0.56394#####> Valid Avg loss: 0.75148, Acc:0.55140, F1: 0.55140
===> Epoch: 5: Training loss decreased (0.80640 --> 0.71703), Acc: (0.54644 --> 0.56416), F1: (0.54622 --> 0.56394).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 6 Train Avg loss: 0.70678, Acc: 0.56840, F1: 0.56857#####> Valid Avg loss: 0.76814, Acc:0.56542, F1: 0.56542
===> Epoch: 6: Training loss decreased (0.71703 --> 0.70678), Acc: (0.56416 --> 0.56840), F1: (0.56394 --> 0.56857).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 7 Train Avg loss: 0.68928, Acc: 0.56570, F1: 0.56549#####> Valid Avg loss: 0.76309, Acc:0.55140, F1: 0.55140
===> Epoch: 7: Training loss decreased (0.70678 --> 0.68928), Acc: (0.56840 --> 0.56570), F1: (0.56857 --> 0.56549).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 8 Train Avg loss: 0.69164, Acc: 0.57110, F1: 0.57126#####> Valid Avg loss: 0.81363, Acc:0.46729, F1: 0.46729
====> Epoch: 9 Train Avg loss: 0.68510, Acc: 0.57380, F1: 0.57396#####> Valid Avg loss: 0.80548, Acc:0.55607, F1: 0.55607
===> Epoch: 9: Training loss decreased (0.68928 --> 0.68510), Acc: (0.56570 --> 0.57380), F1: (0.56549 --> 0.57396).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 10 Train Avg loss: 0.69331, Acc: 0.57071, F1: 0.57049#####> Valid Avg loss: 0.76163, Acc:0.56542, F1: 0.56542
====> Epoch: 11 Train Avg loss: 0.68071, Acc: 0.57572, F1: 0.57589#####> Valid Avg loss: 0.76587, Acc:0.56542, F1: 0.56542
===> Epoch: 11: Training loss decreased (0.68510 --> 0.68071), Acc: (0.57380 --> 0.57572), F1: (0.57396 --> 0.57589).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 12 Train Avg loss: 0.67742, Acc: 0.57919, F1: 0.57935#####> Valid Avg loss: 0.75383, Acc:0.56542, F1: 0.56542
===> Epoch: 12: Training loss decreased (0.68071 --> 0.67742), Acc: (0.57572 --> 0.57919), F1: (0.57589 --> 0.57935).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
====> Epoch: 13 Train Avg loss: 0.66770, Acc: 0.57572, F1: 0.57550#####> Valid Avg loss: 0.80728, Acc:0.45327, F1: 0.45327
===> Epoch: 13: Training loss decreased (0.67742 --> 0.66770), Acc: (0.57919 --> 0.57572), F1: (0.57935 --> 0.57550).  Saving model ...
model saved to metro_h2_pt_dp4_fe128_nma_re_1600225746.20922.pth_2
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/ann, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/ann_5_sec/fe_embed_cropped
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601271657.149055.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed_cropped
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601271936.19825.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed_cropped
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601272156.084234.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:False,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601272352.532684.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:150
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601272562.412212.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601273649.994868.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601273772.522114.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601273948.790006.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601274090.934339.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601274197.466768.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601274285.264004.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601274527.071064.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 0train person_ids: []validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601274598.439767.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601274758.530286.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601275120.873942.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601275250.888013.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601275521.699263.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601275742.552958.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601275894.21875.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601276351.536968.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601277110.533573.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601277357.618089.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601277581.695691.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601278168.81447.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601279709.382206.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601279949.09897.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601280158.588937.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601280495.551281.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601280595.083232.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601325402.406975.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
validation type: person, valid_person_index:0
window size: 4, window_stride: 5, seq_max_len:60
is_pretrained_fe:True,early_stop_patience: 200, cycle_length:100, cycle_mul: 2
image_width: 224, image_height: 224
kernel size: 3, lr:0.0003, epoch:500, batch_size:2
cnn_out_channel: 128, feature_embed_size:256
lstm_hidden_size: 256
lower_layer_dropout:0.4, upper_layer_dropout: 0.4
module_embedding_nhead:2
is_module_attention:True,mm_embedding_attention_type:concat
encoder_num_layers: 2, resume training:False
data_file_dir_base_path:/project/Driver_in_the_loop/all_data, modalities:['inside', 'gaze', 'pose']
embed_dir_base: /project/Driver_in_the_loop/all_data/fe_embed
modalities:['inside', 'gaze', 'pose']
executed_number_its: -1
log_filename: exe_metro_h2_pt_dp4_fe128_nma_re.log
model_checkpoint_prefix:metro_h2_pt_dp4_fe128_nma_re
model_checkpoint_filename:metro_h2_pt_dp4_fe128_nma_re_1601325969.179781.pth, resume_checkpoint_filename:None
log_model_archi: False
tb_log: True
tb_writer_name: tb_runs/metro_h2_pt_dp4_fe128_nma_re, wandb_log_name: metro_h2_pt_dp4_fe128_nma_re
pytorch version: 1.5.1
GPU Availability: cuda:0, no_gpus: 4
total_activities: 15train person_ids: [ 1  2  3  4  5  6  7  8  9 10 11 12 14 13 15 18 17 16 19 20 21]

	Start execution training validation it 1 

train_dataloader len: 3337
valid_dataloader len: 585
test_dataloader len: 587
train performers ids: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
valid performers ids: [2]
test performers ids: [1]
train dataset len: 6674, train dataloader len: 3337
valid dataset len: 1169, valid dataloader len: 585
valid dataset len: 1173, test dataloader len: 585
