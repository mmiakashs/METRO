diff --git a/execution_scripts/utd_mhad_mifu_pt.sh b/execution_scripts/utd_mhad_mifu_pt.sh
deleted file mode 100755
index fa5ee17..0000000
--- a/execution_scripts/utd_mhad_mifu_pt.sh
+++ /dev/null
@@ -1,24 +0,0 @@
-python3 ../metro_training.py \
--tvp 1 \
--lr 0.0003 \
--ng 1 \
--cdn 1 \
--sml 60 \
--bs 2 \
--ep 500 \
--enl 2 \
--fes 256 \
--lhs 256 \
--menh 2 \
--lld 0.3 \
--uld 0.3 \
--cout 64 \
--mmattn_type 'concat' \
--logbd 'log/utd_mhad_pt' \
--logf 'exe_utd_mifu_rdi_s_h122_dp3_ex2_re_vpi2_pt.log' \
--tbl \
--tb_wn 'tb_runs/tb_utd_mifu/rdi_s_h122_re_vpi2_pt' \
--mcp 'utd_mifu_rdi_s_h122_dp3_re_pt' \
--vpi 2 \
--ipf \
--wln 'utd_mifu_rdi_s_h122_re_vpi2_pt'
diff --git a/metro_training.py b/metro_training.py
index e9781ac..b100e08 100644
--- a/metro_training.py
+++ b/metro_training.py
@@ -29,36 +29,9 @@ if (debug_mode):
     sys.argv = [''];
     del sys
 
-modalities = [config.inside_modality_tag,
-              config.outside_modality_tag]
 checkpoint_attribs = ['train_loss', 'valid_loss', 'train_acc', 'valid_acc', 'epoch']
 
 
-def gen_mask(seq_len, max_len):
-    return torch.arange(max_len) > seq_len
-
-
-def pad_collate(batch):
-    batch_size = len(batch)
-    data = {}
-    for modality in modalities:
-        data[modality] = pad_sequence([batch[bin][modality] for bin in range(batch_size)], batch_first=True)
-        data[modality + config.modality_seq_len_tag] = torch.tensor(
-            [batch[bin][modality + config.modality_seq_len_tag] for bin in range(batch_size)],
-            dtype=torch.float)
-
-        seq_max_len = data[modality + config.modality_seq_len_tag].max()
-        seq_mask = torch.stack(
-            [gen_mask(seq_len, seq_max_len) for seq_len in data[modality + config.modality_seq_len_tag]],
-            dim=0)
-        data[modality + config.modality_mask_tag] = seq_mask
-
-    data['label'] = torch.tensor([batch[bin]['label'] for bin in range(batch_size)],
-                                 dtype=torch.long)
-    data['modality_mask'] = torch.stack([batch[bin]['modality_mask'] for bin in range(batch_size)], dim=0).bool()
-    return data
-
-
 parser = argparse.ArgumentParser()
 parser.add_argument("-ng", "--no_gpus", help="number of gpus",
                     type=int, default=1)
@@ -122,6 +95,8 @@ parser.add_argument("-mcf", "--model_checkpoint_filename", help="model checkpoin
 parser.add_argument("-rcf", "--resume_checkpoint_filename", help="resume checkpoint filename",
                     default=None)
 
+parser.add_argument("-mattn", "--is_module_attention", help="is_module_attention",
+                    action="store_true", default=False)
 parser.add_argument("-mmattn_type", "--mm_embedding_attn_merge_type",
                     help="mm_embedding_attn_merge_type [concat/sum]",
                     default='sum')
@@ -229,7 +204,7 @@ log_execution(log_base_dir, log_filename,
               f'lower_layer_dropout:{lower_layer_dropout}, upper_layer_dropout: {upper_layer_dropout}\n')
 log_execution(log_base_dir, log_filename, f'module_embedding_nhead:{module_embedding_nhead}\n')
 log_execution(log_base_dir, log_filename,
-              f'mm_embedding_attention_type:{mm_embedding_attn_merge_type}\n')
+              f'is_module_attention:{args.is_module_attention},mm_embedding_attention_type:{mm_embedding_attn_merge_type}\n')
 log_execution(log_base_dir, log_filename,
               f'encoder_num_layers: {lstm_encoder_num_layers}, '
               f'resume training:{resume_training}\n')
@@ -269,6 +244,7 @@ transforms_modalities[config.outside_modality_tag] = rgb_transforms
 
 mm_module_properties = defaultdict(dict)
 for modality in modalities:
+    mm_module_properties[modality]['cnn_in_channel'] = config.image_channels
     mm_module_properties[modality]['cnn_out_channel'] = cnn_out_channel
     mm_module_properties[modality]['kernel_size'] = kernel_size
     mm_module_properties[modality]['feature_embed_size'] = feature_embed_size
@@ -279,10 +255,11 @@ for modality in modalities:
     mm_module_properties[modality]['dropout'] = lower_layer_dropout
     mm_module_properties[modality]['activation'] = 'relu'
     mm_module_properties[modality]['fine_tune'] = True
-    mm_module_properties[modality]['feature_pooling_kernel'] = 3
-    mm_module_properties[modality]['feature_pooling_stride'] = 3
+    mm_module_properties[modality]['feature_pooling_kernel'] = None
+    mm_module_properties[modality]['feature_pooling_stride'] = None
     mm_module_properties[modality]['feature_pooling_type'] = 'max'
     mm_module_properties[modality]['lstm_dropout'] = 0.0
+    mm_module_properties[modality]['is_attention'] = args.is_module_attention
 
 Dataset = UVA_DAR_Dataset
 
@@ -297,7 +274,7 @@ mm_har_train = Dataset(data_dir_base_path=data_file_dir_base_path,
                        is_pretrained_fe=args.is_pretrained_fe)
 
 person_ids = mm_har_train.data.person_ID.unique()
-num_activity_types = mm_har_train.num_activity_types
+num_activity_types = mm_har_train.num_activities
 log_execution(log_base_dir, log_filename, f'total_activities: {num_activity_types}')
 log_execution(log_base_dir, log_filename, f'train person_ids: {person_ids}')
 mm_har_train = None
@@ -343,7 +320,7 @@ for train_ids, test_ids in loov.split(split_ids):
     restricted_ids.append(split_ids[train_ids[valid_person_index]])
     if (total_valid_persons == 2):
         restricted_ids.append(split_ids[train_ids[valid_person_index + 1]])
-    restricted_labels = 'performer_id'
+    restricted_labels = 'person_ID'
 
     mm_har_train = Dataset(data_dir_base_path=data_file_dir_base_path,
                            embed_dir_base_path=args.embed_dir_base_path,
@@ -371,7 +348,7 @@ for train_ids, test_ids in loov.split(split_ids):
                            embed_dir_base_path=args.embed_dir_base_path,
                            modalities=modalities,
                            allowed_ids=allowed_valid_ids,
-                           allowed_labels='performer_id',
+                           allowed_labels='person_ID',
                            seq_max_len=seq_max_len,
                            window_size=window_size,
                            window_stride=window_stride,
@@ -389,7 +366,7 @@ for train_ids, test_ids in loov.split(split_ids):
                           embed_dir_base_path=args.embed_dir_base_path,
                           modalities=modalities,
                           allowed_ids=allowed_test_id,
-                          allowed_labels='performer_id',
+                          allowed_labels='person_ID',
                           seq_max_len=seq_max_len,
                           window_size=window_size,
                           window_stride=window_stride,
@@ -409,11 +386,11 @@ for train_ids, test_ids in loov.split(split_ids):
     log_execution(log_base_dir, log_filename, f'valid_dataloader len: {len(valid_dataloader)}\n')
     log_execution(log_base_dir, log_filename, f'test_dataloader len: {len(test_dataloader)}\n')
     log_execution(log_base_dir, log_filename,
-                  f'train performers ids: {sorted(mm_har_train.data.performer_id.unique())}\n')
+                  f'train performers ids: {sorted(mm_har_train.data.person_ID.unique())}\n')
     log_execution(log_base_dir, log_filename,
-                  f'valid performers ids: {sorted(mm_har_valid.data.performer_id.unique())}\n')
+                  f'valid performers ids: {sorted(mm_har_valid.data.person_ID.unique())}\n')
     log_execution(log_base_dir, log_filename,
-                  f'test performers ids: {sorted(mm_har_test.data.performer_id.unique())}\n')
+                  f'test performers ids: {sorted(mm_har_test.data.person_ID.unique())}\n')
     log_execution(log_base_dir, log_filename,
                   f'train dataset len: {len(train_dataloader.dataset)}, train dataloader len: {len(train_dataloader)}\n')
     log_execution(log_base_dir, log_filename,
diff --git a/src/dataloaders/uva_dar_dataset.py b/src/dataloaders/uva_dar_dataset.py
index 4a3be4b..0769949 100644
--- a/src/dataloaders/uva_dar_dataset.py
+++ b/src/dataloaders/uva_dar_dataset.py
@@ -146,7 +146,7 @@ class UVA_DAR_Dataset(Dataset):
             filename = f'{self.data.loc[idx, modality][:-4]}.pt'
             activity = self.data.loc[idx, config.activity_tag]
             data_filepath = f'{self.embed_dir_base_path}/{activity}/{filename}'
-            seq = torch.load(data_filepath).detach()
+            seq = torch.load(data_filepath, map_location='cpu').detach()
             seq_len = seq.size(0)
         else:
             filename = self.data.loc[idx, modality]
diff --git a/src/network/UVA_METRO_Model.py b/src/network/UVA_METRO_Model.py
index d57822c..165b299 100644
--- a/src/network/UVA_METRO_Model.py
+++ b/src/network/UVA_METRO_Model.py
@@ -9,8 +9,6 @@ from ..utils import config
 class UVA_METRO_Model(nn.Module):
     def __init__(self, mm_module_properties,
                  modalities,
-                 num_joints,
-                 num_attribs,
                  num_activity_types,
                  window_size, window_stride,
                  modality_embedding_size,
@@ -25,8 +23,6 @@ class UVA_METRO_Model(nn.Module):
         self.mm_module_properties = mm_module_properties
         self.modalities = modalities
         self.num_modality = len(modalities)
-        self.num_joints = num_joints
-        self.num_attribs = num_attribs
         self.num_activity_types = num_activity_types
         self.batch_first = batch_first
 
@@ -66,6 +62,8 @@ class UVA_METRO_Model(nn.Module):
                                                       'feature_pooling_stride'],
                                                   pool_fe_type=self.mm_module_properties[modality][
                                                       'feature_pooling_type'],
+                                                  is_attention = self.mm_module_properties[modality][
+                                                      'is_attention'],
                                                   is_pretrained_fe = self.is_pretrained_fe)
 
             if (self.mm_module_properties[modality]['lstm_bidirectional']):
@@ -76,14 +74,6 @@ class UVA_METRO_Model(nn.Module):
 
         self.mm_embeddings_bn =nn.BatchNorm1d(self.num_modality)
 
-        self.mm_mhattn = nn.MultiheadAttention(embed_dim=self.modality_embedding_size,
-                                               num_heads=self.mm_final_fusion_mhattn_nhead,
-                                               dropout=self.dropout)
-
-        self.mm_mhattn_bn = nn.BatchNorm1d(self.total_fusing_modality_combo)
-        self.mm_mhattn_relu = nn.ReLU()
-        self.mm_mhattn_dropout = nn.Dropout(p=self.dropout)
-
         if (self.mm_embedding_attn_merge_type == 'sum'):
             if (self.lstm_bidirectional):
                 self.fc_output1 = nn.Linear(self.modality_embedding_size, self.modality_embedding_size // 2)
@@ -125,7 +115,7 @@ class UVA_METRO_Model(nn.Module):
         mm_module_output = {}
         for modality in self.modalities:
             tm_attn_output, self.module_attn_weights[modality] = self.mm_module[modality](input[modality],
-                                                                                          input[modality + config.modality_mask_tag],
+                                                                                          input[modality + config.modality_mask_suffix_tag],
                                                                                           input[modality + config.modality_seq_len_tag])
             mm_module_output[modality] = tm_attn_output
 
@@ -140,7 +130,7 @@ class UVA_METRO_Model(nn.Module):
         if(self.mm_embedding_attn_merge_type=='sum'):
             mattn_output = torch.sum(mm_embeddings, dim=1).squeeze(dim=1)
 
-        mattn_output = mattn_output.contiguous().view(nbatches, -1)
+        mattn_output = mm_embeddings.contiguous().view(nbatches, -1).contiguous()
 
         if (self.lstm_bidirectional):
             output = self.fc_output1(mattn_output)
diff --git a/src/utils/model_training_utlis_wtensorboard.py b/src/utils/model_training_utlis_wtensorboard.py
index 98505a8..dbdaf5b 100644
--- a/src/utils/model_training_utlis_wtensorboard.py
+++ b/src/utils/model_training_utlis_wtensorboard.py
@@ -48,68 +48,6 @@ def load_model(model=None,
 
     return model, optimizer, attrib_dict
 
-
-def test_model(model, optimizer, valid_dataloader,
-               loss_function, device,
-               modalities,
-               model_save_base_dir,
-               model_checkpoint_filename,
-               checkpoint_attribs, validation_iteration,
-               log_base_dir,
-               log_filename,
-               show_checkpoint_info=False,
-               is_ntu=False):
-    valid_loss = 0.0
-    valid_acc = 0.0
-    valid_corrects = 0.0
-    f1_scores = []
-    preds_all = np.zeros(0)
-    targets_all = np.zeros(0)
-
-    model, optimizer = load_model(model=model, optimizer=optimizer,
-                                  model_save_base_dir=model_save_base_dir,
-                                  model_checkpoint_filename=model_checkpoint_filename,
-                                  checkpoint_attribs=checkpoint_attribs, show_checkpoint_info=show_checkpoint_info)
-
-    with torch.no_grad():
-        for batch_idx, batch in enumerate(valid_dataloader):
-
-            mask_graph = dict()
-            for modality in modalities:
-                batch[modality] = batch[modality].to(device)
-                batch[modality + '_mask'] = batch[modality + '_mask'].to(device)
-                mask_graph[modality] = batch['modality_mask'].to(device)
-
-            if (is_ntu):
-                batch['indi_sk_mask'] = batch['indi_sk_mask'].to(device)
-
-            batch['modality_mask'] = batch['modality_mask'].to(device)
-            batch['modality_mask_graph'] = mask_graph
-            batch['label'] = batch['label'].to(device)
-            labels = batch['label']
-
-            outputs = model(batch)
-            _, preds = torch.max(outputs, 1)
-
-            valid_corrects += torch.sum(preds == labels.data)
-            f1_scores.append(f1_score(preds.cpu().data.numpy(), labels.cpu().data.numpy(), average='micro'))
-            preds_all = np.append(preds_all, preds.cpu().data.numpy())
-            targets_all = np.append(targets_all, labels.cpu().data.numpy())
-
-            loss = loss_function(outputs, labels)
-            valid_loss += loss.item()
-
-    valid_loss = valid_loss / len(valid_dataloader.dataset)
-    valid_acc = valid_corrects / len(valid_dataloader.dataset)
-    print('Valid it[{}] Avg loss: {:.5f}, Acc:{:.5f}, F1:{:.5f}'.format(validation_iteration, valid_loss, valid_acc,
-                                                                        statistics.mean(f1_scores)))
-    log_execution(log_base_dir, log_filename,
-                  '\n\n#####> Valid Avg loss: {:.5f}, Acc:{:.5f}, F1: {:.5f}\n\n'.format(valid_loss, valid_acc,
-                                                                                         statistics.mean(f1_scores)))
-
-    return valid_acc, statistics.mean(f1_scores), preds_all, targets_all
-
-
 def model_validation(model, optimizer, valid_dataloader,
                      loss_function, device,
                      modalities,
@@ -140,13 +78,13 @@ def model_validation(model, optimizer, valid_dataloader,
         for modality in modalities:
             batch[modality] = batch[modality].to(device)
             batch[modality + config.modality_seq_len_tag] = batch[modality + config.modality_seq_len_tag].to(device)
-            batch[modality + config.modality_mask_tag] = batch[modality + config.modality_mask_tag].to(device)
+            batch[modality + config.modality_mask_suffix_tag] = batch[modality + config.modality_mask_suffix_tag].to(device)
             mask_graph[modality] = batch['modality_mask'].to(device)
 
         batch['modality_mask'] = batch['modality_mask'].to(device)
         batch['modality_mask_graph'] = mask_graph
-        batch['label'] = batch['label'].to(device)
-        labels = batch['label']
+        batch[config.activity_tag] = batch[config.activity_tag].to(device)
+        labels = batch[config.activity_tag]
 
         outputs = model(batch)
         _, preds = torch.max(outputs, 1)
@@ -260,14 +198,14 @@ def train_model(model, optimizer, scheduler,
             for modality in modalities:
                 batch[modality] = batch[modality].to(device)
                 batch[modality + config.modality_seq_len_tag] = batch[modality + config.modality_seq_len_tag].to(device)
-                batch[modality + config.modality_mask_tag] = batch[modality + config.modality_mask_tag].to(device)
+                batch[modality + config.modality_mask_suffix_tag] = batch[modality + config.modality_mask_suffix_tag].to(device)
                 mask_graph[modality] = batch['modality_mask'].to(device)
 
             batch['modality_mask'] = batch['modality_mask'].to(device)
             batch['modality_mask_graph'] = mask_graph
-            batch['label'] = batch['label'].to(device)
-            labels = batch['label']
-            batch_size = batch['label'].size(0)
+            batch[config.activity_tag] = batch[config.activity_tag].to(device)
+            labels = batch[config.activity_tag]
+            batch_size = batch[config.activity_tag].size(0)
 
             outputs = model(batch)
             _, preds = torch.max(outputs, 1)
@@ -287,8 +225,8 @@ def train_model(model, optimizer, scheduler,
 
             if batch_idx % 10 == 0:
                 print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
-                    epoch, (batch_idx + 1) * batch_size, len(train_dataloader.dataset),
-                           100. * batch_idx / len(train_dataloader), loss.item() / len(batch)))
+                    epoch, (batch_idx + 1), len(train_dataloader),
+                           100. * batch_idx / len(train_dataloader), loss.item() / batch_size))
 
         train_loss = train_loss / len(train_dataloader.dataset)
         train_acc = train_corrects / len(train_dataloader.dataset)
@@ -437,8 +375,7 @@ def train_model(model, optimizer, scheduler,
                                                     is_load=True)
     wandb.log({'test_loss(train_best_model)': test_loss,
                'test_acc(train_best_model)': test_acc,
-               'test_f1(train_best_model)': test_f1,
-               'validation_iteration': validation_iteration}, step=validation_iteration)
+               'test_f1(train_best_model)': test_f1}, step=validation_iteration)
     if (tensorboard_writer):
         tensorboard_writer.add_scalar(config.tbw_test_loss + "_train_best_model", test_loss, validation_iteration)
         tensorboard_writer.add_scalar(config.tbw_test_acc + "_train_best_model", test_acc, validation_iteration)
@@ -464,8 +401,7 @@ def train_model(model, optimizer, scheduler,
                                                                                is_load=True)
     wandb.log({'test_loss(valid_best_acc_model)': test_loss_ba_model,
                'test_acc(valid_best_acc_model)': test_acc_ba_model,
-               'test_f1(valid_best_acc_model)': test_f1_ba_model,
-               'validation_iteration': validation_iteration}, step=validation_iteration)
+               'test_f1(valid_best_acc_model)': test_f1_ba_model}, step=validation_iteration)
 
     if (tensorboard_writer):
         tensorboard_writer.add_scalar(config.tbw_test_loss + "_ba_model", test_loss_ba_model, validation_iteration)
@@ -492,8 +428,7 @@ def train_model(model, optimizer, scheduler,
                                                     is_load=True)
     wandb.log({'test_loss(valid_best_loss_model)': test_loss,
                'test_acc(valid_best_loss_model)': test_acc,
-               'test_f1(valid_best_loss_model)': test_f1,
-               'validation_iteration': validation_iteration}, step=validation_iteration)
+               'test_f1(valid_best_loss_model)': test_f1}, step=validation_iteration)
 
     if (tensorboard_writer):
         tensorboard_writer.add_scalar(config.tbw_test_loss, test_loss, validation_iteration)
